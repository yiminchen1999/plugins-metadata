                       Diverse Settings for Learning and Teaching:
   Preservice Teachers Learning Pedagogy Online and On-the-Fly

                          Jody S. Underwood                                 Janet S. Bowers
              Educational Testing Service, Princeton, NJ             San Diego State University
                            609.734.1276                                     619.594.7241
                          junderwood@ets.org                         JBowers@math.sdsu.edu

         Abstract: In this article we assess the effectiveness of an Internet-based mathematics-mentoring
         program that was designed to enhance prospective teachers' ability to communicate with middle
         school students   about mathematics.  The mentoring   involved     reading  solutions that  students
         submitted  to the Math  Forum's online   Problem  of the Week,      and writing   feedback  to those
         students after first practicing mentoring techniques in an online discussion forum. This report
         reports the results of a study held in two courses: one in the fall of 2000 (n=19 mentors), and the
         other in the spring of 2001 (n=10 mentors). We use quantitative data to document improvement
         trends in mentoring quality, and qualitative data to examine the program's success from the
         perspective of the prospective teachers. The results indicate that many of the prospective teachers
         learned to guide students' problem solving with questions and hints and learned about the range
         and types of solution methods that students use to solve problems.

Introduction
         Reform efforts in the field of teacher preparation suggest that prospective teachers (PTs) gain valuable
insights into student thinking when they interact with students in meaningful ways. For example, after reviewing
over 40 studies of teacher professional growth, Kagan (1992) concluded that teacher preparation ought to provide
opportunities for interaction with students through practice that extends beyond the confines of the traditional
college classroom. However, PTs are generally required to take education and content courses that are devoid of any
interactions with real students (Hayes, 2001), and it is difficult for teacher educators working in colleges to arrange
opportunities for PTs to interact with young students in ways that overcome time and distance constraints.

         One source of the problem is that many PTs emphasize the importance of empathy in teaching, which they
consider to be more critical than cognitive variables such as academic proficiency (Pajares, 1992). Pajares also
reports that PTs view teaching as a process of transmitting knowledge and of dispensing information, rather than a
process by which teachers and students communicate about mathematical ideas in an effort to construct deep
mathematical  understandings.  These  beliefs are in stark contrast  to the   prevailing  view of the   importance  of
communication in mathematics teaching espoused by most reform movements in the field of mathematics education.
The most notable source of this contrasting view is The National Council of Teachers of Mathematics (NCTM) who
published the  Principles  and Standards for  School  Mathematics    (2000),  which    is widely accepted  by teacher
educators in the United States as a viable and worthy vision for mathematics teaching.

         To add to the mix, a large body of research reveals that it is difficult to change prospective teachers' beliefs
about how to teach mathematics (Ball, 1990; Cooney, Wilson, Albright, & Chauvot, 1998; Thompson, 1984). Many
prospective elementary teachers report disliking mathematics when they were children, and some report fears of
teaching the subject beyond about the third grade level. Therefore, suggesting that they include more written
explanations in their assignments and focus more deeply on students' views of mathematics is perceived as an
intimidating prospect.

         Kagan (1992) reported that very few programs have found successful ways to confront these views. In
many methods classes, PTs evaluate student work samples (e.g., Blanton & Kaput, 2002; Schorr, 2002; Franke,
Kazemi, Carpenter, Battey, & Deneroff, 2002) and learn a lot from the process, but it is not quite enough. One
program showed that when a group of preservice teachers were provided opportunities to interact with young
children early  in their education, they demonstrated    significant changes     in their  attitudes about  their own
mathematical thinking and about teaching compared to a control group (Philipp et al., submitted). Philipp et al.

                                                       545
concluded that when the PTs were focusing on the children's own ways of thinking, they realized that traditional
teaching limits children's propensity to come up with profoundly novel and rich mathematical thinking. Although
the success of this program is exciting, it would be difficult to implement on a large scale because it would be
difficult to find a sufficient number of students to work with PTs in an already demanding schedule.

       In response to the impediments  of arranging      authentic    experiences  between   PTs  and students,   some
researchers have designed multimedia-based "virtual experiences" that use technology to engage PTs in explorations
of students' mathematical thinking. For example, Lampert and Ball (1998) developed a large database of videos
filmed in two mathematics classrooms that they taught. These researchers found that when PTs are specifically
encouraged to focus on students' thinking as they viewed the videos, they engaged more readily in conversations
about the students' learning. This represented a significant shift from prior observations focusing exclusively on
"what the teacher should have done", or "the way that I was taught this material when I was in elementary school."

       Other efforts to provide "virtual experiences" for PTs have reported similar results. For example, Bowers
and Doerr (in press) in their study of one CD-ROM video report that PTs were able to put themselves in the role of
being a teacher by hearing the teacher in the video reflect on her practice and also predict what modifications she
would make in her lesson plan for the following day. These authors concluded that when PTs are specifically asked
to focus on the students' learning and the teacher's role in capitalizing on student answers, they come to appreciate
the teacher's role in enhancing student thinking through effective mathematical communication. However, the PTs
are still missing the authentic experiences where they are engaging in actual teaching with real children.

       In our study, we attempted to overcome the drawbacks mentioned above by providing a "virtually authentic
experience" for PTs to interact with middle and high school students by being "mentors" for the Math Forum @
Drexel's Problem of the Week. Our hypothesis was that if we could provide strong, consistent, personal feedback to
all mentors in addition to the authentic experience of working with students, they would develop an appreciation for,
and skill in, providing mathematical guidance to students via written communication. In this paper, we report on our
efforts to assess the degree to which the online mentoring experience supported this hypothesis.

Method
Activity Description
       The Math  Forum  @   Drexel (http://mathforum.org)         is an Internet portal of projects  and   resources for
mathematics and mathematics education. One of the most popular features of the website is called the "Problem of
the Week" (PoW), which at the time of our study contained six areas: upper elementary, middle school, algebra,
geometry, discrete math, and calculus/trigonometry. Each week a problem is posted in each area, and students from
around the world submit solutions using a web form. A student is given "credit" for a solution if the answer is
correct and there is a clear and complete explanation of how the answer was reached. All students who received
credit are listed in the answer section of the PoW area the following week. What makes this PoW program so unique
is that all submitters receive feedback from real people (called "mentors"), with the hope that the students will read
the feedback, work on improving their solutions and explanations, and submit revisions. The mentors try to help the
students overcome misconceptions and work on the clarity and completeness of the explanation. For their part, the
students enjoy the personal attention, and are also motivated to submit answers so they can see their names (and
possibly their entire solutions) posted in the answer section.

       The  mentoring  project was implemented        in two      different mathematics  courses  taught    during   two
consecutive semesters. During the first three sessions, PTs prepared to mentor using an online discussion forum. To
prepare, PTs solved math problems and then read sample student solutions taken from the Problem of the Week
archives. They were then asked to write responses to each of these sample students based on the Math Forum's
standards for responses, which include having no mathematical or spelling errors, establishing a consistent tone, and
encouraging students to submit a revision by providing clear (but not leading) feedback. The Math Forum's PoW
coordinator then posted feedback to the responses in the discussion area. Finally, PTs discussed their classmates'
written responses in the online discussion forum.

       During the second three sessions, PTs used the Math Forum's online PoW office. Here the PTs read 3-5
real students' answers, drafted responses to the students, received feedback from the PoW coordinator about their

                                                        546
responses, and revised their responses if needed. The PoW coordinator would not send the student any responses
that did not yet meet the strict criteria of the Math Forum.

Participants
         The nineteen PTs from the first course were enrolled in one of two mathematics courses designed for
prospective elementary and secondary teachers during the fall of 2000 at a large urban university in the southwestern
United States. Seven of these were prospective secondary teachers and 12 were prospective elementary teachers.
The goal for the class was to support the prospective teachers' skills in mathematical proof and problem solving. In
the case of  the prospective     secondary  teachers, it served   as a transition course from lower- to higher-level
mathematics. In the case of the prospective elementary teachers, it served as one of several courses that could be
taken in order to receive a specialization in mathematics (i.e., become eligible to teach middle-school mathematics).
Participation in this mentoring project and in this study was voluntary; the alternative was to complete a series of
three "log" problems that involved writing detailed descriptions of complicated mathematical problems. Sixteen
students opted for the alternative.

         Twelve PTs participated in the second course, which was run as part of a higher-level mathematics course
for prospective secondary teachers and masters' students during the spring, 2001 semester. However, two PTs had
taken the first course, and so their data are excluded, leaving this group with 10 PTs . There were several differences
between this class and the first. First, participation in this project was not voluntary; it was an essential part of the
class curriculum, although participation in the study was optional. Second, this course was an elective course with
the express goal of learning how to integrate technology into the teaching of higher-level mathematics. Thus, those
enrolled knew that there would be a large amount of computer use and all were technologically savvy. Third, all of
the PTs enrolled in this class were more mathematically proficient and more mathematically confident than many of
those in the first course.

Data Corpus
         The data corpus consists of two sets of data from each of the two course studies. The first set of data
contains all the written draft responses composed by the mentors, accompanied by the feedback they were given by
the PoW coordinator. The second set of data contains written responses to surveys about the course.

Methods of Analysis
         The first set     of data (the written responses    from the  mentors  to the students) was analyzed using
quantitative methods. Data from the two courses were analyzed together because the mentors are samples from the
same population, despite the differences described above. Each response a mentor wrote to a student was graded
using the 14 performance attributes listed in Table 1. An initial version of the attributes was defined by analyzing
mentor responses. The attributes were modified and improved through discussions with other mentor trainers at the
Math Forum. All scores were dichotomous: "0" indicated lack of acceptable performance on the attribute, and "1"
was assigned when there was no evidence to the contrary, usually in the form of presence of the attribute. In
practice, this gave the mentor the benefit of the doubt for grading purposes.

         An analysis of improvement was conducted by comparing: (1) the mentors' performance on the first set of
draft responses in the discussion area during session 1 (time 1) with (2) the mentors' performance on the set of draft
responses to real students in the final PoW experience during session 6 (time 2). The scores for each performance
attribute were averaged over each set of responses in one PoW for each mentor at each time. The variable of interest
was computed by taking the average mentor score at each time for each attribute, averaging those scores across the
class, and then adding together those scores for the set of attributes in each of the three categories shown in Table 1.
This gave us an indication of the movement of the class, but tended to ignore special cases. Comparisons between
the two times for each of the three categories of performance attributes were evaluated using a repeated measures
ANOVA.

Course Survey
         The second data set, an anonymous evaluation form containing 18 questions, was completed at the end of
each course. All 19 PTs in the first course and 11 of the 12 PTs in the second course completed the survey. All
questions but one were open-ended in order to gain as much unique information as possible. All open-ended
questions were analyzed using a grounded theory method (Strauss and Corbin, 1990) wherein new categories are

                                                          547
formed until all data is categorized. Three questions were added to the original questionnaire for the second course.
Some of the questions were about the course structure, and some of them were about performance and learning.

Table 1. Response Performance Attributes.

Category Performance             Description
          Attribute
Manner    personal                Be personal. Greet them by name at the beginning of your reply.

          nice opening            Start with something positive. It makes it easier to read criticism when it starts
                                  with something positive, so open your reply by saying something good about
                                  what they wrote.
          specific encouragement Be specific with your praise. For example, "You explained what you did really
                                  well." or "Good start." If there's nothing obvious, you can simply thank them
                                  for submitting to the Problem of the Week.
          nice closing            End with something nice or encouraging. If they're wrong, give them the idea
                                  that you think they can figure it out if they spend a little more time with it.
Form      proofread               PROOFREAD! When you write to students, you are modeling the behavior
                                  you'd like them to have. If you have typos or grammatical errors, it looks
                                  sloppy and can be hard to read. If you have problems spelling, please use a spell
                                  checker and cut-and-paste your reply.
          consistent              Don't praise poor work. If you tell them they did great work, you are implying
                                  that no changes need to be made. So, if there are changes that need to be made,
                                  don't tell them they did an excellent job.
          write good amount       Be concise. Say what you have to say, and no more. Writing too much can be
                                  confusing, as everything you write should have significance.
Pedagogy  specific request        Make specific requests for revisions. If you can find their exact mistake, point it
                                  out without giving them the answer. If the student needs to fix something, be
                                  specific in your request.
          open to student view    Ask probing questions. Your questions should probe what the student is
                                  thinking, not test them on what you think they should know. Or maybe a hint
                                  would be better...
          good hints              Give good hints. Understand what the students are trying to do, and try to lead
                                  them from there to the right path.
          non-leading             Don't ask leading questions. These types of questions don't help the student
                                  learn. For example, it would be better to ask, "How did you get the measure of
                                  the interior angles?" than to ask, "Did you use (n-2)180?"
          meaningful work         Only request meaningful work. Don't ask students to do something that isn't
                                  required by the problem, unless you're stretching them beyond a correct
                                  solution. You can ask them to improve things like grammar and spelling.
          correct math            Be mathematically correct. Use proper mathematical vocabulary, check your
                                  arithmetic, check their use of both!
          stretching correct      Stretch students who have correct solutions. Let them know that's what you're
                                  doing, that it's not required.

Results
       To summarize the results of the two studies, we present the quantitative results that describe the change in
mentoring attributes of the prospective teachers' responses. We then present a summary of the end-of-course survey.

Baseline Skills of Prospective Teachers
       The PTs in both studies began the project with high (over 90%) performance levels for the "pedagogy"
attributes of asking for meaningful work, using correct mathematical statements, and presenting students with ideas

                                                      548
to stretch their mathematical  thinking at appropriate    times  (see time 1  in Figure 1). They      started with high
performance levels for the "manner" attributes of starting their feedback with something positive and making
specific requests rather than being general about how to improve a solution (see time 1 in Figure 2). They did not
start with high performance levels for any of the "form" attributes (see time 1 in Figure 3). Figures 1 through 3 show
performance levels for times 1 and 2, each averaged over the PTs' responses in each course for each attribute (where
the attribute name ends in a "1" for course 1 and in a "2" for course 2). For definitions of each attribute, see Table 1.

                                                        Pedagogy    Change

                                stretching_correct2
                                stretching_correct1
                                     correct_math2
                                     correct_math1
                                 meaningful_work2
                                 meaningful_work1
                                       nonleading2                                             time 2
                                       nonleading1                                             time 1
                                       good_hints2
                                       good_hints1
                            open_to_student_view2
                            open_to_student_view1
                                  specific_request2
                                  specific_request1

                                                 40%     50%  60%   70%   80%  90% 100%

Figure 1. "Pedagogy" performance for times 1 and 2. Each attribute appears once for course 1 and once for course 2.

Areas of Improvement
        Improvements were measured from prospective teachers' first mentoring experience to their last experience
for an entire category. The change in scores between time 1 and time 2 were statistically significant for each of the
categories (see Table 2).

Table 2. Repeated Measure ANOVA results on the performance categories.

                 Performance       Time 1 Avg                Time 2 Avg       F          Pr > F
                 Category                  (sd)                   (sd)        Value
                  Pedagogy              5.85 (0.70)           6.36 (0.66)        11.90    0.0018
                  Manner                3.51 (0.64)           3.85 (0.28)         9.78    0.0041
                  Form                  2.29 (0.62)           2.69 (0.33)        17.60    0.0002

        More specifically, the PTs improved in the "pedagogy" attribute of making specific requests of students
(48% to 71%), but neither group ended the course performing at high levels of over 90% (see time 2 in Figure 1).
Both groups improved in the "pedagogy" attribute of giving good hints (PTs in course 1 went from 51% to 74%),
but only the PTs in course 2 ended doing this at high levels. Both groups also improved in the "form" attributes of
being consistent, and they both ended the course doing this at high levels (see time 2 in Figure 3).

        The two areas in which the PTs in course 1 improved a lot were the "manner" attributes of addressing the
student in a personal way and ending the response with something encouraging, and the "form" attribute of writing
an appropriate amount of text (see time 2 in Figure 2). In contrast, the PTs in course 2 were already performing at a
high level, and hence could not show statistically significant improvement. The PTs in course 2 caught up to and
even surpassed the PTs in course 1 in being open to the student's view, that is, giving facilitative rather than
directive feedback.

                                                         549
       In summary, the quantitative data show that the PTs generally made great strides in the three categories of
pedagogy, manner, and form (see Figure 4). Figure 4 presents the average scores in each of the three categories, so
the details of Figures 1-3 get somewhat blurred. What can be seen is that both groups improved most significantly in
the form attributes, followed by pedagogy and then manner, though at different levels. There were a few attributes
within these categories in which PTs did not attain high performance levels by the end of the project, including
making specific requests and proofreading.

                                                  Manner   Change

                                   nice_closing2
                                   nice_closing1
                        specific_encouragement2
                        specific_encouragement1                                      time 2
                                  nice_opening2                                      time 1
                                  nice_opening1
                                      personal2
                                      personal1

                                               60%    70%     80%    90%   100%

 Figure 2. "Manner" performance for times 1 and 2. Each attribute appears once for course 1 and once for course 2.

                                                   Form Change

                      wrote_good_amount2
                      wrote_good_amount1
                               consistent2                                              time 2
                               consistent1                                              time 1
                               proofread2
                               proofread1

                                         50%     60%    70%    80%     90%    100%

  Figure 3. "Form" performance for times 1 and 2. Each attribute appears once for course 1 and once for course 2.

               100%
                95%
                                                                                 Pedagogy (Group 1)
                90%
                                                                                 Pedagogy (Group 2)
                85%
                                                                                 Form (Group 1)
                80%
                                                                                 Form (Group 2)
                75%
                                                                                 Manner (Group 1)
                70%
                                                                                 Manner (Group 2)
                65%
                60%
                               Time 1                   Time 2

                Figure 4. Patterns of change between groups, averaged across the categories.

Qualitative Summary
       The overall indication from the surveys was that the PTs found this online experience to be worthwhile and
would encourage others to choose this option if given the choice. Most of the questions in the survey were open-
ended, making it difficult to aggregate, but providing a full range of answers. The PTs identified characteristics of

                                                       550
the project that were positive: it helped bridge the preparation/practice divide (e.g., the response does not go directly
to the student), helped develop mathematical communication, teamwork (e.g., sharing ideas), and one noted that
feedback from the PoW coordinator was helpful. Accordingly, PTs also made suggestions to improve the course.
There were some suggestions about scheduling: meet face to face to discuss progress, some wanted more students or
more sessions for more practice, and some wanted fewer; some said that the project was fine as is. The vast majority
in course 2 (the first group was not asked directly) felt it to be a good method for teaching and learning.

Discussion
         The goal of this intervention (in both intent and execution) was to overcome some of the typical problems
associated with preparation for practicums, including practical experience with individual students and having
pedagogical practice. In this section, we will discuss the degree to which this goal was attained and will end by
summarizing how the qualitative data shows how the course was perceived by the PTs.

         Practical experience with individual students. As has been displayed in these studies, communicating with
students directly provides a more authentic environment than simply evaluating student work samples. As one PT
said: "This is the closest I have been to mentoring `live' students." We also saw that the PTs gained a sense of
accomplishment when they saw students' continued work in response to their feedback. However, the authenticity
can only be realized if the students revise their work in response to the mentors' feedback. There is some indication
that there is a correlation between the quality of the mentors' responses and the number of times students revise their
solutions (Renninger & Shumar, 1998), though in practice many good mentor responses get no student revisions, as
was the case for one student in our study.

         Pedagogical practice.     From  the perspectives of all three groups  of participants in these      studies (the
professor, the PTs, and the PoW coordinator), we can conclude that this course engaged the PTs in authentic
experiences that caused them to re-evaluate their views about the pedagogical value of conceptual explanations, and
the importance of learning to communicate with students in ways that are facilitative rather than directive. Thus, we
can say even more broadly that while a virtual mentoring experience cannot replace the value of face-to-face
interactions with students, it can provide authentic experiences within which PTs can begin to develop a teaching
style and shift hats from thinking of themselves purely as providers of mathematical content to facilitators of
learning. In particular, the PTs had time to think about what to say before responding to students, student revisions
gave practical feedback to PTs about their comments, and PTs learned useful pedagogical strategies, including
question-asking and hint giving skills, learning to explain what they mean, and not giving contradictory information
to students. Three PTs indicated that the strongest part of this experience was that their responses were reviewed
before being sent to the students.

         The participants in course 2 were generally more mathematically proficient, mature, and, in some cases,
experienced as teachers. Therefore, it is not surprising that these participants began at higher baseline levels than the
participants in course 1 for most of the "pedagogy" attributes, including asking open-ended questions instead of non-
leading or closed questions, the "manner" attributes of starting the response by addressing the student personally and
of closing their responses with something encouraging, and the "form" attribute of writing a good amount relative to
the students' solutions. The one pedagogy attribute in which the PTs in course 1 began at higher levels than those in
course 2 was coded as "open to student". This attribute involved being sensitive to how the students were solving
the problem and not simply imposing their ideas of how to do it, even if the approach the student took diverged from
their own. This finding is consistent with Pajares' (1992) findings stating that prospective teachers value and
emphasize empathy toward children.

         The finding that both groups began by being somewhat inconsistent with their replies indicates that PTs
often confuse compliments with encouragement. Perhaps these PTs felt that positive statements, even if unfounded,
make students feel good about what they have done. This is consistent with their stated goals of helping young
students in supportive ways,       and with  the research  indicating  that PTs   often assume    that      empathy  and
encouragement are necessary and sufficient characteristics of good teachers. However, the Math Forum has found
that the practice of providing blanket compliments tends to mislead or even confuse students to the point where they
may feel that their answer is correct and does not need further revising. A review of the literature on feedback to
students supports this idea (Underwood, Tregidgo, & Gentile, 2003). The approach that the Math Forum takes is to

                                                       551
say something positive about something that the student has done well. Sometimes this is difficult because the
student does not provide anything good to work with, but as is evident here, the PTs learned to do it consistently.

         In conclusion, the methods described provide three valuable contributions to the field of teacher education.
First, the scoring rubric enabled researchers to quantify and measure the mentors' pedagogical growth. This is a
novel contribution because pedagogical growth is often seen as a generally elusive variable that is described as
difficult to measure due to its highly subjective nature. Second, the inclusion of writing and justifying answers aligns
well with both the NCTM Standards and the current emphasis on Writing Across the Curriculum.       Providing PTs
with evidence that highlights the value of mathematical writing as both an educative tool and an assessment tool is
much more convincing than simply having a professor of education try to communicate its power.    Third, both the
method   of virtual tutoring  and  the scoring rubric for assessing  mentor growth  are flexible, extensible         and
generalizable. The same virtual tutoring method could be generalized to almost any academic subject. Moreover, in
further instantiations of this method, we capitalized on the extensibility of the design to incorporate other features
such as having mentors form the questions and maintaining the same student-mentor pairs over an entire semester.
The generalizability of the analytic rubric enabled us to accommodate these changes into the grading rubric so that
we could continue to measure and quantify mentor growth.

References
Ball, D. L. (1990). Breaking with experience in learning to teach mathematics: The role of a preservice methods
         course. For the Learning of Mathematics, 10(2), 10­16.
Blanton, M.L. & Kaput, J.J. (2002). Developing Elementary Teachers' Algebra "Eyes and Ears": Understanding
         Characteristics of  Professional  Development  that Promote  Generative and Self-Sustaining   Change         in
         Teacher Practice. Presented at AERA 2002, New Orleans, LA.
Bowers, J. S., & Doerr, H. M. (in press). Designing multimedia case studies for prospective mathematics teachers.
         To appear in the Journal of Educational Multimedia and Hypermedia.
Cooney, Wilson, Albright, & Chevaut, J. (1998). Conceptualizing the professional development of secondary
         preservice mathematics teachers. Paper presented at the Annual conference of the American Educational
         Research Association, San Diego, CA.
Franke, M.L., Kazemi, E., Carpenter, T., Battey, D., & Deneroff, V. (2002). Articulating and capturing generative
         growth: implications for professional development, Presented at AERA 2002, New Orleans, LA.
Hayes, D. (2001). The impact of mentoring and tutoring on student primary teachers' achievements: a case study',
         Mentoring and Tutoring, 9(1),5-21
Kagan, D. M. (1992). Professional Growth among Preservice and Beginning Teachers. Review of Educational
         Research, 62( 2),129-69.
Lampert, M., & Ball, D. (1998). Teaching, multimedia, and mathematics: Investigations of real practice. New York:
         Teachers College Press.
National Council of Teachers of Mathematics (2000). Principles and standards for school mathematics. Reston, VA:
         Author.
Pajares, M.  F. (1992).  Teachers' beliefs and educational research: Cleaning up  a messy  construct.  Review         of
         Educational Research, 62(3), 307-332.
Philipp, R. A., Clement, L., & Thanheiser, E. (submitted for publication). The role of a children's mathematical
         thinking experience in the preparation of prospective elementary school teachers. International Journal of
         Educational Reform: Special Issue titled "Developing and Improving Mathematics Teachers' Competence:
         Practices and Approaches Across Educational Systems".
Renninger, K.A. & Shumar, W. (1998). Why and how students work with the Math Forum's problem(s) of the
         week: Implications for design. Paper presented at the International Conference of the Learning Sciences,
         Charlottesville, VA.
Schorr, R.Y. (2002). Looking at change in the teaching of mathematics. AERA 2002, New Orleans, LA.
Strauss, A. & Corbin, J. (1990). Basics of Qualitative Research: Grounded Theory Procedures and Techniques. NY:
         Sage Publications.
Thompson, A. (1984). The relationship of teachers' conceptions of mathematics teaching to instructional practice.
         Educational Studies in Mathematics, 15, 105­127.
Underwood, J.S., Tregidgo, A., & Gentile, C. (2003). Literature review on response to student writing. Educational
         Testing Service Research Report.

                                                       552
