         Anticipatory Cognitive Mapping of Unknown Spaces by
  People who are Blind Using a Virtual Learning Environment

                                         David Mioduser & Orly Lahav
                                  School of Education, Tel Aviv University
                                      Ramat Aviv, 69978, Tel Aviv, Israel
                                  Tel: 972-3-6408465, Fax: 972-3-6407752
                                          Email: miodu@post.tau.ac.il

          Abstract:   Mental   mapping   of spaces, and  of the   possible paths  for navigating   these
          spaces, is essential for the development of efficient orientation and mobility skills.   Most
          of the information   required  for this  mental  mapping    is  gathered through    the visual
          channel.  People  who   are blind  lack this crucial information    and in consequence     face
          great difficulties (a) in generating efficient mental maps of spaces, and therefore (b) in
          navigating proficiently within these spaces.   The work reported in this paper follows the
          assumption that the supply of appropriate spatial information through compensatory
          sensorial channels, as an alternative to the (impaired) visual channel, may contribute to
          the anticipatory mental mapping of unknown spaces and consequently, to blind people's
          spatial performance.  The main goals of the study reported in this paper were: (a) The
          development of a virtual learning environment enabling blind people to learn about real
          life spaces which    they are   required  to navigate   (e.g.,  school,  work  place,   public
          buildings); (b) A systematic study of blind people's acquisition of spatial navigation skills
          by means of the virtual learning environment; (c) A systematic study of the contribution
          of this anticipatory mapping to blind people's spatial skills and performance in the real
          environment.   In the   paper a brief description   of  the virtual learning  environment   is
          presented,  as well  as findings  regarding   blind  persons'   learning process    and actual
          performance in the real space.

Introduction
          The ability to explore unknown spaces independently, safely and efficiently is a combined product
of motor, sensory and cognitive skills.   Normal exercise of this ability directly affects individuals' quality
of life. Mental mapping of spaces, and of the possible paths for navigating these spaces, is essential for the
development of efficient orientation and mobility (O&M) skills.       Most of the information required for this
mental mapping is gathered through the visual channel (Lynch, 1960).           People who are blind lack this
information, and in consequence they are required to use compensatory sensorial channels and alternative
exploration methods (Jacobson, 1993).       The research reported here is based on the assumption that the
supply of appropriate spatial information through compensatory sensorial channels, as an alternative to the
(impaired) visual channel, may help to enhance blind people's ability to explore unknown environments
(Mioduser, in press).

          Research   on  blind people's  mobility   in known   and    unknown    spaces (Golledge,   Klatzky,   &
Loomis, 1996; Ungar, Blades, & Spencer, 1996), indicates that support for the acquisition of spatial
mapping and orientation skills should be supplied at two main levels: perceptual and conceptual.           At the
perceptual level, the deficiency in the visual channel should be compensated with information perceived via
other senses.    Hearing, smell   and touch   are powerful    information  suppliers    about known   as  well  as
unknown spaces.      The auditory channel supplies essential information about events, or the presence of
other people (or machines or animals) in the environment.      In indoor space the blind can use echo feedback
(by whistling, clapping hands or talking) to estimate distances (Hill, et al, 1993).          The smell channel
supplies  additional  information   about particular   situations (e.g., perfumery,   bookstore   or bakery  in a
shopping center) or about people.       Haptic  information   appears  to be  of  great potential for supporting
appropriate spatial performance.    Fritz, Way and Barner (1996), define haptics as follows: "tactile refers to
the sense of touch, while the broader haptics encompasses touch as well as kinesthetic information, or a

                                                       334
sense of position, motion and force." For the blind, haptic information is commonly supplied by the cane
for low-resolution scanning of the immediate surroundings, by palms and fingers for fine recognition of
objects' form, texture and location, and by the feet regarding surface information.

        As for the conceptual level, the focus is on supporting the development of appropriate strategies
for the efficient exploration of the space and the generation of efficient navigation paths.       For example,
Jacobson (1993), described blind people's indoor environment familiarization process as one that starts
with the use of a perimeter-recognition-tactic -walking along the room's walls and exploring objects
attached to the walls- followed by a grid-scanning-tactic -aiming to explore the room's interior.

        Advanced computer technology offers new possibilities for supporting blind people's acquisition
of O&M     skills, and the development  of  alternative   navigation  strategies, at both    the perceptual and
conceptual levels.   Current Virtual Reality (VR) technology facilitates the development of rich virtual
models of physical environments and objects to be manipulated, offering blind people the possibility to
undergo learning or rehabilitation processes without the usual constraints of time, space, and a massive
demand of human tutoring (Loomis, Klatzky & Golledge, 2001; Schultheis & Rizzo, 2001; Standen, Brown
& Cromby, 2001).     Research on the implementation of haptic technologies within VR spatial simulation
environments reports on its potential for supporting rehabilitation training with sighted people (Darken &
Banker, 1998; Waller, Hunt & Knapp, 1998), and perception of virtual textures and objects by blind people
(Colwell, Petrie, & Kornbrot, 1998; Jansson et al, 1998).

        The research reported in this paper follows the assumption that the supply (via the technology) of
compensatory perceptual and conceptual information may contribute to blind persons' cognitive mapping
of spaces. To examine the above assumption we developed a multisensory-virtual-learning-environment
(MVLE) and studied the exploration process of an unknown space by blind subjects using the MVLE.
Their performance was compared to that of a control group of blind people who explored directly the real
environment simulated in the MVLE.    The main research questions of this study were:

1.  Does the walking in the virtual learning environment contribute to the construction of an efficient
    cognitive map of the unknown space?
2.  How does this cognitive map contribute to the blind person's O&M performance in the real space?

The Haptic Virtual Learning Environment
        For  the   study we  developed a   virtual environment   simulating   real-life spaces.    This virtual
environment comprises two modes of operation:

Developer/Teacher Mode
        The core component of the developer mode is the virtual environment editor.          Figure 1 shows the
environment-editor screen.    The developer   mode   allows  the researcher   or  teacher to  build  navigation
environments according to instructional or research needs. This module includes three tools:

             (a)       Environment builder - by this tool the developer defines the physical characteristics
                       of the space, e.g., size and form of the room, type and the size of objects (e.g., doors,
                       windows, furniture pieces) and their location.
             (b)       Force-feedback editor - by this editor the developer is able to attach Force-Feedback
                       Effects (FFE) to all objects in the environment.   Examples of FFE's are vibrations
                       produced by force fields surrounding objects, or tactile characteristics of structural
                       components such as walls and columns (e.g., friction).
             (c)       Audio-feedback editor - this editor allows the attachment of sounds and auditory
                       feedback to the objects, e.g.: "you are facing a window" or realistic sounds (e.g.,
                       steps). Additional auditory feedback is activated whenever the user enters an object's
                       effect field, supplying important information related to the objects.

                                                    335
Learning Mode
          The learning mode, or the environment within which the user works, includes two interfaces:

             (a)     The user  interface    consists  of  the virtual environment  simulating real   rooms and
                     objects to be navigated by the users using the Force Feedback Joystick (FFJ).
             (b)     The teacher interface comprising several features that serve teachers during and after
                     the learning session. On-screen monitors present updated information on the user's
                     navigation performance, e.g., position, or objects already reached.         An additional
                     feature  allows the      teacher  to record  the  user's navigation path,   and  replay it
                     aftermath to analyze and evaluate the user's performance.       Figure 2 shows a user's
                     monitor  data,  and    her navigation    paths within the  room's space  and   around the
                     objects.

Figure 1. 3D environment builder                              Figure 2. M.'s exploration path

Method
Participants
          The study included 31 participants who were selected on the basis of the following seven criteria:
total blindness; at least 12 years old; not multi-handicapped; received O&M training; Hebrew speakers;
onset of blindness at least two years prior to the experimental period; comfortable with the use of
computers.  The participants' age range was 12-70 years (see Table 1), mostly adults in the age range of 24-
40. We defined two groups that were similar in gender, age and age of vision loss (congenitally blind or
late blind): The experimental group, including 21 participants who explored the unknown space by means
of the MVLE, and the control group, 10 participants who explored directly the real unknown space.

          Table 1. The study's participants

                                 Gender                   Age                  Age of vision loss
      Group                  Female   Male        Adult       Teenage   Congenitally blind  Late blind
                                                 (24-70)      (12-20)
      Experimental group(n=21) 11       10         15           6               11                10
      Control group(n=10)      6            4        8          2               6                 4

Research Instruments
          The main instruments that served the study were:

The Unknown Target Space
          The space to be explored, both as real physical space and as virtual space in the MVLE (see
Figures 3-4), was a 54 square meters room with three doors, six windows and two columns. There were
seven objects in the room, five of them attached to the walls and two placed in the inner space.

                                                       336
Figure 3.  The MVLE representation of the target space                    Figure 4. The Real space

Exploration Task
          Each participant was asked individually to explore the room, without time limitations.   The
experimenters informed the participants that they would be asked to describe the room and its components
at the end of their exploration.

          In addition three instruments were developed for the collection of quantitative and qualitative data:

Orientation and Mobility (O&M) Questionnaire
          The questionnaire comprised 46 questions concerning the participants O&M ability indoors and
outdoors, in known and unknown environments. Most of the questions were taken from O&M
rehabilitation evaluation instruments (e.g., Dodson-Burk & Hill, 1989; Sonn, Tornquist & Svensson, 1999).

Computer Log
          The Log allowed the researchers to track the user's learning and exploration process in the MVLE,
as regards to their exploration strategies, distances traversed, duration, switch of strategies and stops.

Evaluation and Coding Schemes
          These instruments served the experts analysis of the participant's O&M skills and capabilities and
his or her acquaintance process with the new space.

Procedure
          All participants worked and were observed individually.   The study was carried out in four stages.
The  first stage focused   on    the evaluation  of the participants' initial  O&M   skills  using   the    O&M
questionnaire.   In the second stage (two meetings, about three hours) the experimental group became
acquainted with the virtual learning environment's components and operation modes. The third stage, the
main part of the study, focused on participants' exploration of the unknown space.    The experimental group
explored   the space using  the   virtual environment,  while  the control group    explored directly      the real
environment. This stage lasted about 1.5 - 2.5 hours. In the last stage both groups performed O&M tasks in
the real target space. In the last two stages all participants' performances were video-recorded.

Results
          Although in this paper we focus on questions related to the anticipatory cognitive mapping of an
unknown space and its role in actual O&M performance (stages two and three), we will briefly summarize
our observations during the exploration stage (stage 1) as necessary background for the subsequent results.
A detailed presentation of the findings of the exploration stage can be found in Lahav & Mioduser, (in
press). Significant  differences     were found  between  the  experimental    group and  the     control   group
concerning the characteristics of the exploration process.   These differences are related to four variables:
the total  duration  of the exploration,    the total distance traversed,  the sequence  of   main   strategies
implemented and the number of pauses made while exploring the unknown space. The participants in both
groups implemented similar exploration strategies, mostly based on those used for their daily navigation of

                                                      337
real spaces. However, the experimental group participants, in comparison with the control group, used a
more varied range of strategies and several participants developed a few new strategies while working
within the virtual environment (e.g., a "constant scanning" strategy by which the user activates probes to
collect information about the room's interior while collecting perimeter information -somehow resembling
the use of a long cane in the real space).    These strategies could be generated only within the MVLE,
representing an important added value of the work with the computer learning system.             The participants
from the experimental group walked a longer distance to complete the exploration, and made more pauses
for technical or reflective purposes. Summarizing the results of the exploration stage we can claim that the
participants learning with the MVLE completed a more comprehensive, detailed and reflective examination
of the unknown space than the control group. How this learning process affects the cognitive mapping of
the unknown space, and the subsequent performance in the real space, are at the core of this paper's
research questions

Research Question 1: Does the walking in the virtual learning environment contribute to
the construction of an efficient cognitive map of the unknown space?
         After the exploration process the participants were asked to give a verbal description and to
construct a physical model of the explored space. Four variables of the participants' verbal and physical
representations were examined: room size, room shape, structural features and components' location. The
control group participants (who explored directly the real space) performed better in verbally describing the
rooms' size (c2(2)=9.07; p<0.05) and the rooms' shape (c2(2)=7.02; p<0.05).             The participants from the
experimental group performed better in describing the structural components (t(28)=4.63; p<0.001) and
their location (t(29)=2.85; p<0.001). However in the physical model, most participants in both groups
constructed an appropriate model of the room and its components.

         The  experimental    group's   representation was  more   specific        and elaborated, in  the verbal
description as well as in their models. For example, 29% of the experimental group participants placed all
the seven objects located in the environment, and 43% placed six objects. In contrast, none of the control
group participants placed all seven objects in their models and only 30% placed six objects.

         The  participants used  four   types of spatial features  to   describe      the environment:  perimeter
description (e.g., N. -33 years old/late blind/male/experimental group- described: "on one of the wall there
is the first door, the prism, another door... the prism between them...continuing with this wall you can
reach  the cube, blackboard,  door...");  object-to-object description      (e.g., G.  ­12 years old/congenitally
blind/female/experimental group- described the environment: "at the lower wall there are two doors and
near one of them there is a cube and near the other one there is a prism..."); items list (e.g., V. ­17 years
old/congenitally blind/female/experimental group- described the environment: "I found a prism, a door and
there is also a pole, a diagonal box and a square"); and descriptions from the entrance-door-perspective
(e.g., M.  -39-years old/late blind/female/experimental    group-  described       the environment:   "if you are
walking left from the door, when the door is behind you you can reach to the prism... walking forward you
can find five or six windows at the wall that is in front of the door...").

         Data related to varied aspects of the participants' descriptions are shown in Table 2.       Most of the
participants from the experimental group generated two main types of descriptions of the environment:
perimeter description (38%) and object-to-object description (34%).         In contrast, 40% of the control group
participants described the environment in the form of a list of items.

         Participants of both research groups generated three types of spatial representation (route model;
map model and integrated representation) in similar distribution.

         As regards to the sequence of item-types included in the verbal descriptions, the results show a
significant difference between the groups (c2(1)=10.60; p<0.005).  Most participants in the experimental
group (81%) described first the rooms' structure and later on its content.   In contrast, control group
participants described first the inner components and later on the rooms' structural components.

         Examination of the physical models shows significant difference between the groups in overall
quality (c2(8)=7.35; p<0.05) and in particular features as well. For example, looking at first-item-

                                                    338
placement in the physical model significant difference was found in building sequence -similar to that
observed in the verbal descriptions- (c2(7)=11.32; p<0.05).
Table 2. Descriptions generation

                                                               Experimental group       Control group
                                                                      (n=21)               (n=10)
  Spatial description      Perimeter description                      8 (38%)              2 (20%)
                           Object-to-object description               7 (34%)              2 (20%)
                           List of objects description                4 (19%)              4 (40%)
                           Entrance door point of view                2 (10%)              1 (10%)
                           Other                                        --                 1 (10%)
  Spatial representation   Route model                                8 (38%)              3 (30%)
                           Map model                                  7 (33%)              5 (50%)
                           Integrated representation                  6 (29%)              2 (20%)
            * c2(8)=7.35; p<0.05

         The findings for the first question indicate that the experimental group participants constructed
fairly complex cognitive maps of the unknown space, as reflected in their verbal and physical descriptions.
These maps comprise multiple layers, e.g., structural layer (referring to the overall configuration and
dimensions of the room), compositional layer (in relation to the identification of inner components and they
arrangement in space), relational layer (focusing location of objects relative to each other, or distances
among objects). A procedural component complements the previous layers in the form of strategies for
exploration/recall of the target space (e.g., perimeter, object-to-object). The learning process within the
MVLE, by its unique features, supported the construction of a knowledge-rich model at all its different
layers.

Research Question 2: How does this cognitive map contribute to the blind person's O&M
performance in the real space?
         After the exploration process and the construction of the cognitive map, the participants were
asked to perform two orientation tasks in the real space. It should be recalled that the experimental group
participants entered the real space for the first time to perform the tasks, and were not given the option to
first explore the room ­they did that in the MVLE only. Five variables were examined: successful
completion of the tasks, use of direct paths to the target location, time spent on task, number and duration
of stops (short stops and long stops) and total length of the path. Most of the subjects of the experimental
group successfully performed both orientation tasks in the real space. Significant difference was found
between the groups in the subjects' performance in the target-object task.  Most subjects of the
experimental group successfully performed the target-object task while choosing a more direct and shorter
path than the control group participants. When examining the perspective-taking task, most subjects of the
experimental group successfully performed the task in shorter time and path length.

Table 3. Performance in the real environment

                                          Target-object task                  Perspective-taking task
                            Experimental      Control group              Experimental   Control group
                            group (n=21)         (n=10)                  group (n=21)      (n=10)
    Success (%)                  81%              40%           *            71%            60%
    Direct path (%)              67%              20%           **           34%            30%
    Time (Seconds)                66               118                        153           191
    Short stops (mean)             3                6                         3                  5
    Long stops (mean)             1.5              2.7                        1.5                3
    Length of the path            28               47           ***           86             95
   * c2(2)=7.02; p<0.05; ** c2(3)=8.20; p<0.05; *** p<0.05

         The results are clearly indicative of the contribution of the learning with the MVLE to the
participant's anticipatory mapping of the target space and consequently to their successful performance in

                                                   339
the real space. Moreover, they show that such a mapping resulted in greater capability of the subjects of the
experimental group in performing the real-space tasks.

Main Conclusions
Construction of Cognitive Maps as a Result of Learning with the MVLE
       Participants in the experimental group were able to construct complex maps of the unknown space
while working with the MVLE, prior to their acquaintance with the real space. As a result of their intensive
interaction with the components of the virtual learning environment, the users were exposed to a wide
range of haptic and audio feedbacks.    This information allowed them to devote most of their attention and
resources to the consolidation of the structural, compositional and relational aspects of the space's overall
map. In addition, it seems that the participants developed particular perspectives of the space, and strategies
for approaching it, as a result of the features and affordances of the MVLE (e.g., the tendency to describe
the space from the perimeter to the inner space, in a whole and holistic manner).   In contrast, we found that
the exploration of the real space contributed to the control group's ability to estimate the objects' size and
distances among them, functions not supported yet in the MVLE.

Performance in Orientation and Mobility Tasks as a Result of Learning with the MVLE
       The first real space walking experience of most subjects in the experimental group was a confident
and resolved one. It was noticeable that this walking was based solely on spatial knowledge acquired as a
result of their acquaintance with the room in the virtual environment. We found many evidences of the
robustness of the constructed map and its contribution to the subjects' performance. One example is their
frequent use of the "Object to Object" strategy while accomplishing the tasks. Previous research (e.g.,
Golledge et al., 1978; Hill et al., 1993) reported that successful navigators among people who are blind
make recurrent use  of   this strategy. The  often   use of it by participants  in the experimental    group   is
indicative of the holistic nature of their inner representation of the space, allowing them to construct
efficient navigation paths based on isolating sub-sets of objects and their relative location.

        This internal representation represented a powerful tool for guiding the secure navigation in the
real space immediately after entering it, and for locating all spatial components required to perform the task
in the shortest possible time and ambulation path.

Current Constraints and Future Implications
       In this first attempt to examine the cognitive mapping process and its effect on actual performance
we had to define its limits as first stage of a more comprehensive research agenda. For example, one set of
limits relates to features offered by the environment (e.g., besides steps and scale representation there are
no measurement tools that allow users to get accurate information about dimensions or distances; or a
feature permitting scanning of objects at different heights that was disabled for this study to constrain the
number of variables under consideration). Other aspects deliberately constrained relate to the characteristics
of the target space: in this first stage we focused on a closed space without complicated topographical traits
(which again represent a complete set of additional variables that might lead to different results).

       Based on this first stage our research agenda includes the modeling of increasing open and highly
complex spaces (e.g. a building, University campus, museum, shopping mall), the offering of additional
exploration tools, and the study of overall exploration and mapping strategies by people who are blind who
use recurrently the MVLE for different spaces. We believe these studies are of theoretical and practical
value as well, for (a) training and rehabilitation processes requiring the acquisition of orientation and
mobility skills and strategies, and (b) learning processes of subjects involving spatial information, by
congenital and late blind people.

References
Colwell, C., Petrie, H., & Kornbrot, D. (1998).      Haptic virtual reality for blind  computer      users. Paper
       presented     at   the     Assets    `98  Conference,      Los  Angeles,      CA.         Available    in:
       http://phoenix.herts.ac.uk/sdru/pubs/VE/colwell.html
Darken , R.P., & Banker, W. P. (1998). Navigating in natural environments: A virtual environment training
       transfer   study. Paper    presented at  the IEEE  Virtual Reality Annual   International     Symposium.
       Atlanta, GA.

                                                      340
Dodson-Burk, B., & Hill, E.W. (1989). Preschool orientation and mobility screening. A publication of
         division IX of the association for education and rehabilitation of the blind and visually impaired.
         New York, NY: American Foundation for the Blind.
Fritz, J., Way, T., & Barner, K. (1996). Haptic representation of scientific data for visually impaired or
         blind persons.   Proceedings of the Eleventh   Annual Technology   and   Persons   with Disabilities
         Conference, California State University, Northridge, Los Angeles, CA.
Golledge, R., Klatzky , R., & Loomis, J. (1996). Cognitive mapping and wayfinding by adults without
         vision. In J. Portugali (Ed.), The construction of cognitive maps (pp. 215-246). The Netherlands:
         Kluwer.
Hill, E., Rieser, J., Hill, M., Hill, M., Halpin, J., & Halpin R. (1993). How persons with visual impairments
         explore novel spaces: Strategies of good and poor performers. Journal of Visual Impairment and
         Blindness, 295-301.
Jacobson, W. H. (1993). The art and science of teaching orientation and mobility to persons with visual
         impairments. New York, NY: American Foundation for the Blind.
Jansson, G., Fanger,  J.,  Konig, H., &  Billberger,  K. (1998).  Visually impaired    persons'  use of the
         PHANToM     for information about texture and 3D form of virtual objects. In J. K. Salisbury & M.
         A. Srinivasan  (Ed.)  Proceedings   of  the Third   PHANToM     Users   Group     Workshop,  MIT,
         Cambridge, MA.
Lahav, O., & Mioduser, D. (in press). Exploration of Unknown Spaces by People who are Blind, Using a
         Multisensory Virtual Environment (MVE).    Journal of Special Education Technology.
Loomis, J. M., Klatzky, R. L., & Golledge, R. G. (2001). Navigating without vision: Basic and applied
         research. Optometry and Vision Science, 78, 282-289.
Lynch, K. (1960). The image of the city. Cambridge, MA: MIT Press.
Mioduser, D. (in press). From real virtuality in Lascaux to virtual reality today: cognitive processes with
         cognitive technologies.
Schultheis, M. T., & Rizzo, A. A. (2001). The application of virtual reality technology for rehabilitation.
         Rehabilitation Psychology, 46(3), 296-311.
Sonn, U., Tornquist, K., & Svensson, E. (1999). The ADL taxonomy - from individual categorical data to
         ordinal categorical data. Scandinavian Journal of occupational therapy, 6, 11-20.
Standen,  P.J., Brown, D.J., & Cromby,     J.J. (2001).  The effective use of  virtual environments  in the
         education and rehabilitation of students with intellectual disabilities. British Journal of Education
         Technology 32(3) 289-299.
Ungar, S., Blades, M., & Spencer, S. (1996). The construction of cognitive maps by children with visual
         impairments.   In J. Portugali  (Ed.), The  construction of   cognitive maps   (pp.247-273),   The
         Netherlands: Kluwer.
Waller, D., Hunt, E., & Knapp, D. (1998). The transfer of spatial knowledge in virtual environment
         training. Presence: Teloperators and Virtual Environments 7(2), 129-143.

                                                    341
