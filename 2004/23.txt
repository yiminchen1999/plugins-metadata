                Cracking the Nut ­ But Which Nutcracker to Use?
  Diversity in Approaches to Analyzing Collaborative Processes in
                               Technology-Supported Settings

                                         Nikol Rummel & Hans Spada
                   Department of Psychology, University of Freiburg, 79085 Freiburg, Germany
                               Tel: ++49/ 761/ 203-2421, Fax: ++49/ 761/ 203-2490
                                Email: <lastname>@psychologie.uni-freiburg.de

       Abstract: Research on collaborative learning and problem-solving in technology-supported
       settings increasingly focuses on understanding collaborative processes, not just assessing their
       outcomes (learning gains or products). Developing such understanding is a prerequisite for
       promoting collaboration in an informed way. Different methodological approaches have been
       adopted for analyzing collaborative processes in technology-supported settings. As no single
       method is sufficient to unravel all aspects of a collaborative process, researchers must choose
       approaches that allow them to gain data on those aspects that are of focal interest for a given
       research question. This symposium will highlight aspects of the diversity of methodological
       approaches. The speakers of the symposium will describe the process analyses conducted as part
       of their research in different content domains and collaborative settings. They will discuss
       merits and shortcomings of these methods in revealing particular aspects of the collaborative
       processes. The discussion will compare and contrast the different methodological approaches,
       working towards the development of a "methodological toolbox" which could support informed
       choice of the appropriate methods of analysis.

Panel Overview
       In research on technology-supported collaborative problem-solving and learning it is of great importance
to understand what makes up good collaboration and to evaluate technologies and instructional measures aimed at
supporting such collaboration. There is an amazing diversity in the approaches that have been adopted in trying to
crack this nut. The various methodological approaches differ strongly with regard to dimensions like the data
sources used, the level or unit of analysis, and the way the analyses are conducted (technology and tools used).

       The     methodological  approaches  to analyzing   collaborative process range from   analyses of     activity
patterns to various types of discourse analysis (e.g. Chinn, O'Donnell & Jinks, 2000), but also to interaction and
social network analyses (Reffay & Chanier, 2002) or matrix analysis (Wortham, 1999). Coding schemes have
been developed to assess instances of certain types of behaviors or speech acts in a quantitative way (e.g.
Pilkington, 1999). Such approaches have sometimes been criticized for focusing merely on the occurrence of
behaviors   or utterances while disregarding  the quality of the process  (Rummel   &  Spada,  in press).        More
qualitative approaches    have  been taken to  analyze  the  collaborative   interactions in more  meaningful,
contextualized ways (Guribye & Wasson, 2002). In turn, such "holistic" approaches have been criticized for
lacking methodological rigor and interpretative strength (Hammersley, 1992).

       These methodological approaches have been applied to different sources of data. Logfiles can provide
information about activities taking place during the collaboration, their authorship, duration and the like. Audio
files or transcripts, as well as written dialog from interactions in text-based collaboration settings, make it possible
to scrutinize the collaborative dialog on different levels and with different granularity. Video data provides a rich
information source with regard to the situational context in which a collaborative interaction is embedded.

       Also with regard to the level and unit of analysis there is great diversity, ranging from analyzing turns,
speech acts or time units of various length, to analyzing bigger chunks of the interaction, like scenes. Analytic
approaches may further differ in which aspects of the interaction they include in their analysis (verbal behavior
and non-verbal aspects of the behavior, like gesture, posture, facial expression, voice modulation; Whittaker &
O'Conaill, 1997).

                                                    23
         In this symposium we want to highlight aspects of the multi-faceted diversity of approaches to analyzing
collaborative processes. We plan to discuss approaches to analyzing collaborative processes in a variety of
technology-supported collaborative settings. The individual contributions will characterize the analyses conducted
as part of their research on the dimensions introduced above. They will discuss the merits and shortcomings of
these methods of analysis in revealing aspects of the collaborative process relevant to their research questions. An
overall discussion will have the goal to compare and contrast the individual approaches. The overarching goal of
the symposium is to motivate scientific discourse about the diversity of approaches taken to analyze collaborative
processes. No  single method  is  sufficient to unravel   all aspects of  a collaborative  process.  Qualitative and
quantitative methods, as well as theory-based and data-driven approaches need to complement one another to help
reveal the richness of information contained in a collaborative interaction. Yet there is always the necessity to
make  a  choice; to choose  methodological   approaches    that  allow one  to  gain  data on  those aspects  of  the
collaborative process that are of focal interest for a given research question. It would be very desirable to have a
"methodological   toolbox" at hand,  which   could support    an informed   choice of  the appropriate    methods of
analysis. It is our goal to work towards the development of such a toolbox.

Individual Contributions

An Emergent Methodology for Examining "Collaborative Space" in Educational Technology
Environments
Cynthia Carter Ching (University of Illinois at Urbana-Champaign; USA)
& X. Christine Wang (SUNY Buffalo, USA)

         Conventional methods of studying collaboration at computers often focus on learning gains or surface
indicators of equal access as measures of "effectiveness." This kind of methodology fails to capture the richness
and meanings of children's collaboration, particularly when children are involved in spontaneous or seemingly
unstructured computer activities. To help address this problem we are developing a qualitative methodology for
studying  children's  face-to-face computer   collaboration.    Our  work   examines   student  interactions  within
configurations of physical and social spaces surrounding educational technology ­ both conscripted spaces as
mandated by authority figures and emergent spaces as negotiated by students (Ching, Kafai, & Marshall, 2000;
Wang & Ching, 2003; Wang, 2003). Built on existing methods of interaction analysis (Jordan & Henderson,
1995) and grounded theory (Strauss & Corbin, 1998), theories of space (Soja, 1996) and emergent goals (Saxe,
1991), and other studies using "space" to describe collaborative activities in classrooms (Gutierrez, Baquedano-
Lopez, & Tejeda, 1999), this method is ethnographic in nature and uses videos as a vital means to examine social-
spatial-cognitive collaborative processes and to identify affordances and constraints thereof. Our goal is to view
children's collaborations from their own perspectives and establish multiple indicators of effectiveness.

Employing Quantitative and Qualitative Methods to Analyze Collaborative Process in a
Computer-Mediated Setting at Three Levels
Hans Spada & Nikol Rummel (University of Freiburg, Germany)

         In our assessment of collaborative process we distinguish between three levels of analysis: (1) a macro
level, assessing the coordination of joint work, (2) a micro level, assessing the communication, and (3) the
domain- related content and quality of the collaboration. To gain information about the collaborative process at
these levels, we  have taken  three approaches:    First, on  the basis  of log-files the  activity  patterns of  the
collaboration were analyzed. This analysis provided information about the pattern of individual and joint phases
of work. Secondly, video recordings and transcripts allowed an analysis of the dialogs at all three levels. For the
analyses of the macro and micro aspects of the dialogs, we developed a system of criteria drawing on empirical
findings of what aspects characterize good collaboration. The units of analysis were minutes (macro) and turns
(micro). The focus of the domain-related analysis was on "topics" arising within the dialog and their attributes
(relevance, depth of discussion etc.). A promising third approach has been taken by performing a multi-step
analytic procedure  which  combines  a more     holistic qualitative approach   (Mayring,  2003)  with    quantitative
elements. By means of this analysis, process dimensions relevant for a successful collaboration were identified.
The various   methods  to analyze  collaborative process   were   applied   and evaluated  in a study in   which  we
investigated the effects of instructional support measures to improve computer-mediated collaboration on a

                                                    24
sample of 36  dyads collaborating     for several hours  (Rummel  &     Spada, submittted). We  discuss     gains and
problems of the different approaches.

From Coding and Counting to Exploring and Understanding: Methodological Experiences in
Analyzing Collaborative Interactions with Shared Representations
Dan Suthers (University of Hawai'i at Manoa, USA)

       My    research is generally     concerned    with understanding      how  people collaborate      with  shared
representations. In a recent study, I wanted to see whether differences in features of representation of evidential
reasoning used by collaborators would influence their interactions. I predicted ways in which the representations
prompt consideration of evidential relations, and how the salience of represented ideas facilitates subsequent
reference to the ideas. Given these predictions, the most straightforward methodology was to code the talk and
actions of the participants, count up occurrences of each code, and compare means through statistical techniques
(Suthers & Hundhausen, 2003). Subsequently my colleagues and I used similar methods to compare the use of
shared representations in face-to-face and online modes of interaction (Suthers, Girardeau, & Hundhausen, 2003).
The quantitative methodology was valuable for establishing the presence of predicted phenomena, but did not
facilitate an understanding of how shared representations are used to mediate collaboration. For that question, a
data-driven qualitative methodology is more appropriate, as the objective is to identify and understand what is
there rather than to test a theoretically derived hypothesis. We are presently engaged in a micro-level analysis of
individual collaboration episodes to understand how online participants collaborate through their manipulations of
a graphical evidence  map and distribute     their collaboration across    graphical and linguistic representations
("chat"). In the panel presentation, I will summarize how the different kinds of research questions led to choice of
methodologies, and will elaborate on our use of visualizations of transactions in the latter analysis.

Assessing Quality Features of Online Contributions: Bringing Microanalysis of Written Texts
Together With Participants' Subjective Perceptions.
Rainer Bromme, Regina Jucks, & Anne Runde (University of Münster, Germany)

       Research on text-based computer mediated communication and cooperation mainly treats participants'
contributions as utterances or speech acts, using theoretical frameworks of research on verbal interaction. In
contrast we will argue that this kind of communication produces written artifacts. We start with a discussion of
methodological implications of these different perspectives emphasizing the blind spots and the focus of both
views. To regard contributions in a text-based scenario both as text as well as utterances, is all the more important
when communicating partners differ tremendously with regard to their knowledge background. This will be
exemplified by data collected in a research project on expert-layperson interactions in medical advice scenarios.
Using methods that have been developed in educational psychology to assess the quality of instructional materials
we analyzed experts' written explanations. In addition to identifying text features that indicate text quality, this
research tradition has invented readability scores and comprehensibility ratings, mostly based on theoretical
assumptions about the impact of 'objective' text features on learning and understanding. We have developed
methods that focus on readers' subjective perceptions of texts and their assumptions about authors' intention.
Based on these kinds of data, predictions can be made regarding the impact of specific text characteristics on
recipients' perception of text features in computer mediated settings.

It is More Than Just One Nut to Crack: A Multidimensional Approach to Analyzing Collaborative
Knowledge Construction in Computer-Supported Learning Environments
Frank Fischer, Armin Weinberger (University of Tübingen, Germany)
& Heinz Mandl (University of Munich, Germany)

       Recent studies on technology-supported collaborative knowledge construction have underlined that we
face a multi-faceted methodological problem in this area of research. In a series of experimental studies, we
addressed this problem using a multi-dimensional approach to analyzing the written argumentative discourse of
groups with different cooperation scripts. In analyzing argumentation we were concerned with the structure of
single arguments as well as the dynamics of discussions (e.g., argument-counterargument-reply). Moreover, we
analyzed the social modes of co-construction, i.e., the extent to which these argumentative activities are conducted
in a transactive way, in which learning partners mutually refer to the others contribution (as opposed to a less
transactive mode where learners rather work individually while being in a group setting). As units of analysis for

                                                      25
the coding we used segments gained in a propositional analysis. The qualitative data were quantified to serve as
basis of comparison between the different experimental conditions. Moreover, qualitative graphical discourse
analyses were conducted leading to case studies to better understand the argumentative dynamics of the online
discussions. The measures proved both, reliable with respect to inter-rater agreement as well as sensitive to the
different   kinds of   support   for collaborative      knowledge      construction    realized  in the   experimental    settings.
However, like in other studies of collaborative knowledge construction, the relation of process indicators to
collaborative outcomes is high but their relations to individual learning outcomes are relatively modest. We
discuss methodological and theoretical explanations of the results as well as their consequences for the analysis of
collaborative knowledge construction.

Discussant
Pierre Dillenbourg (École Polytechnique Fédéral de Lausanne, Switzerland)

References
Ching, C. C., Kafai, Y. B., & Marshall, S. (2000). Spaces for change: Gender and technology access in collaborative software
          design. Journal of Science Education and Technology, 9, 45-56.
Chinn,  C.  A., O'Donnell,   A. M.,  & Jinks,    T. S. (2000). The  structure of  discourse in  collaborative  learning. Journal of
          Experimental Education, 69(1), 77-97.
Guribye, F. & Wasson, B. (2002). The ethnography of distributed collaborative learning. In G. Stahl (Ed.), Computer support
          for collaborative learning: Foundations for a CSCL community. Proceedings of CSCL 2002 (pp. 637-638). Mahwah,
          NJ: Lawrence Erlbaum Associates.
Gutiérrez, K. D., Baquedano-López, P., & Tejeda, C. (1999). Rethinking diversity: Hybridity and hybrid language practices in
          the third space. Mind, Culture and Activity, 6(4), 286-303.
Hammersley, M. (1992). What's wrong with ethnography. London: Routledge.
Jordan, B., & Henderson, A. (1995). Interaction analysis: Foundations and practice. Journal of the Learning Sciences, 4(1), 39-
          103.
Leitão, S. (2000). The potential of argument in knowledge building. Human Development, 43, 332-360.
Mayring,   P. (2003).  Qualitative   Inhaltsanalyse    [Qualitative  content  analysis]. Grundlagen    und  Techniken (8. Aufl.).
          Weinheim: Beltz.
Pilkington, R. M. (1999). Analysing educational discourse: The DISCOUNT scheme (Technical Report No. 99/2). Leeds, UK:
          University, Computer Based Learning Unit.
Reffay,  C. &   Chanier,  T. (2003). How  social    network  analysis  cam help   to measure  cohesion  in collaborative  distance-
          learning. In B. Wasson, S. Ludvigsen & U. Hoppe (Eds.), Designing for change in networked learning environments.
          Proceedings of the International Conference on Computer Support for Collaborative Learning (CSCL) 2003 (pp.
          343-352). Dordrecht, NL: Kluwer Academic Publishers.
Rummel, N., & Spada, H. (submitted). Learning to collaborate: An instructional approach to promoting collaborative problem-
          solving in computer-mediated settings.
Rummel, N. & Spada, H. (in press). Sustainable support for computer-mediated collaboration: How to achieve it and how to
          assess it.  In R.  Bromme, F.  W. Hesse       & H.  Spada,   Barriers and    biases in  computer-mediated      knowledge
          communication and how they may be overcome. Dordrecht, NL: Kluwer Academic Publishers.
Saxe, G. B.   (1991). Culture  and  cognitive development:     Studies in mathematical   understanding.   Hillsdale, NJ: Lawrence
          Erlbaum Associates.
Soja, E. W. (1996). Thirdspace: Journeys to Los Angeles and other real-and-imagined places. Malden, MA: Blackwell.
Strauss, A., & Corbin, J. (1998). Basics of qualitative research: Techniques and procedures for developing grounded theory
          (2nd ed.). Thousand Oaks, CA: Sage.
Suthers, D.,  Girardeau,  L. &  Hundhausen,    C.   (2003). Deictic roles of  external representations  in face-to-face  and online
          collaboration.  In B. Wasson,   S.  Ludvigsen     &  U.  Hoppe  (Eds),  Designing   for change   in  networked  learning
          environments.   Proceedings  of    the International  Conference   on  Computer   Support   for  Collaborative  Learning
          (CSCL) 2003 (pp. 173-182). Dordrecht: Kluwer Academic Publishers.
Suthers, D. & Hundhausen, C. (2003). An empirical study of the effects of representational guidance on collaborative learning.
          Journal of the Learning Sciences, 12(2), 183-219.
Toulmin, S. (1958). The uses of argument. Cambridge: Cambridge University Press.
Wang,   X.  C.  (2003).  Third  space: Sharing      a computer  in a  first-grade classroom.   Unpublished    doctoral dissertation.
          University of Illinois at Urbana-Champaign.
Wang, X. C., & Ching, C. C. (2003). Social construction of computer experience in a first-grade classroom: Social processes
          and mediating artifacts. Early Education and Development, 14(3), 335-361.
Whittaker, S. & O'Conaill, B. (1997). The role of vision in face-to-face and mediated communication. In K. E. Finn, A. J.
          Sellen  &   S. B.  Wilbur  (Eds.), Video-mediated    communication      (pp. 23-50).  Mahwah,    NJ: Lawrence   Erlbaum
          Associates.
Wortham, D. W. (1999). Nodal and matrix analyses of communication patterns in small groups. In C. Hoadley & J. Roschelle,
          Proceedings of CSCL `99 (pp.681-686). Mahwah, NJ: Erlbaum.

                                                               26
