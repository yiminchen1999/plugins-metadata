            Designing a video-mediated collaboration system
                                    based on a body metaphor

  Hiroshi Kato1), Keiichi Yamazaki2), Hideyuki Suzuki1), Hideaki Kuzuoka3),
                                Hiroyuki Miki4), and Akiko Yamazaki5)
1) C&C Media Research Laboratories, NEC Corporation, 2)Faculty of Liberal Arts, Saitama University, 3)Institute
   of Engineering Mechanics, University of Tsukuba, 4)Media Laboratories, Oki Electric Industry Co. Ltd., and
                                          5)Nursing School of Douai Hospital

                      Abstract                                  transmission of hand gestures and the question of eye
Optimum arrangement of communication resources for              contact. Some      CSCW    systems,     such  as VideoDraw
a distance education   system    to support    collaborative    (Tang et al., 1990) and ClearBoard (Ishii et al., 1992),
learning,   including    hand-manipulation     of  physical     have provided solutions in this respect. However, if one
objects,  was  empirically      investigated.  The  authors     wants to use them in remote support for collaborative
propose a `body metaphor' concept, which follows the            work     involving    manipulation   of   physical   objects,
ordinary body arrangement in everyday instruction. It           which requires allowing for the objects to be spread out
allows: (1) to display instructor's pointer; (2) to display     in  a three-dimensional    space   and  for  participants to
instructor's face;   (3)  to display  views    of  learner's    move around,     they  show   clear  limitations.   In  these
orientation; (4) to arouse learner's awareness of being         cases, it is necessary to devise systems for supporting
watched   by   the   instructor;    and  (5)    to  dispose     remote    collaboration  between     many    participants in
communication resources apart enough so as to clarify           different positions and different environments (Kuzuoka
the learner's orientation.                                      et al., 1992, 1994, 1995)      An    essentially  flat  work-
Comparative experiments revealed that body metaphor             support system like ClearBoard cannot be turned into
setting  supported   smoother     collaboration    than  the    one   that  supports   collaboration   in   three-dimensional
conventional face-to-face metaphor setting.                     space; and it is physically impossible to accomplish
                                                                perfect eye contact if many participants are allowed to
Keywords-- distance education, CSCW, collaborative              move around in the work space.
learning, ethnomethodology, interaction analysis, video             The purpose of this research is not simply to point
conference                                                      out the physical limitations of these CSCW systems,
                                                                but   it is   to try  to   delineate clearly   the   intrinsic
Introduction                                                    limitations. We refer to the concept underlying in the
Most of the distance education systems in use today             distance education systems in use today as the `face-to-
have been built on the basis of a bi-directional video-         face metaphor' (Figure 1), which ultimately aims          to
mediated    tele-conference  system,    i.e.,  views  of  a     create an environment in which distant people talk as if
lecturer's face and/or learning material are transmitted to     in close face-to-face conversation. However, it is still
the learners' sites, and vice versa. In such a system,          not   clear enough     how  the  face     view   is  used in
however, it has been pointed out that gaze, gestures,           collaboration, why it is helpful, and what arrangement
and other body movements are generally not as effective         of    audio/visual     resources     is     appropriate   for
as in normal face-to-face communication _iHeath et al.,         collaboration.
1991, 1992). Therefore, the prevailing systems are not              We     have   performed  some    remote    collaboration
sufficient,  particularly   for conducting     collaborative    experiments      with AlgoBlock,     a  computer    tool  for
learning in which non-verbal communication plays an             collaborative    learning,  by   deploying     cameras    and
important role, such as in a scientific experiment or in        monitors in distinct spatial arrangements. As          regards
a physical exercise, although they may be acceptable            the use    of several   cameras  and    monitors    we   were
for an education style like lectures in which symbolic          influenced by the work of Gaver and Heath on Multiple
(verbal  or  visual) information    transmission    from  a     Target Video (MTV)       (Gaver  et    al., 1993,   Heath  et
teacher to learners is dominant.                                al.,1995) who analyzed which pictures         are   important
   Research in computer supported cooperative work              and   what    kind of  image   people     pay  attention  to.
(CSCW) has studied this problem mainly in regard to             However, our pilot study conducted beforehand revealed

CSCL `97 Proceedings                                 Page 142                                             December 1997
                                 Figure 1. The face-to-face metaphor concept
that many  cameras   and   monitors could   often cause      analyzed   how    instructors  and   learners     positioned
user's confusion. Too many resources were not always         themselves    during  instruction.  When     the  instructor
beneficial, so how   to   configure those resources has      points at an object, the following points seem to be
become our concerns. We, therefore, concentrate on the       important: (1) the learners should be able to see the
question of how the images on monitors       of various      instructor's pointer; (2) the instructor should be able to
parts of the body (face, hands, and so on) should be         see that the learners are orienting themselves towards
arranged in the work space. That is, our aim is to find      the pointed object as well as the pointer, when they are
out how people use body images distributed in various        observing the instructor's pointing; (3) the instructor
ways in a shared work-space as resources for reciprocal      should be able to reassure     the  learners  by  words  or
actions. Accordingly, we want to establish the validity      actions  that the  instructor  is  aware of   the   learners'
of redistributing the body images and bodies themselves      orientation; (4) the learners should be able to see the
in a way based on a body metaphor.                           face of the instructor, when they want to know how the
                                                             instructor is evaluating their    behavior   or  when   they
Body metaphor concept                                        want to  draw    the instructor's  attention;   and (5) the
From   ethnomethodological    studies  on   cooperative      instructor  should   be   able  to  notice    the   learners'
work, by Heath     (1986),  Goodwin  (1981), Nishizaka       orientation   toward  the instructor   himself/herself   as
(1991), Yamazaki (1994), and Yamazaki et al. (1996),         well.
we know that even more important than the face-to-face           Conditions (1) through (5) are achieved naturally,
view is to make it possible that the instructor can see      as long as the instructor's pointer is in front of both
the learners are looking at what he or she is pointing       the learner and the instructor and the learner is in the
out and that   the learners can become    aware of  this     instructor's field of vision. Here again it is important
circumstance. We realize that this reflexive awareness is    that the instructor's hand and face are separated enough
accomplished through the interaction and positioning of      to make it possible for the instructor to discern which
bodies in a shared space.                                    the learner   is watching,  the   hand or    the  face. We
     Based on a pilot study we conducted beforehand, we      considered  how   to  apply   this physical   arrangement,

                                       Figure 2 The body metaphor concept

CSCL `97 Proceedings                              Page 143                                          December 1997
occurring in everyday instruction, to the arrangement of      movements, such as in a scientific experiment or in
monitors     and    cameras     in    a    video-mediated     physical training.
communication     system.   We   attempted   to  use   the
ordinary body    arrangement    as a  metaphor    for  the     Workspace setting
placement of cameras, the face view, and hand-gesture         In the experimental workspace of both the instructor's
monitors (Figure 2), and named it `body metaphor'.            and the learners' sites, the arrangements of
                                                              communication resources, such as video monitors,
Experiments                                                   video cameras, and AlgoBlocks, were as follows.
                                                                  The learners' site had three cameras (two in front of
Task                                                          the learners and one on the ceiling) and three monitors.
We used AlgoBlock (Suzuki et al., 1995) as the subject        One of the front cameras was able to     pan,   tilt, and
matter   for  the   remote   collaboration   experiments.     zoom according to remote control     by  the   instructor.
AlgoBlock    is  an educational  programming     language     The other, referred to as  the in-context    camera,  was
incorporated  into  physical  blocks   (Figure  3).   Each    fixed in such a way as to simultaneously capture the
command corresponds to a kind of block and the learner        table used for assembling AlgoBlocks, the monitors in
can construct a program by connecting blocks to each          the back of the room, and all the learners. The ceiling
other by hand. Learners are supposed to build a simple        camera captured all the learners and   the   whole work
program for guiding a submarine on a CRT screen to            space. The three monitors showed the instructor's face,
its destination.                                              his/her hand gestures, and the AlgoBlock screen. The
     AlgoBlock    was devised   as  a tool   to draw   the    in-context  camera  and  the remote  controlled  camera
originally individual work of writing a program into          were set in the vicinity of the face-to-face view. The
the sphere of collaboration. By giving the commands of        monitor, referred to as the hand-gesture view, showed
the programming language, which are usually hidden            image from hand-gesture camera in instructor's site, in
inside the computer, a physical form such as blocks,          which    instructor's   hand-gesture   appeared.      The
the work of programming is turned into an overt action        instructor's voice was produced from the monitor with
involving visible body    movements.     The   movements      the face-to-face view.
can  be  observed    by   other  participants.  Such   an         The instructor's site had two cameras: one, referred
observation can then be reciprocally used as a resource       to  as  the  hand-gesture  camera,   for capturing    the
in cooperative work. By transforming a mental work            instructor's hand gestures on the hand-gesture monitor
into  physical   actions,  AlgoBlock     can   enrich  the    and the other, referred to as the face-to-face camera, for
resources of collaboration.                                   the face of the instructor. Three monitors were placed in
     There   are two  reasons   why   we have   employed      front of the instructor. On the left, from the instructor's
AlgoBlock for this study. First, because of the reasons       point of view, was a    personal computer     display  for
above, AlgoBlock makes it easy to analyze how the             remote control of the camera mentioned earlier, with
collaboration proceeds. That is, the resource used by the     the view taken by that camera.     The   monitor  in  the
learners to achieve the goal of collaboration becomes         middle, in the vicinity of which the face-to-face camera
visible to an outside observer as well as to the learners     was set, showed the view of the in-context camera. The
themselves. Second, the task using AlgoBlock can be a         monitor to the right, referred  to as  the   hand-gesture
good model of collaborative work involving physical           monitor,   could be   switched between   the   in-context

                   Figure 3. An example of the AlgoBlock session (left) and the screen image (right)

CSCL `97 Proceedings                                Page 144                                        December 1997
                       Figure 4. Experimental setting of pattern-2 (body metaphor)

                     Figure 5. Experimental setting of pattern-1 (face-to-face metaphor)
camera, the remote controlled   camera, the  ceiling
camera, and the AlgoBlock screen. Since this monitor       ·   Pattern-1: This setting was taken after the tele-
was viewable in the hand-gesture camera, learners could        conference-based distance education systems, i.e.,
observe the instructor's pointer on something showing          the face-to-face metaphor. The front of the room
on the hand-gesture monitor.                                   had the face-to-face view (right) and the hand-
                                                               gesture view (left). The AlgoBlock screen was
                                                               placed at the back of the room (Figure 4). In short,
                                                               all the devices for communicating with the
                                                               instructor were gathered on one side of the room.

                                                           ·   Pattern-2: This setting was based on the body
                                                               metaphor. Only the face-to-face view was in front,
                                                               and the hand-gesture view and the AlgoBlock
                                                               screen were placed at the back (Figure 5).

CSCL `97 Proceedings                         Page 145                                           December 1997
                             Table 1. Transcript from pattern-2 setting experiment

                                                              to the instruction.
In pattern-2, we paid special attention to the following
    points:                                                    Other conditions
                                                                  The experiment was conducted with four groups:
1)  At the learners' site, the hand-gesture view should       each group consisted of one instructor and two learners.
    be positioned opposite the instructor's face-to-face      All subjects were university students. An experimental
    view.                                                     session for each group took one hour in which both
                                                              patterns were tried. Experimenters taught the instructors
2)  The in-context camera should be positioned so that        how to use AlgoBlock in advance.
    an instructor could see the hand-gesture view in the
    context of the learner's site.                            Observation
                                                                  By taking   a   close look  at how   the        monitors
    The only difference between these two settings was        transmitting  body   images   were  mutually        used as
the location of the hand-gesture view in the learner's        resources for  collaboration  and  communication,        we
site. It addresses the issues of whether the instructor       noticed the following.
could see his/her own hand gestures in the context of
the learner's site and whether      the instructor   could     Observableness of learner's orientation
clearly determine  which  of views      the  learner was      In pattern-2 when giving   directions, instructors     used
looking at. Pattern-2 make it possible for the instructor     their in-context view to check how learners watched the
to  check   whether  the  learners    were   looking   at     hand-gesture view (Figure 6).
instructor's hand-gesture and how they were responding            When   the  instructor   gave  particularly      detailed

     Figure 6. Scenes from the experiment using pattern-2 setting (left: instructor's site, right: learners' site
        shown in the in-context view). Face-to-face view is next to the camera, and hand-gesture view and
                                     AlgoBlock screen are facing the camera.

CSCL `97 Proceedings                               Page 146                                        December 1997
directions,  she alternatively   viewed  the  hand-gesture        L5:      Yes.
monitor   and  the   in-context  view.   At this time    the      I4:      This, in the first place.
instructor made sure that, while giving instructions, the         L5:      Ah, Yes.
learner was watching the pointing finger (Table 1).               I4:      This is a goal, a goal.
     In this transcript, time proceeds from left to right.        L4:      Well, does my hand show?
Here we had two learners L2 and L3 at the learners'               Table 2. Transcript from pattern-1 setting experiment
site, and an instructor I1 at the instructor's site. The
horizontal rows beginning with the subjects symbols                   The cause     of the difficulty  was    that   instructors
give    utterances   in   Japanese,    and   the  English         could not monitor how learners       were   watching     their
translations appear in parentheses below. The direction           pointing. Because the hand-gesture      view    was   located
of gaze is recorded above the dialog, where ---- indicates        beside the in-context camera and near the face-to-face
continuation. AL and H stand for the AlgoBlock screen             view, instructors were not able to know whether or not
and  the   hand-gesture    view   at   the  learners'   site,     learners were showing recipiency. In this way, pattern-1
respectively, HM and C are used for the hand-gesture              caused communicative asymmetry (Heath et al., 1991,
monitor and the in-context view at the instructor's site,         1992), which occurs in video-mediated communication.
and P indicates that the instructor was pointing at the
hand-gesture monitor.Instructorsascertained,beforegivingdirections,whether or not the learner took a posture of watchingthe hand-gesture view. When learners did not take up awatching position, instructors used the indexical word`kono'(these) to get the learners' attentionandmakethemwatchthehand-gestureview.Instructorsalsointerrupted instruction when they noticed that learnerswere not watching the hand-gesture view.We discovered that, in this kind of setup (pattern-2), when the learner watches the hand-gesture view, theposture indicates `recipiency' (Goodwin, 1981, Heath,1986), which is a social display to show that one isready to receive information. It turned out that throughthe in-context view in pattern-2 instructors monitoredwhetherlearnerswereshowingrecipiencyforinstruction.Inpattern-1(Figure7),bycomparison,itwasdifficultforinstructorstomonitorrecipiency.Asshown in Table 2, the instructor (I4) asked `Can yousee my hand?' `Does my hand show?' and even whenthe learner (L5) affirmed `Yes, I can.', these questionswereoftenaskedrepeatedly.Instructorsalsooftenrepeated instructions concerning the same object usingdemonstrative pronouns like `kore wo'(this) and phraseslike `kore wo koko ni'(this here). Moreover, instructorsexaggerated their pointing actions on the hand-gesturemonitor by moving their hands vigorously.Awareness of an instructorWheninpattern-2theinstructormovedorplacedhis/herfingercontinuouslyonthehand-gesturemonitor, it was utilizedasareciprocalresourceforinteraction. As shown in the transcript (Table 1), whenthe learner (L2) looked at the hand-gesture monitor, andsaid `hai (yes)', the instructor (I1) removed her fingerand started to point at another object. The movement ofthe instructor's finger showed that she understood thelearner's action.It can be said that the instructor's finger movementbecomesareciprocalinstrumentindicatingthattheinstructor was monitoring the learner's actions. This,coupled with the instructor's face-to-face views and theinstructor'soralresponse,constitutesavaluableresource for the learner to monitor that the instructor iswatching the learner's action. In other words,itcanenhance the learner's awareness of the instructor.Incontrasttothis,inpattern-1,theinstructorsometimes removed his/herfingerfromthemonitorbefore the learners displayed their understanding of whatthe instructor was pointing to, or kept it on the screenfor an unnecessarily long time. These were because theinstructor was not aware of whether or not,orhowcarefully, thelearnerswerewatchinghis/herfinger.Conversely, whenthelearnerstriedtoascertaintheinstructor's response by looking at the hand-gesture andthe face-to-face views, this did not always go smoothly
I4:       <watching in-context view and hand-gesturemonitor alternatively>either, since the instructor did not know which of theviews (hand-gesture or face-to-face)thelearnerswere
          At first, can you see my hand?                          looking at.
          <looking at in-context view>
L5:       Ah, Yes, I can.                                         Surrogate for an instructor
I4:       Oh, you can.                                            When, in pattern-2, learners tried to ask a question, or
I4:       These blocks can be connected both in row and in        when the AlgoBlock operation had been           successfully
column.                                                           completed, they often looked at the face view to check
L5:       Yes.                                                    the instructor's reaction and approval.
I4:       And, what can I say, this submarine, here can you
see a submarine, can't you?

CSCL `97 Proceedings                                  Page 147                                             December 1997
                                   Table 3. Transcript from pattern-2 setting experiment

     Table 3 shows a transcript from pattern-2 when the          instructor could do. Therefore, it sometimes happened
learner (L6) succeeded in reaching a goal. As shown in           that learners   began to talk    regardless   of instructor's
the transcript, the instructor (I7) was looking at either        state of attention, although     the trouble    was   restored
the hand-gesture monitor (HM) or the in-context view             easily by conversation.   Learners    tended   to  anticipate
(C), but which view they were watching was not clear             that the instructor was watching their actions at any
in the videotape data, and the learner was looking at the        time, while this was not always the case.
AlgoBlock    screen (AL)   to  check  the    result of  his          This asymmetry in system design arises from the
program execution. As soon as he realized that the trial         difference in role between an instructor and a learner,
was successful (when the sound effect representing the           since we presupposed     an  educational    situation   rather
submarine's arrival to the goal (Snd) started), he said          than equally collaborative work.
something that sounded like an expression of success                 This problem may be solved by introducing a new
and snapped his fingers in both hands. Then, he turned           in-context view at the learner's site      just  like at  the
his face to the face-to-face view (FV). At that moment,          instructor's site. However, adding more monitors may
the instructor said "Congratulations!." In this way, the         possibly not be as effective as we suppose, judging by
boundary    of  a   series  of   activities  was    marked       the following problem.
interactively by those actions.                                      Another problem was the instructor's confusion in
     There  are   several  relevant  timings   when     the      utilizing  communication      resources;    the    instructor
instructor could give congratulations: at the       moment       sometimes pointed     outside the    hand-gesture    camera's
the submarine arrives at the goal,    after  the    learner's    capture range   on  the  hand-gesture    monitor,    or  even
remark, or after the sound effect. As well as these, this        pointed at a monitor that learners could not see, and the
observation proved that the learner's action of turning          same kind of confusions may possibly happen also at
his face to the instructor's face view could also provoke        the learner's site. The reason was that it was not always
the instructor's reaction. In this sense, it can be said         clear what information was transferred to the other site,
that the instructor's face view in the learner's site of         although it was possible for the instructor to know, if
pattern-2   played   the    role   of    the   instructor's      he/she carefully watched the in-context view. However,
representative, or surrogate. This happened because in           it could be troublesome for the instructor to have to
pattern-2 the face view was far enough apart from the            watch another monitor in order to see how his/her own
other resources for the instructor to notice the learner's       fingertip showed    on   the  hand-gesture    view    in  the
orientation to it. In this fragment, by using the face-to-       learner's site.
face view   as  a   surrogate,  participants  interactively          A possibility is that there were too many resources
marked the activity's boundary, and thus to achieve the          to  utilize, or  that the   relationship    among     various
end of a session successfully.                                   communication     resources   was    too    complicated   to
     In pattern-1,  by contrast,    reply,   reaction,  and      understand. Therefore,   closer  examination      to  validate
evaluation were not always immediately performed. The            the  necessity   of   individual resources     and/or    more
instructor,  not    knowing    learner's    orientation  to      sophisticated integration of those resources needs to be
himself/herself, often failed to catch the proper time to        investigated in our future work.
intervene in a learner's activity.
                                                                 Conclusions
Remaining problems                                               It is well known that in everyday communication the
However, there were still some problems common to                relative position of person and person, or person and
both patterns.                                                   machine,   plays  an  important    role  (Goodwin,      1981,
     One of the problems was that learners could not             1995).  One     may assume    that   since  communication
know which views the instructor was oriented towards.            takes place using the bodies of individuals, it depends
There was an asymmetry in communication resources                strongly on the deployment       of  those  bodies.   If one
between learners and the instructor, i.e., learners could        wants     collaboration   through       a     video-mediated
not observe the instructor's in-context view, while the          communication     system  to  occur   in    a natural    way,

CSCL `97 Proceedings                                 Page 148                                             December 1997
spatial arrangement of functional resources originating          Heath,   C.,  Luff,   P.,   and   Sellen,   A.  (1995):
from body part functions becomes a fundamental issue.                "Reconsidering   the  Virtual Workplace:   Flexible
Consequently, we have proposed the concept of a body                 Support   for  Collaborative  Activity",   Proc.  of
metaphor       in     configuring      a     video-mediated          ECSCW'95, 1995, pp. 83-99.
communication system.                                            Ishii, H. and Kobayashi, M. (1992): "ClearBoard:      A
    By    deploying    three   communication       resources         Seamless    Medium    for    Shared   Drawing    and
(objects for manipulation, face view, and hand-gesture               Conversation with Eye Contact", Proc. of CHI'92,
view) on the basis of the body metaphor, it became                   1992, pp. 525-532.
clear which    of  them    learners   were   orienting  to.      Kuzuoka,     H.     (1992):      "Spatial     Workspace
Specifically, the instructor could see learners looking at           Collaboration:    SharedView      Video    Supported
the instructor's pointing. Hence, the     instructor  could          System   for   Remote   Collaboration   Capability",
recognize  the  learner's recipiency, and    learners  were          Proc. of CHI'92, 1992, pp. 33-42.
aware of instructor's observation. In addition, it turned        Kuzuoka,  H.,  Kosuge,    T., and  Tanaka,  M.  (1994):
out that   the learner  could    use the  face  view   as a          "GestureCam:    A   Video  Communication    System
surrogate  of  the    instructor to  call   the  instructor's        for Sympathetic Remote Collaboration", Proc. of
attention and to interactively mark activity boundaries.             CSCW'94, 1994, pp. 35-43.
    We have been working         on  the  field study  of a      Kuzuoka, H. Ishimoda, G., Nishimura, Y., Suzuki, R.,
classroom at school and a workplace of emergency care                and Kondo, K. (1995): "Can the GestureCam be a
for several years. Taking such findings into account in              Surrogate?", Proc. of ECSCW'95, 1995, pp. 181-
addition to the findings discussed here, we will try to              196.
refine the  body-metaphor    concept   by   figuring  out a      Nishizaka, A. (1991): The Social Order of Therapy II,
better balance between understandability and richness of             Mejigakuin Ronsou, 475, Meijigakuin University,
communication resources, so that we can develop more                 (in Japanese).
practical systems for remote collaborative learning or           Suzuki,  H.  and  Kato,  H.   (1995): "Interaction-Level
remote medical procedures.                                           Support for Collaborative Learning: AlgoBlock-An
                                                                     Open     Programming      Language",      Proc.   of
Acknowledgments                                                      CSCL'95, 1995, pp. 349-355.
The authors would like to thank Dr. Tammo Reisewitz              Tang, J., and Minneman, S. (1990): "VideoDraw: A
and Mr. Ron Korenaga for their contributions to this                 Video Interface for Collaborative Drawing", Proc.
work.  We   also   thank   Dr.   Graham     Button for  his          of CHI'90, 1990, pp. 313-320.
insightful comment on this paper. This research was              Yamazaki, K. (1994): The Pitfalls of a Beautiful Face--
supported by grants from     Grant-in-Aid    for  Scientific         Ethnomethodological       Studies   on    Sexuality,
Research   (A)  07309018     (Head   Investigator:  Keiichi          Harvest-sha. Tokyo, (in Japanese).
Yamazaki),     1996      CASIO       Science     Promotion       Yamazaki,    K.,     and    Yamazaki,      A.   (1996):
Foundation,       and   1996      the     Telecomunication           "Ethnomethodology          of       discrimination--
Advancement Foundation (TAF).                                        Organization   of   Category  and   Organization  of
                                                                     Situation", in Series: Contemporary Sociology 15,
References                                                           Iwanami-shoten, Tokyo, (in Japanese).
Gaver, W., Sellen, A., Heath, C., and Luff, P. (1993):"One is not enough: Multiple Views in a MediaAuthor's Address
    space", Proc. of INTERCHI'93, 1993,           pp.  335-      Hiroshi Kato and Hideyuki Suzuki: C&C Media
    341.                                                         Research Laboratories, NEC Corporation, 1-1,
Goodwin,    C.    (1981):  Conversational    Organization:       Miyazaki 4-chome, Miyamae-ku, Kawasaki, Kanagawa,
    Interaction between speakers and hearers, Academic           216, Japan. kato@ccm.cl.nec.co.jp,
    Press, New York.                                             hideyuki_suzuki@ccm.cl.nec.co.jp.
Goodwin, C. (1995): "Seeing in Depth", Social Studies            Keiichi Yamazaki: Faculty of Liberal arts, Saitama
    of Science 25, pp. 237-274.                                  University, 255 Shimo-okubo, Urawa, Saitama 338,
Heath,  C.  (1986):   Body   Movement       and  Speech   in     Japan. yamakei@sacs.sv.saitama-u.ac.jp.
    Medical Interaction, Cambridge University Press,             Hideaki Kuzuoka: Institute of Engineering Mechanics,
    Cambridge.                                                   University of Tsukuba, 1-1-1, Tennoudai, Tsukuba,
Heath, C., and Luff, P. (1991): "Disembodied Conduct:            Ibaraki, 305, Japan. kuzuoka@kuzuoka-
    Communication through video          in  a  multi-media      lab.esys.tsukuba.ac.jp.
    environment",      Proc.  of     CHI`91,    1991,  New       Hiroyuki Miki: Media Laboratories, Oki Electric
    Orleans, pp. 99-103.                                         Industry Co., Ltd., 550-5, Higashiasakawa-cho,
Heath,  C., and    Luff,  P. (1992):   "Media    space  and      Hachioji, Tokyo, 193, Japan. hmiki@hlabs.oki.co.jp.
    communicative          asymmetries:         preliminary      Akiko Yamazaki: 4-3, Haruno 1-chome, Oomiya,
    observation of video-mediated interaction", Human            Saitama, 330, Japan.
    Computer Interaction, 7(3), pp. 315-346.

CSCL `97 Proceedings                                  Page 149                                         December 1997
