         Global Text Processing in CSCL with Learning Protocols:
                   A Coding Scheme for Eye Movement Analyses
                Michael Oehl, Hans-Rüdiger Pfister, Anja Gilge, Leuphana University of Lüneburg,
                                  Wilschenbrucher Weg 84, 21335 Lüneburg, Germany
                    Email: oehl@uni-lueneburg, pfister@uni-lueneburg, anja.gilge@gmx.de

         Abstract: Although eye movements have proved to be a valuable source of information for
         the study of cognitive processes, they are hardly regarded within CSCL. A crucial reason for
         this is the lack of suitable observational schemes. To bridge this gap, a coding scheme for
         global  text    processing     in   CSCL   on    the base  of   established  well-defined   eye   movement
         measures is proposed. The scheme was evaluated in a study on explicit references in CSCL
         with learning protocols.

Introduction
         Computer-supported collaborative learning (CSCL) is based upon successful communication, i.e., the
collaborators   should   understand       each  other's   contributions   to  the learning   discourse    and  build  a  shared
understanding of the content. Due to the medial properties of synchronous chat communication, a frequently
reported negative  phenomenon          is the somewhat     "chaotic"   discourse  structure, i.e., often  the group   discusses
several topics in parallel, so apparently related turns are, in contrast to spoken conversations, sometimes not
adjacent. Hence, chat-based communication usually suffers from deficits due to incoherence of contributions
and  related  problems    (e.g. Herring,      1999). Participants   are  frequently   not able  to identify   the relationships
among individual contributions ­ a phenomenon called co-text loss by Pimentel, Fuks, and de Lucena (2003).
To  improve   matters,   the   learning    protocol  approach     (Pfister   &  Mühlpfordt,  2002)   as   a special   variant of
scripted collaboration was suggested. Similar approaches have been developed (Kollar, Fischer, & Hesse, 2006).
The learning protocol approach can be viewed as a special variant of CSCL (Kollar, Fischer, & Hesse, 2006;
Pfister & Mühlpfordt, 2002). It proposes that synchronous chat-based discourses can be improved by controlling
learners' discourse interactions by implementing a set of discourse rules in the virtual learning environment.
These  sets  of  rules,  which    we   call   `learning   protocols', can    be regarded  as a  kind   of collaboration   script
controlled and moderated automatically by the learning system itself. Among other features, learning protocols
define the sequence of participants' contributions, they require to assign a contribution type (such as `question',
`explanation', etc.) to each contribution, and, most importantly, they require participants to explicitly indicate
the reference of their contribution. Learners indicate what the referred to element of the current contribution is.
This might be a previous contribution from the chat-history, or a fragment of some additional learning material,
such  as a   common      text,  images,      or diagrams      provided   by  the  learning  environment     accessible   for  all
participants. The  system      automatically     visualizes   the   referential  relation with  an   arrow.   As  a result,   the
relationship  of a contribution      to   previous  contributions   can   be  directly perceived   on  the  screen,   by simply
following the connecting arrows. Theoretically, these explicit references should increase the coherence of the
discourse and, as a consequence, improve global text processing, understanding and learning performance. In
previous studies   the   potential   benefits    of  learning   with   this  kind of   learning protocols   in contrast   to  an
unstructured chat discussion could be demonstrated for specific knowledge domains. Especially, it was found
that it is the referencing function, i.e., visualizing relationships among contributions or between a contribution
and  additional  fragments,     which     is of major   importance    with   respect  to  learning outcomes    (Mühlpfordt    &
Wessner, 2005; Stahl, Zemel, Sarmiento, Cakir, Weimar, Wessner, et al., 2006).
         However,   so     far it is   still unclear   in which   way    these  explicit  references influence    the cognitive
processing   of  learners  within    a  CSCL    setting   in  order to   provoke  higher  learning   results, as  reported.  We
suppose  that   explicit references     enhance    the  coherence   of   the learning  discourse   and therefore  simplify    the
learners' global text processing. This question is addressed in the current experimental study by means of eye
movement     analyses   to gain   indications    of  learners'  use   of explicit references.   Scince a  behavioural    coding
scheme for eye movement analyses of global text processing is lacking in the field of CSCL research, at first a
suitable one had to be developed for this purpose. In this paper the defined categorial coding scheme for eye
movement analyses will be introduced as well as preliminary results on learners' use of explicit references will
be reported.

Methods
         Students (N = 24; 18 female and 6 male) from different faculties and of different age (M = 23.17; SD =
4.17) volunteered   as    participants     in this  experimental    study.   Participants  were  randomly     assigned   to  two
experimental treatments, following an about 20 minutes long standardised learning discourse about the topic

                                                                                                                                    3-03
         `earthquakes' within a learning protocol environment, based on the Concert Suite® software. In the two different
         treatments    participants    were either provided    with   a  learning   discourse   including explicit  references    or   not.
         Within the treatment without explicit references, these were substituted by equal textual hints. Eye movements,
         as dependent variable, were recorded by the head-mounted eye-tracking device iView XTM HED® and encoded
         with the software Interact® (version 6.10.4). For the eye movement analysis a categorial coding scheme had to
         be defined.     Participants'  eye   movements   were    finally encoded      according   to two   information   categories:   i)
         behaviour and ii) point of interest. The first category i) behaviour comprised all possible behavioural actions of
         learners within the learning protocol scenario (reading, searching, browsing and writing). The definitions of the
         variables were based on significant and well-defined eye movement measures in terms of fixations and saccades
         (e.g. Radach     and  Kennedy,     2004). The   second    category    ii) point of  interest indicated   the point  within    the
         learning  protocol    environment,    the  i) behavioural    category     was  related to (e.g.  common     learning   material,
         discourse    contributions    within  the  chat-history,  etc.).    The   variables  within  each  category     were   mutually
         exclusive and the combination of two variables out of the two categories resulted in one definite eye movement
         code  for global     text processing.  Three   trained raters   encoded    the  recorded  eye  movements     according     to the
         developed categorial coding scheme. On average each participant's experimental session resulted in about 400
         definite eye    movement      codes. For  each category   of    the coding  scheme     high  inter-rater reliabilities could  be
         obtained:    i) behaviour   (M  =  0.86)  and  point   of interest   (M   = 0.91).  With    regard to the   guidelines   for  the
         collection and standardised analysis of eye movements proposed by Scott and Findlay (1993), the developed
         coding scheme in the current study meets the required quality standards of objectivity and reliability.

       Results
                   Results    showed    different  text  processing      between    the  two  experimental     treatments.   If   explicit
         references    were   provided,  learners  read  current   contributions    25%    more  frequently  t(46) =  5.339,    p < .001.
         Furthermore they spent on average 0.10 seconds per word more on reading the current contribution t(46) = 2.978,
         p = .005. Additionally explicit references caused learners to search the reference scope about 2.7 times more
         frequently t(46) = 9.67, p < .001 and to read it twice as long (M = 3.48s, SD = 1.82s) than without explicit
         references (M = 1.70s, SD = 1.20s), t(46) = 4.009, p < .001.

       Conclusion
                   Studies in research on CSCL usually gain their scientific findings from pre-/post-tests, video or logfile
         analyses.    Although     eye movements    have  proved      to be  a  valuable   source  of  information    for   the study   of
         cognitive    processes,   they are hardly  regarded    in the   field of  CSCL.    A crucial  reason  for  this  is the  lack  of
         suitable observational schemes. To bridge this gap, we proposed a categorial coding scheme for global text
         processing in CSCL on the base of established well-defined eye movement measures. The empirical evaluation
         showed    its   high objectivity   and  reliability. So   it could    serve as   an additional   approach    to lighten   CSCL
         processes. Besides, the experimental results of eye movements showed that explicit references caused a more
         intensified text processing among learners. Conclusions for the design of (chat-based) CSCL environments will
         be derived.

       References
         Herring,  S.    (1999).   Interactional  coherence    in  CMC.      Journal   of  Computer-Mediated       Communication,       4,
                   [http://www.ascusc.org/jcmc/vol4/issue4/herring.html].
         Hyönä, J., Lorch. R. F., & Rinck, M. (2003). Eye movement measures to study global text processing. In J.
                   Hyönä (Eds.), The Mind's Eye: Cognitive and Applied Aspects of Eye Movement Research (pp. 313-
                   334). Amsterdam: Elsevier.
         Kollar,  I.,  Fischer,  F., &  Hesse,   F. W.   (2006).   Collaboration     scripts  ­ a  conceptual     analysis.  Educational
                   Psychology Review, 18, 159-185.
         Pimentel, M. G., Fuks, H., & de Lucena, C. J. P. (2003). Co-text loss in textual chat tools. In P. Blackburn, C.
                   Ghidini, R. M. Turner & F. Giunchiglia (Eds.), Modeling and using context. Lecture notes in computer
                   science (Vol. 2680, pp. 483-490). Berlin: Springer.
         Pfister, H.-R.,   &  Mühlpfordt,     M.  (2002). Supporting     discourse   in  a synchronous    learning   environment:      The
                   learning protocol approach. In G. Stahl (Ed.), Proceedings of CSCL 2002 (pp. 581-589). Hillsdale, NJ:
                   Erlbaum.
         Radach, R. & Kennedy, A. (2004). Theoretical perspectives on eye movements in reading: Past controversies,
                   current issues, and an agenda for future research. European Journal of Cognitive Psychology, 16, 3-26.
         Scott, D., & Findlay, J.-M. (1993). Visual search and VDUs. In D. Brogan, A. Gale & K. Carr (Eds.), Visual
                   search 2 (pp. 301-307). Philadelphia, PA: Taylor & Francis.
         Stahl, G., Zemel, A., Sarmiento, J., Cakir, M., Weimar, S., Wessner, M., & Mühlpfordt, M. (2006). Shared
                   referencing      of   mathematical     objects     in     online   chat.   Paper    presented     at   ICLS      2006,
                   [http://www.cis.drexel.edu/faculty/gerry/ pub/icls2006.pdf].

3-0
