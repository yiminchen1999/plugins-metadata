      Designing and Assessing Modeling and Visualization Technologies
                                              (MVT) Enhanced Learning
              BaoHui Zhang, Michael J. Jacobson, Beaumie Kim, Feng Deng, Suneeta Pathak, Hans G. Lossman
                               Learning Science Lab, Nanyang Technological University, Singapore
                    Email: Baohui.Zhang@nie.edu.sg, Michael.Jacobson@nie.edu.sg, Beaumie.Kim@nie.edu.sg,
                          Feng.Deng@nie.edu.sg, Suneeta.Pathak@nie.edu.sg, Hans.lossman@nie.edu.sg
                               Xiuqin Lin, Beijing Normal Univeristy, China, xianyoulin@126.com
                          Pratim Sengupta, Uri Wilensky, Northwestern University, Evanston, IL, USA
                                        Email: g-sen@northwestern.edu, uri@northwestern.edu
                        Kenneth E. Hay, Indiana University, Bloomington, IN, USA, kehay@indiana.edu

                Abstract:      Models    are the  core  of  scientific theory.  Some  researchers      have argued   that
                modeling is fundamental to scientific inquiry (e.g. Clement, 2000). There has been increased
                literature on how to use inquiry and modeling for science learning. However, challenges still
                exist.  For   example,   how   do   different  modeling  tools and  learning activities   shape   student
                learning trajectories? How do they impact student science learning? What are the assessment
                measures      that can  serve as  formative    and/or  summative   purposes  in the    different learning
                environments?       This   symposium     introduces    how  computer-based      MVT     (i.e., NetLogo,
                Biologica,     and  Astronomicon)     were    integrated  into different learning   environments,    and
                highlights how alternative and formative assessment measures have been used for assessing
                student   learning   progression    and outcomes.     The symposium   concludes    with   some    general
                principles for designing MVT enhanced learning environments and understanding of models
                and modelling as assessment toolkits to gain an insight into student conceptual development.

       Symposium Overview
                Models are the core of scientific theory. Some researchers have argued that modeling is fundamental to
         scientific inquiry (e.g. Clement, 2000). There has been increased literature on how to use inquiry and modeling
         for science learning. However, challenges still exist. For example, how do different modeling tools and learning
         activities shape student   learning  trajectories?   How do   they impact   student science      learning? What   are the
         assessment   measures     that can  serve   as formative   and/or  summative     purposes     in the   different learning
         environments?    This symposium      first introduces  how    computer-based    MVT    (i.e., NetLogo,    Biologica,  and
         Astronomicon) were integrated into different learning environments. Then, research design and results will be
         presented through research projects done in different countries (i.e., the US and Singapore). The symposium will
         highlight how alternative and formative assessment measures, such as process videos, dynamic interviews, log
         files, student physical models, and written responses, have been used for assessing student learning progression
         and outcomes. The symposium concludes with some general principles for designing MVT enhanced learning
         environments to promote conceptual understanding and transfer of learning, and understanding of models and
         modelling as assessment toolkits to gain an insight into student conceptual development.
                The first paper focuses on assessments in particular, and explores the role that formative assessments
         play in the process of learning in the NIELS Learning Environment (NetLogo). The authors demonstrate how
         formative assessments in NIELS can themselves act as scaffolds for learning. They enable the researchers to
         gain an insight into conceptual dynamics of students, by making explicit the underlying knowledge elements
         that are activated in the learners' minds as they engage in these activities. The second paper investigates the
         effect of different instructional design conditions when integrating the Biologica program for teaching genetics.
         Process data (in the form of various types of formative assessments) demonstrate students' learning trajectories
         and how    different instructional   designs   affect student   learning outcomes.  The    final   paper in this  session
         discusses  the epistemological      affordances  of   various modes    of modeling     in the    Astronomicon    learning
         environment. This study emphasizes the importance of articulation - i.e., making students' thinking "visible" to
         themselves as well as their peers (Bereiter & Scardamalia, 1987; Schoenfield, 1985; Collins, 1996) ­ as an
         instructional strategy, and in addition, highlights the effect of creating a public artifact on students' motivation
         and on the process of their knowledge construction.

       Learning Activities as Tools For Formative Assessment - Case Study of a
       Computational Multi-Agent Based Electricity Curriculum (NIELS)

                                                    Pratim Sengupta and Uri Wilensky

3-3
        The new reform agenda in US education (benchmarks for Scientific Literacy, 1993; National Standards
for Science Education, 1994) argues for designing curricula that help learners develop habits of mind to reason
scientifically and   engage   in scientific   inquiry. Duschl &    Gitomar (1997)   argued that assessment   activities in
classrooms can help achieve such goals, as well as provide information about students' progress towards these
goals. In this paper, we discuss these issues in the context of designing learning activities and assessment toolkits
for NIELS (NetLogo Investigations In Electromagnetism, (Sengupta & Wilensky, 2006, 2007), a curriculum based
on a suite of interactive, glass-box simulations modeled in the NetLogo modeling environment (Wilensky, 1999).
By analyzing    results  from    5th and  7th  grade   classroom   implementations  of NIELS,     we a)  demonstrate  the
underlying design    principles  that  guided   our choice  of activities  from  an instructional point  of view, and   b)
highlight how these activities enable us to gain an insight into conceptual dynamics of students, by identifying the
underlying knowledge structures that are activated in the learners' minds as they engage in these activities.
        Recently a number of proposals (Eylon & Ganiel, 1990; Chabay & Sherwood, 1995; White, Frederiksen, &
Spoehr, 1993; Sengupta & Wilensky, 2006) elaborated the need for introducing students to microscopic level models
of electricity. The goal of such models is to enable students to relate the macroscopic phenomena (such as electric
current & voltage) in terms of simple rules of interactions between individual-level microscopic objects (electrons,
ions, etc). We designed NIELS based on our theoretical argument (Wilensky & Resnick, 1999; Sengupta & Wilensky,
2006, 2007) that it is possible to engender an expert-like understanding of the relevant phenomena by bootstrapping
naïve knowledge elements, provided these elements are activated not only at the macroscopic level, but also at the
microscopic    level of  description  of the   relevant phenomena.     These knowledge  elements   are  object-based  and
primitive ­ i.e., they arise from our earliest interactions with the physical world (diSessa, 1993; Inhelder & Piaget,
1967). The primary goal of every NIELS model is to provide students with a qualitative sense-of-mechanism of
electric current, voltage etc. and related phenomena in simple electrical circuits in terms of these knowledge elements.
Furthermore, by translating the relevant phenomena in terms of primitive object-based knowledge elements, we
envisioned that NIELS models would enable much younger students (e.g., 5th graders) to makes sense of the same
phenomena that even high school and/or college students find difficult to understand.
        Every NIELS models is accompanied by an Activity Booklet that contains relevant content (physics)
background, instructions that scaffold students' interactions with the model, and prompts for students to log their
observations and describe their observations in details. Often, after logging their observations, students are asked to
relate the microscopic level rules to macroscopic phenomena and vice versa. And finally, the activity sheets also
prompt students      to provide  detailed   mechanistic   reasoning  of relevant  phenomena.    In addition,  one of    the
researchers in the classroom conducts short interviews with randomly individual students while they interact with
the models. In these interviews, students were often asked to provide mechanistic explanations of other related
phenomena, and in addition, further questions were asked to clarify ambiguous terms in their written responses.
The data thus collected in 5th and 7th grade classrooms (n=23 & n = 26 respectively) was coded in terms of
students' mention of objects and interactions at the microscopic level, the macroscopic level, and the underlying
knowledge   structures   that these  responses    were  indicative of. The   knowledge elements    were  coded based    on
diSessa's (1993) schematization of P-prims and Chi, Slotta & Leuw's (1994) schematization of object-schemas.

           Figure 1. Knowledge Elements In Students' Explanations In Model 2 (Current In A Wire).

        In NIELS models, while some activities specifically ask students to focus only on micro-level agents
and rules of interaction between these agents (e.g., Activity 2 in Figure 1), others prompt them to focus on only
macro-level representations (e.g., graph of current vs time) (e.g., Activity 1 in Figure 1), whereas some prompt them
to relate these two levels of representations by asking them to design novel scenarios and/or experiments (Activity 3
in Figure 1).These activities not only support the students' knowledge construction process, but also make this process
(of knowledge construction) explicit through their responses, which bring to light the epistemological roles of each
activity. We argue that such formative assessment tools allow us to understand the gradual development of learners'
understanding   through   making     explicit the evolving complexity   of their explanations (and   in some  cases, their
observations). Figure 1 below shows a sample analysis of the evolving complexity of 5th grade students' explanations
in three successive activities in one of NIELS models (Model 2: Current In A Wire). The Y-axis denotes the number
of different knowledge elements that we identified in each explanation, while the X-axis denotes student-id. Note that
in Figure 1, as students progress through the design space of the learning activities, they are able to co-ordinate
multiple knowledge elements. In our paper, we will discuss in detail how such formative assessment tools provide us

                                                                                                                               3-33
         with a complete cognitive trajectory of each learner while they interact with the NIELS models, as well as enable us to
         perform comparative between-student analyses.

       Exploring Modeling and Visualization Technology (MVT) Enhanced Biology
       Teaching and Learning in Singapore

                 BaoHui Zhang, Michael J. Jacobson, Beaumie Kim, Feng Deng, Xiuqin Lin, and Suneeta Pathak

        Introduction
                   How to integrate computer-based modeling tool for learning conceptually challenging science topics?
         In this paper, we    discuss  how   BiologicaTM,   a computer-based    modeling  tool, was   used in different  learning
         conditions for teaching and learning genetics. The software was developed by the Concord Consortium. It is a
         scriptable modeling tool for genetics and population dynamics (Buckley et al., 2004). There have been studies
         that   used  Biologica  as   more   standalone   software    for individual student    use from   different theoretical
         perspectives. In this study, we explored different ways to integrate Biologica in order to maximize its potentials
         for promoting student conceptual understanding in Singapore context.
                   Genetics has been a challenging topic for students because they had difficulties in connecting the visible
         traits to the underlying    mechanism   of inheritance  (Stewart,  1982; Tsui &    Treagust, 2007).  BioLogica   allows
         students to manipulate objects such as DNA, genes, chromosomes, gametes, of genetics represented at different
         levels. Students are able to see directly the results such as an offspring's physical traits by combining parents'
         genes (Buckley et al., 2004). Students' moment-by-moment actions and input as required by the software can be
         recorded as "log files" to reveal student learning progression (Buckley, Gobert, & Horwitz, 2006).
                   The  larger-scale   research involving     Biologica has  focused on   learning  associated  with    individual
         student use of the program. Implementing Biologica in Singapore brings strong factors, such as teachers and
         education    system,   that impact  student   learning  significantly. Using  a  counter-balancing   design    approach
         (Pollatsek   & Well,   1995),  we   hope   to find out how   different teaching  sequences   for  using Biologica   and
         traditional teaching might impact students' learning outcomes (e.g. their understanding of genetics concepts).
         Another approach was a lab book approach, with which teachers guide the class with whole class discussions
         and    small  group    interactions according    to  a  researcher-designed   student  lab   bookas   opposed    to the
         individualized Biologica-only tasks. This study involved four Secondary Three classes in a Singapore school
         with three conditions (see, Table 1 below) in order to compare the effects of different learning sequences and
         activities. Some formative measures were taken in order to track student learning progression and gauge class
         instruction. Considering the content and length of lessons, we choose six topics out of the 12 Biologica activities
         for the four classes: Introduction, Rules, Meiosis, Monohybrid, Horns Dilemma, and Invisible Dragon.

        Methods
                   The study was conducted in an all boy school in Singapore. Among them, A and B were the two best
         classes, and C and D were weaker classes. The traditional approach for Class A and B was taught by a senior
         teacher, Mr. Z., who has been teaching for 25 years in the school. The Biologica sessions of Class A and B were
         taught by a young teacher, Mr. L., who has been the school for a year and it was the first time for him to teach
         Biology. Class C and D were taught by a young teacher, Ms. Y., who has taught for about four years.
         Table 1: Biologica unit implementation at MSH, research design.

         Class [N]                                                    Sequence
            A [25]      Pretest          Traditional                  MidTest                 Biologica            PostTest
                                          (Mr. Z.)                                              (Mr. L.)
            B [36]      Pretest          Biologica                    MidTest                Traditional           PostTest
                                          (Mr. L.)                                              (Mr. Z.)
            C [29]      Pretest                                     (MidTest)                                      PostTest
                                                         Biologica plus lab book (Ms. Y.)
            D [34]      Pretest          Biologica                    MidTest                Traditional           PostTest
                                          (Ms. Y.)                                              (Ms. Y.)
                   Table 1 shows the design of the curriculum arrangement. The implementation took place over a three-
         week period during school vacation time. The traditional way of teaching took about 6 periods (40 minutes per
         period) as planned. The Biologica cycle actually took 8 periods. The three classes, A, B, and D, were designed
         to be  two   conditions  (a)  Biologica  first, and  then traditional  approach; and   (b) Traditional  first, and  then
         Biologica. Class C provides each student a lab book to provide more scaffolds when students were using the
         Biologica    software. There  were   pre-, mid-,   and post- content   assessment. Basically, they   were the  same  33

3-3
multiple choice questions (MCQs) plus two open-ended transfer test items, and one structured question that is
aligned   with   Singapore   O-Level  exam.    Besides  the pre-,  mid-,   and post-tests   to assess  student  content
understanding, we also collected log files, pre-, mid-, and post-surveys of student attitudes towards science and
science   class, and student   computer  screen recordings  and   conversation  (process    videos), and target student
focus group post-interviews. Field notes were used to organize and triangulate our analysis.
          The improvement in test performance (33 MCQs) within each class was tested by              paired t-test.   The
improvements from pre to mid and pre to post were compared among the four classes by GLM (the general
linear models) controlling for the pre score.   The effect of the Biologica under the counter-balanced design was
examined by GLM after re-organizing the data based on the design.

Results and discussion
          Our preliminary analysis of the 33 MCQs scores indicated that all four classes improved significantly
(p<0.01) when comparing their pre-test and post-test performance. After controlling for the pre-test score, the
differences from pre- to post- tests were 10.26 (se=0.79), 11.51 (se=0.67), 7.82 (se=0.83), and 5.70 (se=0.68) for
the 4 classes, respectively. All pair-wised comparisons were significant except for the pair 3A and 3B. We also
found that the improvements from pre- to mid-tests were also significant for all classes (10.73 (se=0.80), 11.27
(se=0.78), 7.55 (se=0.79), 4.08 (se=0.68), respectively) while none of the changes from mid- to post-tests were
significant. Based on the 33 MCQs, 3B improved slightly more than 3A from pre- to mid- to post-test, but they
did not   have   a significant difference. This seems    to indicate  that using the Biologica    application   allowed
students to learn equally well as if they were taught by an experienced teacher measured by the MCQs. We
expect our analysis of the transfer and structured questions to indicate some differences in terms of the effects of
different conditions. Both teachers and the students we interviewed preferred condition 2 if they had a choice of
the teaching sequence and did not need to consider preparing for O-level exams. During the post-interview,
Teacher Z. mentioned that he prefers Biologica first and then traditional for his teaching. He felt that Biologica
first and then traditional teaching or a combination of the kind should help students the most because students
were able to understand the certain genetics concepts through their hands-on activities using Biologica and then
they were more ready to listen to the teachers and to make more sense of teacher instruction.
          We found that students in both 3B and 3D, which were in the same condition (condition 2) (Biologica
first and traditional second), had a significant improvement from pre to mid-test, but 3B improved significantly
more. Therefore, it seemed that the software helped the stronger students to improve more than the weaker
students. This was especially apparent when comparing the mid-test results of the two classes. .
          It was interesting in our focused interviews with the target students from each class that they preferred
traditional teaching if they had to choose between traditional teaching and the use of Biologica alone because
teachers would prepare them for O-level exam better. If there was no consideration of the O-level exam, most of
them would choose Biologica because they thought the software allowed them to think independently. They also
liked that the software was quite visual and allowed them to manipulate the objects to see the outcomes. Class C
used   Biologica   and student lab  book  without the  traditional teaching  sessions,   it was interesting  to see   that
although they had just finished half of the 6 topics, students made more significant improvement compared to its
counterpart, class D in mid-test.
          Our analysis has been very preliminary. We have open-ended structured items and transfer items that will
provide   richer information   about student learning  progression   compared   to the MCQs     . They   are still  being
analyzed.  Further,  our process  videos,  log files, and surveys  of student  attitudes towards  science   and  science
learning should provide much richer information about the learning processes and student learning outcomes. The
final conference paper will provide a full reporting of these analyses and a consideration of their implications.

Acknowledgement
This material is based on work supported by the Learning Sciences Lab of NIE (LSL 16/06 ZBH). The authors
would also like to thank Dr. Janice Gobert for her contribution to our research design.

Integrated Modeling-Based Inquiry for Addressing Astronomy Misconceptions:
From Sky, Sketches, and Styrofoam to 3D Computational Models

                               Beaumie Kim, Hans G. Lossman, and Kenneth E. Hay

          The    mysterious  nature  of  heavenly bodies    has fascinated  mankind    since   ancient times.   Amateur
astronomer  groups     that observe  the night  sky   together is common    around  the  world.   The  development     of
intricate telescopes   and  image  capturing technology   brings   even more   accurate  and   beautiful images    of the
skies, and  thus    better  understanding   of  different   heavenly  bodies.  The   fundamental     understanding     of
astrophysics, the planetary motions and light, however, still remains hard to grasp with the same sky-gazing
practice. The history of science provides a rich literature on the development of astronomy as a science subject

                                                                                                                             3-3
         of  its  own. The   records and    studies reflect both  current   and past social practices as   well as the common
         misconceptions     of laypersons    and   astronomers.  People   have   a  tendency  to  develop   personal  or  private
         conceptions    about  phenomena     even   though   they  have  no   direct experience   of  those phenomena.    These
         misconceptions often relates to a kind of `pre-belief' held by the person. Normally we tend to draw conclusions
         based    on  what   we   know   and   experience.   The   18-minute    video,   "The Private  Universe",   shows    how
         knowledgeable individuals retain their personal theories - in this case, about the causes of Earth's seasons - even
         after the classroom lessons has proved them wrong (Schneps & Sadler, 1989). These `hard-to-change-beliefs'
         often cling on all the way up to adulthood. Some of the more common misconceptions, like the astrophysical
         relation of the Sun, Earth and Moon, are rooted in an underestimation of distance between the bodies while there
         is an overestimation of relative sizes of the bodies. Other typical misconception people have is that the Sun and
         the Moon     always   is on opposite   sides  of the   Earth, that  people  are seeing  different phases  of the Moon
         depending on their locations and that seasons are caused by the relative distance between the earth and the sun
         (Hansen   et  al., 2004;  Philips, 1991;   Sadler, 1998). Some   studies   also suggests the there are misconceptions
         about astronomy itself, such as `astronomers spend most of their time looking through telescopes,' `physics has
         no bearing on astronomy,' `astronomy is not a science,' and `astronomy is only the study of stars' (2001).
                   Astronomicon was specifically developed with the purpose of addressing such misconceptions. With this
         3D modeling environment the learners are able to build and simulate their own solar system to make observations
         and   draw  conclusions   (Hay,    Shaw,  &   Hauschildt, 2000).    Astonomicon's  domain    specific  advantage is the
         embedded knowledge of physics and the complex relationships you can observe when changing the input data. The
         physical properties of the planetary system ­ e.g., mass, distance and axial inclination - is given a priori to us,
         whereas the inquiry of planetary motions, light and system change comes a posteriori on the basis of the inquirer's
         observations (e.g. moon phases, seasonal changes). Previous research (Kim & Hay, 2004) indicates that learners
         naturally employ tradition models of expression (i.e. sketching planetary motions, and physically modeling with
         their   hands and   other objects  in the  environment).  This   is also  how   ancient and  modern   astronomers have
         communicated their ideas until today. This research has taken into account how early astronomers, like Galileo
         Galilei, observed the regular patterns of the motions of visible celestial objects, and then communicated his ideas
         about the connection between physics and geometry of planetary motions through his diagrams (Latour, 1990). By
         using these kinds of traditional methods in combination with computational models and modern technology we
         hope that we can challenge the learner's naïve experiential claims and misconceptions.

        The Astronomy Day I & II
                   Despite   the  public interests  in astronomy   and   astronomical    knowledge,   the  school curriculum  in
         Singapore has just set a minimal time for this science area. This project initially planned a two-night astronomy
         camp with the Science Centre, Singapore (SCS), at which a group of 12-14 year old students are provided with
         an opportunity for an in-depth inquiry into the world of astronomy. We developed a camp program, in which the
         participants alternate among sky-gazing, sketching of ideas and observations, building and modifying Styrofoam
         models and doing modeling-based inquiry using Astronomicon. Modeling-based inquiry (Hay, Kim, & Roy,
         2004 ) is a specific pedagogical approach that focuses on computer modeling to investigate phenomena that
         might be difficult to do without such technology. The process of modeling-based inquiry (MBI) includes:
               1.  Initiate an inquiry question (e.g., How will the Earth look like from the Moon?)
               2.  Plan for model and collect data (e.g., Assuming that the Earth would have phases seen from the Moon,
                   collect physical/orbital parameters of Sun, Earth, and Moon);
               3.  Model the phenomenon (e.g., Create Sun, Earth to orbit Sun, and Moon to orbit Earth);
               4.  Validate the model and revise if necessary (e.g., Running the model, realize that Earth and Moon are
                   too close so that Moon collides with Earth);
               5.  Use  the  model   as  a  source  of data  to address  the  original question  and  visualize data  to explore
                   relationships (e.g., Make a viewpoint to observe Earth from the Sun; observe from above the Sun in
                   order to understand Sun-Earth-Moon relationship);
               6.  Develop a warranted conclusion (e.g., Conclude that Earth has phases seen from the Moon within same
                   period of time, but show different faces unlike the Moon. This is due to the changing positions and
                   angles among Sun-Earth-Moon);
               7.  Present conclusion to colleagues (e.g., Present the conclusion by comparing the timed observation data
                   and screen capture of different viewpoints).
                   The chance to create personal representations and public artifacts allows learners to have a ownership
         of their learning and deeper understanding, that is, more meaningful and motivational (Bransford et al., 2000).
         The learners' artifacts and how they talk about them also provide important formative assessments for teachers
         and researchers. They not only become public but also help learners to self-assess their ideas by seeing and
         listening about others' work.
                   We advertised this event to the selected secondary schools that have a record of visiting the SCS for
         astronomy education programs and are located not too far away from the vicinity of SCS. One school responded

3-3
with the interest of brining a group of 13 and 14 year old girls participating in an international girls' club every
Friday  afternoon. They   get  together  for    activities that provide   opportunities     to develop   their  character  as
responsible citizens, and provide service to the community. Accommodating the schedules of the school and the
SCS, we decided to modify the program into a 2 separate astronomy days.
          Smith, diSessa, and  Roschelle    (1993)   has   suggested   that instead  of trying    replacing misconceptions
with  expert knowledge,   we   should   let learners  bring  forth  their   misconceptions     and  discover   the  reasoning
behind them. During the two Fridays of astronomy day, we had a series of physical or computational model
making session and presentations. We had two researchers and three SCS staff as facilitators. Each day guiding
teacher and seven students arrived about 2PM and left about 10PM after night sky observations. We let them
form three groups of two or three students according to their preference.
Table 1: Astronomy day program.
Day I              Survey                 Styrofoam model(solar system)PresentationsAstronomicon modeland observations(scale and orbits)ObservatoryInflatable planetarium
Break                                            Lunar phases exercise assignment
              Styrofoam model           Astronomicon modelDay II(Sun-Earth-Moon)(lunar phases)SurveyPresentationsPresentationsObservatoryInterviews
          The survey is adopted relevant questions from Astronomy Diagnostic Test version 2.0 (Hufnagel et al.,
2000), and modified to include additional three questions to ask them explain concepts with sketches to confirm
their answers from multiple choice questions. They developed a physical model in Styrofoam balls and other
materials to  help them   explore   the planetary    motions,   and then    explained what     they   made  to  the audience
(teacher, facilitators, and other students). Students created the solar system model within Astronomicon and
observed  planets' movements.      Observatory   sessions   came    as the  last activity that    connects  the God's   view
exercises in the classroom to the Earth's sky-gazers' view.
          Before coming   back  for  the    second   day,  we   asked  students   to  complete     basic lunar    observation
exercise. They either posted them on their club's blog or emailed them to us. At the beginning of the second
day, we talked about what lunar phase that day was and what seasonal changes northern hemisphere people
were  experiencing  (February   29,  2008;   last  quarter  to  waning   crescent;   winter    to spring).  They   made   and
presented Sun-Earth-Moon Styrofoam model based on that information. For Astronomicon exercises, we give
different exercises on lunar phases to three groups (comparing lunar phases and phases of Earth seen from the
Moon; comparing three theories on lunar phases; exploring relationship between revolution and rotations and its
effect on lunar phases). After their presentations, we did a short Astronomicon demo and discussion on the
cause  of seasons  on Earth.   We   used    the same  survey    instrument,  and   while    they  are  doing   the  night sky
observations, we conducted small group interviews          (2 or 3 students each time).

Preliminary Findings
          We finished the data collection on the 29th of February and are still processing the multimedia data
(video and audio recordings and screen captures). In the previous research we found that students often turn to
naïve  scientism   believing  their model    represents    real phenomena     that   doesn't    need   validation.  Another
observation was that some participants saw the making of the 3D model as the primary goal rather than viewing
it as a component for learning progression to better understand certain phenomena (Kim & Hay, 2004). We
believe that the current approach help learners to focus on their ideas rather than the model building itself. By
making most of the participants' thought processes explicit we hope to better understand how conceptual change
comes about. This was made possible as they work in pairs, sketch and write down their ideas and build both
physical  and virtual models.   We   are able   to   make   the following   observations    because    most  of   the  learner
activities were made public.
          From the pre-survey, many students showed common misconceptions about the scales, orbits, phases,
and  seasons  of our  solar  system.    The  initial look   at  the post-survey   result  was     not  very encouraging    as
underestimation of the scale was address by seeing a "dot" of the Sun and the invisible Earth and the Moon
using Astronomicon but did not show any improvement in their choice of answers. Same happened for the orbit
of the Earth. When we ask students about the orbit during the interview, few said, "because you said the Earth is
not a perfect circle..." and one mentioned, "because we had to choose `circular orbit' for the modified model
and `elliptical orbit' is the real one..." We did not realize that the literal meaning of words would make them
fall immediately   back   to their  preconceptions.   We    saw  some     improvements      on    the phases   of  the moon,
especially the students who grappled more with Astronomicon for exercises. One of the students, Joanna had the
misconception that Earth's shadow blocking the Moon caused phases. Figure 1 shows her initial drawing and
explanation of lunar phases from the    pre-survey and her Astronomicon exercise posted on the blog.

                                                                                                                                  3-3
                  On the second day, we purposely gave the comparing lunar phase theories exercise, which includes
         "shadow theory" to her group, so that Joanna might be able to discover her misconceptions. They spend a long
         time to build the shadow theory model and finally were able to make the shadowed phases happen, which they
         called, "lalaland   Moon"  (see, Figure  2). At the  beginning     of their  presentation,  they  displayed   their initial
         thoughts  (similar to Figure 1 writing) and Jaonna emphasized, "this is what we thought before this exercise."
         However, in presenting the accepted theory model, her explanation the phases fell back to "shadow blocking"
         (see, Figure 2). Finally during the interview, we asked her again to explain how phases occur. She confidently
         explained new moon and other phases until she reached the full moon. She again immediately became confused
         and said, "then   this is new moon    again..." We   spend  a bit    more   time  with her  for   reasoning   through her
         dilemma. We believe that this is just the beginning of her conceptual change, where her confident "shadow
         theory" is being challenged and she is discovering her reasoning behind it. During the symposium, we will
         discuss our further analysis of data and deeper understanding of the students' progression.

                                                         (Initial thoughts)
                                                         a) Why you think we see different phases of the moon?
                                                         - We see different phases of the moon as the moon revolve around the Earth, an
                                                         since the moon reflects light from the sun, sometimes the Earth's shadow will
                                                         block some parts of the moon, thus we see phases.
                                                         - The Earth revolves and rotates and sometimes, the Sun's rays cannot reach the
                                                         moon to be reflected, thus we see phases.

                                                         (With Astronomicon modeling and observation)
                                                         b) How are the Earth and the Moon lit? Why do you think they are lit in
                                                         such a way?
                                                         The moon and the Earth both reflect light from the Sun as they both do not
                                                         produce or emit their own light.

                                                         c) How do the phases of the moon change?
                                                         When the Earth rotates and revolves, the rays of the sun may be blocked thus
                                                         only lighting up a part of the moon, thus we see phases.

                                                         e) What do you think is causing the phases of the Moon? Does your
                                                         observation from the evidence fit with your thoughts? If not, what did you
                                                         find out from this exercise that you did not know before?
                                                         The parts of the Moon facing the Sun. Yes, my observations from the evidence
                                                         fit with my thoughts

                         Figure 1. Joanna's Initial Phases Drawing and Parts of Astronomicon Exercise Assignment

                         Figure 2. Joanna and Sandy's Presentation Slides (Comparing Theories on Lunar Phases)

       References
         Belcher,  J. W.,  &  Olbert, S.  (2003). Field  line motion in     classical electromagnetism.    American     Journal     of
                  Physics, 71, 220.
         Bereiter, C., & Scardamalia, M. (1987). The psychology of written composition. Hillsdale, NJ
         Bransford,   J. D., Brown,   A.  L., Cocking,  R. R.,  & Donovan,      S.   (2000). How    people  learn:    Brain, mind,
                  experience, and school (expanded edition).    Washington, DC: National Academy Press.
         Buckley, B. C., Gobert, J. D., & Horwitz, P. (2006). Using log files to track students' model-based inquiry.
                  Paper presented at the International Conference of the Learning Sciences, Bloomington, IN.
         Buckley, B. C., Gobert, J. D., Kindfield, A. C. H., Horwitz, P., Tinker, R. F., Gerlits, B., et al. (2004). Model-
                  based teaching and learning with BioLogicaTM: What do they learn? How do they learn? How do we
                  know? Journal of Science Education and Technology, 13(1), 23-41.

3-3
Chi, M. T. H., Slotta, J. D. & de Leeuw, N. (1994). From things to processes: A theory of conceptual change for
        learning science concepts. Learning and Instruction, 4, 27-43.
Clement, J. (2000). Model based learning as a key research area for science education. International Journal of
        Science Education, 22(9), 1041-1053.
Collins, A. (1996). Design Issues for Learning Environments. In S. Vosniadou, E. De Corte, R. Glaser, & H.
        Mandl (Eds.) International perspectives on the psychological foundations of technology-based learning
        environments. Hillsdale NJ: Lawrence Erlbaum Associates (pp. 347-361).
Comins, N. F. (2001). Heavenly errors. An accompaniment of "Heavenly errors: Misconceptions about the real
        nature   of  the   universe,"    Columbia       University  Press    Retrieved   November,   2007    from
        http://www.physics.umaine.edu/ncomins/
Duschl, R. A., & Gitomer, D. H. (1997). Strategies and Challenges to Changing the Focus of Assessment and
        Instruction in Science Classrooms. Educational Assessment, 4(1), 37-73.
Eylon, B.-S., &  Ganiel,  U. (1990).   Macro-micro   relationships: The   missing  link between electrostatics and
        electrodynamics in student reasoning. International Journal of Science Education, 12 (1), 79-94.
Gutwill, Joshua, Frederiksen, John & Ranney, Michael (1996). Seeking the causal connection in electricity:
        shifting among mechanistic perspectives. International Journal of Science Education, 18 (2), 950-693.
Hansen, J., Barnett, M., MaKinster, J., & Keating, D. P. (2004). The impact of 3-D computational modeling on
        student understanding of astronomical concepts. International Journal of Science Education., 26(13),
        1555-1575.
Hay, K. E., Kim, B., & Roy, T. C. (2004). Virtual reality modeling-based inquiry: Conceptual coherence and
        alternative theories   trials. Paper   presented at the  Annual    Meeting of   the American Educational
        Research Association, San Diego, CA.
Hay, K. E., Shaw, J. S., & Hauschildt, P. H. (2000). The Virtual Solar System Project: Students building virtual
        models  for scientific understanding.    In D.  G. Brown   (Ed.), Teaching  with  Technology (pp.  66-68).
        Bolton, MA: Anker Publishing.
Hufnagel, B., Slater, T., Deming, G., Adams, J., Adrian, R. L., Brick, C., & Zeilik, M. (2000). Pre-course results
        from the Astronomy Diagnostic Test. Publications Astronomical Society of Australia, 17(2), 152-155.
Kim, B., & Hay, K. E. (2004). Creating universe with computer: Charting the structure of distribution between
        learner  and a cognitive   tool. Paper   presented  at the Annual  Meeting  of  the American Educational
        Research Association, San Diego, CA.
Latour, B. (1990). Visualization and cognition: Drawing things together. In M. Lynch & S. Woolgar (Eds.),
        Representation in scientific activity (pp. 19-68). Cambridge, MA: MIT Press.
Philips, W. C. (1991). Earth science misconceptions. The Science Teacher, 58(2), 21-23.
Pollatsek, A., & Well, A. D. (1995). On the use of counterbalanced designs in cognitive research: A suggestion
        for a better and more powerful analysis. Journal of Experimental Psychology: Learning, Memory, and
        Cognition, 21(3), 785-794.
Sadler, P. M. (1998). Psychometric models of student conceptions in science: Reconciling qualitative studies
        and distractor-driven assessment instruments. J. of Research in Science Teaching, 35(3), 265-296.
Schneps, M., & Sadler, P. M. (1989). A private universe [18 minute video]. Santa Monica, CA: Pyramid Films.
Schoenfeld, A. H. (1985). Mathematical problem solving. New York: Academic Press.
Sengupta, P., &  Wilensky,   U. (2005).   N.I.E.L.S: An  emergent   multi-agent  based  modeling environment    for
        learning physics. Paper presented at the 4th International Joint Conference on Autonomous Agents and
        Multiagent Systems (AAMAS 2005), Utrecht, Netherlands.
Sengupta, P.,   &   Wilensky,   U.     (2006). NIELS:    An    agent-based   modeling   environment  for  learning
        electromagnetism.    Paper  presented   at  the annual  meeting   of the American    Educational Research
        Association (AERA 2007), San Francisco, CA.
Smith, J. P., diSessa, A. A., & Roschelle, J. (1993). Misconceptions reconceived: A constructivist analysis of
        knowledge in transition. Journal of the Learning Sciences, 3(2), 115-163.
Sneider, C. I., & Ohadi, M. M. (1998). Unraveling students' misconceptions about the earth's shape and gravity.
        Science Education, 82(2), 265-284.
Stewart, J. H. (1982). Difficulties experienced by high school students when learning basic Mendelian genetics.
        The American Biology Teacher, 44, 80-84, 89.
Tsui, C.-Y.,  & Treagust, D.   F. (2007). Understanding     genetics: Analysis of  secondary  students' conceptual
        status. Journal of Research in Science Teaching, 44(2), 205-235.
White, B., & Frederiksen, J. (1987)."Qualitative Models and Intelligent Learning Environments." In R. Lawler
        & M. Yazdani (Eds.), AI and Education (pp. 281-305). Ablex Publishing Corporation.
White, B., & Frederiksen, J. (1998). "Inquiry, Modeling, and Metacognition: Making Science Accessible to All
        Students." Cognition and Instruction, 16(1), 3-118.
diSessa, A. (1993). Towards an epistemology of physics. Cognition and Instruction, 10, 105-225.

                                                                                                                       3-3
