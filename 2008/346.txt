               Using contrasting cases to relate collaborative processes and
                                                   outcomes in CSCL

                         Nikol Rummel, University Freiburg, Institute of Psychology, Engelbergerstr. 41,
                                  79085 Freiburg, Germany, rummel@psychologie.uni-freiburg.de
                         Cindy Hmelo-Silver, Rutgers University, Department of Educational Psychology,
                               10 Seminary Place, New Brunswick, NJ, USA, chmelo@rci.rutgers.edu

                  Abstract:    This  symposium    brings together   a  panel  of researchers   using contrasting    case
                  methodology to analyze computer-supported collaborative learning in a wide range of learning
                  environments.     Such  analyses can   help researchers   better understand   the differences  in  the
                  collaborative processes by sharpening researchers' perception and facilitating the discovery of
                  appropriate explanations for these differences.

                  With   the goal of   empirically assessing  the  effects  of support  for computer-supported       collaborative
         learning (CSCL), the important question that arises is which variables one should look at. A criticism of most
         studies investigating the effects of instructional interventions for CSCL is that they have concentrated either on
         analyzing the collaborative process or the outcomes. We believe that in order to fully evaluate the impact that
         support measures may have, it is necessary to bring together outcome data and data from collaborative process
         analyses. Assessing   both   sources  of data  in  combination   allows   one  to gain   insights into  the relationship
         between   process   characteristics and  the  collaborative  and/or   individual  outcomes  of    the  interaction. Such
         analyses  are critical  for  developing   a   theory of   good computer-mediated       collaboration.   We   argue   that
         contrasting case analysis is a promising approach to relate collaborative processes to outcome criteria. Such
         analyses can sharpen researcher perception by making important differences salient (Marton, 2006). Analysis of
         distinctly dissimilar cases can exploit the variability among cases and thus facilitate discovery of appropriate
         explanations  which   can   help in  developing   coding   categories  (Firestone,  1993;  Strauss    & Corbin,   1998).
         Contrasting  cases  can, for  example,   help illuminate  the differences  between    more  and   less effective groups
         within one experimental condition or enable the researcher to compare particular types of groups (e.g., effective
         and less effective groups, heterogeneous or homogeneous groups, same gender and mixed gender groups) across
         conditions.
                  The contributions in this symposium have implemented different types of contrasting case analyses in
         their research.  The  first paper   examines   the distinction between     the discourse   processes    of  scripted and
         unscripted  learners. The   second  paper compares    successful   and  unsuccessful  dyads who     had received    script
         support while learning with an intelligent tutoring system. A rating scale was used to examine variables related
         to their interaction processes during a collaborative post test. The third paper contrasts more and less successful
         groups of preservice teachers as they use online resources for problem-based learning; resource use is analyzed
         from both quantitative and qualitative perspectives. The fourth paper compares sets of contrasting (class) cases
         to examine   factors  related to learning   outcomes   in  computer-supported     knowledge  building    settings.  Each
         contribution  will begin by   discussing  the rationale/goal  that was  used   to select particular cases   for analysis.
         Further, the methods used for the collaborative process analyses will be described and the measure that was used
         to create the contrast will be introduced (e.g., learning gains, number of problems solved, amount of scaffolding
         needed). A substantial part of the contributions will be dedicated to discussing methodological approaches to
         combining   data   from the  different sources, and   to  discussing  the results  of the  contrasting  cases   analyses.
         Following the presentations, we will invite the panelists and audience to engage in a discussion to reflect on the
         kinds of conclusions that can be drawn from this genre of research.

       Patterns of discourse and cognition of poor, good, and scripted online
       learners

                         Armin Weinberger, Karsten Stegmann, Frank Fischer, Department of Psychology,
                                     Ludwig-Maximilians-Universität (LMU) München, Germany

                  The socio-cultural notion of knowledge construction as being social and mediated through language
         (Vygotsky, 1978) has strongly influenced the field of CSCL (Koschmann, 1996). CSCL research building on
         Vygotsky's work has stressed the social nature of knowledge, but individual cognitive processes and knowledge
         gains have been subject to less empirical research (Salomon & Perkins, 1998). Specific CSCL environments
         allow think-aloud protocols to be collected while learners are communicating in a text-based fashion and thus,
         patterns of discourse   and  cognitive  processes  can  be  analyzed   (Stegmann,   Wecker,  Weinberger,     &  Fischer,

3-3
2007).  Assuming   that   there   are  mutual   relations  between  discourse   and individual  cognitive   processes,   we
investigate (RQ1), how do poor learners differ from good learners (`poor' or `good' in terms of small or large
individual knowledge gains after CSCL) in their patterns of internal and external speech?
         With new technologies mediating communication, CSCL settings have also been conceived as an ideal
context to    facilitate collaborative   learning  processes,    and consequently,    individual  knowledge      gains  (see
Koschmann,    1996).     Scripting CSCL    is an   instructional  approach that  aims to scaffold    specific processes  of
CSCL    until learners   are capable   of  self-regulating  their  interaction processes in  a  productive  way    (Fischer,
Kollar, Mandl,    &      Haake,   2007).   Scripts facilitate  specific  discourse  activities,  and   modify    individual
expectations and cognitive processes. Assuming that scripts take effect at the social as well as the cognitive
plane, we investigate (RQ2), how do scripted learners differ from unscripted learners in their patterns of internal
and external speech?

Methods
         Comparing       scripted  vs. unscripted  CSCL,    we    conducted a   study with  48  students  of   Educational
Science at the LMU Munich. The learning task was to apply attribution theory to problem cases. Participants
were randomly assigned to groups of three, and to one of two experimental conditions. Whereas the control
group received no additional support in analyzing the three problem cases in three separate discussion boards
within the CSCL environment, the scripted learners were assigned to act as case analysts for one of the three
problem  cases  and  as   constructive    critics for  the remaining  two   cases supported    by prompts     such as   "My
proposal for an adjustment of the analysis is". Think-aloud and discourse protocols were collected. Focusing on
individual aspects of discourse and cognition, we selected individual learners based on their performance in a
knowledge test after the CSCL session (poor vs. good learners) in both conditions (scripted vs. unscripted).
Analysis of the discourse data was conducted based on a multi-dimensional coding scheme of propositional
segments (Weinberger & Fischer, 2006). We focused on transactivity of the discourse (Teasley, 1997), i.e. to
what extent   learners   referred  to  and  operated   on  the reasoning of their learning   partners,  and   on a specific
epistemic quality of the discourse, i.e. to what extent learners were able to apply theoretical concepts to problem
case information. Both, transactivity and epistemic quality of discourse were ranked as low, middle, or high.
The post test on knowledge involved solving another problem case individually; it was similarly analyzed based
on the  extent  learners   were    able  to adequately     apply  concepts  of  attribution theory   to case   information
(Weinberger & Fischer, 2006).

Results
         With respect to RQ1, results show that poor learners performed well during the collaborative phase in
terms of applying a number of theoretical concepts adequately to problem case information without much deep
elaboration of the learning material and equally well referred to contributions of the learning partners without
much   deep   elaboration  of their   messages    (see Figure  1). Good  (unscripted)  learners   in contrast, engaged   in
longer periods of deep elaboration before or during production of contributions of high epistemic quality (see
Figure 2).

                  Figure 1. Poor learner                                        Figure 2. Good learner

         With   respect   to  RQ2,     analyses show   that scripted  learners  engaged   in extended    periods   of   deep
elaboration of both the learning material and the contributions of the learning partners leading to an overall
higher  epistemic and     transactive  quality  of discourse   as  well as to  larger individual  knowledge      gains. The
emerging discourse/ cognition pattern of scripted learners closely resembles the good learner pattern (figure 2).
The script applied in this study thus facilitates learners to engage in a good learner mode of thinking deeply
(yellow bar) before engaging in discourse activities of high epistemic quality (blue bar).

                                                                                                                                3-3
        Conclusions
                    It is plausible to assume that discourse reflects important aspects of individuals' cognitive processes.
         Still, the results   of contrasting   cases of  poor,  good,  and scripted   learners  point   towards  some    gaps between
         quality of the discourse and individual cognitive processes and knowledge gains. An approach which could be
         labelled surface processing of the learning material or satisficing (Chinn, O'Donnell, & Jinks, 2000) seems to
         suffice to effectively deal with the learning task at hand, but results in poor individual knowledge gains. Good
         learners, however, elaborate the learning material to a substantially larger extent than poor learners or simply
         put: good learners think deeply before they write. Both, internal and external speech may not be identical -
         particularly with good learners - but rather induce each other. With respect to RQ2, we could find that scripts
         seem to be a feasible approach to model and induce approaches of good learners. These results indicate that
         scripts  could    be conceived     as  process-oriented   tools to  scaffold   and   enable    learners to  engage   in deep
         elaboration    of the   learning  material  and   in transactive  discourse    activities rather  than  to restrict  learners'
         otherwise   apparently     suboptimal  approaches.    By contrasting    cases, we  have   found   specific patterns  of good
         learning, which can be induced by scripts.

       Using contrasting cases to better understand the relationship between
       students' interactions and their learning outcome
                     Dejana Diziol,      Nikol Rummel, Institute of Psychology, University of Freiburg, Germany
         George Kahrimanis, HCI Group, Electrical and Computer Engineering Department, University of Patras, Greece
                Talia Guevara, Johannes Holz, Hans Spada, Institute of Psychology, University of Freiburg, Germany
         Georgios Fiotakis, HCI Group, Electrical and Computer Engineering Department, University of Patras, Greece

                    Ample   research    has shown    that interaction  support   such  as  collaboration   scripts can   improve both
         students'  interactions    and  their  outcome   (e.g. Rummel    &  Spada,    2005).   Still, some  groups  fail despite   the
         guidance they receive. We analyze contrasting cases to answer the question what makes the difference between
         groups that fail and groups that succeed.
                    The cases presented were selected from a study on collaborative problem-solving with the Cognitive
         Tutor Algebra (CTA), an intelligent tutoring system for mathematics education in high schools. In the study
         (Diziol, Rummel, Spada, McLaren, 2007), we enhanced the CTA to a collaborative learning setting. Although
         the CTA has shown to improve learning in mathematics (e.g. Koedinger, Anderson, Hadley, & Mark, 1997), it
         also has been criticized for promoting shallow learning: Students often engage in trial and error strategies and
         misuse the opportunity to ask for hints by merely copying the correct answers (Baker, Corbett, Koedinger, &
         Roll, 2004). By promoting mutual elaboration, collaboration can help to overcome these shortcomings (Teasley,
         1995). To ensure an effective use of the collaborative CTA environment, we developed a collaboration script
         that guides students' interaction, and encourages them to use their impasses as starting points for elaboration. In
         the study,    we  compared      individual  learning,  unscripted   collaborative   learning,   and   scripted  collaborative
         learning,  all with    the CTA.    Following   an instruction  phase,   learning  was   assessed  regarding    three different
         aspects: We found a positive script impact on transfer and future collaborative learning; however, the script did
         not enhance     outcome     in  the   collaborative  retention  test.   In  fact, scripted    dyads even   showed    a  slight
         disadvantage    regarding    the  outcome   variable   that  assessed   the amount     of assistance    needed  to  solve  the
         problems.   But   the   variance   in this outcome    variable  was   high, indicating    that some   dyads benefited   from
         scripting while others did not. To better understand the difference between more and less successful dyads on
         the collaborative retention test, we related students' learning outcome to their collaborative interaction, using
         contrasting case analyses.

        Method
                    In the retention test, students collaborated on the CTA to solve problems that were isomorphic to those
         during instruction with script support no longer available. In addition to the CTA logs, all interactions were
         recorded with audio and screen capture. Outcome variables gained from the CTA logs were the percentage of
         errors on the first attempt (error rate) and the average amount of assistance needed to solve the tasks (assistance
         score). Recall    that  dyads  in  the scripted  condition  showed    a great  deal of  variance    especially  regarding  the
         assistance score. Therefore, we contrasted successful and less successful dyads to unravel reasons for the high
         amount   of   assistance   needed   in some  dyads.    Since  prior knowledge,     assessed    by students' math     grade (in
         percent), positively correlated with all outcome variables, dyads with an equivalent level of prior knowledge
         were chosen for the contrasting case analysis to avoid confounds.
                    To  analyze     the interaction,  we   applied   a  rating scheme      that assessed   the   quality of   students'
         collaboration on two different levels. The first level of analysis focused on the quality of collaborative problem-
         solving during particularly difficult problem sequences: Mathematical understanding (MU) assesses the dyad's
         comprehension of the problem steps, taking both the correctness of their solution and the expressed level of

3-3
understanding when reading hints or correcting errors into account; capitalization of the social resource (SOR)
and capitalization of the system resources (SYR) assess if students effectively use the learning opportunities
given  in the  enhanced      Tutor    environment,   and  dyad's   strategy (DS)     summarizes    students'   general  behavior
during problem-solving by describing their main learning strategy with five distinct categories (e.g. trial and
error  strategy   vs.  consulting    with  their  partner). On    the second    level, we   divided  the problem     into several
sequences and evaluated students' collaborative behavior based on an adapted version of the analysis method
developed by Meier, Spada, and Rummel (2007): Communication flow (CF) assesses if students show mutual
awareness and maintain a joint focus, mathematical elaboration (ME) and elaboration on hint (EH) evaluate the
extent  and    quality    of students'   elaboration   on   their actions and    on    CTA   hints  they  receive,   and   dyad's
motivation (DM) measures students' attitude towards the joint problem-solving activity. We applied the rating
scheme to our process data using Activity Lens (formerly known as ColAT), a software tool that permits the
integration    of several      data  sources   (Avouris,    Fiotakis,  Kahrimanis,     Margaritis,   &   Komis,    2007).   With
ActivityLens, CTA log data and video recordings were combined, enabling us to select specific sequences of the
video for process analyses. Rating was done on a five-point scale (0 = very bad, 4 = very good). To guide the
rater's assessment, a rating handbook described the dimensions in more detail and gave examples for high and
low   ratings. Analysis      of interrater reliability (ICC,   adjusted, single  measure;    Cohen's      for dyad's strategy)
showed good results. Ratings were averaged across sequences, yielding one score per dimension for each dyad.

Results
          Table 1 shows process and outcome data of the two focus dyads. Although both dyads entered the
learning   situation      with  a similar    prior  knowledge,    the  dyad     Hertz   (anonymous      student    login) needed
substantially  more       assistance  to solve the   collaborative    retention test   than Aristotle.  Data   from  the  process
analysis could help to explain the difference: although both dyads made a similar amount of errors on the first
attempt (ER), Aristotle took greater advantage of both social and system resources (SOR and SYR) offered in
the collaborative CTA environment. In particular, they did not engage in trial and error strategy to solve the task
(DS),  but  used      the hints  offered   by the   CTA   as starting  point    for elaboration    (EH). Also,   the amount    of
elaboration on the mathematical problem (ME) was higher than in the Hertz dyad. This positive collaborative
behavior reduced the overall amount of assistance needed from the system (AS). Further, it is interesting to note
the high ratings of the Aristotle dyad's communication flow (CF) and their motivation (DM). We cannot judge
whether   this    greater    motivation   was  a    consequence    or  prerequisite    for  the successful     collaboration.  To
summarize, the better collaborative outcome of Aristotle could be explained by the superior interaction: this
dyad   was  able  to   transfer   the scripted collaborative   behavior   from   instruction    to post  test. They  engaged   in
mutual elaboration and used the collaborative learning environment more effectively. Further analyses will be
needed to see if the dyad's positive interaction can also be found in the collaborative future learning test, that is,
if it helps them to approach the new mathematical content. Also, we have to explain the worse interaction in the
first dyad,  i.e. why     they  did   profit less   from the script   support.  To   answer  this  question,   we  are  currently
analyzing their collaboration during instruction and these results will be presented at the conference.

Table 1: Process and outcome variables of two selected dyads

                                 outcome variables        process variables level 1          process variables level 2
       Dyad            PR        ER           AS          MU       SOR    SYR        DS      CF      ME        EH    DM
       Hertz           81,0      0,40         2,00        1,0      1,5    1,0        yes     2,3     1,0       1,0   2,0
       Aristotle       82,5      0,38         1,03        2,5      3,5    3,0        no      4,0     2,8       2,3   4,0
          PR = averaged prior knowledge, ER = error rate, AS = assistance score, MU = mathematical understanding, SOR = capitalization
on social resource, SYR = capitalization on system resources, DS = occurrence of trial and error or hint abuse as dyad's strategy, CF =
communication flow, ME = mathematical elaboration, EH = elaboration on hint; DM = dyad's motivation. Grey indicates interaction
ratings higher than 2

Using Contrasting Cases to Understand How Learners Use Online Resources

                          Cindy E. Hmelo-Silver, Rutgers University, New Brunswick, NJ, USA
                      Heisawn Jeong, Hallym University, Chuncheon, Gangwon-do, South Korea

          The goal of this study was to explore how students use online learning resources and how this may be
related to their learning in an online problem-based learning (PBL) environment. Little research has examined
students' exploration of learning resources. We believe analyzing contrasting cases is particularly useful when
little prior research can inform us what the critical aspects of students' activities are and can help in identifying
important   resource      exploration    activities related to students'  learning.    Learning    resources   refer to   the raw

                                                                                                                                          3-3
         materials of learning. Unlike textbooks or handouts specifically tailored to students' grade level and learning
         objectives, this is not necessarily the case with learning resources. For learning resources to become useful for
         students' learning,  the information   in the learning   resources needs to  be selected  and  processed further  to
         meaningfully address students' learning needs in the course of PBL.

        Methods
                  This study was conducted in the context of the online STELLAR environment for PBL (Derry, Hmelo-
         Silver, Nagarajan, Chernobilsky, & Beitzel, 2006). The STELLAR system provides preservice teachers with
         opportunities to engage with learning sciences concepts by using video cases as contexts for collaborative lesson
         redesign. The system consists of three components: an online learning sciences hypertext, the Knowledge Web
         (KW); a PBL online module; and a library of video cases that present examples of classroom practice. These
         cases provide rich contexts for discussion as students engage in redesign of instruction depicted in the cases as
         well as providing links to the KW, helping students identify fruitful concepts for further exploration.    The PBL
         online module   provides  tools  that  scaffold students' individual  and   group activities, including  a  personal
         notebook for recording initial observations, a threaded discussion for sharing research, and a whiteboard where
         students  discuss proposals  for lesson   redesign. This STELLAR     course  consisted of 3   online problems,  each
         lasting 2-3 weeks and using a hybrid online and face-to-face course structure. The students' goal was to redesign
         a lesson based on learning sciences principles. They started by individually studying a video case and recording
         observations and ideas in an online notebook. The group then identified concepts to explore for their redesign,
         conducted  and shared    research, and collaboratively   designed  lessons. They  used threaded  discussions  and a
         group whiteboard as shared workspaces in for their online work. The students met face-to-face as they identified
         concepts to explore and shared the redesign at a poster session. This study examined how students went about
         selecting and processing information from various learning sciences concepts in the KW.
                  To identify resource use linked to students' learning outcomes, we selected one high-achieving group
         (Group H) and one low-achieving group (Group L) and examined how they differ in various aspects of resource
         exploration. Groups were selected based on mean course grade, which included grades for PBL activities, a
         take-home final, and a video analysis task. The most effective group had the highest mean grade in the class.
         The contrasting   group  had the   second  lowest   mean grade.  We  did not  select the  lowest group  because   of
         extremely uneven participation. The second lowest group was chosen for contrast because there was relatively
         even participation among the group. We studied these groups as they worked on the second online problem.
                  The analysis was based on students' log data and their postings on the Discussion Board and group
         White Board. Based on these data, we contrasted the two groups on activities related to resource use (e.g., type
         of resources used, number of visits to resources). The analyses are ongoing, but so far quantitative analyses
         showed that more successful groups tended to explore resources more widely and deeply (Jeong & Hmelo-
         Silver, 2008). In this paper, we report on how the two groups differed qualitatively in processing the information
         provided in the KW.

        Results and Discussion
                  Both Group H and L researched similar numbers of concepts in the KW and posted portions of their
         research on the Discussion Board. To clearly differentiate how the two groups might have encoded the resources
         differently, we analyzed the postings on the concepts that both groups researched. There were two such concepts,
         `hands-on  learning'  and `discussion  methods'.    Comparison  of  the contents  of posting  revealed that the two
         groups adopted different strategies in processing and posting the results of their research. Group L more or less
         directly copied and pasted the contents of the KW onto the Discussion Board. On the other hand, Group H,
         although they also did lots of `copying and pasting', processed it further. They edited the contents of the KW
         prior to posting. Their copying was more `selective' in the sense that they did not copy the whole paragraph, but
         only parts of it, probably the one's they deemed relevant and important to their current problem. Group H also
         paraphrased the contents and generated inferences, which can be clearly seen in the following example. Both
         groups posted what they found out about `IRE' from the KW. The KW's description is:

                  "Initiate, respond, evaluate"    is used   frequently in  what  may   be labeled   the traditional
                  classroom. It has been called the "default pattern" in classroom discourse. The teacher asks a
                  question and the student answers, but its goal seems to be a playback of course content rather
                  than a window into deep learning. Teachers may feel more comfortable with this technique
                  when they seek more control or want to probe comprehension while keeping students more
                  attentive to what they are saying. (See Chinn & Waggoner, 1992).

         Group L's posting on IRE was an exact copy of this paragraph down to the citation. In contrast, Group H's
         posting on the same topic was:

3-30
         IRE (Initiate, respond, evaluate) - this is considered the traditional way of teaching. First the
         teacher asks a question then the student responds and the teacher then either rewards the
         student if it's a correct answer by appraisal or corrects them with the correct information.

Note that Group H first connected what IRE stands for by putting `initiate, respond, and initiate' inside the
parenthesis. This post also summarized the rest of the explanation in the student's own words. Note also that the
last part of the description `the teacher then either rewards the students if it's a correct answer by appraisal or
corrects them with the correct information' was not in the KW's definition. Thus, the student elaborated the
definition.
         Regardless of how much information is available as a resource, it needs to be processed and integrated
with the learner's representation and toward the goal of generating problem solutions. Our analysis suggests that
what sets more and less successful groups apart was not necessarily the number of concepts researched but
rather how they processed and used the information provided in the learning resources. Although contrasting
cases were   useful in identifying   potentially important learning  processes, however,    these  findings  remain  as
hypotheses that need to be further examined but they suggest more formal coding methodologies that might be
used in subsequent studies.

CSCL Learning Outcomes Beyond Process: Nature or Nurture?

                                   Nancy Law, University of Hong Kong, China

      Irrespective of the theoretical or methodological subscription of the teacher/researcher, work in the area of
CSCL   is generally  underpinned   by    the assumption  that  learning is facilitated by  social  interactions  among
learners and that the learning outcomes can be improved through better task design (e.g. whether the production
of a concrete deliverable is involved, etc.) and/or process (e.g. use of scaffolds, grouping, awareness tools, etc.)
designs.  However,   do   individual  characteristics matter?  If yes,  what  characteristics, and  how?    This   paper
examines three sets of contrasting cases of CSCL using Knowledge Forum® for asynchronous discussion to
identify what kinds of differences appear to contribute to different learning outcomes in knowledge building.
The findings point to three important factors associated with different levels of learning outcomes: the extent to
which  the  learners   relates to the  inquiry   problem,  the  culture and   experience    of the  learners,  and  the
epistemological beliefs of the learner. While the first factor is related to the learning and facilitation design, the
second relates to nurture and the third appears to be closer to the innate intellectual orientation of the learner.
Some initial thoughts on the implications of these findings are discussed.

Contrasting cases set 1
      Two classes of grade 8 students conducted an inquiry on the topic of slimming, the first one (class A) with
less facilitation from the teacher, the second one (class B) with closer facilitation and greater expectations from
the teacher. The inquiry was carried out over a period of about 8 weeks with weekly class meetings. Students
used Knowledge Forum® to conduct their inquiry in groups of two to three students, ending with an informal
class presentation  of  the results.  A  misconceptions   test consisting  of items    on food,   lifestyle and  weight
management related to slimming was given to the two groups of students at the end of the learning process.
Class B accumulated much more discourse data compared to class A, which initially gave the impression that
class B  was  more   deeply engaged    in the  learning task.  On  the  other hand, the   misconceptions    test results
indicated that class A in fact had significantly fewer misconceptions in the food and lifestyle items compared to
class B. Further content analysis showed that class A had a higher density of keywords indicating reflection,
making claims and questioning than the other class. Class A students appeared to be able to develop greater
intrinsic interest and ownership in studying the topic as the teacher was more hands-off while the teacher gave
closer monitoring and more in-class discussion of the online discussions.

Contrasting cases set 2
      This  set of  cases involved    an international collaboration   between  two classes    of fifth grade  students
through an online discussion platform with one group more experienced in online knowledge building activities
than the other. Before the collaboration, the novice class tended to produce isolated notes filled with information
and confined their efforts to their own selected topics. When the more experienced class joined in, the discourse
of the students in the novice class changed from information-centered toward more meaningful negotiations;
many more of their notes were now linked with one another and they no longer confined their reading and
responses to their own study topic. The class more experienced in knowledge building more readily expressed
disagreement in their discourse. There was also evidence that the novice class learned to ask more questions in
their online discussion   from    the experienced  class.  When    the  joint-collaboration ended,  the     novice class
maintained the changes in interaction patterns that reflected a stronger knowledge building orientation. Besides

                                                                                                                           3-3
         differences in experience with online knowledge building activities, the difference in discourse behavior could
         have  some  relationship  with  the socio-cultural  differences  between    the two  classes.  The   novice  class was
         situated in Hong     Kong  and  the children  were  more   used  to studying    given   topics and   content while  the
         experienced class was from a Canadian school where learning in the school was generally organized around
         questioning and inquiry. This study was reported at some length in Lai & Law (2007).

        Contrasting cases set 3
               A class of grade 10 students was conducting online knowledge building activities on a number of topics,
         first on issues related to energy and later on global warming. While students may be similarly engaged in the
         discussion in terms of the frequency of their contributions and ownership of the topic under discussion, there
         can be distinct differences in the ontological categories of the ideas discussed. Some of the students focused
         their discussions on abstract concepts and tried to understand the mechanisms underpinning the problems of
         energy crisis and global warming. These students were able to point out early in the discussion some of the
         prominent misconceptions such as: the term energy crisis is a misnomer as it is more appropriate to refer to the
         problem as (non-renewable) fuel crisis; and ozone is not a green house gas. On the other hand, many of the
         students were not interested in understanding the mechanisms or abstract scientific concepts but much more
         interested in learning about what should be done to solve the energy crisis and how to contribute to slowing
         down  global   warming  at  a personal level  (e.g. ways  to reduce  electricity "consumption"     and   building  solar
         panels, etc.). Students tended to focus on only one of these two different foci though they were fully aware of
         the discussion on the other. A closer examination of this discussion reveals that the different discourse foci can
         be linked to different epistemological orientations of the students ­ what counts as valuable knowledge to the
         students. For example, some of the students expressed the following views in their online discussion:

                  My theory: I also don't understand why summer streamflows will increase, but we all know
                  that  there would  be  many  problems  if  global warming   is not  solved.  Therefore,   is it more
                  worthwhile for us to discuss the solution instead of the impact.

                  The scientists may find a perfect solution of global warming tomorrow. By the way, what we
                  can do is just we have learnt such as using public transports to replace driving ourselves and
                  use less air conditioners, etc. Think of a ultimate solution is not our work. There will be a
                  great help already if we do our responsibilities.

         There appear to be two parallel discussions that went on, one with understanding the scientific concepts and
         theories about energy crisis and global warming and generic approaches to solving these problems while the
         other conversation was on enumerating/identifying concrete methods of alleviating those problems. However,
         as the above discourse excerpts reveal, it is not true that these students were not reading or not aware of the
         other parallel discussion,  but they  have chosen    the  discussion they   wanted   to  engage   in  because of   their
         epistemological positions.

        Discussion
               Using contrasting cases reveals different factors contributing to differences in learning outcomes in CSCL
         settings. The findings from the first set of contrasting cases are in some sense "expected" as these reflect that
         teachers' behavior and engagement matters and that deeper learning will result from greater personal ownership
         and intellectual engagement in the topic of study. The findings are also potentially "more useful" in that it sheds
         light on pedagogical design that can be immediately relevant to the teacher. The second set reveals that the prior
         experience of students have important impacts on the learning process and outcomes. This finding does have
         pedagogical   implications, but the  "solution" is  not obvious  and involves    a  much   longer  term  design effort.
         Implications arising from the third set of contrasting cases are probably controversial. There is no indication that
         the  students' different   epistemological   orientations  (or  priorities) were    linked to   different   educational
         experience. Is the difference innate? Can it be nurtured? Can educational programs be designed to change one's
         epistemological orientation and if so, what role can CSCL play in it, if any?

       References
         Avouris, N., Fiotakis, G., Kahrimanis, G., Margaritis, M., & Komis, V. (2007) Beyond logging of fingertip
                  actions: analysis  of  collaborative learning   using  multiple    sources  of data.  Journal   of  Interactive
                  Learning Research, 18(2), 231-250.
         Baker, R. S., Corbett, A. T., Koedinger, K. R., & Roll, I. (2005). Detecting when students game the system,
                  across tutor  subjects and  classroom  cohorts.   Paper presented   at  the Proceedings   of  User  Modeling
                  2005.

3-3
Chinn, C. A., O'Donnell, A. M., & Jinks, T. S. (2000). The structure of discourse in collaborative learning. The
         Journal of Experimental Education, 69(1), 77-97.
Derry, S. J., Hmelo-Silver, C. E., Nagarajan, A., Chernobilsky, E., & Beitzel, B. (2006). Cognitive transfer
         revisited: Can we exploit new media to solve old problems on a large scale? Journal of Educational
         Computing Research, 35, 145-162.
Diziol, D., Rummel, N., Spada, H., & McLaren, B. (2007, July). Promoting learning in mathematics: Script
         support for collaborative problem solving with the Cognitive Tutor Algebra. Paper presented at the
         Conference on Computer Support for Collaborative Learning (CSCL) 2007. New Brunswick, NJ, USA.
Ericsson, K., & Simon, H. (1987). Verbal reports on thinking. In C. Faerch & G. Kasper (Eds.), Introspection in
         Second Language Research (pp. 24-54). Clevedon, Avon: Multilingual Matters.
Firestone, W.  A.   (1993). Alternative  arguments    for generalizing  from  data as applied   to qualitative researh.
         Educational Researcher, 22(4), 16-23.
Fischer, F., Kollar, I., Mandl,    H., &  Haake,   J.  (Eds.). (2007).  Scripting  computer-supported     collaborative
         learning. New York: Springer.
Jeong, H., & Hmelo-Silver, C. E. (2008). Use of learning resources in a technologically-mediated online PBL
         environment. In Proceedings International Conference on PBL 2008. Colima, Mexico.
Koedinger, K. R., Anderson, J. R., Hadley, W. H., & Mark, M. A. (1997). Intelligent tutoring goes to school in
         the big city. International Journal of Artificial Intelligence in Education, 8, 30-43.
Koschmann, T. (1996). CSCL: Theory and practice of an emerging paradigm. Mahwah, NJ: Erlbaum.
Lai, M., & Law, N. (2007). Peer Scaffolding of Knowledge Building through Collaboration of Groups with
         Differential Learning Experiences. Journal of Educational Computing Research, 35(2), 121-142.
Marton, F. (2006). Sameness and difference in transfer. Journal of the Learning Sciences, 15, 499-535.
Meier, A., Spada, H. & Rummel, N. (2007). A rating scheme for assessing the quality of computer-supported
         collaboration processes. International Journal of Computer-Supported Collaborative Learning, 63-86.
Rummel, N., & Spada, H. (2005). Learning to collaborate: An instructional approach to promoting problem-
         solving in computer-mediated settings. The Journal of the Learning Sciences, 14(2), 201-241.
Salomon,   G., &  Perkins,   D. N.  (1998).  Individual   and   social aspects of  learning. Review    of Research  in
         Education, 23, 1-24.
Stegmann, K., Wecker, C., Weinberger, A., & Fischer, F. (2007). Collaborative Argumentation and Cognitive
         Processing - An Empirical Study in a Computer-Supported Collaborative Learning Environment. In C.
         Chinn, G. Erkens, S. Puntambekar (Eds.), Mice, Minds, and Society (pp. 661-671). New Brunswick:
         ISLS.
Strauss, A., &  Corbin.   (1998).  Basics   of  qualitative research:   Techniques    and procedures   for developing
         grounded theory (Second ed.). Thousand Oaks CA: Sage.
Teasley, S. (1995). The role of talk in children's peer collaborations. Developmental Psychology, 31,      207-220.
Teasley, S. (1997). Talking about reasoning: How important is the peer in peer collaboration? In L. B. Resnick,
         R.  Säljö, C.  Pontecorvo     & B. Burge   (Eds.),  Discourse,  tools  and   reasoning:   Essays  on  situated
         cognition (pp. 361-384). Berlin: Springer.
Vygotsky,   L. S. (1978).   Mind   in  society. The development    of  higher  psychological   processes.  Cambridge:
         Harvard University Press.
Weinberger,  A.,  &  Fischer,   F. (2006).  A   framework    to analyze  argumentative    knowledge    construction in
         computer-supported collaborative learning. Computers & Education, 46, 71-95.

Acknowledgements
Diziol et al.: This research project was partly funded by the Pittsburgh Science of Learning Center (NSF), by the
Landesstiftung  Baden-Württemberg,       and    by  the   Kaleidoscope   Network   of  Excellence   project    Cavicola
(Computer-based     Analysis  and  Visualization    of  Collaborative  Learning   Activities).  We  thank  Dr.  Bruce
McLaren for his constructive support and input during the initial stages of the project. Hmelo-Silver & Jeong:
This research  was  funded   by  an   NSF ROLE     grant  # 0107032.   Any   opinions, findings,   and conclusions  or
recommendations     are those of   the authors  and do  not  necessarily reflect  the views  of the National   Science
Foundation.    Weinberger,    Stegmann,     &    Fischer:   This  research    project  was     funded   by  Deutsche
Forschungsgemeinschaft (DFG).

                                                                                                                          3-33
