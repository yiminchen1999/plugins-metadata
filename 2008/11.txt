Identification ­ Interpretation/Evaluation ­ Response: A framework
      for analyzing classroom-based teacher discourse in science

            Loucas T. Louca, European University-Cyprus, P.O. Box 22006, 1516 Lefkosia, Cyprus,
                                              Louca.L@cytanet.com.cy
        Dora Tzialli, Zacharias C. Zacharia, University of Cyprus, P.O. Box 20537, 1678 Lefkosia, Cyprus
                                     Email: sep7td2@ucy.ac.cy, zach@ucy.ac.cy

         Abstract:  The   first aim  of  this study was   to  contribute  to a  growing   body   of  research     in
         teacher-student   classroom   discourse, by   describing,  in  detail, the  discourse     "moves"     of a
         teacher during   science conversations.    Our  second   aim   was  to develop   an enriched     analytic
         framework   that  can   account for  the context,   the  content and   the purpose   of   the discourse
         moves identified, arguing for a shift of attention in research toward the process of deciding
         which discourse move to use, rather than solely their description. We analyzed a total of 930
         minutes of whole-class conversations facilitated by an experienced science teacher over two
         years of elementary science lessons. The findings revealed a repertoire of discourse moves
         that the teacher chose from during instruction based on the context and the epistemological
         properties of   the student   discourse  content,   supporting   our   contention   for the   need    of a
         framework that can describe the nature of those choices.

Introduction
         A  fast growing   body   of research  in science   and   other educational    contexts  has   built an   interest in
classroom-based discourse (e.g., Abell et al, 2000; Carlsen, 1991; Driver et al, 2000; Gallas, 1995; Hogan, 1999;
Kelly & Crawford, 1997; Lemke, 1990; Cazden, 2001; Edwards & Mercer, 1987; Edwards & Westgate 1994)
for its relevance to student inquiry (Gallas, 1995; Hammer, 1995; van Zee & Minstrell, 1997; van Zee, 2000;
van Zee et al, 2001), to the development of student ideas in science (Mortimer, 1998) to student acquisition of
cognitive and social skills (Cazden, 1988; Edwards & Mercer, 1987), and to student conceptual change and
cognitive development (Adey & Shayer, 1993). Following this current trend in science education research, along
with  an  emphasis  to   develop  rich,  detailed   case  studies  of   authentic  science   lessons   as    a strategy    for
investigating patterns of talk in authentic science lessons (Chin, 2006; van Zee et al, 2001; Arons, 1983; Roth,
1996;   van Zee  &  Minstrell,  1997;  Watt,  1996;   Barnes  &   Todd,   1977),   we   investigated a  science     teacher's
discourse moves over the course of two years of teaching. Our aim was to provide a detailed picture of the
teacher's discourse moves by accounting for the context, the content and the purpose of each teacher move
identified as a response to student conversational contributions, as well as, to develop an analytic framework for
studying teacher-student classroom discourse in naturalistic science lessons.

Theoretical framework
Classroom interaction and discourse in science
         The study of teacher-student classroom interaction and discourse has recently received the increasing
attention of the educational research community. As a result a number of studies focused on this issue, which
revealed a variety of theoretical views about the analysis of discourse that differ in the aspects of discourse that
each analytic framework     looks into.  Thus,   suggesting  that classroom    discourse  is by    nature a  very    complex
process that includes numerous aspects that one has to take into account.
         For  instance,   Edwards    and  Mercer      (1987)   organized     their  analysis  of   the    classroom-based
communicative    processes   around  the  extent  of  the  teacher  control   over  the  discourse   and   the    content  of
knowledge,   which  appears   to  be a  central  theme   in  classroom   talk.  They    identified numerous       features of
teachers' classroom-based discourse with varying teacher control, but they suggested that teachers often exert
tight control over classroom-based discussions even in the cases of hands-on student-centered science activities.
Lemke (1990) identified two broad categories of discourse strategies, dialogue and monologue strategies, used
by science teachers. Among the most influential features of Lemke's work was the identification of what he
found to be the primary mode of classroom discourse. He named it "triadic dialogue," and it typically consists of
three moves: (i) teacher initiation of the conversation (often through a teacher question), (ii) student response to
the question  and  (iii) teacher evaluation   of that response.   According    to  this framework    the  teacher    asks  an
information-seeking question, requiring a short answer. After the student response, the teacher praises correct
answers  and  makes  corrections    to  those  answers   that were  incorrect   or  provide  feedback     by   encouraging
students to externalize ideas, generate hypotheses and test them. This framework has been commonly refereed to
as  the "IRE"  framework     (Initiation-Response-Evaluation;     Mehan,   1979)    or  the IRF    framework      (Initiation-

                                                                                                                                  2-
       Response-Follow-up or Feedback, Sinclair & Coulthard, 1975; Cazden, 1988) in an effort to highlight that the
       role of the third move doesn't necessarily need to be an explicit or formal evaluation of the student contribution.
                Chin    (2006)  analyzed   classroom-based   discourse  specifically   looking   for patterns   of   teacher
       questioning and she developed a "questioning-based discourse" analytic framework coding for four aspects of
       discourse: the student's discourse content, the type of the teacher's utterance (as a response to the preceding
       student utterance), the student thinking elicited, and the interaction pattern. Chin's study showed that depending
       on the correctness or not of the student answer, the teachers in the study differentiated their feedback. Orsolinini
       & Pontecorvo (1992) analyzed a number of small or large group science discussions among students 5 and 6
       years of age.    Their analysis dealt  with the  discourse  continuity (minimal   talk vs. extended    talk) and   the
       agreement  or  disagreement   among    different speakers.  The  most  frequent   categories  of teacher's   talk was
       repetition/rephrasing, requests for clarifications and requests for explanations.
                Mortimer and Scott's (2003) framework includes two dimensions of classroom discourse: interactive or
       non interactive discourse as the one dimension, and authoritative or dialogic discourse as the second dimension.
       In the authoritative discourse the teacher conveys information and his discourse involves questions, statements
       of facts and reviews, and student utterances are usually given in response to a teacher question and they have
       limited length. On the other hand, the dialogic discourse supports challenge and debate and it often includes
       open questions. Student discourse is in many cases spontaneous and consists of longer sentences. Both types of
       discourse can be interactive and non-interactive, depending on the role of the students.
                Van   Zee  &  Minstrell (1997)  examined   ways   of speaking  of an  experienced   teacher that  foster  the
       communication of physics principles through "reflective discourse," By in which a student provides statement
       expressing student's own thoughts, comments and questions and then a teacher asks a question (based on that
       student statement) that seeks to help students better articulate their ideas, beliefs and conceptions, followed by
       additional student statements.   That definition excludes teacher questions that test student knowledge and the
       evaluation of correctness of student answers. Rather, in reflective discourse the teacher tries to reflect student
       thinking back to them providing them space to express their own thoughts in comments and questions. van Zee
       and Minstrell's (1997) analysis focused on the immediate actions plans that teacher's reflective discourse moves
       instantiated, the emergent   goals  they served   and the  underlying  beliefs they  embodied.    They identified   3
       recurrent themes that describe the use of questions by the teacher during reflective discourse: he used questions
       to help his students (a) make their meanings more clear, (b) consider a variety of views in a neutral manner and
       (c) monitor the discussion and their own thinking.
                In addition to the variety of theoretical views about the analysis of teacher-student classroom discourse
       shown above, two additional issues emerge from this literature. First, studies applying the IRF framework for
       analyzing classroom discourse focus more on the structure of the discourse (how a cycle of teacher question and
       student answers is initiated and maintained). However, other studies (e.g., van Zee & Minstrel, 1997; Chin,
       2006; Roth, 1996) suggest that teacher questioning, for instance, is influenced by the content and the context of
       the discourse, which the IRF cannot describe, because the unit of analysis is teacher question-student answer-
       teacher feedback. Second, although these studies have revealed a large collection of teacher discourse-based
       strategies mostly (but not exclusively) for asking questions, they have failed at large to provide a framework that
       could be   useful in   both studying  teacher discourse,  and also helping  teachers   to prepare  for this  kind  of
       classroom-based discourse. Following van Zee and Minstrel's (1997) and Chin's (2006) studies we feel that
       science teacher education community needs to develop better understandings about how teachers respond to
       their students' contributions, as well as, the discourse moves that may be used in different contents and contexts.
                The first aim of this study was to contribute towards this way. Specifically, we aimed to describe the
       discourse moves of an experienced science teacher as a response to student conversational contributions within a
       science learning environment. In doing so, we feel that it is vital to our analysis to provide as many details as
       possible not only about the teacher's discourse moves, but also the context and the content that might have
       influenced   his moment-by-moment      decisions.  Below,   we  provide  a review   of  the   most frequently     used
       framework for analyzing teacher-student classroom discourse, namely, the IRF framework, and explain why it
       cannot serve as the framework for contextualizing our study. In particular, we suggest that the IRF structure
       represents only   a small   segment of the  teacher-student classroom  discourse,  in  which  the  focus  is only  on
       teacher initiation and follow-up in a discussion, whereas, a framework that focuses on student contributions and
       teacher responses to those contributions in a conversation is needed. By this, we argue for a shift of attention in
       research towards investigating the process of deciding which discourse move to use, rather than solely their
       description.

       Analysis of teacher discourse
       The IRF as a framework for analyzing classroom discourse
                Lemke's (1990) IRF framework has dominated the research in classroom discourse over the last decade
       or so (Chin, 2006; Mortimer & Scott, 2003), by becoming the most commonly way of analyzing classroom
       discourse and therefore investigating teacher questioning as a prominent feature of such classroom talk (Carlsen,

2-2
1991; Dillon, 1988; Gall, 1984; Hunkins, 1989). However, IRF framework has received numerous criticisms
over the years. First, while there might be some useful features in this framework, it reflects at large traditional
approaches to teaching (Cazden, 2001). Viewing teaching through the IRF lens, provides a (traditional) view of
teaching that involves moving through a series of questions planned ahead of time (van Zee & Minstrell, 1997),
which  fit the  teacher's agenda.   The   teacher   asks  only   "display"    questions  to which   she  already  knows   the
answer, aiming at testing student knowledge or "co-opting students to participate in what could be otherwise a
lecture" (Cazden, 2001, p. 46). The application of the IRF framework in teaching has also restrictive effects on
students reasoning, forcing student responses to be short, pitched at the recall or lower-order cognitive level, and
teacher-framed   (Chin,   2006).  Also,   it cannot    account    for  adjustments    to  the   teacher's agenda    during a
conversation, acknowledgment of student contributions in the conversation (in the light of engaging students in
taking more responsibility for thinking), or shifting authority for judging students answers from the teacher to
the students, in one way of fostering more critical ways of thinking (van Zee & Minstrell, 1997).
         Second, despite calls for promoting student inquiry in elementary grades (Hawkins, 1974; NSES, 1996;
Minstrell & van Zee, 2000; Osborne et al., 2004; Louca & Hammer, 2007) in contrast to traditional views of
simply  promoting    traditional content  in   science  learning,   the  application   of  the  IRF   framework   in science
teaching and learning ignores aspects related to student inquiry and developing student abilities for scientific
reasoning.   As van Zee & Minstrell, (1997) note, inquiry teaching in science involves a rather complex process
of adjusting    questioning based   on   the teacher's    evaluation   of   what   takes  place  during   the discussion,  to
accommodate student contributions. However, the F step of the framework focuses on the correctness of the
student's answers (thus representing a focus on content) and not on student i.e., abilities for student inquiry.
         Thirdly,   although this   framework     can  be  used   for  analyzing    classroom   discourse   focusing  on  the
teacher's practices, it ignores the relation of those practices to student discourse. Even in the case of Mortimer
&Scott (2003) who suggested a possible expansion of this framework (from IRF to IRFRF) to represent dialogic
interactions in  the classroom   discourse,    they still assume    that  all discourse   moves   need   to be initiated  and
concluded by the teacher who will be closely eliciting, monitoring and providing feedback to student discourse
with no reference to the notion of teacher responses as a follow-up of student discourse (van Zee et al, 2001;
Orsolini   & Pontecorvo,    1992).  Carlsen    (1991)     has argued    that  research   on  classroom-based     questioning
discourse  must  acknowledge     that the meaning      of questions   is dependent    of  their context   discourse, that the
content  of  questions  cannot   be ignored,   and   that  research    on   questioning   has   needs to  acknowledge     that
classroom questions are not simply teacher behaviors but mutual constructions of teachers and students.
         We   do  not   undervalue  the  Lemke    (1990)  framework,     since  it  played  an  important   role in directing
research on aspects of classroom-based discourse.         However, the IRF structure represents only a small fragment
of the teacher-student    classroom   discourse.   Chin   (2006)  suggested    that "future   research  could  look  into the
differential effect of different types of feedback, the conditions under which different types of feedback are most
effective"  (p. 1341).  We  feel that there    is much    more   going on   in the  classroom   than  asking  questions   and
evaluating student answers to those questions. Thus, we suggest that instead of having a framework that focuses
on teacher   initiation and follow-up    of  a discussion,    it might   be more    productive  to  have  a framework     that
focuses  on  the student  contributions  during    the conversation    and    teacher decisions/responses     based  on those
contributions (van Zee et al, 2001), representing an on-going assessment that "includes monitoring what the
students are saying for aspects that may be productive in moving the inquiry forward, even if these differ from
scientifically accepted views" (van Zee et al, 2001, p.163). As van Zee & Minstrell (1997) note "analyzing
teacher-student-teacher sequences directs attention to the steps by which a teacher moved through a set of ideas
associated with a topic. Shifting the unit of analysis one turn, to student-teacher-student sequences, highlights
the ways that a teacher's questions influenced student thinking" (p. 230).

Our Identification ­ Interpretation/Evaluation ­ Response Framework (I.IE.R)
         Given the need for a more enriched framework for analyzing the teacher-student classroom discourse
than the   IRF,  we  propose a   new  framework     that  suggests    moving   from   a   teacher  initiation and   follow-up
framework, to a framework focusing on student contributions and teacher responses to those contributions. Our
framework has a three-part structure, consisting of (i) teacher identification of student contribution (answering
to the question "what is the teacher responding to?"), (ii) teacher interpretation and evaluation of their students'
contribution and (iii) teacher response to their students' contribution ("how is the teacher responding?"). Our
framework is concerned with how teachers perceive student contributions in a conversation in science, how they
evaluate them and how they respond to those contributions. We do not narrow teacher actions and responses
only to  questions,   but we  seek    to broaden    the   framework    to   account   for teacher   prompts,   clarifications,
evaluations and restatements of student contributions.        Additionally, we take student contributions to include not
only knowledge claims and ideas, but also student reasoning and inquiry, student epistemologies, and student's
use of empirical data and everyday experiences to support their ideas, thus making the framework more student-
centered to account for the complexity of the regular science classroom, following research suggesting that the

                                                                                                                                 2-
       role of science teachers should be viewed as supporting student inquiry (i.e., Hammer 1995) and student sense
       making in the science classroom (i.e., Scott, 1998).

      Methodology
                This is a qualitative case study documenting ways of speaking (Hymes, 1972; Hymes & Farr, 1982;
       Philipsen,   1982; 1992)   of a  particular  teacher  in a  particular  context  (van    Zee   &  Minstrell,  1997).  We
       investigated the discourse moves of a male teacher in science lessons over the course of two years of once-a-
       week lessons. The selection of the teacher was based on three reasons: (a) his substantial experience in teaching
       science  in  elementary  schools  (13  years), (b)  his educational   background    (doctoral  student)  and  (c) he  was
       identified as one of the exemplary teachers by the school district.
                The study involved two groups of students, one group per year, at a metropolitan elementary school in
       Cyprus. The first group involved 5 fifth graders and 4 sixth graders (year 1), whereas, the second group involved
       4 fifth graders and 7 sixth graders.       During  each  year, we   set up  an  afternoon   computer/science    club, and
       students volunteered to participate in the study. Students (10-12 years olds) met with the same teacher once a
       week for 90 minutes for a total of 7 months, during which they studied a number of physical phenomena. From
       a total of 47 lessons videotaped (24 during the first year and 23 during the second year), 32 (16 per year) were
       spent studying physical phenomena (a total of 1920 minutes of classroom work). For this study, we purposefully
       selected and fully transcribed whole class conversations from all teaching sessions as the primary data source. A
       total of 930 minutes of student conversations facilitated by the teacher were analyzed.
                For  the  purposes   of this study, we   analyzed   discourse  data   using our  proposed    I-IE-R  framework.
       However, due to space limitations, in this paper we report findings only for the "I" and "R" part of our I-IE-R
       framework because they are the only parts that could be directly derived from the analysis of transcript.             The
       "IE" part is not a process that we can code for from the transcript, but a mental process that we can only see its
       results (the  "R"  part of  the  framework).   In a different  paper   we   discuss  data   collected from  a number   of
       interviews with the teacher that provide insights to the IE process. Following Chin's (2006) study, we developed
       a coding scheme for 3 aspects of classroom discourse that are relevant to the I-IE-R framework: (a) what did the
       teacher respond to (coding for student contribution(s) that the teacher responded to), seeking to account for the
       "I" part of the analytic framework, and (b) how did the teacher respond. The latter two were used to account for
       the "R" part of our analytic framework. Working from the transcript we isolated each teacher utterance and the
       first two authors investigated its immediate before and after context, trying to reach a consensus as to what was
       the teacher responding to and how he responded to what he was identifying (both in terms of type of discourse
       used and the content of its response). Starting from the literature we identified a number of different areas for
       each of the three discourse elements that we intent to code for. Then, in many reiterative cycles of interpretation
       we discussed our emerging codings and made adjustments following open coding (Strauss & Corbin, 1998). Our
       unit of  analysis  was  the I-IE-R    "exchange"   which    included  the  preceding   discourse   that the  teacher  was
       responding to, and his immediately response. After finalizing our coding scheme, coding was carried out by the
       first two authors independently (Cohen's Kappa=0.835), and differences in the assigned codes were resolved
       through  discussion. We    then  presented   findings to the teacher    in the context   of an informal  interview,   as a
       participant check.

      Findings
       What did the teacher respond to?
                The first aspect of the teacher discourse codes for what the teacher responded to ("I" part the I-IE-R
       framework).   This  required  close inspection  of  the  utterances  preceding  each   teacher   "move",  as  well as the
       teacher response and then try to reach intercoder agreement on which of those aspects the teacher responded.
       Therefore, the first aspect of our framework identifies which part of the student conversational contribution the
       teacher responded to.
                Following the attention of current trends in science education research (Louca & Zacharia, 2007; May
       et al, 2006; Russ, 2006), our final coding scheme includes five different areas (see Table 1) that account for the
       all the types of student contributions we have identified in the conversations analyzed, and beyond of traditional
       views   that focus solely  on   scientific  knowledge   (content), to   include issues   related with   student scientific
       reasoning    and logic, the  nature   of the science    and logistical  issues  related  with  the management      of the
       conversation. Those five areas include: (i) knowledge claims (73,4% of the total utterances coded), (ii) scientific
       reasoning and logic (5,6%), (iii) everyday experiences (5,9%), (iv) epistemologies (0,7%), and (v) the direction
       of the conversation (14,1%).
                By knowledge claims we refer to conversational elements that are directly related with the content (that
       is, the knowledge) of the conversation, similar to what Mortimer & Scott (2000) suggest and to what Chi (2006)
       has included in her coding scheme.       However, we have expanded this category to differentiate among different
       conversational   elements  that  may   fall under  the  knowledge    claims    category.  Almost   half of  the teacher's
       responses addressed scientifically accepted knowledge claims (49,7% of the total coded utterances, or 67,8% of

2-
the utterances coded under knowledge claims), whereas 11,1% of his total responses (or 15,1% of the utterances
coded under  knowledge    claims) addressed  non-scientifically accepted  knowledge    claims.    7,6%  of the  total
teacher's responses (or 10,4% of the utterances coded under knowledge claims) were invoked by the emergence
(or presence) of a number different knowledge claims in the conversation offered by different students. 2,8% of
his total responses (or 3,8% of the utterances coded under knowledge claims) seemed to have been invoked by a
student changing a previously stated idea, and 2,2% of the total teacher responses (or 3,0% of the utterances
coded under knowledge claims) followed a student question regarding a knowledge claim.
        As far as the teacher's responses to students' scientific reasoning and logic (5,6%) is concerned, they
were differentiated based on what David Hammer calls a hidden assumption underlying student ideas offered in
the conversation (3,1%  of  the total utterances coded  or  55,9% of  the utterances   coded under    reasoning   and
logic), scientifically accepted use of analogies (0,2% and 3,4% respectfully), non-scientifically accepted use of
analogies (0,2%  and   3,4% respectfully) (May   et al, 2006),  student claims   for a dependency     related to  the
phenomenon   under   study (0,4%  and  6,8%  respectfully), students  providing  grounds    for a previously  stated
dependency or knowledge claim (0,7% and 11,8% respectfully), and grounds for knowledge claims (1,0% and
18,6% respectfully).

Table 1. Different elements of the classroom discourse that the teacher responded to.

                          Scientifically accepted knowledge claim                                          49.7%
                          Non- scientifically accepted knowledge claim                                     11.1%
  Knowledge Claims(73.4%) A student changes her knowledge claimA student question regarding a knowledge claim2.8%2.2%
                          Different students present different knowledge claims                            7.6%
                          Hidden assumption                                                                3.1%
                          Scientifically accepted use of an analogy                                        0.2%
  Logic & Reasoning       Non-scientifically accepted use of an analogy                                    0.2%
        (5.6%)            Students offering a claim for a dependency                                       0.4%
                          Students offering grounds for a dependency or knowledge claim                    0.7%
                          Students offering grounds for a knowledge claim                                  1.0%
      Experiences         Experiences from everyday life related to the phenomenon under study             2.8%
        (5.9%)            Lack of experience related to the phenomenon under study                         3.1%
  Logistical issues of    A student changes the direction of the conversation                              2.6%
    the conversation      The teacher begins a conversation about a new topic                              8.8%
       (14.1%)            A student asks a question regarding the topic of the conversation                2.7%
                          A student asks a question about the kind/form of the answer that the
    Epistemologies        teacher expected (i.e., an example, a theory, a mathematical example)            0.3%
        (0.7%)            Lack of understanding the differences among contradicting knowledge
                          claims offered in the conversation                                               0.4%

        In terms of his responses to students' experience (6,3% of total utterances coded), 2,8% of the total
utterances coded (or 43,9% of the utterances that fell under experiences) were teacher responses to everyday life
experience appropriately related to the phenomenon under study that students shared in during the conversation.
0,4% of the total utterances coded (or 6,1% of the utterances that fell under experiences) were responses to
experiences offered in the conversation inappropriately related the phenomenon under study, and 3,1% were
responses to the lack of use of any experience related to the phenomenon under study to the conversation.
        Most of the cases that fell under his responses regarding logistical issues related to the discussion (14%
of the total utterances coded) were associated with the teacher beginning a new topic for conversation (8,8% of
the total utterances coded or 62,6% of the utterances that fell under logistical issues of the conversation). 2,6%
of the total utterances coded (or 18,4% of the utterances of this category) addressed a change in the direction of
the conversation caused by students' contributions whereas 2,7% of the total utterances coded (or 19% of the
utterances of this category) addressed a student's question related to the topic of the conversation.
        Lastly,  0,7%  of  the teacher's responses  addressed  issues related to epistemology.    In  particular, the
teacher responded to a student question about the kind or form of the answer that the teacher expected from
students (0,3% of the total coded utterances or 42,9% of the utterances coded under epistemology) or the lack of
students' understanding   about the differences  among  contradicting  knowledge     claims already   offered in  the
conversation (0,4% or 57,1% respectfully).

How did the teacher respond?

                                                                                                                         2-
                 Although research in student-teacher discourse in science has for some time now called attention on a
       number of different aspects of the discourse, a large part of research in educational settings has focused on the
       kinds and  characteristics of  teacher  questions  during  (science)  instruction.   We feel   that there is  much more
       going on in the conversation in terms of what the teacher does than solely asking questions. Starting from the
       literature (van Zee & Minstrel, 1997; van Zee et al, 2001; Edwards & Mercer, 1987) we identified a number of
       different ways for responding in the classroom, and then through open coding we developed new codes and a
       structure for   the different types of  teacher actions   during  the conversations    analyzed    ("R" part  the I-IE-R
       framework).     Our expanded coded scheme includes four major categories of teacher actions (see Table 2): (1)
       prompting (61,6%), (2) making clarifications (17%), (3) evaluating student ideas or reasoning (2,3%) and (4)
       restating student ideas (19,1%) (or as Edwards & Mercer (1987) suggest, paraphrastic interpretation of student
       contribution).

       Table 2. The teacher discourse moves.

                                                      ask students for ideas (open ended)                             10.8%
                             Knowledge Claims(38.3%)  ask students for ideas (non-open ended)ask students for justifications of their ideas13.5%14.0%
          Prompts for                                 ask students to evaluate different ideas                         3.7%
           (61.6%)           Reasoning (22.1%)        ask students to infer relationships among various ideasask students to engage in argumentation3.5%5.5%
                                                      ask students for explanations                                    9.4%
                            Experiences                                                                                1.2%
                            The topic under study                                                                      7.3%
             Make           Reasoning (1.1%)clarificationssimilarities among knowledge claimsClaims for "dependencies" 1.0%0.1%
             about          Students' experiences                                                                      1.2%
             (17%)          The direction of the conversation                                                          6.1%
                            Students' epistemologies                                                                   1.1%
        Evaluate students' ideas or reasoning                                                                          2.3%
        Restate student ideas or reasoning                                                                            19.0%

                 The coding scheme for teacher prompting (61,6%) (or as Edwards and Mercer (1987) put it elicitation
       of student responses) includes a number of different conversational elements. He prompted for student ideas
       about a situation/phenomenon in an open-ended manner (10,8% of the total utterances coded or 17,5% of the
       utterances that fell under prompts), or asked a question requiring a short and specific answer (13,5% and 21,8%
       respectfully).  Additionally, the teacher called for clarifications of a previously stated idea (van Zee & Minstrell,
       1997) or reasoning knowledge claims (14% or 22,8% respectfully), for evaluation of student contributions in the
       conversation (3,7% or 6,0% respectfully), for drawing connections among different contributions (3,5% or 5,7%
       respectfully),  and  for  engaging  in  argumentation     (5,5%   or 9%    respectfully).  He   also prompted     for the
       development of explanations about a previously stated idea or reasoning (9,4% or 15,2% respectfully), and for
       (additional) experiences (van Zee et al, 2001) that could support student ideas about the phenomenon under
       study or their reasoning (1,2% or 2% respectfully).
                 Teacher clarifications (17%) also cover a spectrum of different things that include clarifications about
       student knowledge     claims  (content) (7,3%   of the    total utterances coded    or 43,3%    of  utterances  coded  as
       clarifications), about similarities or differences among knowledge claims (1% or 6,2% respectfully), and claims
       about the  dependencies    related  to the phenomenon      under  study  suggested   by    the students (0.1%   or 0.6%
       respectfully).  Regarding     experiences, 1,2%   of the   teacher's    actions  (or 7,3%    of  his  actions  coded   as
       clarifications) were  related  to  examples  offered  in   the  conversation    and  their possible  relations  with  the
       phenomenon under study. Regarding clarifications about logistical issues related to the discussion, 6,1% (or
       36% respectfully) of the teacher actions were clarifications about the direction of the conversation.        Lastly, 2,3%
       or (6,7% respectfully) of his clarifications were addressing epistemological aspects of the student discourse in
       the form of clarifications about the kind or the form of the answer that he expected from the students.

      Discussion & Conclusions
                 By  combining   the  findings from   the two    coding  schemes,  a   number    of   instructional moves were
       revealed. For   instance, when    the  teacher responded    to  student questions    about   knowledge    claims, he  re-
       addressed  them  to  the whole  class,  without giving    any   answers directly or  dismissing  any  student   question.
       Additionally,   when  students  provided   scientifically incorrect  knowledge   claims    (ideas), the teacher   did not

2-
evaluate   them  himself, but  rather he    steered the  student  conversation   towards   evaluating    those  ideas and
focused, primarily, on identifying and addressing the flaws of students' reasoning rather their ideas. During the
informal interview, the teacher clarified that he used this strategy when he sensed that the students were not
simply stating an incorrect idea, but rather they reached incorrect conclusions through flowed reasoning. He
further explained that by addressing this kind of student reasoning, he hoped to help students resolve the issue.
Further, when the teacher responded to knowledge claims (73,4%), he prompted (43,7%) or less often made
clarifications (29,7%)   that were   related to the  knowledge      claims. Additionally,    the  teacher seemed   not to
respond differently to correct or incorrect knowledge claims, whereas he differentiated the responses between
correct (0,2%) or incorrect elements of student reasoning (0,2%). When he responded to his students' reasoning
(5,6%)  or experiences   (6,3%),  the teacher   seemed   not  to  follow a  dominant    strategy: he prompted   or made
clarifications related to knowledge claims, students' reasoning, experiences, epistemologies and direction of the
conversation.  His   responses to correct    reasoning   were  divided   between  prompts    for  reasoning   (0,1%)  and
clarifications for the direction of the conversation (0,1%), whereas his responses to incorrect reasoning were
divided between making clarifications for the topic under study (0,1%) and students' experiences (0,1%). We
will present details of the relationships between what the teacher was identifying in terms of student inquiry and
how he responded, as well as, short snippets of student-teacher interaction to ground our claims.
         Overall, the teacher's profile revealed a large repertoire of discourse moves that the teacher chose from
during instruction. Their use appeared to depend on the context and the epistemological properties of the content
of the  student   discourse, showing  sophistication     in identifying  and evaluating   student   contributions  in  the
conversation   prior to any   instructional response.    In different situations (i.e., correct  or incorrect  knowledge
claims or reasoning) he used a different discourse move based on the content and the context of the student
utterance he responded to.
         Findings from this study have two major implications for research and teaching. First, the revealed
repertoire of  discourse  moves,  along  with   other    research indicating that there   is more   going  on  in teacher
discourse than simple questions (Roth 1996; van Zee & Minstrel, 1997; Chin, 2006; Cazden, 2001), supports
our suggested need for more detailed investigations of teacher-student classroom discourse. Research in teacher
and student discourse needs to use analytic frameworks that can describe the nature of teacher minute-by-minute
choices. To do that, the content of the student contribution, its context need to be take under account, as well as
the content of the teacher response, its characteristics and the rational of the decision for using one response
over another. We feel that our proposed framework may help move research towards that direction, from a
teacher  initiation and follow-up    framework,   to   a framework    focusing   on student  contributions    and teacher
responses to those contributions. Our framework is concerned with how teachers perceive student contributions
in a conversation in science, how they evaluate them and how they respond to those contributions. We do not
narrow   teacher  actions  and  responses    only   to   questions, but  we  seek   to   account    for teacher prompts,
clarifications, evaluations and restatements of student contributions.      Additionally, we take student contributions
to include not only knowledge claims and ideas, but also student reasoning and inquiry, student epistemologies,
and student's use of empirical data and everyday experiences to support their ideas.
         Secondly, assessing student conversational contributions during class is a challenging work because it
requires that the teacher identifies, interprets and evaluates his students' scientific inquiry before responding.
Teachers have very limited time to make such judgments, and thus they need to develop their in-class "instincts"
for responding to their students' reasoning. Findings from studies like the one we describe in this paper could be
used as the basis for designing professional development courses that can help teachers develop their in class
"instincts," about what they should be looking for in terms of their students' scientific inquiry and how they
should respond in an attempt to scaffold their students' scientific inquiry.

References
Adey,   P. &   Shayer,  M.   (1993).  An exploration     of  long-term   far-transfer   effects following  and  extended
         intervention program in the high school science curriculum. Cognition & Instruction, 11(1), 1-29.
Arons, A. (1983) Achieving wider scientific literacy. Daedalus, 2, 91-122.
Barnes, D. & Todd, F. (1977). Communication and learning in small groups. Routledge & Kegan Paul.
Carlsen,   W.  S. (1991).  Questioning   in  classrooms:     A sociolinguistic   perspective.    Review   of  Educational
         Research, 61, 157-178.
Cazden, C. (2001). Classroom discourse: The language of teaching and learning. Portsmouth, NH: Heinemann.
Cazden, C. B. (1988) Classroom Discourse. Portsmouth, NH: Heinemann.
Chin, C. (2006). Classroom Interaction in Science: Teacher questioning and feedback to students' responses.
         International Journal of Science Education, 28(11), 1315-1346.
Collins, A., & Stevens, A.L. (1982). Goals and strategies of inquiry teachers. In R. Glaser (Ed.), Advances in
         instructional psychology: Vol. 2. Hillsdale, NJ: Erlbaum.
Dillon, J. T. (1985). Using questions to foil discussion. Teaching and Teacher Education, 1, 109-121.

                                                                                                                             2-
       Driver, R., Newton, P., & Osborne, J. (2000). Establishing the norms of scientific argumentation in classrooms.
               Science Education, 84(3), 287-312.
       Edwards, A. D., & Westgate, D. P. G. (1994). Investigating classroom talk. London, UK: Falmer Press.
       Edwards, D., & Mercer, N. (1987). Common knowledge: The development of understanding in the classroom.
               London, UK: Methuen.
       Gall, M. (1984). Synthesis of research on teacher's questioning. Educational Leadership, 42, 40-47.
       Gallas, K. (1995). Talking their way into science: hearing children's questions and theories, responding with
               curricula. NY: Teachers College Press.
       Hammer, D. (1995). Student inquiry in a physics class discussion. Cognition & Instruction, 13, 401-430.
       Hawkins, D. (1974). The Informed Vision: Essays on Learning and Human Nature. New York: Agathon Press.
       Hogan, K. (1999). Thinking aloud together: A test of an intervention to foster students' collaborative scientific
               reasoning. Journal of Research in Science Teaching, 36, 1085-1109.
       Hunkins, F. (1989). Teaching thinking through effective questioning. Boston: Christopher-Gordon.
       Hymes, D. & Farr, M. (1982) Ethnolinguistic study of classroom discourse. Final report to NIE, ERIC 217 710.
       Hymes, D. (1972). Models for the interaction of language and social life. In J. Gumperz & D. Hymes (Eds.),
               Directions in sociolinguistics: The ethnography of communication (pp. 35-71). NY: Holt & Rinehart.
       Kelly, G.J., & Crawford, T. (1997). An ethnographic investigation of the discourse processes of school science.
               Science Education, 81, 533 - 559.
       Lemke, J. L. (1990). Talking science: Language, learning and values. Norwoord, NJ: Ablex.
       Louca, L., &   Zacharia,  Z. (2007).   Nascent abilities for scientific inquiry in  elementary   science. In the
               proceedings   of the Second  European   Cognitive  Science Conference   (pp. 53-58). East   Sussex,  UK:
               Lawewnce Erlbaum Associates.
       May, D. B., Hammer, D., & Roy, P. (2006). Children's analogical reasoning in a 3rd-grade science discussion.
               Science Education, 90(2), 316-330.
       Mehan, H. (1979). Learning lessons. Cambridge, MA: Harvard University Press.
       Mortimer, E. F. (1998). Multivoivedness and univocality in classroom discourse: An example from theory of
               matter. International Journal of Science Education, 20(1), 67-82
       Mortimer, E., & Scott, P. (2000). Analysing discourse in the science classroom. In R. Millar, J.Leach, & J.
               Osborne (Eds.), Improving science education: The contribution of research. Buckingham, UK: Open
               University Press.
       National Research Council [NRC]. (1996). National Science Education Standards. Washington DC: National
               Academy Press.
       Orsolini, M. & C. Pontecorvo (1992). Children's Talk in Classroom Discussions. Cognition & Instruction, 9(2),
               113-136.
       Osborne, J., Erduran, S., & Simon, S. (2004). Enhancing the quality of argumentation in school science. Journal
               of Research in Science Teaching, 41(10), 994-1020.
       Philipsen, G. (1982). The qualitative case study as a strategy in communication inquiry. The Communicator, 12,
               4-17.
       Philipsen, G. (1992). Speaking Culturally: Explorations in Social Communication. Albany: Suny Press.
       Roth, W.  M.  (1996). Teacher  questioning  in an open-inquiry  learning  environment: Interactions  of context,
               content, and student responses. Journal of Research on Science Teaching, 33, 709-736.
       Russ,  R. S.  (2006).  A  framework    for recognizing   mechanistic reasoning   in  student scientific   inquiry.
               Unpublished Doctoral dissertation, University of Maryland, College Park.
       Sinclair, J., & Coulthard, M. (1975). Towards an analysis of discourse. London, UK: Oxford University Press.
       Solomon, J. (1994). The rise and fall of constructivism. Studies in Science Education, 23, 1-19.
       van Zee, E. H., & Minstrell, J. (1997). Using questioning to guide student thinking. The Journal of the Learning
               Sciences, 6, 229-271.
       van Zee, E., Iwasyk, M., Kurose, A., Simpson, D. & Wild, J. (2001). Student and teacher questioning during
               conversations about science.   Journal of Research in Science Teaching, 38(2), 159 ­ 190.
       van Zee,  E.H. (2000).   Analysis of a student-generated  inquiry discussion. International  Journal of   Science
               Education. 22, 115-142.

      Acknowledgments
       This study was partly supported by the Cyprus Research Promotion Foundation Awards /0505/44.

2-
