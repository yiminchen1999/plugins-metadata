                Symposium: Supporting the use of multiple representations
                                   in multimedia learning environments
           Organization:Maria Opfermann, Knowledge Media Research Center, Konrad-Adenauer-Str.40, Tübingen,
                                                Germany, m.opfermann@iwm-kmrc.de
             Jan van der Meij, University of Twente, P.O. Box 217, Enschede, Netherlands, j.vandermeij@utwente.nl
                Discussion: Shaaron Ainsworth, School of Psychology, University of Nottingham, University Park,
                             NOTTINGHAM NG7 2RD, U.K, Shaaron.Ainsworth@nottingham.ac.uk

                  Abstract: Many learning environments contain multiple representations. Using them can lead
                  to a deeper level of cognitive processing when learners make mental transformations between
                  representations. However, research has revealed two problems. First, it has been shown that
                  learners often do not make spontaneous use of such multiple options. Second, the translation
                  process is often difficult. The papers presented in this symposium aim at supporting learners'
                  use of multiple representations as well as their translation process. The first study provided
                  learners with different types of representations and asked them to translate those into other
                  representations. The     second     study examined    the effectiveness    of contextual   scaffolds  in
                  computer simulations.The third study aimed at supporting hypermedia learning with multiple
                  representations  by  means       of metacognitive   modelling   and    prompting  of representational
                  awareness.   The fourth   study     investigated if sequencing  dynamic    representations  combined
                  with explicit instruction to relate and translate between representations has a positive effect on
                  learning outcomes.

       Study      1:     Translation       processes          in   learning      with     multiple     representations           ­
       problem analysis in mathematics

                  Tina Seufert, Saarland University, Campus, 66123 Saarbrücken, t.seufert@mx.uni-saarland.de
           Markus Vogel, University of Education, Reuteallee 46, 71634 Ludwigsburg, vogel02@ph-ludwigsburg.de
              Roland Brünken, Saarland University, Campus, 66123 Saarbrücken, r.bruenken@mx.uni-saarland.de

                  In most of the domains in natural science information is conveyed by using different representational
         forms like graphs, tables, text or formulas. In order to construct a coherent mental representation of the domain,
         learners have   to understand each     of the   single  representations as  well as to  integrate them.   The  integration
         process can be seen as a process of mapping of corresponding elements between the different representations
         (Seufert, 2003). For example a text describes the growing of population and a corresponding line graph depicts
         this growth by an increasing line: to understand the relation between text and graph the learners have to map the
         concept of "growing" to the "increase" of the line. A prerequisite for this mapping process is the process of
         translating  between  textual and  graphical     sign   systems  (in  other words   between   descriptive  and  depictive
         representations). In our example learners have to translate "growth" into "increasing line" or vice versa. As
         figure 1 shows, this type of transformation requires changing columns and is thus called vertical. Moreover, in
         natural science, e.g. in mathematics or chemistry, learners often have to switch between mathematical/chemical
         models and real-world models (Vogel, Girwidz & Engel, 2006). For example a verbal real-world task (add two
         apples and   three  apples)  has  to   be    transformed    into a mathematical     formula  (x   =  2+3). This   type  of
         transformation is called horizontal as it requires changing between the rows (see figure 1). Moreover, especially
         in mathematics some integration tasks require both types of transformations (e.g. mapping a verbal task and a
         line graph of a linear function).
                  Based on a large amount of empirical research we can state, that learning with multiple representations
         is often difficult and even leads to lower learning outcomes than learning with single representations (for an
         overview    see Ainsworth,  1999).     It is  argued   that these  difficulties are mostly  due   to problems     with the
         integration of multiple representations. The aim of our study is to find out whether these integration difficulties
         can be   traced  back to  translation     problems.  Hence,   we   analyzed  translation  processes    in the  domain   of
         mathematics.    Based on  the   analysis     of problems    we   want to develop    instructional   strategies to support
         translation. We    hypothesized   that learners    task performance   decreases   when   one  type  of transformation   is
         required, and even more when both transformations are required.

3-
                         Description                                      Depiction
mathematical model       formula       /                                  mathematical
                         equation         y = mx + n                      graph

real-world model         data   table/                                    data diagram
                         text

                          Figure 1. Taxonomy of representational types in mathematics.

Method
        In order to test our hypotheses we developed 18 transformation tasks for all types of changes. We
focused on the mathematical domain of linear functions. Learners were given for example a mathematical graph
of a linear function and were asked to translate it into a linear equation or they were given a data table and were
asked to produce a mathematical graph of the underlying linear function. The produced representations were
rated by using a set of criteria, like correctness of scale in line graphs or correct translations, e.g. from the word
"increase" to a positive value of "m" in the linear equation. In order to avoid effects of prior knowledge we
provided an information sheet with the relevant aspects of linear functions before the transformation tasks had to
be solved. This was important because we didn't want to assess mathematical but representational competences.
In a within-subjects design with n = 30 subjects we analyzed, whether different subsets of tasks entail different
performance levels: with or without vertical transformation, with or without horizontal transformation, without
any, with one or with two transformations. For the vertical and horizontal transformations we also analyzed
whether transformations in one direction are more difficult than in the other (description to depiction or vice
versa / mathematical to real-world or vice versa).

Results
        The  probability  of  task solutions for all subsets of  tasks  can be   seen   in table  1. An  ANOVA     with
repeated measures revealed an unexpected effect for vertical changes: performance was better when a vertical
transformation was   required compared    to no  vertical transformation   (F(1)   = 38.96,  p <  .001,  2=  .57). The
analysis of type of vertical transformation makes obvious that especially the transformation from depiction to
description was difficult compared to the opposite direction (F(1) = 8.48, p < .01, 2= .23). With respect to the
horizontal transformation we   found  the  expected   advantage  for  the  tasks without   horizontal  change   (F(1) =
60.24, p < .001, 2= .68). In this case both directions of change revealed equal results (F(1) = 0,51, n.s.). The
question whether task difficulty increased with the number of required changes cannot be answered clearly: the
three subsets of tasks differ significantly (F(2) = 18.39, p < .001, 2= .39). However, we found the expected
lower scores for one change compared to no change (a priori contrast: F(1) = 115.07, p < .001, 2= .80). but
again better scores when two changes were required (a priori contrast with one change: F(1) = 10.38, p < .01,
2= .26). To enlighten the unexpected result patterns we analyzed the tasks more deeply and found out that the
type of representation   which  was   presented  (and   only had    to  be read)   had   no  significant influence   on
performance,  but  that performance   differed  considerably    for the types   of representations    which  had to   be
produced: Especially the production of equations and texts were very difficult, whereas tables were the easiest,
followed by data diagrams and linear graphs.

Table 1: Probability of task solution and standard deviation for different subsets of tasks.

 without vertical change         .53          .22          maths to real-world                 .53          .25
 with vertical change            .67          .18          real-world to maths                 .56          .21
 description to depiction        .72          .18          without any change                  .77          .22
 depiction to description        .61          .23          with one change                     .57          .19
 without horizontal change       .69          .19          with two changes                    .69          .22
 with horizontal change          .53          .19

Discussion
        To summarize the results, we found that students had enormous problems in transforming different
types of representations. For half of the tasks the probability of task solution was less than 60%. However,
despite our theoretical assumptions the difficulties were not that closely related to the type of transformation.
For the vertical change dimension we found even reverse results: i.e. that it is not relevant whether learners have
to change   between   descriptions  and   depictions.   Instead the  difficulties  go   back   to  specific production
affordances, i.e. to verbalize  the  meaning     of  an equation/graph     etc. or   to extract   an  equation  from  a
diagram/text/table etc. The horizontal change dimension on the other hand revealed the expected results, which

                                                                                                                            3-
         support  other findings  from   maths    studies  (see Vogel   et   al., 2006). As    a next  step   we want   to develop
         instructional  aids for translation  with    a special  focus  on    the  verbalization    of the  meaning    of  different
         mathematical representations.

        References
         Ainsworth, S. (1999). The functions of multiple representations. Computers and Education, 33, 131-152.
         Seufert, T. (2003). Supporting coherence formation in learning from multiple representations. Learning and
                   Instruction, 13, 227-237.
         Vogel,   M., Girwidz,   R. &  Engel,   J. (2006).  Supplantation    of   Mental Operations    on  Graphs.  Computers   &
                   Education, in press, doi:10.1016/j.compedu.2006.02.009.

       Study 2: Using Narratives as Contextual Scaffolds for Science Simulations
                      Jan L. Plass1, Bruce Homer2, Yan Wang1, Minchi Kim3, Catherine Milne1, Trace Jordan1
          1. Program in Educational Communication & Technology, New York University; Email: jan.plass@nyu.edu
                             2. PhD Program in Educational Psychology, the Graduate Center, CUNY
                    3. Educational Technology, Department of Curriculum and Instruction, Purdue University

                   Research  has made    a  compelling  case that   the effectiveness    of active  learning  approaches   such as
         discovery learning, problem-based learning, and experiential learning depends on the level of guidance learners
         receive.  Approaches   where    learners  receive only  minimal   instructional    guidance   have   recently come  under
         considerable criticism by science educators and educational psychologists (Kirschner, Sweller, & Clark, 2006).
         Many ways of providing instructional guidance have been explored. In technology-based learning environments,
         one of the most common approaches to provide instructional guidance is the use of scaffolds. Scaffolds serve to
         support learners in specific areas to facilitate the learning process (Wood, Bruner & Ross, 1976).
                   The present study investigated the use of contextual scaffolds for computer simulations for science
         education. In particular, we were interested in the differential effects of using case examples versus narrative
         structures to facilitate learners' knowledge generation in chemistry computer simulations. Research suggests
         that narrative structures are effective tools for make meaning and understanding experiences, including learning
         experiences (Bruner, 1991; CTGV, 1992). Even for scientific knowledge, which is typically presented through
         arguments in which embedded empirical evidence supports specific models and theories, there appears to be a
         cognitive bias towards linear narrative in the construction of knowledge (Abbott, 2003).
                   In science education, the use of narratives has been extensively studied in inquiry-oriented classroom
         settings. There are three major functions of narratives that set them apart from case examples. Narratives serve
         as:  (1) conceptual  links  between    students'  experiential  knowledge      based    on their  daily experiences  and
         paradigmatic structural knowledge (based on the use of evidence for supporting scientific argument) often found
         in abstract form in science textbooks (Bruner, 1986; Kurth, Kidd, Gardner, & Smith, 2002), (2) semantic cues
         that capture  students' attention   at   the beginning  of   inquiry     and further  assist  knowledge   comprehension
         (Graesser,   1981), and (3)   a method    of  connecting   complex   ideas    and  events  by  providing  structures and
         sequences  of  phenomena    under  investigation   (Norris et  al., 2005).   Over  time,   narrative provides  a  coherent
         ideational structure that permits the linking and integration of content components (Talmy, 2000).            This process
         of embedding simulations in a narrative structure that connects phenomena and abstract explanatory models
         may help resolve a significant problem in science learning: Symbol systems often remain referentially isolated
         in science classrooms, and students are not provided with opportunities to integrate the different symbol systems
         that can be used alternatively to describe the same phenomenon (Roth et al., 1997).
                   The  present  study investigated    the effectiveness   of narratives    as contextual   scaffolds  for science
         simulations. The simulations were developed as part of the Molecules and Minds project, a 3-year study funded
         by the US Department of Education's Institute of Education Sciences to develop computer simulations for high
         school   chemistry. The    current study   compared    three methods      of  providing  a   context for the   simulation:
         narratives, case examples and a baseline control. It was hypothesized that narratives would result in improved
         learning compared to the case examples and the baseline control.

        Method
                   Participants were students from a large rural high school in Texas (60% females). Of the initial 227
         participants, missing data excluded 21. For the remaining 206 students, 77% identified as Hispanic, 15% as
         white and 8% as black, Asian or other ethnic background. The students were from 10th grade (63%) and 11th
         grade (37%).
                   At the beginning of the experiment, students were asked to complete a survey measuring their interest
         in chemistry. Students were then given a knowledge pretest consisting of eight multiple-choice questions on the
         topic of Gas Laws. Before they started exploring a simulation of the Ideal Gas Law, students were randomly

3-300
assigned to three groups with different content scaffolding. One group was given a case example illustrating the
manifestation  of Gas   Laws  in  real  life situations. Another   group  was     presented with a  narrative in which
observations made in the story could be explained by using the gas laws. The third group was the baseline group
that was not given any content scaffolding.     After exploring the simulation, students were given a knowledge
posttest consisting of 15 multiple-choice questions. Students were also given a transfer test with five real-life
problems. Finally, all students received a brief survey about the cognitive load they experienced during their
exploration of the simulation.

Analysis and Results
         Outlier analysis identified four participants who spent less than 30 seconds and made 3 or less clicks on
the simulation. They were excluded from the analysis. In order to testing if different content scaffolding had an
impact on students' click count and time on task during the exploration of the simulation, regression analyses
were conducted    separately. After  controlling  for  students' interest  in  chemistry,   regression analysis  results
showed that narrative scaffolding condition was a significant predictor of students' time on task (F2, 198 = 6.185,
p = .002) and click counts (F2, 198 = 4.168, p = .017). This indicated that scaffolding was effective in increasing
participants' engagement in the learning.
         The study results also showed that cognitive load was significantly predicted by students' pretest scores
(F1, 199 = 34.712, p < .043) and their interest in chemistry (F1, 199 = 5.889, p = .016). The higher students' pretest
scores, the lower the cognitive load they experienced during their interaction with the simulation. Also, the more
interest students had in chemistry, the lower the cognitive load they experienced.
         Students'  pretest scores  and   scaffolding    differences were  used   to predicting  their posttest  scores.
Regression analysis results indicated that pretest score (F1, 219 = 142.909, p < .001) and scaffolding difference
(F1, 219 = 3.194, p = .043) were significant in predicting posttest score. That is, students with higher pretest
scores and who had scaffolds performed significantly better than other students. The group having a narrative
story as content scaffolding had the highest posttest group mean. After controlling for pretest scores, students in
the narrative  scaffolding  group performed    significantly  better than  the  example  scaffolding   group  (F1,                   219 =
2.847, p = .046). Time on task had no significant effect on the posttest scores.
         The students' performance on the transfer test was also explored. In the transfer questions, students
were either asked to explain or make suggestions relating the gas laws to a real life phenomenon (e.g. why tire is
flat, how to prevent aerosol from exploding). The narrative scaffolding group again had highest group mean on
transfer test scores, followed   by the example     scaffolding group  and  then   the  baseline group. However,    the
difference among the three groups was not significant.

Discussion and Conclusions
         Our results indicated that narrative scaffolds were better able to facilitate learning from computer-based
science simulations than case examples or no scaffolds. These results support anecdotal evidence we obtained in
prior research indicating that participants use the narrative during the process of exploring the simulations to
describe the phenomena under investigation and to connect what they have experienced to abstract explanatory
models.  This  research provides  initial evidence   for  the effectiveness    of narratives as contextual scaffold                      in
computer-based    science  simulations. Future  research   is required  to verify   our findings and   expand   them                     to
different contents and settings.

References
Brown,   A.   (1992). Design   experiments:    Theoretical  and  methodological      challenges  in creating  complex
         interventions in classroom settings. The Journal of Learning Sciences, 2(2), 141-178.
Bruner,  J. (1999). Postscript:  Some   reflections on   education   research. In E. C. Lagemann    &   L. S. Shulman
         (Eds.), Issues in education research: Problems and possibilities (pp. 399-409). San Francisco: Jossey-
         Bass.
Hawkins, J., & Pea, R. D. (1987). Tools for bridging the cultures of everyday and scientific thinking. Journal
         for Research in Science Teaching, 24, 291-307.
Lave, J. (1987). Cognition in practice. New York: Cambridge University Press.
Wood, D., Bruner, J., & Ross, G. (1976). The role of tutoring in problem solving. Journal of child psychology
         and psychiatry, 17, 89-100.

Study 3: The benefits of instructional support in hypermedia learning

                      Maria Opfermann, Peter Gerjets, Knowledge Media Research Center,
                              Konrad-Adenauer-Str. 40, 72072 Tuebingen, Germany,
                          Email: m.opfermann@iwm-kmrc.de, p.gerjets@iwm-kmrc.de
                    Katharina Scheiter, Eberhard Karls University, Konrad-Adenauer-Str. 40,

                                                                                                                                               3-30
                                       72072 Tuebingen, Germany, k.scheiter@iwm-kmrc.de

                  When trying to bridge the gap between multimedia and hypermedia, one can share the view of Rouet
         and Levonen (1996) or Jonassen (1996) and see hypermedia as an integration of multimedia with hypertext
         elements.  That  is, learners have  access  to information   that can include  multiple   representational  codes  and
         address different sensory modalities. Additionally, this information can be retrieved in multiple ways, linearly as
         well as nonlinearly. Prior research in hypermedia learning has shown that learners are not always able to benefit
         from the multiple options that such environments offer, that is, they are overloaded by and/or do not use their
         freedom  with regard    to navigational and representational    choices. In other   words, they are  not able to  self-
         regulate their learning with the environment. Authors like Azevedo (2005) or Bannert (2005) assume that it
         might well be that learners do not lack     those abilities completely but that they may need to be prompted or
         trained to display sophisticated learning strategies. Our study thus investigated whether hypermedia learning can
         be enhanced   by means     of two forms  of instructional  support.  More   specifically,  we were   interested in the
         relationship between instructional support, individual learner characteristics, and learning outcomes.

        Method and procedure
                  The learning environment we used to investigate our research questions was a hypermedia environment
         that aimed at conveying basic principles of probability theory by means of worked examples which show the
         problem statement, solution steps, and final solution for problems from different probability categories (e.g., the
         probability to correctly guess the three medal winners out of a race of seven). For each example, learners could
         choose whether they wanted to retrieve it with arithmetical information only, enrich it with written or spoken
         text or animations   or use   any combination   of  these. We   used  a  2*2  design varying  the following   factors:
         metacognitive   tool  / no    metacognitive tool,    prompting  of  representational  choices   / no    prompting   of
         representational choices. The metacognitive tool that was used in two of the resulting four conditions was a
         video displayed at the beginning of the learning phase that aimed at supporting the metacognitive monitoring
         and  evaluation  of   learners. When    prompting    of representational    choices  took  place,   learners  received
         explanations of the advantages and disadvantages of the respective representational formats directly before they
         chose a format for the respective worked-out example they were about to have a look at. These variations result
         in the following four experimental conditions: (1) No metacognitive support / no representational prompts, (2)
         Metacognitive support / no representational prompts, (3) No metacognitive support / representational prompts,
         and (4) Metacognitive support / representational prompts.

        Participants
                  Participants were 145 students from German schools with an average age of 16 years. There were 61
         female and 81 male students. They were assigned to one of the four experimental conditions randomly. The
         studies were conducted as group settings in the schools' computer rooms, that is, the classes took part as a
         whole, but each participant worked on a computer on his / her own.

        Procedure
                  Before working with the learning environment, students filled out a comprehensive questionnaire that
         aimed   at  assessing   learner   characteristics, including  metacognitive    strategies.  Directly after   learning,
         metacognitive activities were assessed by means of an online questionnaire. The learning environment consisted
         of a personal data questionnaire, a short technical instruction, a pre-test with 12 items to assess prior knowledge
         concerning probability theory, an introduction to the domain, the example-based learning phase that was subject
         to experimental manipulation, and a post-test with 19 items, whereby eight items were similar to those in the
         pre-test and therefore suitable to measure knowledge gains. Learners could work through the environment on
         their own pace, look at examples repeatedly, or proceed to the posttest whenever they thought they had learned
         enough.

        Results
                  Descriptive data show that of the 12 pre-test items, learners answered between 2 and 9 correctly with
         an average of 5.59 (SD = 1.68). The four experimental conditions did not differ with regard to pretest scores.
                  The  further   data  analysis  revealed   some surprising   results. Learners  in  all conditions   achieved
         significant knowledge gains, that is, they improved from pre- to post-test (t(144) = 7.60; p < .001). However,
         contrary to  our expectations,  the best results   and  highest knowledge     gains were   achieved  by  learners who
         received neither representational prompting nor metacognitive modelling, followed by learners who received
         prompting but no modelling or modelling but no prompting. The lowest knowledge gains were achieved by
         learners who received metacognitive modelling and representational prompting (see Figure 1). As revealed by
         an ANOVA, the overall group difference was significant (F(3,141) = 3.837; p = .011). This effect can mainly be
         traced  back to  the difference between  modelling    and  no modelling   (F(1,141)  = 8.753;   p =  .004),  while the

3-30
                      Knowledge gains in %
difference between prompting and no prompting does not reach statistical significance (F(1,141) = 2.709, p =
.102). There was, however, an interaction between metacognitive activities and experimental condition. In short,
providing   modelling  or                    prompting    did not      seem to  make      a  difference for    learners     scoring  low   on  the
metacognitive scales. For sophisticated learners, however, providing additional instructional support appeared to
be highly detrimental (F(1,67) = 7.22; p < .01).

                                             60                                                       With representational
                                                                                                      support
                                             50
                                                                                                      Without
                                                                                                      representational
                                             40                                                       support

                                             30

                                             20

                                             10

                                              0
                                                    With metacognitive         Without
                                                         modeling           metacognitive
                                                                               modeling

                                           Figure 1. Knowledge gains for the four experimental conditions.

         An interesting finding is that learners chose the representational formats that contained animations to a
significantly higher extent than formats that did not contain animations. However, this choice did not relate to
performance.   Additionally,                    written  text +    animation   were     chosen  significantly    more       often by  participants
receiving modelling than by those not receiving modeling.

Discussion
         The findings of the study were partly surprising. Although all learners achieved significant knowledge
gains after learning,  they                   did  not   benefit  from   additional     instructional support.   This    refers   to their overall
performance as well as to their learning behaviour. With regard to representational choices, it was found that
independently of representational prompting, multiple representations that contained animations were preferred.
This might be due to motivational or novelty effects. With regard to performance, it was found that learners who
already possess sophisticated metacognitive abilities/knowledge do not need additional instructional support. It
might even hinder their learning when metacognitive modelling as shown in the video demonstrates strategies or
thinking  other than   what                   a    sophisticated   learner  has used      so far, therefore    interfering    with   his learning
behaviour.  For learners                    with   no metacognitive      strategies or    less sophisticated    metacognitive      abilities, such
instructional support on the other hand might provide them with ideas of how to structure and regulate their
learning. However, the question still remains whether all learners are generally better off with no instructional
support at all or whether the video and the prompting devices were just not designed in an optimal way. To
further investigate these questions, we are currently working on a study on fading of multiple representations as
another way of fostering the benefits from using representations in hypermedia learning. Results of both studies
will be presented and discussed at the symposium.

References
Azevedo, R. (2005). Using hypermedia as a metacognitive tool for enhancing student learning? The role of self-
         regulated learning. Educational Psychologist, 40, 199-209.
Bannert,  M.   (2005). Explorationsstudie                     zum      spontanen metakognitiven        Strategie-Einsatz      in   hypermedialen
         Lernumgebungen.                        In    C.  Artelt   &    B.  Moschner        (Eds.).   Lernstrategien        und   Metakognition:
         Implikationen für Forschung und Praxis (pp. 127-151). Münster: Waxmann.
Jonassen, D. H. (1996). Computers in the classroom. Mindtools for critical thinking. New Jersey: Prentice Hall.
Rouet, J.  F., &  Levonen,                      J. J. (1996). Studying      and learning     with   hypertext:   Empirical      studies  and  their
         implications. In J.-F. Rouet, J. J. Levonen, A. Dillon, & R. J. Spiro (Eds.), Hypertext and Cognition (pp.
         9-23). Mahwah, NJ: Erlbaum.

                                                                                                                                                      3-303
       Study 4: Sequencing Multiple Dynamic Representations - Supporting students'
       learning with multiple representations in a dynamic simulation-based learning
       environment

                      Jan van der Meij, Ton de Jong, University of Twente, Faculty of Behavioural Sciences,
                                               Department of Instructional Technology,
                                      Email: j.vandermeij@utwente.nl, a.j.m.dejong@utwente.nl

                  The   ability to relate  multiple  representations  and   translate between   them    assists students   in deeper
         domain   knowledge     acquisition. Connecting     different representations   forces   learners  to   reflect beyond    the
         boundaries   and  details   of the  first representation  to anticipate  on   correspondences     in   the  second   (Petre,
         Blackwell,   & Green,   1998).   To relate  representations,  learners  have   to mentally    search   for similarities and
         differences. To   translate between   representations,   learners  need  to  interpret the effects   that  changes   in one
         representation have    on corresponding     representations. An    important  requirement     for learning    with multiple
         representations in simulation-based learning environments is how to support learners in the processes of relating
         and translating. Both integration and dynamic linking of representations (Ainsworth & Peevers, 2003; Chandler
         & Sweller, 1991; van der Meij & de Jong, 2006) are of proven value. Physical integrated representations appear
         to be one representation. With dynamically linked representations, actions performed on one representation are
         automatically shown in all other representations. Another way to support learners in simulation-based learning
         environments, is providing model progression (White & Frederiksen, 1990). Based on the model progression
         used, the number    of  representations   can be   increased  iteratively.  As  a result,  the number      of relations and
         possible translations  are  increased likewise.    Starting with  a few  relations and   possible  translations    and  then
         introduce   more   relations   and  possible  translations   step-by-step    might   support   learners    in  relating  the
         representations and translating between them. This paper reports the results of two studies in which different
         types of support for relating and translating between representations were examined.

        Study 1
                  In study one, two versions of the same simulation-based learning environment covering the physics
         topic of moments were compared: a learning environment providing the representations step-by-step (R-Step
         condition) and a learning environment providing all representations at once (R-Once condition). Subjects were
         88 students at the start of their first year of secondary vocational education. The simulation interface contained
         five  representations:  (1) a  concrete   representation (animation   of an   open-end    spanner),    (2) a  diagrammatic
         representation (an  abstract   representation  of  the   variables  playing  a  role in   the  concrete    situation), (3) a
         numerical representation (showing the values of the variables involved), (4) a dynamically changing equation
         and (5) a dynamically changing table (showing one row that was dynamically updated when variables were
         manipulated  by   the  subjects).  Prior  knowledge   was   measured   with  a  pre-test  containing   domain     items and
         transfer items. Learning results were measured with a post-test containing domain items, transfer items, relate
         items and translate items. The domain items tested whether the subjects were able to reproduce the content they
         were explicitly asked to explore in the learning environment. The transfer items tested the ability of the subjects
         to apply their acquired knowledge in new situations. The relate items asked students to relate similar variables
         from representations with different representational codes. To be able to answer translate items correctly, the
         subjects had to make a mental translation from manipulations on one representation to the effects in another
         representation. Overall, we found that the subjects learned from working in the learning environment; the post-
         test scores on the domain items and transfer items were significantly better than the pre-test scores. Despite our
         expectations, no differences were found between the two experimental conditions. The subjects learned equally
         well regardless of the way in which the representations were presented. Also, the extent to which the subjects
         experienced complexity of both the topic and the learning environment did not differ between the experimental
         conditions.

        Study 2
                  While study one focused on surface level support, in study two we examined the effect of providing
         hints and prompts   to  encourage   the   subjects to translate between    representations.   Two  versions    of  the same
         simulation-based inquiry learning environment on the physics topic of moments were compared. One learning
         environment provided all representations at once and instructional support focused solely on relations between
         the  domain  variables    (R-Once   condition).    The second    learning    environment   provided    the    subjects  with
         representations step-by-step and with instructional support that focused additionally on relating representations
         and   translating between    them   (R-Step  condition).    Subjects were    86   students from    secondary    vocational
         education  (first year) and    125 students  from  pre-university   education   (third year).  The   simulation    interface
         contained seven representations: (1) a concrete representation (animation of a tackle, an open-end spanner or car

3-30
crane), (2) a diagrammatic representation, (3) a numerical representation, (4) a dynamically changing equation,
(5) a moment-arm graph, (6) a moment-force graph and (7) a dynamically changing table. Prior knowledge was
measured with a pre-test containing domain items and transfer items. Learning results were measured with a
post-test containing domain items, transfer items, relate items and translate items. To control for the influence of
differences in cognitive load, we used an electronic questionnaire to ask subjects to rate their cognitive load four
times as they worked with the learning environment. Overall, we found that subjects learned from working with
the learning environment. Post-test scores were significantly better than pre-test scores. As expected, we found
that sequencing   representations  combined     with instructional support   focusing on relating   and translating
representations did lead to better learning outcomes. However, this was only found for the domain test items. A
trend, in favour of the R-Step condition, was found on relate items. No differences were found on transfer items
and translate items. Subjects in the R-Step condition reported higher cognitive load scores. Subjects did not,
however, discriminate between cognitive load types. As a consequence, we were not able to identify what type
of load caused the higher cognitive load of the R-Step condition.
         In the symposium the results of both studies will be discussed. The discussion will focus on how to
support relating  and translating between   representations  and it's consequences  for the design   of simulation-
based learning environments.

References
Ainsworth, S. E., & Peevers, G. J. (2003). The Interaction between informational and computational properties
         of external  representations   on problem-solving   and   learning. Paper presented at the   25th Annual
         Conference of the Cognitive Science Society, Boston, Massachusetts, USA.
Chandler,   P., &  Sweller,  J. (1991).  Cognitive   load theory   and the format  of  instruction. Cognition  and
         Instruction, 8, 293-332.
Petre, M.,  Blackwell,   A. F., & Green,   T. R. G.  (1998). Cognitive  questions  in software visualization. In J.
         Stasko, J. Domingue, M. Brown & B. Price (Eds.), Software visualization: Programming as a multi-
         media experience (pp. 453-480). Cambridge, Massachusetts: MIT Press.
van der Meij, J., & de Jong, T. (2006). Learning with multiple representations: Supporting students' learning
         with   multiple representations in   a dynamic   simulation-based   learning environment.   Learning  and
         Instruction, 16, 199-212.
White, B. Y., & Frederiksen, J. R. (1990). Causal model progressions as a foundation for intelligent learning
         environments. Artificial Intelligence, 42, 99 -57.

                                                                                                                        3-30
