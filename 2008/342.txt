                Metacognitive Support for Reading in Science Classrooms

           Phillip Herman, Louis M. Gomez,      Department of Learning Sciences, Northwestern University, Evanston, IL
                     Kimberley Gomez,      College of Education, University of Illinois at Chicago, Chicago, IL
            Adam Williams, Kristen Perkins, Department of Learning Sciences, Northwestern University, Evanston, IL
                        Email: herman@northwestern.edu, l-gomez@northwestern.edu, kimwillig@uic.edu,
                                 a-williams@northwestern.edu, kristen-perkins@northwestern.edu

                  Abstract: Students struggle to read science texts. This is especially problematic for designers
                  of inquiry-based learning environments that make ambitious demands on readers. We report
                  on our   efforts to  provide  targeted  strategic supports   for  struggling  adolescent   readers   in
                  science classrooms. Environmental science and biology high school students learned to use
                  tools  designed   to foster   three specific  metacognitive     skills: recognizing   text structure,
                  reflecting on content, and representing the gist of a text in a summary. During one school
                  year, students had regular opportunities to use these strategies in class. Participants completed
                  one tool use assessment at the end of the school year in which they used the tools during
                  reading of a science text. Students then answered science comprehension questions about the
                  text.  Tool  proficiency  was  correlated   with  both   reading   and  science  achievement.     Tool
                  proficiency also predicted science achievement when controlling for on-entry reading ability.
                  The implications for science instruction are discussed.

       Introduction
                  Reading   proficiency   remains   a key  roadblock    to successful   implementation   of  ambitious    science
         instruction for too many students in America. Science instruction that stresses inquiry requires students to read
         texts to learn  new  content  in order  to   successfully engage   in the  kinds  of practices  valued  by  the  science
         education  community.     These  practices   include reasoning   from  evidence,   communicating    with   others  about
         science, conducting complex investigations, analyzing and representing data, engaging in cost-benefit analyses,
         etc.  (National Research     Council,  1996).   Too   often,   students,  particularly in   traditionally  under-served
         educational settings, do not have the opportunity to develop science text reading proficiency that would allow
         them access to important science content. Teachers, too, are often under-prepared to support reading in science
         in ways that would deepen students' understanding of key science content (Gomez, Herman, & Gomez, 2007).
         Because  of a   limited repertoire of  pedagogical   strategies,  teachers  often skip  readings,   assign readings   for
         homework, or didactically lecture about the content in the readings. Therefore, texts, a critical learning resource,
         are often ignored or underutilized in science instruction in too many high schools.
                  Designers   of inquiry  learning  environments    have   focused   on a  myriad  of  challenges   to successful
         inquiry in classrooms, including issues related to learning progressions, use of real-world data, the role of tools
         in investigations, and  how   to assess learning  in  inquiry  settings  -- to   name  just a few.  However,     too little
         attention has been focused on reading in inquiry settings. Contemporary science classrooms are characterized by
         complicated texts  and  more   diverse  kinds  of texts   than in prior  decades.  Instead  of just textbooks,   science
         learners read from the Internet, trade books, science journals, newspapers, etc.
                  The following figures give some idea of the extent to which students are struggling to read in America:
              x   Only 31% of America's eighth-grade students -- and roughly the same percentage of twelfth graders
                  -- meet the National Assessment of Educational Progress standard of reading "proficiency" for their
                  grade level (NCES, 2005, 2003).
              x   Among low-income eighth graders, just 15% read at a proficient level (NCES, 2005).
              x   In a typical high-poverty urban school, approximately half of incoming ninth-grade students read at a
                  sixth- or seventh-grade level (Balfanz et al, 2002).
              x   A mere 3% of all eighth graders read at an advanced level (NCES, 2005).

        The science reading gap
                  There is a large gap between what many students can read independently, with little or no teacher
         support, and what they are regularly expected to read in science class. To better understand reading proficiency
         in science classrooms, we administered the Degrees of Reading Power (TASA, 1999), which measures reading
         comprehension and can provide a measure of reading complexity for any reading passage, to all ninth-grade
         students at the Chicago high school that participated in this project. The mean DRP score for ninth graders was
         about 39. The left side of Figure 1 gives an example of text that students can read independently when they have
         a  DRP   score of 39. The  right  side is  a sample  of text   (DRP=66)   from   the Investigations  in Environmental

1-
Science curriculum, a National Science Foundation-funded curriculum in use at the school.

  Passage with a DRP score of 39 (mean score for               Text those same ninth graders are expected to read,
  ninth graders in our sample):                                from the environmental science curriculum they are
                                                               using (DRP=66):
  A bird's wings are well shaped for flight. The wing is       Beginning about 75 years ago, hundreds of small
  curved. It cuts the air. This helps lift the bird. The       dams began to be "decommissioned." In the last
  feathers are light. But they are strong. They help           decade, 177 dams were removed nationwide, with 26
  make birds the best fliers. A bird can move them in          of these in 1999 alone. Salmon conservation was not
  many directions. Birds move their wings forward and          the sole reason for decommissioning these dams.
  down.  Then they move them up and back. This is              Many were in poor condition, dilapidated from lack
  how they fly.                                                of maintenance and they posed a flood risk for areas
                                                               downstream.
        Figure 1. Text students can read independently and text excerpted from their science curriculum.

         Given this gap, what are the options for schools that want to ensure that students achieve in science?
One choice is to choose different curricular materials in which readings are closer to the complexity level on the
left in Figure 1. That would entail using upper-elementary or early middle school science curricula with these
high  school   students. Another option    is to change   the  existing texts  to remove   those elements  (vocabulary,
complex clauses, inferences, etc.) that increase complexity. A third option, which we mentioned earlier and
which we believe to be common in high schools, is for teachers to essentially ignore the texts in instructional
activity. Or, if they use the texts at all, they might didactically lecture about key content. All of these options do
a  disservice  to  students --  texts should   not   be  ignored.  We   choose    a fourth option: to  provide  reading
comprehension supports to scaffold reading and learning from texts like those on the right side of Figure 1.

The Adolescent Literacy Support Project (ALSP)
         We report on our efforts to develop, implement, and evaluate a program of science reading supports for
students and   teachers  in one Chicago    high  school   who   implemented    two  yearlong, inquiry-focused   science
curricula: Investigations in Environmental Science in ninth grade and BSCS Biology: A Human Approach in
tenth grade. ALSP provides pen-and-paper and electronic reading support tools to students and professional
development for teachers on the use, purpose, and affordances of the tools, as well as ways to closely couple
reading activity to science learning goals. The explicit goal of the ALSP project has been to increase students'
science  and   reading   achievement  through    student   use  of tools  that encapsulate  effective  science  reading
strategies and to research the connection between reading achievement and science achievement. An influential
report (National   Reading  Panel,  2000)  that  summarized     evidence-based    approaches  to  supporting struggling
readers noted that reading achievement increased dramatically when students were able to learn and use specific
strategies to monitor and deepen their understanding of texts. In the following sections, we describe the tools
that instantiate the strategies we support. Next, we describe the setting for our work. Then, we present initial
findings about how proficiency with the tools is related to science learning and reading comprehension. Last, we
discuss the implications of this work.

Reading strategies: structure, reflection and gist
         Science readers should have a corpus of strategies they can use prior to, during, and after reading to
learn  from  text. Students  benefit  when    they   are taught to apply  comprehension     strategies when   they read
(Anderson, 1992; Collins, 1991). Through repeated transactions with texts and by collaborative analysis and
discussion with peers, students can better internalize and ultimately take ownership of the strategies (Pressley,
El-Dinary, et al, 1992; Biancarosa & Snow, 2006). When internalized and used frequently, strategy use can lead
to large positive  effects  on text comprehension      (Anderson,   1992). Strategies   can help  students   identify the
structure of text in general; as well as its critical elements such as main and supporting ideas, arguments and
evidence, etc., and signposts such as transitions, comparisons, and contrasts (Gomez, Herman, & Gomez, 2007).
In addition, students should know how to reflect about, deconstruct, organize, and analyze text so that elements
of the text can be examined and critiqued for understanding and communication (Gomez, Gomez, & Herman,
2008). They should also know how to summarize a text to integrate new and prior knowledge about a topic into
one   holistic  representation  of   their    understanding.   Summarization      helps  students  communicate     their
understanding of the gist of what they have read (Kintsch, 1998).
         Each tool is designed to encapsulate an effective reading strategy for science texts. They are designed
to help  develop   metacognitive    reading   skills to  increase  active cognitive   processing  of text. Such  active
processing   should  increase   reading    comprehension      and  science    achievement.  Though     there are many

                                                                                                                             1-
         conceptualizations of metacognition in the literature, we focus on developing students' conscious control of
         reading including planning, selecting, and using     appropriate strategies; monitoring  reading  comprehension;
         analyzing the effectiveness of reading strategies; and changing reading behaviors when necessary (Ridly, Shutz,
         Glanz, & Weinstein, 1992). We conjecture that increases in metacognitive reading skills will allow students to
         comprehend more challenging text. Over time, as teacher support fades and reading strategies are internalized,
         students will be able to read more challenging texts more independently. Next we describe each tool in detail.

        Annotation
                 Text annotation is a strategy to make the author's message more explicit to the reader. Students are
         taught how to identify and mark important information, and disregard irrelevant information. Students typically
         annotate (by marking on the text) one or more of the following items:
            x    Difficult vocabulary words and in-text definitions
            x    Main ideas/arguments and related supporting ideas/evidence
            x    Headings, transitional words, and other signposts
            x    Other difficult words (non-science vocabulary) and sentence construction
            x    Inferences
            x    Conclusions
                 The structure of text and the connection between content elements becomes clearer as students, for
         example, search for supporting ideas for a main     idea they have already   identified. Teachers can model this
         annotation process to scaffold readings for their students, building to the place where students are independently
         annotating text. Below is an example of an annotation from an article on global warming.

                                        Figure 2. Example of a student's annotation.

        Double-Entry Journals
                 A double-entry journal (DEJ) is a reader-response log that provides a structure for students to monitor
         and document their understanding of science texts. Completing a DEJ provides students with the opportunity to
         actively read and reflect on what they have read. The variety of DEJ structures allows teachers to focus student
         reading on an important idea or skill unique to a text (vocabulary, main ideas with supporting ideas, relating
         information in the text to prior knowledge, etc.).

                                        Figure 3. Example of a double-entry journal.

        Summarization
                 Summary writing is a critical scientific skill. It requires the reader to effectively digest new information
         and communicate it in writing in a way that makes sense to him as well as an external audience. Summarization
         is a particularly difficult task when students are reading texts far above their reading level. In summarizing,

1-
students must comprehend the text, identify main ideas, differentiate secondary ideas, integrate new knowledge
with prior knowledge, and condense the information in a succinct and logical way.
         Students had opportunities to summarize using both pen and paper and Summary Street, a web-based
program that gives students immediate, machine-generated feedback on their summary writing. Summary Street
allows students multiple opportunities to revise their summaries until they reach a specified standard. Summary
Street supports student summarization by giving feedback on content, spelling, redundancies, irrelevancies, and
plagiarism. The program allows students to get instant and private feedback on their work.            Because the tool
provides high levels of student interactivity, the teacher's class time is freed to have one-on-one conversations
with students about their summaries and their understanding of the text (Kintsch et al, 2000).

The Intervention
         Over the last three years, the project has developed, implemented, and evaluated a suite of paper and
electronic tools to support reading in ninth- and tenth-grade science classrooms at a large public high school in
Chicago,  which     we  will call   "Lopez."  We    provided   ongoing,   practice-based   summer     and  school-year
professional development     for  teachers that  stresses   ways to  integrate literacy activities with   their science
learning goals. We co-developed literacy and science activity pacing guides, scoring rubrics and other curricular
implementation   supports    with the  teachers.  Though    our  work  with  teachers   is a critical element   of this
intervention, it is not the focus of this paper. (For more details about our approach to professional development,
see Sherer,  et al, in press). Two    research   assistants were located  at the  school   throughout  the year.  They
provided  materials  and  expertise    on  site. We   collected  substantial   amounts   of  data, including    student
performance indicators, demographics, and student artifacts.
         All students had used all three kinds of tools throughout the school year, but based on our ongoing
observations of classrooms, opportunity to use the tools varied greatly by teacher. Some teachers made tool use
a routine part of instruction. Others used the literacy supports less frequently. Some teachers preferred one kind
of tool and less frequently used the others.
         During  the   2006-2007    school year,   we supported    eight  ninth- and  tenth-grade  teachers and    their
students in 31 classrooms. Lopez serves 2,100 students. Approximately 90% of the student body is considered
low-income   based   on eligibility for  free or  reduced   lunch. The   students are  68%   Hispanic,  28%     African-
American, and 2% white. Nine percent are designated Limited English Proficient. For the 2004-2005 school
year, only 21% of the students at Lopez met or exceeded standards in reading based on a statewide, standardized
test of reading proficiency. Only 10% of students in science met or exceeded standards on the same test.
         In 2006-2007, we administered the Degrees of Reading Power (DRP) test twice to all ninth graders in
October and May. At the beginning of their freshman year, the 9th grade students' performance on the DRP
indicated that of the 450 ninth graders tested, more than 300 had independent reading comprehension levels that
were two or more years below grade level. Obviously, the students at Lopez are struggling readers and are not
atypical of many readers in underserved schools.

Methods
         In May   of 2007,   442  ninth-  and  tenth-grade   participants from   Lopez  who  were  part of  the  ALSP
intervention completed a two-day tool use assessment. Students were first randomly assigned to conditions in
which they were instructed to use one of the three tools (annotation, DEJ, or summary) during and after reading
a text from the environmental science curriculum that was unfamiliar to them. Then, after using one of the three
tools, students  were   instructed  to  answer   a series   of short constructed-response    items    designed  by the
researchers to measure science achievement (see Figure 4).

         1.  What is global warming?
         2.  List the four consequences of global warming below. Explain how each consequence of
             global warming that you listed could affect the environment and life on earth.
         3.  What kinds of weather event changes are predicted as a result of global climate change?
         4.  What is the main cause of global warming, according to most scientists?
         5.  Why are some animals more likely to become extinct than other types of animals if the
             current rate of global warming continues?
         6.  What is some evidence that snow and ice are decreasing?
                        Figure 4. Sample of science achievement items from the tool use assessment

         We designed this assessment so that we could collect data that was fairly well standardized across
classrooms. The assessment was given over the same two days for all teachers. Students had two full class
periods to read the text, use the tools, and then answer questions about the reading. Researchers were involved
in and tracked administration of the assessment and noted problems such as absences for one or both days of the

                                                                                                                            1-
         administration. After collecting the assessments, we began to score tool use and science achievement. Teachers
         were not involved in the scoring of their own students.
                  Two researchers and two teachers who had implemented the environmental science curriculum worked
         collaboratively to develop scoring rubrics for the science achievement items, and for tool use for each of the
         three tool conditions. To develop a rubric to score the science questions, we worked to determine what evidence
         from the reading could be used to construct the best answer to each question. For example, for the first question,
         "What is global warming?" we determined that a correct definition should include two notions that were made
         explicit in the text: Global warming involves an increase in temperature and has a worldwide effect. We wanted
         to  ensure that   a high  score  was    possible for  each  student  who   carefully  read  the text   and that  it was  not
         necessary to know a lot about the topic beforehand to receive a high score.
                  Next, we worked to develop rubrics for scoring student work with tools. As in the rubric for the science
         achievement items, we took an elemental approach. So, a student's annotation score represents a total of their
         scores across 26 individual elements. We only scored elements of the annotation work that we believed were
         most clearly related to receiving a high score on elements of the science achievement questions. For the global
         warming definition question mentioned above, we determined that for annotation, boxing (indicating a word is
         an important science vocabulary word) and noting where the embedded definition is in the paragraph might be
         related to receiving a correct score on that science item. After deconstructing answers into elements like these,
         we  looked  at   each   literacy tool   to determine   how  literacy   work   might   help  a student  in  identifying   and
         comprehending each science element.
                  Once initial rubrics were developed, scoring ensued. Teachers and researchers scored a sample of 40 of
         the same   student  question    sets to work   towards   a reliable rubric  that allowed   for  high inter-rater  reliability
         estimates. Scorers needed to be in agreement on this sample before they could move on to scoring all tests.
         Initial agreement   was  high.   Whenever      agreement   fell below  85%,  critical discussions   took  place that  led   to
         clarification and redesign of the rubrics. When the scorers achieved the reliability standard for all questions, the
         teachers  divided   the  exams   in  half  and scored  independently.  They    met regularly   to ask  questions    they had
         flagged and did an additional trial of 10 exams in the middle of scoring as a final reliability check. A similar
         process was used for scoring elements of tool proficiency. Tool proficiency was scored by one teacher and one
         researcher with additional scorers involved during inter-rater reliability checks.
                  Once    scored,  we  conducted     a  series of correlational and  regression  analyses    to determine    whether
         proficiency with tools (based on rubric scores) was correlated with indicators of science achievement. Then, to
         further explore   the connection     between   tool proficiency   and  science achievement,     we  conducted   a   series  of
         regressions that included prior reading achievement as a covariate in predicting performance on the science
         questions  in the   tool assessment.    These  regressions  can   help us  understand   whether   working   with    the tools
         improves science learning above and beyond a student's on-entry reading achievement.

       Results
                  Correlation results are presented in Table 1. As indicated, reading comprehension (DRP performance)
         is correlated with science achievement as measured both on the tool use assessment and by a unit science test
         administered in all classrooms earlier in the year. Reading comprehension also predicted tool proficiency. Tool
         proficiency   for each   tool is correlated    with science  achievement    as measured     on  the tool assessment.     DEJ
         proficiency   is correlated   with  science   achievement  as   measured   on  the unit science   test but annotation    and
         summary proficiency are not. The sample size for the unit test is much smaller than for the tool assessment.
         Summary scores and DEJ scores better predict science achievement then do annotation scores.
                  Regression     results  are presented   in Table  2.   We  used the  October   standardized   reading   score   as a
         covariate to determine whether tool proficiency increases the variance explained in science achievement once
         on-entry   reading   scores   are    controlled. Writing   good    summaries     and  detailed  DEJs     predicted   science
         achievement   above   and   beyond    reading  proficiency.     Annotation scores  did  not predict  science achievement
         when controlling for reading ability.

         Table 1: Correlations for tool scores, reading achievement, and science achievement.

                                                                                                                    Science
                                                          Pre DRP            Post DRP                           comprehension
                                                          (Reading             (reading          Unit         (score on answers
                                                         achievement        achievement         science          to questions
                                                           October              May)             test           about reading)
          Pre DRP (reading             Correlation                   1
          achievement October)         N                            342

1-
 Post DRP (reading           Correlation                 .79*                     1
 achievement May)            N                           285                  348
 Unit science test           Correlation                 .33*                 .50*           1
                             N                            81                   83          109
 Science comprehension       Correlation                 .57*                 .51*         .34*                         1
 (score on answers to
 questions aboutreading)     N                           325                  336          107                       424
 DEJ tool score              Correlation                 .48*                 .49*         .56*                      .42*
                             N                           102                  102            37                      129
 Summary tool score          Correlation                 .36*                 .36*         .26                       .43*
                             N                            94                  101            30                      118
 Annotation tool score       Correlation                 .27*                 .32*         .18                       .23*
                             N                           119                  120            36                      144
* p<.05

Table 2: Regressions for 3 models: Predicting science achievement from tool proficiency and reading achievement.

                        Models                   F       Adjusted R2      B     SE B       E    Significance
               Model 1                           23.8             .29

                    Reading (Pre DRP)                                     .21       .03  .52        <.0001*
                    Annotation Score                                      .07       .08  .07             .35

             Model 2                             31.6             .41
                    Reading (Pre DRP)                                     .20       .03  .52        <.0001*
                    Summary Score                                         .48       .17  .25           .005*

             Model 3                          25.42               .33
                    Reading (Pre DRP)                                     .17       .04  .46        <.0001*
                    DEJ Score                                             .26       .11  .21           .02*
            *p<.05
Discussion
         The results indicate reading comprehension, as measured by the DRP test in October, strongly predicts
science  performance   across  the two   measures     of science  achievement     used  in this study. This  provides   an
important justification for our reading work in science classrooms. Science teachers and their students need to
be convinced that the focus on making texts more prominent in science instruction is worth it, that such a focus
can  lead   to increased   science     learning. The   connection     between   reading    comprehension     and  science
achievement is clear from our data. Reading is a critical predictor of science learning.
         Tool   proficiency,  for  all three kinds    of tools, was   related  to reading    comprehension   and  science
achievement. This is also an important finding that helps provide a rationale for the approach we have taken.
Reading   work  that is done    in science   classrooms     must  lead to  changes   in  science  achievement    for such
approaches to be taken up by participants. It also provides initial evidence that the tool work is being properly
contextualized  within  science   instruction by   teachers   and students.   Adolescents    need  to become   skillful in
applying  strategies while   they  are reading   content-area   texts  so that the  application  of strategies is closely
coupled to disciplinary activity (Heller & Greenleaf, 2007). Learning to apply strategies to disciplinary text
connects the strategy use to the knowledge and reasoning process that are specific to the disciplines (Heller &
Greenleaf). This is a key element of our approach: Strategies must be taught, customized and understood in
relation to science  texts that have   their own   structures,   purposes, and    roles in science  learning. Too  often,
decontextualized   strategies are  taught in  reading    or language   classes  to  give  students  some support   across
content domains. The evidence for the utility of domain-independent strategies is unconvincing. We conjecture
that science-specific reading strategies, closely integrated into science instruction, are more likely to address the
reading gap described above than more generic strategies that require teachers and students to engage in work

                                                                                                                             1-
         that is removed     from  working   toward   their science   learning  goals. It  is still an   open   question about   how
         specific/generic reading strategies can apply across and within content domains. For example, though the work
         we have done to date has taken place in environmental science and biology classrooms, it is unclear whether
         reading in physics, chemistry, or geology would require fundamentally different strategies encapsulated in tools
         or whether there is more similarity than differences in science readings across disciplines.
                  Another    important    finding  is that DEJ   and  summary    proficiency,     but  not annotation    proficiency,
         predicted science   achievement     on the   tool assessment    when   controlling   for on-entry  reading   levels.  These
         findings suggest that teaching students these relatively targeted ways to read and learn from texts can increase
         understanding of texts, and that understanding does translate into higher science achievement. This provides us
         with  some   evidence    that the   tools are  helping   students develop     metacognitive     skills  such  as improved
         comprehension monitoring and strategy application.
                  It is interesting that annotation proficiency did not predict science achievement when controlling for
         on-entry reading level but that DEJ and summary proficiency did. This may impact how we redesign materials
         and  supports   for tools in  future   work.  It  may  be  that marking   a  text  during    annotation  is  somehow     less
         supportive of metacognitive skill growth and comprehension because it is potentially a less active process than
         DEJ and summary work, which require more active transformation of understanding because students have to
         construct new    (physical,   written) representations    of the  text in   the DEJ   and     summary   work.   That    is an
         interesting speculation for future work. Also, it is possible that elements of the annotation do predict science
         achievement on particular items from the list in Figure 4 but do not predict the total score as well. Finally, it is
         possible that, because the scoring rubric included 26 different items that made up the annotation score, the
         connection between annotation proficiency and outcome is masked. We will study the relative utility of the tools
         more carefully in future research.
                  Because we made an effort to standardize administration of the tool use assessment, we were unable to
         examine some interesting questions about tool proficiency that we would like to explore in future work. For
         example,  we    considered  allowing   students    to choose  which    tool they  would    use  with   the  reading  on    the
         assessment, perhaps allowing them to demonstrate the metacognitive skill of strategy choice. But, to ensure that
         we had roughly equal numbers of students in each condition, we decided to randomly assign students. In follow-
         up work and in our ongoing analysis of existing data, we will try to determine whether particular tools work
         better with specific kinds of texts and learning assessments. Though the science achievement measure on the
         tool use assessment was designed in consultation with one teacher to reflect typical kinds of assessment of
         science learning in the curriculum, it is clear that we did not develop a measure of science achievement that is
         independent from students' reading comprehension. Students had to write responses after reading the passage to
         the questions. Thus, writing was also involved in producing evidence of science achievement. None of this is
         different than what typically occurs in the assessment of science learning, but it is worth noting how science
         assessment is often inextricably bound with reading comprehension skills whether that is acknowledged or not.
                  As inquiry approaches to teaching and learning become widespread in American schools, more and
         more students with varying reading strengths will be participating in these ambitious learning environments. For
         struggling readers and even for their more accomplished peers, reading to learn (Yore & Shymansky, 1992)
         remains a challenge. Yes, this skill -- perhaps even more than others that have received more attention from the
         science education community -- likely predicts a host of science-related outcomes including, ultimately, the
         likelihood that a student becomes a scientifically literate adult who reads about science through text to stay
         informed  about   the world.     To develop   accomplished    science  readers   requires  providing    students    and their
         teachers with tools and supports, including opportunities to learn about, practice, and customize the tools to
         reflect their deepening proficiency with the strategies that the tools encapsulate. Our work is an attempt to better
         understand the connection between reading achievement and science achievement and to take that connection
         seriously in  the redesign    of reading  activity in  inquiry  classrooms   to make     text a more   prominent    learning
         resource in instruction.
                  We are particularly interested in understanding how science instruction changes when students have
         better understanding of and access to the content of science readings. Future extensions of this work include a
         careful mapping of science reading comprehension to instructional activity. For example, if students understand
         a text  better, are  there  changes    in the  quality  of   classroom  discussions    around     that text, including     the
         participation of struggling readers who were too often marginalized by the challenge of discussing texts that
         they did  not   understand.   There  are  many    ways  in which  increased     reading  comprehension       likely leads  to
         increases in science achievement. Understanding those pathways may help us design more, and more effective,
         reading supports that closely couple reading activity to science learning activities.

       References
         Anderson, V. (1992). A teacher development project in transactional strategy instruction for teachers of severely
                  reading-disabled adolescents. Teaching & Teacher Education, 8, 391­403.

1-
Balfanz, R., McPartland, J. M., and Shaw, A. (2002). Re-conceptualizing extra help for high school students in
         a  high standards   era.   Baltimore,   MD:  Center   for Social  Organization of  Schools, Johns  Hopkins
         University.
Biancarosa, C., & Snow, C.E. (2006) Reading Next--A Vision for Action and Research in Middle and High
         School Literacy: A Report to Carnegie Corporation of New York (2nd Ed.). Washington, DC: Alliance
         for Excellent Education.
Collins, C. (1991). Reading instruction that increases thinking abilities. Journal of Reading, 34, 510-516.
Gomez, K., Gomez, L. M., & Herman, P. (2008). Conspicuous strategies to support reading to learn: Preparing
         urban youth to engage in science inquiry. Manuscript submitted for publication.
Gomez,   L., Herman,   P.,  &   Gomez  , K.  (2007).  Integrating  text in content-area classes: Better supports for
         teachers and students. Voices in Urban Education, 14, 22-29.
Heller, R. & Greenleaf, C. (2007). Literacy instruction in the content areas: Getting to the core of middle and
         high school improvement. Washington, DC: Alliance for Excellent Education.
Kintsch, E.,  Steinhart,    D., Matthews,    C.,   Lamb,   R., and   LSA   Research  Group    (2000).   Developing
         summarization skills through the use of LSA-based feedback. In J. Psotka (Ed.). Special Issue of
         Interactive Learning Environments, 8(2), 87-109.
Kintsch, W. (1998). Comprehension: A paradigm for cognition. New York: Cambridge University Press.
National Center   for  Education     Statistics.  (2003). Remedial   education  at  degree-granting   postsecondary
         institutions in fall,  2000.  Washington,     DC:   U.S.  Department   of Education,  National   Center for
         Education Statistics.
National Center   for  Education     Statistics. (2005).  The  Condition   of Education   2005   (NCES   2005­094).
         Washington, DC: U.S. Government Printing Office.
National Reading     Panel. (2000).  Teaching    children to read:  An  evidence-based  assessment   of the scientific
         research literature on reading and its implications for reading instruction: Reports of the subgroups
         (NIH Publication No. 00­4754). Washington, DC: U.S. Government Printing Office.
National Research     Council.   (1996).  National   Science   Education   Standards.   Washington,   DC:   National
         Academy Press.
Pressley, M., El-Dinary, P.B., Gaskins, I., Schuder, T., Bergman, J., Almasi, J., et al. (1992). Beyond direct
         explanation:  Transactional   instruction  of reading  comprehension   strategies. The  Elementary   School
         Journal, 92, 511­555.
Ridley, D. S., Schutz, P. A., Glanz, R. S., Weinstein, C. E. (1992). Self-regulated learning: The interactive
         influence of metacognitive awareness and goal-setting. Journal of Experimental Education, 60, 293-
         306.
Sherer, J., Gomez, K., Herman, P., Gomez, L., White, J., & Williams, A. (in press). Literacy infusion in a high
         school environmental science curriculum. In K. Bruna and K. Gomez (Eds.), Talking science, writing
         science: The work of language in multicultural classrooms. Mahwah, NJ: Laurence Erlbaum.
Touchstone Applied Science Associates (TASA). (1999). DRP Program: The readability standard. Brewster,
         N.Y: Author.
Yore, L. D., & Shymansky, J. A. (1991). Reading in science: Developing an operational conception to guide
         instruction. Journal of Science Teacher Education, 2, 29-36.

Acknowledgements
This work was supported in part by the National Science Foundation under REC No. 0440338. Any opinions,
findings, and conclusions or recommendations expressed in this material are those of the authors and do not
necessarily  reflect those  of  the National Science   Foundation.   We   would also like  to thank  Jennifer Sherer,
Jolene White, Beverly Troiano, and all the teachers and students who worked with us.

                                                                                                                          1-
