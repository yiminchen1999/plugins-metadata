   Computer    Spelling             Checkers:       An  Example        Cognitive       Tool

                                       Lorana A. Jinkerson, Ph.D.
                                        Department of Education
                                      Northern Michigan University
                                      Marquette, MI   USA 49855
                                          ljinkers@runu.edu

Introduction
     Mankind has readily developed tools [Salomon, 1993] to aid him/her in the pursuit of alleviating
labor and providing for his/her life's needs and desires. From the invention of the wheel and before, the
development and use of tools has separated humans from the other animal species. Physical tools (wheels,
levers, inclined planes, etc.) and cognitive tools (symbols systems, books, slide rules, etc.) have both
supported us in our labors to improve our lives.
     Historically, however, it appears as though the acceptance of tools has been more widely achieved in
the non-school world than in schools. Thornburg (1993) alludes to this phenomena by describing how a
physician from the 19th century would be totally out of place in today's medical community, but, in
contrast, a teacher from the 19th century could be placed in a modem classroom and know exactly what to
do, implying that current classrooms have not changed much since the 1800's in terms of the most
commonly used tools, e.g. blackboards, books, paper and pencils.
     Further, it appears as if physical tools have generally been more readily accepted than cognitive
tools. For a carpenter to do his/her work, many physical tools are necessary. No one would expect an
apprentice carpenter to build a cabinet without these physical tools. Nor would we expect a child who has a
physical handicap of poor eyesight to complete his/her schoolwork without the support of corrective lenses.
Yet, in school, we often limit students' access to cognitive tools, especially when evaluating them on their
learning, e.g. students are encouraged to seek the wisdom contained in a dictionary (a cognitive tool) while
learning definitions, pronunciations, and spellings of words, but for the 'test' of their knowledge, a
dictionary is forbidden them. Yet, as adults we rely upon cognitive tools in all our tasks. Consider how
well Tom Brokaw would present the evening news without a teleprompter? With the recent and current
advancements being made in cognitive tools, e.g. computers and supporting software, resistance to the full
integration of cognitive tools must be addressed by the educational community.

Research questions
     Computer spelling checkers, an integral part of most word processing software, may be considered an
example of a cognitive tool. Concern on the part of teachers, parents, and administrators regarding the
cognitive effects of early use of spell checkers, as with calculators and word processors themselves, led to
this study. The following questions were posed: 1) Identification: How well do students identify misspelled
words? 2) Correction: After identification, how well do students correct misspelled words in a document? 3)
Correction rate: What is the correction rate, defined as the number of corrected misspellings divided by the
number of identified misspellings? 4) Efficiency: How efficient are students at identifying misspellings and
making corrections? I defined efficiency to be the number of misspelled words corrected divided by the time,
in minutes, spent on the task. 5) Final product Which treatment factor provides the best overall final
product in terms of the fewest spelling errors per total words written? 6) Spelling performance: Over a
semester, how well do students learn to spell words which, in their own writings, they misspelled at least
once, and subsequently corrected?

                                                                                                             427
    Method
        From January to June 1993, 49 students in two fourth-grade classes in a town in southeast Michigan
    participated in this study. To control for teacher effects, within each class, students were randomly assigned
    to one of four treatment groups: manual (AM), collaborative manual (CM), spell check (ASP), or
    collaborative spell check (CSP). Analysis of variance of the students' 1992 national percentile spelling sub
    test scores of the CAT (California Achievement Test) showed no significant differences among the groups
    (F-value (3.42) = .029, p = .9934). Further, it was noted that both classrooms had similar word processing
    experiences. Since the beginning of the school year, both classrooms had been completing word processed
    papers approximately once a week. Most of the students had no formal keyboarding, therefore it was
    assumed that a certain portion of their spelling errors would be typographical.
        The study included three phases: pretesting, treatment, and post testing. In Phase I (pretesting),
    students were given an oral and a multiple choice spelling test. In addition, the students participated in a
    practice proofreading session for their particular group using a story I had prewritten for the occasion.
        In Phase II (treatment), the students went to the computer lab approximately once a week, either to
    compose or to transfer documents (stories, poems, letters, reports) onto the word processing program. Once
    each student had entered his/her document into the computer, it was saved on a diskette for later retrieval.
    Students in one classroom completed a total of eight documents each, while those in the other classroom
    completed a total of six documents each, over the nearly six-month course of the treatment. With each
    document saved on a diskette, each student or pair of students, in the case of the collaborative groups,
    would join me in the classrooms' quiet room. The student or students were asked to "think out loud" [see
    & Simon 1984) as they proceeded to identify and correct spelling in their documents, either at the desk in
    the case of the AM and CM groups, or at the computer in the case of the ASP and CSP groups. As the
    students worked a video-camcorder captured their actions and voices, and, in the case of the students
    utilizing the computer, the computer monitor as well.
       In Phase m (post testing, students were given the same oral and multiple choice spelling tests as
    initially. And, in addition, they took an individualized oral spelling test over words they had used and
    misspelled in their own writings during the treatment phase.
        Throughout the study, I aided the students in the computer room when they did their word
    processing, helping them save their files, encouraging them to spell as best they could when writing, but
    emphasizing not to worry about spelling errors as such until they did their proofreading in the quiet room
    with me and/or their partner later in the week.
        In addition to the documents composed by the students, I produced four stories containing typical
    misspelled words obtained in a previous study [see Jinkerson & Baggett 1993] and from earlier writings of
    the students in this study. Each story contained words that the spell checker would identify as misspelled, as
    well as words that would be skipped by the spell checker. The first story was used for practice to teach the
    students how to check their writings for spelling errors. Stories two, three, and four were given to the
    students during the treatment phase. By including these prewritten stories for students to identify and correct
    the misspellings, individual student differences in word choice, length of papers, etc. were controlled for
    this portion of the data.

    Analysis
        One- and two-factor ANOVAs were used as a basis for answering the research questions. All
    significant ANOVAs, both one-factor and two-factor, were followed by Scheffe post hoes tests to correct for
    multiple tests on dependent variables [Winer, 1971]. Since each treatment group can be described in terms
    of the presence or absence of two kinds of partners, either human or technological, the two-factor ANOVA
    tests for the main effects of the factors and the interaction between them, while the post hoc Scheffe tests
    following a significant one-factor ANOVA identify the specific pairs of means that are significantly
   different among the four treatment groups. Results and discussion of each research question follow focusing
    primarily upon the differences between manual identification and correction vs. spell checker identification
   and correction.

428
Identification. If students cannot identify spelling errors, they cannot correct spelling errors. Therefore,
this initial step of identification becomes crucial to the remaining task of correcting spelling errors, and it
contributes to the results of some of the other variables, e.g. correction, correction rate, efficiency, and final
product
     Typically, in elementary classrooms, teachers circle misspellings in students' writing, thereby
identifying for students the spelling errors they have made. The student knows he/she has made an error
only when the paper is returned to him/her, and after the teacher has graded it, or at least seen it as a rough
draft The red marks may confinn a student's belief that he/she is a poor speller.
     If a goal of education is to foster independent thinking, decision making, and taking responsibility
for their own learning, students must be able to proof their work and make corrections before it is turned
into the teacher. From the results of this study, it is evident that students cannot do that task alone. The
average rate of identification of misspellings for students manually proofing their own writings was only
8.5% or 3.9 words. Yet, the average number of misspellings per student in the AM group over the course
of the treatment was 46 words. That means, on average, these students identified only 4 misspelled words,
leaving 42 words still unidentified and therefore, uncorrected. As one boy stated, "I know there are lots of
spelling mistakes because I am a poor speller, but I don't know which ones are wrong." It would seem that
some students perceive their own difficulties very well.
     All the students were to write their papers without concern for spelling, to just do the best that they
could: they were told they would take care of spelling errors later. During the proofing process, some
students in the AM group quickly read through their writing and then announced, "It's all okay. I did it
right the first time." In fact, three students in the AM group never identified a single spelling mistake over
the whole semester, yet, these same students had misspelled, on average, 17 words. Since these students did
not identify mistakes, they also did not correct mistakes. In essence the students were either confident that
they wrote all the words correctly the first time, did not take the spelling proofing task seriously, or were
so unsure of their spellings that they didn't know which words were right or wrong. Therefore, they made
no attempt at all.
     With the prewritten stories, the students in the AM group identified 44.4% of the actual
misspellings, a statistically significant increase from the 8.5% identified in their own writings, but still
significantly lower than any of the other groups for the prewritten stories. Since these stories were not
written by the students, we can discount the idea that they knew the words were written correctly the first
time, so they may have approached the task more diligently. Further, since I had written the stories, the
students may have felt challenged to try harder to identify the mistakes, knowing that I had deliberately
make the errors and was trying to stump them. Another possibility, of course, is that the prewritten stories
contained a higher proportion of misspelled words that the students already knew how to spell, and therefore
they could identify them more easily.
     In contrast to both manual groups (AM and CM) identifying 21.5% of their misspellings, the
students in the spell checker groups (ASP and CSP) identified 84.2%, a significantly higher proportion (F
value (4.806) = 154.142, p = <.0001). A spell checker is designed to identify words (letter strings) in a
document that do not match a prescribed list of words in the program's dictionary (word list). Obviously, it
does this task relatively well compared to these fourth grade students. Of course, it fails to identify
homophones, real-word errors (e.g. "from" for "fonn", etc.), and words that are not in its list (e.g. proper
nouns).
     It seems self-evident, given what a spell checker does, that students using a spell checker to aid them
in identifying misspellings would identify a larger proportion than students working without a spell
checker. Students need help with this difficult step and a spell checker seems to meet this need for a large
proportion of misspellings.
     Further, the spell checker offers the possibility of doing so immediately after the student has written
the paper, and before the teacher has had a chance to see it. If immediate feedback is important, and research
indicates that it is [see Kulhavy 1977], it seems reasonable that allowing students to use spell checkers
would be welcomed.

Correction. Once students have identified misspellings through whatever method, the next task becomes
correcting those identified misspellings. In a typical classroom students often never get to this step. If the
teacher circles (identifies) the students' misspellings in a particular paper for the student, a similar, but

                                                                                                                429
    more complete [1] task than what the spell checker has done up to this point, then depending upon the
    requirements of the teacher, the student may be asked to correct those errors, or the paper may be forgotten,
    and thus the student will never correct those errors, as the class moves on to new assignments. Few
    teachers take the time to require students to correct the circled misspellings and resubmit the paper with the
    correct spellings. In fact, some teachers go further that just identifying the misspellings. Instead, they
    actually supply the correct spelling by writing above the circled word the proper spelling. If teachers do not
    require students to correct identified misspellings, the chances are that the students will not even look at the
   circled words only long enough to feel good or bad about the number of red circles. Nothing forces the
    student to confront those misspellings unless the teacher is diligent about the students making corrections.
        In contrast, most spell checkers, when identifying a word as possibly misspelled, stop and force the
    user to make a decision about how to proceed, that is, whether to ignore it, to retype it, or to ask for
   suggestions. Of course, the student can make the wrong decision, but at least he/she must acknowledge that
   for some reason, the spell checker stopped on that word.
        As with identification, the students in the two manual groups corrected the lowest proportion of
   identified words, 17.0%, vs. 50.4% for those students in the two spell checker groups. Adding the spell
   checker as a technological cognitive partner significantly increased the number of words corrected (F-value
   (1.379) = 59.791, p = <.0001). Similar results were noted for the prewritten stories, 41.8% vs. 68.3% {F
   value (.855) = 38.662, p = <.0001).
        A word of caution needs to be addressed in the use of correction by spell checkers. The students in
   both classes had been studying the environment in relation to "Earth Day" and had learned of the danger of
   overuse of aerosol spray cans to the ozone layer. Consequently, in the final prewritten story, I included a
   misspelling, "aresal" for "aerosol." The spell checker did not offer the correct spelling, instead it offered
   only one option, "arousal." All but one student in the spell checker groups immediately selected "arousal"
   to replace my misspelling of "aerosol." Students must be very aware that just because the spell checker
   offers only one option, that is not necessarily the correct one. Just as with calculators, students must be
   taught to develop critical questioning skills when working with spell checkers and not just blindly accept
   the solution offered.
        Another observation noted in the identification and, subsequently, the correction process was the
   students' knowledge of words not studied through school spelling lessons. In the final prewritten story, I
   inserted the incorrect spelling "nintindo" for "Nintendo." Over 80% of all the students in all groups
   identified and corrected this misspelling. This raises questions about incidental learning of correct spellings
   versus learning correct spellings through traditional school spelling lessons.

   Correction rate. The correction rate provides evidence as to how well the spell checker as a
   technological cognitive partner aids the student in correcting errors that have been identified. Students in the
   AM group were able to correct approximately 55% of the words they identified as misspellings in their own
   papers and approximately 65% of the identified words in the prewritten stories. It is interesting to note that
   the addition of a technological cognitive partner, the spell checker, did not significantly alter the students's
   rate of correction after identification (Correction rates of 66.1% and 74.6%, respectively, for students in the
   spell checker groups for their own stories and the prewritten stories.) Overall for all groups and all
   documents, correction rates averaged 69%. It appears that the spell checker does not aid students in
   correction rates, that no matter what method of correction is used, students can correct misspellings that
   have been identified as misspellings approximately 70% of the time. This supports the results reported in
   Jinkerson & Baggett's previous work (1993).

  Efficiency. Efficiency is often used as a measure to ascertain whether one method of completing a job is
   preferable to another in terms of the amount of work done per unit of time. As elsewhere, time is a
   precious resource in schools. If students spend an inordinate amount of time on one task, the amount of
   time of remaining tasks becomes short-changed. It becomes important for students to work within a
   reasonable time allotment. When efficiency of correcting misspellings is evaluated in this study, students
   with a spell checker correct more words per minute than do students correcting manually. This fact is

   [1] More complete in that a spell checker does not identify homophones, real-word errors, grammatical
       errors, etc. whereas a teacher, of course, would identify all types of spelling errors.

430
especially evident when comparing the AM with the ASP groups, where the ASP group corrects over four
times as many words per minute as the AM group (.432 vs .100 words corrected per minute for ASP vs.
AM groups respectively). Overall, students working with a spell checker have significantly higher
efficiency ratios than those working manually (F-value (.406) = .15.656, p = <.001).
     Relating to efficiency, for some students using the spell checker an interesting observation was
noted. If a word was identified as suspect, for example, "invirnment", and the spell checker failed to offer
the correct alternative, "environment". to the student in the list of suggested spellings, the student would
return to the 'retype the word' option of the spell checker and type another spelling of "environmenL" Often
the student was aware that the new spelling he/she typed was still incorrect, but by entering a different
string or configuration of the characters, the spell checker would be able to offer different suggested
spellings. A few diligent students would work back and forth in this manner several times trying to get the
spell checker to provide the correct spelling. Obviously, this use of the spell checker took more time,
thereby possibly decreasing the student's efficiency than manual or even traditional spell checker methods.
Yet, it demonstrates the extent that the spell checker can become a real cognitive tool to the student.
     Another observation made of a few students in the spell checker groups was a general interest in and
playing with the spell checker. For example, a few students deliberately misspelled a word just to see what
the spell checker would suggest. It became a game to them to stump the spell checker. A couple of students
went so far as to just enter a string of letter and then ask the spell checker if those letters comprised a real
word spelling. Obviously, this activity added to the time on task for identifying and correcting errors and
consequently distorted the "real" efficiency. Yet, I believe it was valuable experimenting and should be
promoted as a method of word exploration. I can't recall ever observing a student write a word on paper and
then to go a dictionary to look it up to see if it was a real word. If teachers are interested in students'
vocabulary development, 'word play' such as observed here should be encouraged.

Final product. The results demonstrated that there were no significant differences in the proportion of
total words correctly spelled in each student's original papers (overall, approximately 7.8% words
misspelled). After correction, however, there was a significant difference in the proportion of total words
correctly spelled in the students' final papers for the main effect of manual vs. spell checker (F-value (.018)
= 8.477, p = <.01).. Students correcting their papers with a spell checker end up with a final product
containing significantly fewer spelling errors that those who correct their papers manually (6.9%
misspellings in final products vs. 3.4% for spell checker groups). Similar results were observed with the
prewritten stories where students correcting manually had 9.9% misspellings in the final versions while
those correcting with the spell checker had only 5.4% (F-value (.025) = 38.662, p = <.0001).

Spelling performance. While no statistically significant results were noted in the students'
personalized post-treatment oral spelling tests that would allow for generalizations to be made to other
populations, a practical difference was noted in the results with this particular group of students. Out of a
possible 10 points, the students in the AM group scored, on average, 4.25 correct. The students in the CM
group scored, on average, 5.17 correct. The students in the ASP group scored, on average, 5.31 correct.
And, the students in the CSP group scored, on average, 6.25 correct. Thus, the teachers in this study should
value the 9% to 20% increase in their student's score. Using practical results as the criteria then, again, for
this particular group of students, it appears that using a spell checker to identify and correct misspelling,
students learn to spell those words correctly more often than students who manually identify and correct
misspellings.

Conclusion
     Overall, the students in the two spell checker groups (ASP and CSP) outperformed the students with
no technology partner. They identified and corrected a higher percentage of both their own misspellings and
those in the prewritten stories. Hence, their final products were freer of spelling errors. Furthermore, the
students utilizing a spell checker identified and corrected more words per minute than those manually
correcting spelling. Correction rates, however, were not significantly different among the groups. Finally,
although no significant differences were found in the students personalized post-treatment oral spelling

                                                                                                                 431
    tests, practical differences wef noted, a 9% to 20% increase in scores over those in the AM fuoup. These
    results add computer spelling checkef to the gfwing cadre of fhnological cognitive tools students and
    adults can and should use on a regular basis in the complefon of their work.
          With cognitive technologies such as computers and suppofing soff§are, including flling checkers,
    "...the technology is encountered, engaged. It becomes something to master, defeat, learn fpom, or fe
    advice fqm." [see Howard 1994) (p. 395) This suppof Perfs' (1993) "frson-plf¬" system, Pea's
    (1993) concept of tools as indispenfble insf£ments of menfity, as well as Salomon, Perfns, and
    Globerson's (1991) ''partners in cognifon" mfel. On an analytical level, the user is wef aware that he/she
    is interacfg with a machine, not a human being, but df«g the actf©l interactions with fe machine, the
    user may sense being in communication with the machine much lfye communication with another human
    (see Howard in press). Thus, the technology medfxtes sf¦denf¤' lives, and has implications for both
   fgofv and the cfculum.

  References
    [Efcsson & Sfzon 1985) Ericsson, K. A., & Simon, H. A. (1985). Protocol analysis: Verbal reports as data.
   Cambridge, MA: MIT Press.

   [Howard in fess] Howard, D. (in press). Computers and adult first-time users: Toward understanding of human
   computer interaction. Infational Journal of Qualitative Studies in Education.

   [Howard 1994] Howard, D. (1994). Toward a theory of educational technology. In J. Willis, B. Rubin, & D. A.
   Willis (Eds.) Technology and teacher education annual, 1994. Association for fe Advancement of Computing in
   Education, Charlottesville, VA. 393-396.

   [Jinkerson & Baggett 1993) Jinkerson, L. A., & Baggett, P. (1993). Spell checkers: Aids in identifring and
   correcting spelling errors. The Journal of Computing in Childhood Education, 4(4), 291-306.

   [Kulhavy 1977) Kulhavy, R. W. (1977). Feedback in written insf¢ction. Review of Educational Research, 47(2),
   211-232.

   [Pea 1993) Pea, R. D. (1993). Practices of distributed intelligence and designs for education. In G. Salomon (Ed.)
   Distributed cofttions: psychological and educational considerations. New York: Cambridge University Press.

   [Perkins 1993] Perkf|, D. N. (1993). Person plus: A distributed view of fg and learning. In G. Salomon
   (Ed.) Distributed cognitions: psychological and educafonal considerations. New York: Cambridge University
   Press.

   [Salomon 1993] Salomon, G. (1993). On the nature of pedagogic computer tools: The case of the Writf{g Parf er.
   In S. P. Lajoie & S. J. Defy (Eds.) Computers as cofsitive tools. Hillsdale, NJ: Lawrence Erlbaum.

   [Salomon, Perkins, Globerson 1991) Salomon, G., Perkins, D. N., & Globerson, T. (1991). Parf¡ers in
   cognition: Extending human  intelligence with intelligent technologies. Educational Researcher, 20(3), 2-9.

   [Thornburg 1993] Thornbfªg, D. D. (1993, October). Paper presented at the annual Seaborg Math and Science
   Conference, Marquef¥e, MI.

   [Winer 1971] Winer, B. J. (1971). Statistical principles in experimental design. New York: McGraw-Hill.

432
