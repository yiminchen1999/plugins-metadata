         Transfer          Effects   of   Semantic       Networks           on      Expert      Systems:
                                          Mindtools         at      Work

                                             RoseM. Marra
                                          College of Engineering
                                      Pennsylvania State University
                                     University Park, PA 16802-3206
                                             nnarra@psu.edu
                                            David H. Jonassen
                                      Pennsylvania State University
                                          Instructional Systems
                                     University Park, PA    16802-3206
                                           jonassen@psu.edu

           Abstract:   Semantic  networks and  expert systems       can support learning and critical
           thinking as Mindtools (knowledge representation formalisms for analyzing the world,
           accessing   information,  interpreting  and  organizing       personal  knowledge,   and
           representing    what learners  know to  others).      Both are cognitive  reflection and
           amplification tools that help learners to construct their own knowledge by designing
           their own knowledge bases. This study examined the effects of building semantic
           networks on the coherence and utility of expert systems subsequently constructed by
           undergraduates.    The ambiguity of the task was problematic for many of the students,
           so more scaffolding of required actions would be appropriate. The kinds of thinking
           required to build semantic nets and expert systems were quite different, with no
           facilitative effect of one on the other. That kind of transfer would also have to be
           better scaffolded.

Introduction:    Computers       as  Mindtools
Instructional technologies have traditionally been used as conveyors of information and tutors of students.     In these
traditional applications, information is stored in the computer. During the "instructional" process, learners perceive the
messages stored in the computers and "interact" with the technology. In contrast, Derry and LaJoie (1993) argue that "the
appropriate role for a computer system is not that of a teacher/expert, but rather, that of a mind-extension "cognitive
tool" (p. 5). Cognitive tools are unintelligent tools, relying on the learner to provide the intelligence, not the computer.
So, we believe that computers are more effectively used as Mindtools (Kommers, Jonassen, & Mayes, 1992). Mindtools
enable knowledge construction and knowledge representation so that learners can learn with technology, not from it
(Salomon, Perkins, and Globerson, 1989). Mindtools (Jonassen, 1996) include (but are not limited to) databases,
spreadsheets, semantic networks,   expert systems, multimedia/hypermedia          construction, computer  conferencing,
microworlds and even programming.     Mindtools are knowledge representation formalisms for analyzing the world,
accessing information, interpreting and organizing their personal knowledge, and representing what they know to others.
They are cognitive reflection and amplification tools that help learners to construct their own realities by designing their
own knowledge bases.
      A number of studies have demonstrated the effectiveness of Mindtools for engaging critical thinking in learners.
However, none   have examined    the combinatorial effects       or the effects of using  one Mindtool   for  fa cilitating
representation by another. Since each Mindtool provides a different formalism for representing content and personal
knowledge, it is reasonable to expect that representing knowledge with one Mindtool might facilitate another.
Semantic  Networks     as   Mindtools

Semantic networking tools are cognitive tools that provide a visual and verbal means for developing concept maps,
otherwise known as cognitive maps. Cognitive maps are spatial representations of ideas and their interrelationships that
are stored in memory, i.e. structural knowledge (Jonassen, Beissner, & Yacci, 1993).  Programs such as SemNet (Fisher
1990,1992), Learning Tool (Kozma, 1987), and TextVision (Kommers, 1989) enable learners to interrelate the ideas that

                                                                                                              219
 they are studying in multidimensional networks of concepts, to label the relationships between those concepts, and to
 describe the nature of the relationships between all of the ideas in the network.
         The   purpose of  semantic  networks     is to represent the  organization  of  ideas that someone   knows    or the
 underlying organization of ideas in a content domain.    So, semantic networks require learners to analyze the structural
 relationships among the content being studied.      They can also be used as evaluation tools for assessing knowledge
 acquisition.
         Semantic networking aids learning by requiring learners to analyze the underlying structure of ideas they are
 studying. Constructing computer-based semantic nets engages learners in:
       the reorganization of knowledge,
       explicit description of concepts and their interrelationships,
       deep   processing of knowledge,   which      promotes better   remembering   and retrieval  and the ability to apply
        knowledge in new situations,
       relating new concepts to existing concepts and ideas, which improves understanding, and
       spatial learning through spatial representation of concepts in an area of study (Fisher, Faletti, Patterson, Lipson,
        Thornton, & Spring, 1990).
 Constructing semantic networks and cognitive maps has been shown to be an accurate means for representing cognitive
 structure (Jonassen, 1987). Semantic networks also provide a useful evaluation tool for measuring the acquisition of
 knowledge    In a geometry class, concept maps were used to evaluate teaching outcomes and to monitor student progress
 in the course (Mansfield & Happs, 1991).
         The usefulness of semantic nets and concepts maps is perhaps best indicated by their relationships to other
 forms of higher order thinking. They have been significantly related to formal reasoning in chemistry (Schreiber &
 Abegg, 1991), and reasoning ability in biology (Briscoe & LeMaster, 1991; Mikulecky, 1987).        Semantic nets have also
 been shown to be related to examination performance (Goldsmith, Johnson & Acton, 1991).             Knowledge of subject
 content is more organized after using semantic nets as a study tool (Jonassen, 1994).

 Expert  Systems    as    Cognitive  Tools

 Expert systems have evolved from research in the field of artificial intelligence. An expert system is a computer program
 that simulates the way human experts solve problems - an artificial decision maker (Grabinger, Wilson, & Jonassen,
 1990). For example, when we consult an expert (e.g., doctor, lawyer, teacher) about a problem, the expert asks for
 current information about our condition, searches his or her knowledge base (memory) for existing knowledge that relates
 to elements of the current situation, processes the information, arrives at a decision, and presents his or her solution.
 Like a human expert, an expert system is approached by an individual (novice) with a problem.       The system queries the
 individual about the current status of the problem, searches its own knowledge base of IF-THEN rules for pertinent facts
 and rules that reflect an expert's knowledge previously stored in the expert system, processes the information, arrives at a
 decision, and reports the solution to the user.
         Although, expert systems are primarily used in businesses as advisors that control processes, they also have
 many applications in education.  A good deal of research has focused on developing expert system advisors to help
 teachers identify and classify learning disabled students or to assist students in selecting the correct statistical test (Karake,
 1990; Saleem & Azad, 1992).
         Expert systems can also function as cognitive tools.     Trollip, Lippert, Starfield, & Smith (1992) believe that
 the development of expert systems results in deeper understanding because they provide an intellectual environment that:
        demands the refinement of domain knowledge,
        supports problem solving, and
        monitors the acquisition of knowledge.
         Building expert systems requires the developer to explicitly model the knowledge of the expert in a causal
 manner. Expert systems is one of the only formalisms for depicting procedural knowledge (Gagne, 1987).         As learners
 identify the IF-THEN structure of a domain, they are forced to articulate the nature of decision making tasks; this deeper
 understanding should make subsequent practice opportunities more meaningful.          This is not to suggest that the mere
 development of an expert system necessarily leads learners to acquire the compiled procedural knowledge of a domain.
 Starfield and Lippert (1987) found that the analysis of subject matter required to develop expert systems is so deep and so
 incisive that learners develop a greater comprehension of their subject matter, because building expert system rule bases
 engages learners in analytical reasoning, elaboration strategies such as synthesis, and metacognition.     Lai (1989) found
 that when nursing students developed medical expert systems, they developed enhanced reasoning skills and acquired a
 deeper understanding of the subject domain.     Physics students who used an expert system to  create questions, decisions,
 rules, and explanations pertaining to classical projectile motion developed more refined domain-specific knowledge due to
 greater degrees of elaboration during encoding and greater quantity of material processed in an explicit, coherent context,
 and therefore in greater semantic depth (Lippert & Finley, 1988). MBA students who developed knowledge bases on tax

220
laws in an accounting course were consistently engaged in higher order thinking, such as classifying information,
breaking down content, organizing information, and integrating and elaborating information (Knox-Quinn, 1992).       All of
the students who developed rule bases showed substantial gains in the quantity and quality of declarative and procedural
knowledge and improved their problem solving strategies.
       This study examined the effects of building semantic nets as a Mindtool on the construction of subsequent
expert systems in the same knowledge domain.       Semantic nets engage significant knowledge analysis efforts, and they
have been used successfully as knowledge elicitation tools for building expert systems (Cook & McDonald, 1987).
Further, prior research shows that some type of preliminary knowledge organization task is necessary for expert system
generation (Knox-Quinn, 1988; Tamashiro & Bechtelheimer, 1991).           Thus, we believed that the knowledge analysis
engaged in building a semantic network of a knowledge domain would positively transfer to the sensitivity, elegance, and
coherence of the expert system knowledge bases that were subsequently constructed by learners.
Method

Materials
Semantic network and expert system shell software were chosen for their ease of use, availability on a Macintosh
platform, and cost.    The semantic networking software used in the study was SemNet (Fisher, 1992).      SemNet is a
Macintosh based semantic networking software tool which allows for easy creation of semantic networks by defining
concept-relationship-concept sets, called instances, that describe the relationships between concepts. For example, an
instance about dogs might be, dog-has type-border collie.
       The expert system shell EXSYS was chosen for creating expert systems.       EXSYS was chosen predominantly
for its easy, Macintosh-based user interface.     EXSYS allows users to create expert systems with probably the least
amount of computer science programming type skills.       Users construct the if-then rules of the expert system (often
considered the most complex portion of expert system construction) by clicking on buttons and selecting previously
created factors and choices that EXSYS then uses to create if-then rules.

Procedure
Subjects were undergraduate education students in a large eastern university.  Subjects were enrolled in a junior/senior
education course on the use of technology in the classroom.     Subjects were randomly assigned to either the group that
created semantic networks in conjunction with expert systems (hereafter, the SemNet group), or the group that created
only expert systems (hereafter, the non-SemNet group).    Regardless of the group, all subjects created expert systems.
There were three expert system topics for the study.  General education majors created expert systems to advise teachers
on classroom management and discipline issues; exercise science education majors created expert systems to help a user
create a physical fitness program, and special education majors created expert systems to help teachers decide how to
handle a potential special education referral.
       Once subjects were assigned their topics, they completed one to two page preliminary essays that described their
introductory knowledge of their topic. Students were instructed to concentrate on a discussion of the pertinent factors
needed to make decisions in their domains plus the likely domain decisions and inter-relationships between these
decisions and factors.
       All subjects were trained to use the expert system software, EXSYS, as well as in general strategies for creating
expert systems. Training was conducted on three separate occasions giving subjects a chance to absorb the content and
try out EXSYS between training sessions.       In addition, we were available throughout the semester to provide additional
help to subjects on use of EXSYS and creating expert systems.      Subjects had a total of eight weeks to complete their
expert systems.
       Those in the SemNet group received training on the SemNet software.      This training was conducted separately
from the non-SemNet group so there would be no contamination of groups.      Additionally, only SemNet group members
had access to the SemNet software. Non-SemNet group members completed an alternative assignment in graphics while
SemNet group members completed semantic networks.       Subjects turned in their semantic networks three weeks after they
had been trained. This still left them three more weeks before they turned in their expert systems, thus giving them time
to use their semantic network results in their expert systems.
       Once subjects turned in their expert systems, they were then instructed to write an ending essay which reflected
not only on their specific expert system and its content (i.e. the factors, choices and rules it used), but also their thought
processes as they created the expert systems.   As researchers, we wanted to know what caused students difficulties, what
worked and what could be improved.  This ending essay data was supplemented by activity logs that subjects filled out to
record the amount of time spent working on the project, and the kinds of activities engaged in during the project.

                                                                                                           221
 Results

 Of the 32 subjects that began the study, 26 provided all aspects of the data set.     Attrition resulted from dropping the
 course, failure to complete the assignments, and accidental data loss.
          Preliminary essays on topic areas were used to determine the subjects entry level knowledge of their topic area.
 Similarly, ending essays were expected to show subjects' ending level of knowledge as well as an explanation of their
 reasoning processes during the expert system creation process.   The expert systems,   themselves, were expected to show
 an indication of subjects' depth of reasoning in the topic area. Finally, half of the subjects created semantic networks;
 these networks were analyzed for relationships between the networks and the expert systems.    Specific variables collected
 for each of these data types is described more completely below.
 Preliminary   Essays.  Subjects completed    preliminary essays   at   the beginning  of the study in order to show their
 entry level knowledge of the topic area.  A content analysis at the phrase level (Weber, 1990) analyzed  this  data for the
 number of factors mentioned as necessary for decision making in the topic area, the number of choices or decisions that
 this subject considered could be made in the topic area and finally the number of relationships mentioned either between
 choices and factors or simply amongst factors.

 Ending Essays.   Subjects were to complete ending essays that addressed the same areas as the preliminary essays (i.e.
 factors, choices and relationships). However, in spite of specific instructions from the professor, most ending essays did
 not address these aspects. Thus ending   essays could not be analyzed in the same     manner  as the preliminary essays as
 originally planned. Instead, this data was analyzed for common categories that were mentioned in many ending essays,
 such as how learners synthesized in their content area during expert system creation.

 Semantic Networks.    The experimental group produced semantic networks as a "warm-up" activity for developing
 their expert systems. Quantitative descriptive data collected for the networks included the total number of relationships in
 the network, the number of concepts in the network (breadth), the number of concept-relation-concept instances in the
 network (extent), the number of concepts that participate in three or more instances (enmeshed concepts), a count of the
 top 25 percent most embedded concepts as defined by counting all possible paths to a concept from two nodes away
 (central), the number of singly connected concepts (fringe concepts), and the maximum concept embeddedness of the
 network (max. embeddedness) where embeddedness is defined as the count of all possible paths to a concept from two
 nodes away.

 Expert Systems.  The actual expert systems were the main source of data for the study.       Quantitative descriptive data
 collected for the expert systems included the number of rules in the system, the number of qualifiers (or factors)
 considered while making decisions in the domain, the number of choices (or possible decisions) that the expert system
 could produce, and maximum and average depths of the rules in the system (i.e. in the rule "if FACTOR A and FACTOR
 B and FACTOR C, then recommend CHOICE D", three factors are considered thus this rule has a depth of three).

 Table 1:  MANOVA Results for Independent Variable Group and Dependent Variables Qualifier. Rules. Choices.
 Sensitivity and Depth
 VARIABLE        ss                   DF             MS                   F                 p
 QUALIFIERS          14.017           1                   14.017          0.235             0.632
     ERROR        1492.650            25                  59.706
 RULES            360.150             1                360.150            2.001             0.170
     ERROR        4499.850            25               179.994
 CHOICES              2.963           1                   2.963           0.044             0.835
     ERROR        1665.333            25                  66.613
 SENSITIVITY          5.202           1                   5.202           2.372             0.136
     ERROR           54.817           25                  2.193
 RULE DEPTH           0.949           1                   0.949           0.175             0.679
     ERROR        135.329             25                  5.413

          A MANOVA showed that preliminary essays between the two groups were not significantly different from on
 another in terms of their initial knowledge in their domains. A MANOVA analysis was performed on the expert system
 data to determine whether those who produced semantic networks in addition to expert systems, produced "better" expert
 systems than those who did not produce semantic networks.        Note that "better" is defined by the data attributes, as

222
described above, that were collected for the expert systems.   The independent variable was semantic network or non
semantic networking group.    The dependent variables were:  number of qualifiers or factors, number of rules, number of
choices, expert system sensitivity, and rule depth. As shown in Table 1, no significant differences were found between
the groups for any of the expert system variables.
          Correlations between the data gathered for semantic networks and the expert systems were also computed. This
data may be helpful in determining which aspects of the semantic networks are the best predictors of certain attributes of
the resulting expert systems. These correlations are shown in Table 2. The semantic network data attributes are listed in
the top row and the expert system attributes in the first column. Significant positive correlations occurred between the
depth data items from the expert systems and the total number of relations (Ttlrels) in the semantic networks.

Table 2: Semantic Network and Expert System Data Item Correlations

Expert                                               Semantic
System                                               Network
Variables                                            Variables

               Breadth    Extent         Enmesh      Embed25       Ttlrels       Fringe    Mxembd

Qualifier       0.143      0.147           0.042      -0.247        -0.191        0.166      0.492 *
Rules           0.198      0.193           0.168       0.045       -0.100         0.220      0.137
Rule Types      -0.299    -0.278          -0.267      -0.258       -0.627 **      -0.325     0.033
Choices         -0.154    -0.136          -0.064      -0.194       -0.081         -0.126     -0.241
Sensitivity     0.067      0.051           0.072      -0.062        0.365         0.093      -0.120
Max Depth       0.379      0.400           0.405       0.339       0.715 **       0.404      0.305
Avg Depth       0.387      0.376           0.350       0.315       0.731 **       0.425      0.277

Legend:
   Ttlrels (Total Relationships): total number of relationships or links used in the network
   Breadth:   number of concepts in the network
   Extent:    number of concept-relation-concept instances in the network
   Enmeshed Concepts:     number of concepts that participate in three or more instances
   Mxembd (Maximum Embeddedness):          maximum concept embeddedness of the network where
   embeddedness is defined as the count of all possible paths to a concept from two nodes away.
   Embedded_25: count of the concepts that have 25% or more of paths the maximum embedded concept
   Fringe Concepts:    number of singly connected concepts
***pp<<.1.005
          Finally, a content analysis of the ending essays produced the following categories and tallies. As mentioned, the
ending essays could not be analyzed in a manner congruent with the beginning essays as subjects consistently did not
follow directions to include information about the factors, choices and relationships used in their expert systems. Table 3
shows the categories and their tallies.

Discussion

Early analysis indicates that several factors account for the non-significance of the results. Many of these reasons were
clearly and frequently mentioned in the subjects' ending essays (see Table 3). Subjects were clearly not comfortable with
the intentionally ambiguous nature of the project.  They wished for very specific guidance about how many rules and
qualifiers should be in their expert systems. This discomfort with ambiguity indicates this project may have been an
early, and perhaps only experience with an assignment whose boundaries are not clearly stated. This in turn could lead to
subjects concentrate predominantly on determining when they are done with the project rather than on transforming their
semantic network knowledge organizations into expert systems.
          The study hypothesized that the semantic networking exercise would help learners do a preliminary organization
of their content knowledge that would then aid in construction of their expert  systems. The data,  as shown   in   Table 1,
does not support this hypothesis. The data in Table 3, however, indicates that several students from the semantic

                                                                                                               223
 Table 3: Category Counts from Ending Essays

 Category                                             Total Count        SemNet        Non-SemNet

 Increased Content Knowledge                          14                 9             5
 Increased Complexity Understanding                   4                  4             0
 no content knowledge increase"                       4                  1             3
 Described Synthesis Process                          17                 8             9
 Semnet to ES Difficult                               2                  2             NA
 Semnet to ES Helpful                                 1                  1             NA
 Frustrated - system didn't represent their knowledge 4                  2             2
 Frustrated - hit 50 rule limit                       2                  1             1
 Wanted more coaching                                 8                  4             4
 Specified how to improve ES                          4                  2             2
 Not used to ambiguity                                2                  2             0
 Increased awareness computers classrooms             5                  3             2
 Increased confidence with computers                  7                  2             5
 Preferred SemNet                                     3                  3             NA

 networking group commented on the "difficulty" in moving from the kind of thinking they had to do for creating a
 semantic network to the kind of thinking necessary for creating an expert system.    Perhaps semantic network creation
 more  closely approximates a free flowing brain  storming exercise.    On the other hand, expert system creation requires
 that not only one know the factors pertinent in the expert system domain, but understand clearly how and when these
 factors are related. This is a step or two beyond what one gleans from creating a semantic network.
         The obvious conclusion from the above, is that learners needed more scaffolding to move them effectively from
 the preliminary knowledge organization task they completed in creating their semantic networks to the more structured
 task of creating the rules for an expert system. Prior to conducting this study, the research considered providing such
 scaffolding for the semantic networking group.       However, given that both groups received a grade on their expert
 systems, the research and the professor were concerned that such scaffolding for the semantic networking group would
 have given them an unfair grade advantage over the non-semantic networking group.           This decision was made to
 maintain a sense of equity between the two groups, but may not have been the most sound decision for testing the
 proposed hypothesis.
         While the study did not result in the hypothesized improved expert systems for those who created semantic
 networks, it did confirm that the subjects experienced substantial amounts of knowledge synthesis in their respective
 domains.  This result is consistent with previous research (Jonassen, 1993; Knox-Quinn, 1988; Lippert, 1988) in this
 area. Subjects not only reported that they were forced to synthesize and organize their knowledge very completely in
 order to finish the project (which is a pre-cursor to being better problem solvers in their domains), but that they also
 preferred this project over that of writing a paper on a topic.
         Given the above, a future iteration on this study might consider the following changes.
    Provide more scaffolding between semantic network and expert system creation.           For instance, model how a
     completed semantic network can be turned in to an expert system, thus giving subjects more guidance on how to
     make the most of their knowledge organization processes used in their semantic networks.
    Or, create a single new expert system shell which uses a semantic networking interface to gather data for creating its
     rules, choices and factors.   This allows subjects to concentrate completely on relationships within the domain
     without having to use finite cognitive energy to translate their semantic networks into expert systems.
    Collect data on subjects' tolerance for ambiguity.  Examine data for a positive correlation between those subjects
     with a high tolerance for ambiguity and those that create the "best" expert systems.

 References

 Briscoe, C. & LeMaster, S.U. (1991). Meaningful learning in college biology through concept mapping. American
       Biology Teacher, 53(4), 214-219.
 Davis, N.T. (1990). Using concept mapping to assist prospective elementary teachers in making meaning. Journal of
       Science Teacher Education, 11(4) 66-69.
 Cook, N.M. & McDonald, J.E. (1987). The application of psychological scaling techniques to knowledge
       elicitation for knowledge based systems. International Journal ofMan Machine Studies, 26, 533-550.

224
Derry, S.J., & LaJoie, S.P. (1993). A middle camp for (un)intelligent instructional computing: An introduction. In S.P.
        LaJoie   & S.J. Derry (Eds.),  Computers as cognitive   tools    (pp. 1-14). Hillsdale, NJ:   Lawrence Erlbaum
        Associates.
Fisher, K.M. (1990). Semantic networking: New kid on the block. Journal of Research in Science Teaching, 27(10),
      1001-1018.
Fisher, K.M. (1992). SemNet: A tool for personal knowledge construction. In P. Kommers, D. Jonassen, & T. Mayes
      (Eds.), Cognitive tools for learning. (pp. 63-76). Berlin: Springer-Verlag.
Fisher, K.M., Faletti, J., Patterson, H., Thornton, R., Lipson, J., & Spring, C. (1990). Computer assisted concept
      mapping. Journal of College Science Teaching, 19(6), 347-352.
Goldsmith, T.E.,  Johnson,  P.J., & Acton,  W.H. (1991).  Assessing      structural knowledge.  Journal  of Educational
       Psychology, 83, 88-96.
Grabinger, R.S., Wilson, B.G. & Jonassen, D.H. (1990). Designing expert systems for education. New York: Praeger.
Jonassen, D.H. (1987). Assessing cognitive structure: Verifying a method using pattern notes. Journal of Research and
      Development in Education, 20 (3), 1-14.
Jonassen,  D.H.  (1993).  Changes   in knowledge   structures from     building   semantic  net versus  production   rule
      representations of subject content. Journal of Computer Based Instruction, 20 (4), 99-106.
Jonassen, D.H. (1996). Computers in the classroom: Mindtools for critical thinking. Columbus, OH: Merill/Prentice
      Hall ..
Jonassen, D.H., Beissner, K., & Yacci, M.A. (1993). Structural knowledge: Techniques for representing, assessing, and
      acquiring structural knowledge. Hillsdale, NJ: Lawrence Erlbaum Associates.
Jonassen, D.H., Wilson, B.G., Wang, S., & Grabinger, R.S. (in press).         Constructivistic uses of expert systems to
      support learning. Journal of Computer Based Instruction, 20(3), 86-94.
Karake, Z.A. Enhancing the learning process with expert systems. Computers and Education, 14 (6), 495-503.
Knox-Quinn, C. (1988). A simple application and a powerful idea:      Using expert systesm shells in the classroom. The
     Computing Teacher, 16(3), 12-15.
Knox-Quinn, C. (1992, April). Student construction of expert systems in the classroom. Paper presented at the annual
      meeting of the American Educational Research Association, San Francisco, CA
Kommers,   P.A.M.   (1989). Textvision. Eschede,   Netherlands: University     of   Twente, Educational  Instrumentation
     Department.
Kommers,  P., Jonassen, D. H. & Mayes T. (Eds.), Cognitive tools for learning. Heidelberg    FRG: Springer-Verlag.
Kozma, R.B. (1987). The implications of cognitive psychology for computer-based learning tools. Educational
      Technology, (11), 20-24.
Kozma, R.B.    (1992). Constructing knowledge with  learning  tool.   In P. Kommers,   D.   Jonassen, & T. Mayes (Eds.),
      Cognitive tools for learning (pp. 23-32). Berlin: Springer-Verlag.
Lai, K.W. (1989, March). Acquiring expertise and cognitive skills in the process of constructing an expert system: A
      preliminary study. Paper presented at the annual meeting of the American Educational Research Association, San
      Francisco, CA (ERIC Document No. ED 312986)
Lippert, R. C. (1988). An expert system shell to teach problem solving. Tech Trends, 33(2), 22-26.
Lippert, R. & Finley, F. (1988, April). Student's refinement of knowledge during the development of knowledge bases
      for expert systems. Paper presented at the annual meeting of the National Association for Research in Science
      Teaching, Lake of the Ozarks, MO. (ERIC Document No. ED 293872)
Mansfield, H. & Happs, J. (1991). Concept maps. Australian Mathematics Teacher, 47(3), 30-33.
Pea, R.D.  (1985).  Beyond   amplification:  Using the   computer to     reorganize  mental functioning. Educational
        Psychologist, 20 (4), 167-182.
Perkins, D.N. (1986). Knowledge as design. Hillsdale, NJ: Lawrence Erlbaum.
Perkins, D.N. (1993). Person-plus: A distributed view of thinking and learning.       In G. Salomon (Ed.), Distributed
        cognitions.: Psychological and educational considerations (pp. 88-110).Cambridge: Cambridge University Press.
Saleem, N. & Azad, A.N. (1992). Expert systems as a statistics tutor on call. Journal of Computers in Mathematics and
     Science Teaching, 11, 179-191.
Salomon, G. (1993). On the nature of pedagogic computer tools. The case of the wiring partner. In S.P. LaJoie & S.J.
        Derry (Eds.), Computers as cognitive tools (pp. 179-196). Hillsdale, NJ: Lawrence Erlbaum Associates.
Salomon,  G.,  Perkins, D.N., &   Globerson, T.  (1991). Partners   in   cognition: Extending   human   intelligence with
        intelligent technologies. Educational Researcher, 20(3), 2-9.
Schreiber, D.A. & Abegg, G.L. (1991, April). Scoring student-generated concept maps in introductory college chemistry.
      Paper presented at the annual meeting of National Association for Research in Science Teaching, Lake Geneva,
      WI.
Starfield, A. M., Smith, K. A., & Bleloch, A. L. (1990). How to model it: Problem solving for the computer age. New
     York: McGraw-Hill.

                                                                                                              225
Tamashiro, R., & Bechtelheimer, L. (1991). Expert systems in the elementary grades: Developing thinking
       skills and independent learning. Computing Teacher, 18.(5), 21-26.
Thro, M.P. (1978). Relationships between associative and content structure of physics concepts. Journal of Educational
      Psychology, 70, 971-978.
Trollip, S., Lippert, R., Starfield, A., & Smith, K. A. (1992). Building knowledge bases: An environment for making
    cognitive connections. In P. Kommers, D.H. Jonassen, & T. Mayes (Eds.), Cognitive tools for learning. (pp. 105-
    124). Heidelberg FRG: Springer-Verlag.
Weber, R. P. (1990). Basic content analysis (2nd ed.). Newbury Park: Sage Publications.

226
