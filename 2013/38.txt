CSCL 2013 Proceedings                   Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

                    The Influence of Training in Argumentation on
                      Students' Individual Learning Outcomes
                     Julia Gressick, Indiana University South Bend, 1700 Mishawaka Avenue,
                                     South Bend, IN 46634, jgressic@iusb.edu
              Sharon J. Derry, University of North Carolina-Chapel Hill, CB# 3500, Peabody Hall,
                                    Chapel Hill, NC 27599-3500, derry@unc.edu

          Abstract: We conducted an in vivo experiment (Aleven & Koedinger, 2002) to investigate
          the impact   of Adventures    in Argument,       a week-long    online  unit  in   argumentation, on
          subsequent  science  learning  from   an   online   course  in which    individual  and  collaborative
          argumentation   were  the primary    forms    of pedagogy.     The context   of the  study  was  HAL
          Online, an undergraduate course in The Learning Sciences that enrolled 44 students. Using a
          nested design   (students within   groups   within   treatment),   the treatment   condition, Trained
          Argumentation with Modest Scaffolding (TAMS) was compared with an ecological control
          group: Emergent Argumentation with Modest Scaffolding (EAMS). Results of quantitative
          analyses  indicated  that TAMS       was   an  effective   intervention  that   positively  influenced
          students' individual  learning  as   measured    by  a test of  scientific literacy  and scores  from
          coding  of  individual  reflective   blogs.   Direct training   in   argumentation   offers a  viable,
          pragmatic  supplement     or alternative   to immersive     collaborative    pedagogies  that  require
          guidance and scaffolding of students' online argumentation processes by faculty (Cavagnetto,
          2010).

Introduction
We have embraced collaborative and individual argumentation as the primary pedagogical strategies for Human
Abilities and Learning Online (HAL Online), an undergraduate course in The Learning Sciences designed for
educators. The benefit of argumentation as pedagogy has been recognized for its potential to improve science
knowledge and promote scientific literacy (e.g. Cavagnetto, 2010; Driver, Newtown & Osborne, 2000). A belief
common among science educators is that immersing students in the collaborative process of science, where
argumentation    is implicitly embedded    in   this  process,   is  the optimal   way    to promote  scientific literacy
(Cavagnetto, 2010). One drawback to this approach, however, is that it is extremely time-consuming, requiring
students to be immersed for long periods in the scientific process. Moreover, as research indicates (e.g. Glassner
& Schwarz, 2005; Kuhn, 2005), argument quality is generally poor among students across levels. Therefore,
teachers and curriculum designers have significant responsibility for scaffolding and guiding argumentative
discourse. This may be impossible to accomplish effectively through an immersive approach in large classrooms
where teachers   are  overloaded,   restricted by  time,   and may    in some    cases have   weak   argumentation skills
themselves. In our university setting, where there is constant pressure to increase enrollments despite lower
instructional budgets, scaffolding and guidance may be provided online to many students by a single faculty
member unassisted, or with the help of relatively inexperienced teaching assistants. We therefore needed to
investigate viable, pragmatic alternatives to guided argumentation during immersion. One option is designing
instruction that formally  trains students   in argument     structure   prior to introducing   domain  content  through
pedagogies that engage learners in activities requiring evaluation and use of science concepts as evidence for
claims and that hold them responsible for well-reasoned thinking.
          The purpose of this study was to investigate the effectiveness of a week-long argumentation lesson on
subsequent student learning of science and the development of scientific literacy. The performance of a group
receiving the treatment lesson, designated the Trained Argumentation with Modest Scaffolding (TAMS) group,
was compared with an ecological control group that did not receive the training: Emergent Argumentation with
Modest Scaffolding (EAMS). Following the treatment manipulation, both groups participated in an identical
four-week unit which focused on cognitive and neuroscience concepts. Analysis of student performance data
from this unit addressed a range of research questions related to outcomes and discourse processes. Here, we
will focus primarily on results related to the following questions: Q1. Based on a post-unit measure of scientific
literacy, does  TAMS,     compared  to  EAMS,     promote     better  science  learning   from instruction that  engages
students in scientific discourse? Q2. Relative to EAMS, does TAMS increase the spontaneous tendency to use
and make connections among scientific course concepts during subsequent course-related tasks and discussions,
likely indicating more sophisticated processing of the material?

Theoretical Basis for TAMS
Toulmin's model (1958), the Toulmin Argument Pattern (TAP) has served as the basis for many educational
approaches using argumentation (e.g. Kuhn, 1991; Leitao 2000; Stegmann, Weinberger & Fischer, 2007). The

© ISLS                                                                                                               38
CSCL 2013 Proceedings                  Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

TAP focuses on six core elements of arguments. Toulmin's model is the basis of Halpern's (2003) Analyzing
Arguments, a chapter in her award-winning text Thought and Knowledge. This chapter was used as the basis of
argument  training  in  this study.   After  introducing     the  TAP,   Toulmin     (1972)  introduced     the  idea of
argumentation  fields, the idea  (briefly stated)   that argument   components     and   qualities are not   universally
generalizable but must be reflectively adapted to contexts. Thus Toulmin's perspective denotes a 'sweet spot'
between  absolutism   and  relativism  that is  useful   in framing    instructional approaches    in which    a general
argument model can be adapted to different problem contexts. Kuhn (2005) also recognized the importance of
meaningful context with emphasis on teaching general argument skills in a way that can be transferred to new
situations. Our TAMS treatment, a lesson entitled Adventures in Argument, was inspired by these views.

Data Source and Design
This study used an in vivo experimental design (e.g. Aleven & Koedinger 2002). The context of the study was
the spring, 2011   online  section of  Human    Abilities   and   Learning  (HAL     Online)  at   a  large Midwestern
university, an undergraduate course that enrolled 44 future educators from various fields. Undergraduates in this
course read about sophisticated science concepts from cognitive and neuroscience research, and were expected
to gain understanding of and practice with integrating these ideas to support decision making in individual and
group problem-based learning activities. The course was divided into four units comprised of four or five week-
long lessons each. During a lesson, students read and accessed multimedia resources while completing weekly
activities that involved problem solving and higher-order thinking with the learning-science material, and that
incorporated embedded assessments. Every other week the assessment activity required students to write an
individual reflective blog. In alternate weeks, the assessed activity involved small group discussions online. The
treatment manipulation was the last lesson in the first course unit. The course was offered in the Moodle course
management   system.   A  separate Moodle    course   environment      was created   for each condition.    These  were
identical except for the treatment-related manipulations, described next.

Treatment: Training in Argumentation with Modest Scaffolding (TAMS)
The TAMS treatment involved students in a course of formal training in argumentation based on the hypothesis
that the training would improve thinking and lead to more meaningful learning. During the lesson students read
"Analyzing  Arguments,"    a  substantial   chapter on   argumentation     from   the text  Thought    and   Knowledge
(Halpern, 2003). After reading, students completed an individual quiz and participated in collaborative forum
discussion that involved evaluating an argument. The quiz assessed student understanding of key concepts in the
text, including the ability to analyze a written argument. To complete the discussion task, students watched a
TED video of Patrick Awuah (2007) describing a program of liberal arts education offered at Ashesi University
and arguing that this program was developing African leadership. Small groups then collaborated to evaluate the
observed speaker's argument.

Ecological control: Emergent Argumentation with Modest Scaffolding (EAMS)
In the EAMS control group students received an alternative week-long lesson that did not focus on argument
training, but rather on a scientific model of hypothesis testing. During this lesson students read an alternate
chapter of comparable length and complexity from Thought and Knowledge, "Thinking as Hypothesis Testing."
This topic was selected for the control condition because it represents a widely accepted alternative scientific
model for good thinking that is widely taught but does not emphasize argument structure or process. During
EAMS    students also  completed   a quiz   and participated   in a collaborative    forum  discussion.  In  the  forum
discussion, students watched the same TED video of Patrick Awuah (2007) seen by students in TAMS and
collaborated to design a study that would evaluate the speaker's causal hypothesis.

Participants
Using a within classroom design (Salden & Koedinger, 2009), students who enrolled in HAL Online were
assigned to small groups based on common interests as determined by self-report surveys. Small groups were
randomly assigned to the two conditions. Groups comprised three or four students and, to avoid confounding the
group dynamic, students worked in the same groups throughout the course.

Method of Analysis
We  used  a mixed   quantitative   and qualitative  approach     (e.g. Barron,   2003).  Statistical  analysis  followed
procedures for nested designs recommended by Kirk (2012), where individual students were nested in small
groups, which  were    compared  across   conditions.  Qualitative     analysis followed  procedures   for  quantifying
qualitative data recommended by Chi (1997).
        The analysis related to the first research question was based on scores from a scientific literacy post-
test, a written essay requiring students to respond to (supporting or challenging) a statement about the role of the
study of brain research in college curricula for future educators. Post-tests were scored by a panel of three paid

© ISLS                                                                                                                39
CSCL 2013 Proceedings                      Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

experts in scientific literacy who were blind to condition and were trained to use a scoring rubric. The rubric
was developed using the definition of scientific literacy given by the National Science Education Standards,
which    is based on    historically agreed-upon   principles  of  what it means  to   be scientifically literate.  Rubric
criteria subjects  were   scored  on   included: demonstrates     understanding  of science   constructs    in  the article;
accurately uses science to support claims; takes credibility of sources into account; and recognizes multiple
positions on the issue. The scoring reliability based on Fleiss' kappa was .89 on a sample of 10 post-tests.
Scores for TAMS and EAMS were compared using a nested ANOVA design. An identically scored baseline
measure of scientific literacy and concept use, collected from embedded assessments for a course lesson prior to
the experimental/control lessons, provided a covariate.
            We addressed the second research question using Chi's verbal analysis method (Chi, 1997) to score an
individual reflective blog assignment in which students spontaneously used any course concepts they chose to
explain what they learned from a lesson. In this analysis we asked how many concepts students used from
course readings and how they integrated these concepts in their blog posts. The specific adaptation of Chi's
method   included   searching   the  data, coding  the  data   for seven pre-defined   target concepts   about     Lifelong
Learning & Expertise (synaptogenesis; brain region growth with use; regional compensation; expert cognitive
structures;    genetics and   environment    interaction; emotion/motivation;    and   practice ["use    it or  lose  it"]),
representing the data as simplified semantic webs, and seeking and interpreting patterns. Based on semantic
webs, the number of concepts and a score representing the interconnection rate among concepts (n(n-1)/2, where
n = number of concepts used) were tabulated. Reliability of 95% (Cohen's kappa .91) was reached between
coders after a single round of coding based on a sample of 10 blogs. Remaining data were coded by the first
author of this paper. A semantic web was created from each student's blog, with reliability of 89% reached
between coders after one round of discussion. Based on these scores, a nested ANOVA was conducted for
number of concepts and connection rate.

Results and Discussion
The results of this study indicate that TAMS was an effective intervention that enhanced students' subsequent
learning    of  science  content  as   measured    by a   test of  scientific literacy and    assessments    of    students'
understanding of target science concepts revealed in individual reflective blogs.

Q1: Scientific Literacy
A between subjects analysis of variance (condition (TAMS, EAMS); group (1-12); covariate: baseline)
indicated the effect of treatment on a test of scientific literacy was significant. There was a main effect for
condition: F(1, 10.478) = 13.125, p = .002. This means students in the treatment, TAMS (M = 9.898, SE = .531,
95% CI [8.709, 11.088]), had a significantly higher mean scientific literacy score than students in EAMS (M =
7.111, SE = .556, 95% CI [5.891, 8.331]), as measured using the rubric criteria described above.            The
interaction of condition and pre-score was non-significant, which indicates the treatment effect did not depend
on the baseline score.
            This finding suggests that, for advanced undergraduate learners in a learning sciences course, a week-
long formal training lesson in argument structure and quality prior to engaging with science learning was an
effective   approach    that promoted  scientifically literate  written essay  responses  from  students.    This   finding
extends the work of Veerman, Andriessen & Kanselaar (2002) showing that argument prompts at the beginning
of a lesson promote more sophisticated understanding during content-based arguments. Moreover, this finding
adds to the limited body of existing research of how training in argumentation prior to participating in science-
based activities can promote scientific literacy (e.g. Osborne, Erduran, & Simon, 2004).

Q2: Understanding of Science Concepts
A between subjects analysis of variance based on individual student blog data (treatment (TAMS, EAMS);
group (1-12); covariate: pre-treatment score) indicated a statistically significant main effect of treatment on
connection rate F(1, 9.764) = 3.239, p= .04. The main effect of the condition for the number of concepts used by
subjects, however, was not significant F(1, 10.302) = 1.596, p= .107. This means that students in the treatment,
TAMS (M = .862, SE = .062, 95% CI [.722, 1.001]) demonstrated a significantly higher connection rate than
students    in EAMS     (M   = .701,  SE   = .064, 95%    CI   [.560, .843]). However,    TAMS   students      did  not use
significantly more concepts (M= 4.062, SE = .220, 95% CI [3.617, 4.506]) than students in EAMS (M = 3.667,
SE = .229, 95% CI [3.203, 4.130]). For both analyses, the interaction of condition and pre-score were non-
significant, which indicates the treatment effect does not depend on the baseline score.
            The relatively high connection levels for TAMS suggests that treatment students integrated ideas in
their explanations rather than talking about them in a disconnected way. We speculated that higher rates of
connection among concepts may indicate that TAMS students engaged in more evidence gathering, synthesis,
and transformation ­ all processes of higher-order thinking required to participate in online discourse around
complex educational problems that are better understood through conceptual lenses from the learning sciences.

© ISLS                                                                                                                  40
CSCL 2013 Proceedings                   Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

This speculation has been partially confirmed by further qualitative analyses of group interactions that are not
reported here due to space limitations.

Scholarly Significance and Conclusion
Results indicate that TAMS was an effective intervention that influenced online student learning in positive
ways. This suggests that direct argumentation training designed to fall within Toulmin's (1972) `sweet spot'
between generalizability and context can promote scientific literacy and deeper understanding in online course
environments. This study thus contributes to our "cognitive roadmap" of the types of skills that should be
developed to improve argument-based science pedagogy online (Kuhn, 2005, p. 116). Moreover, this study
sheds light on an issue raised in a recent review of argumentation interventions in science classroom activities
(Cavagnetto, 2010).  Cavagnetto   asserts  that argumentation    skills are best  developed   through    immersive
engagement with science. He recognizes, however, the need for systematically investigating efficient alternative
approaches.  The current study   demonstrates   that, at least for undergraduate   learners  in  online  discussion
environments, a skill-based training approach has strong potential to improve subsequent meaningful learning of
psychological science, promoting scientific literacy while addressing practical concerns of efficiency. Online
argument training might be especially useful in relatively unsupervised massive open online courses (MOOCs),
a recent development in distance education aimed at large-scale participation and open access via the web.

References
Aleven, V., & Koedinger, K. R. (2002). An effective metacognitive strategy: Learning by doing and explaining
       with a computer-based Cognitive Tutor. Cognitive Science, 26(2).
Awuah,   P.  (2007).    Patrick  Awuah     on   educating   African     leaders  [video   file].  Retrieved   from
       http://www.ted.com/talks/patrick_awuah_on_educating_leaders.html
Barron, B. (2003). When smart groups fail. Journal of the Learning Sciences, 12(3), 307-359.
       Cavagnetto, A.R. (2010). Argument to foster scientific literacy: A review of argument interventions in
       K-12 science contexts. Review of Educational Research, 80(3), 336-371.
Cavagnetto, A.R. (2010). Argument to foster scientific literacy: A review of argument interventions in K-12
       science contexts. Review of Educational Research, 80(3), 336-371.
Chi, M. T. H. (1997). Quantifying qualitative analyses of verbal data: a practical guide.  Journal       of    the
       Learning Sciences, 6(3), 271­315.
Driver, R., Newton, P. & Osborne, J. (2000). Establishing the norms of scientific argumentation in classrooms.
       Science Education, 84(3), 287-312.
Glassner, A. & Schwarz, B. B. (2005). The antilogos ability to evaluate information supporting arguments.
       Learning and Instruction, 15, 353-375.
Halpern, D. (2003). Thought and Knowledge (4th ed.). Mahwah, NJ, Erlbaum.
Kirk, R.E. (2012). Experimental Design: Procedures for the Behavioral Sciences (4th ed.). Thousand Oaks, CA:
       Sage Publications.
Kuhn, D. (1991). The skills of argument. Cambridge: Cambridge University Press.
Kuhn, D. (2005). Education for thinking. Cambridge, MA: Harvard University Press.
Leitao, S. (2000). The potential of argument in knowledge building. Human Development, 43, 332-360.
Osborne, J., Erduan, S. & Simon, S. (2004). Enhancing the quality of argumentation in school science. Journal
       of Research in Science Teaching, 41, 994-1020.
Salden, R. J. C. M. & Koedinger, K. R. (2009). In vivo experimentation on worked examples across domains.
       Symposium     at the Thirteenth    Biennial Conference   of  the  European  Association    for Research  on
       Learning and Instruction.
Stegmann, K., Weinberger, A., & Fischer, F. (2007). Facilitating argumentative knowledge construction with
       computer-supported collaboration scripts. International Journal of Computer-Supported Collaborative
       Learning, 2, 421-447.
Toulmin, S. (1958). The uses of argument. Cambridge: Cambridge University Press.
Toulmin, S.  (1972). Human      understanding,  volume   1: The  collective  use  and development     of concepts.
       Princeton: Princeton University Press.
Veerman, A., Andriessen, J.E.B., & Kanselaar, G. (2002).    Collaborative argumentation in academic education.
       Instructional Science, 30, 155-186.

Acknowledgments
This material is based upon work partially supported by the National Science Foundation under Grant No.
0822189. Any opinions, findings, and conclusions or recommendations expressed in this material are those of
the author(s) and do not necessarily reflect the views of the National Science Foundation.

© ISLS                                                                                                         41
