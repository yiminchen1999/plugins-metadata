CSCL 2013 Proceedings                     Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

       Collaborative Learning through Socially Shared Regulation
                                Supported by a Robotic Agent
    Jun Oshima and Ritsuko Oshima, Shizuoka University, 3-5-1 Johoku, Naka-ku, Hamamatsu-shi, Japan
                        E-mail: joshima@inf.shizuoka.ac.jp, roshima@inf.shizuoka.ac.jp

         Abstract:  We   designed   a  learning   environment   supported   by a  robotic  agent to  facilitate
         learners'  socially    shared    regulation   of  learning    (SSRL).    In  collaborative   reading
         comprehension,    we   designed   adaptive   scaffolding  scripts  by the   robot  and  its physical
         embodiment    for helping   learners'  planning,   monitoring,   and  behavioral  engagement.   The
         cognitive and conversation analyses show that the use of note-taking strategies, engagement in
         collaborative argumentation, and transfer of understanding were improved by the support of
         the robot as a metacognitive mediator.

Background and Research Purpose
SSRL is a regulatory process model of collaborative learning based on preceding ideas of self-regulated learning
(SRL) and co-regulated learning. In Hadwin, Jäevelä, & Miller (2011), SSRL is defined as "interdependent or
collectively shared regulatory processes, beliefs, and knowledge orchestrated in the service of a co-constructed
or shared outcome/product" (p. 69). In SSRL, learners are collaboratively involved in planning, monitoring,
evaluating, and regulating the socioemotional, cognitive, and behavioral aspects of their learning. In this study,
based on the preceding research on CBLE agents (e.g., Azevedo (Ed.), 2007), we attempted to create a socially
assistive robot as an agent that provides learners with adaptive scaffoldings of SSRL. We consider the advantage
of a robotic agent over a human to be its participatory stance in collaborative learning. Learners at any age
usually recognize instructors or teaching assistants as authority figures who know everything in their class. On
the contrary, a robot may be accepted as an assistant or partner by learners because robots are ordinarily not
considered as  intelligent as   learners. Learners   expect  that the robot  will provide  information   that   they can
exploit. Therefore, learners may maintain their intentionality in regulating collaboration. In addition, robots may
have an advantage of over intelligent PC-based agents. With its physical embodiment, a robot can express its
engagement in learners' collaborative learning through verbal and nonverbal channels (Breazeal, 2002).

Study Description
Thirteen students  including    one graduate   from  the  same    departments  participated in   collaborative  reading
comprehension, an activity structure based on the Jigsaw method that enables learners to engage deeply in
collaborative knowledge construction through understanding multiple document-based resources (Oshima &
Oshima,  2011).  Students   were   first  divided into  four expert   groups.  In each  expert  group,  three   students
collaboratively read and constructed their understanding of a particular article that they would explain to other
students who were divided into jigsaw groups. Through collaboration, each student produced a summary using a
Microsoft Word template provided as a handout for the explanation intended for the jigsaw group students.
Three jigsaw groups were then formed, each consisting of one student from each expert group and one robot.
Students in the jigsaw groups worked to integrate ideas from five different articles explained by the students and
robot. The robot was in charge of explaining article #3. After discussing the five articles, the students reported
how ideas  from    the articles were   related to  each   other   and interpreted them  with   reference to   the basic
framework  of  learning  environments     in a  computer-supported     collaborative  learning  (CSCL)   system.     One
jigsaw group consisted of five students, rather than four, and two students were collaboratively assigned the
same article.

Adaptive Scaffolding Scripts by Robots
Based on recent studies of SSRL (e.g., Hadwin et al., 2011), we developed three types of scripts: planning,
monitoring, and behavioral engagement. For planning, robot said to the learners: "I am now going to explain
line (number) on page (number) to line (number) on page (number). So, please take a look at the section before I
start." After completing a section of the explanation script, robot asked learners if they had questions and if
there was any part that they wanted to listen to again. Then robot said: "Please tell me which part you want to
discuss later. I will remember your answer and tell you [Operators took notes of learners' answers.]." After
providing its explanation, robot said parts of the content that the learners had raised and encouraged them to
examine  their understanding    by  considering   their relation  to  the concept  of the  learning  environment.    For
monitoring, robot asked learners to articulate their explanations (e.g., "Can you explain that part again?" and
"Well, I could not understand what you said."), to monitor their understanding (e.g., "I wonder what others think
of it.") and to integrate their understanding or ideas discussed in their discourse with the concept of learning
environment (e.g., "How is your idea related to others?" and "How can you explain your idea in relation to the

© ISLS                                                                                                               327
CSCL 2013 Proceedings                     Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

framework of the learning environment?"). For behavioral engagement, robot encouraged specific learner's
engagement in the discourse when the operators identified the learner's inactivity (e.g., "So, what do you think,
(learner's name)?"). Robot's physical movement was designed for supporting its adaptive scaffolding scripts
function. It moved its head to slowly look at everybody while it was explaining the article. Its hands moved like
a human was actively talking. In addition, we prepared buttons for moving its head toward specific learners to
request  their   utterance.   For instance,  when    Robot  asked   a specific  learner    to engage   in discourse,    the
corresponding script was spoken with the robot gesturing toward the learner.

Results and Discussion
First, we   found   that our   adaptive   scaffolding scripts  for planning  facilitated   learners' use  of  note-taking
strategies.  They   used   strategies  significantly  more in  robot  explanation  than    in  human   explanation.  The
developed scripts provided metadiscourse for reading comprehension, and we found that learners normally did
not use this type of discourse in collaborative learning.
          Second,   in our    analysis of collaborative argumentation,    our  adaptive    scaffolding scripts  facilitated
learners' engagement       in constructing  reasoning.  The   proportion  of  learners  who    contributed   to reasoning
components in argumentation was increased in the context of human explanations. The further conversation
analysis  suggests    that  adaptive   scaffolding scripts for  monitoring   and  behavioral     engagement     functioned
effectively in human­human interaction, rather than in human­robot interaction. An important role of a robotic
agent  in   such an   interaction  is  as a  metacognitive  mediator   that  prompts    learners'  engagement     through
monitoring their collaborative construction of argumentation and subsequent active behavioral engagement.
          Differences in the effectiveness between the contexts of learner and robot explanations might be worth
examining in further research. One possible interpretation of the results is the trade-off between the roles of the
robotic  agent   as a  metacognitive   tutor and   a  metacognitive   mediator. In the   context  of   robot explanation,
learners might recognize the robot as a metacognitive tutor in the human­robot interaction. Therefore, robot
instructions, such as planning scripts for reading comprehension, functioned quite effectively. However, scripts
for monitoring    and  behavioral     engagement   might   not work   well  to  facilitate learners'   SSRL,    leading to
collaborative construction of argumentation because the robotic agent should have known more about the target
article than the other learners. Shirouzu, Miyake and Masukawa (2002), who discussed constructive interaction,
stated that collaboration is productive when different persons have different roles, such as task doer versus
monitor in problem solving, and when the roles are periodically interchanged. From this perspective, the context
of robot explanation in the jigsaw group might not have been a productive situation where humans and the
robotic agent could have interchanged different roles.

References
Azevedo,    R.  (Ed.)  (2007).  Special   issue: Understanding   the  complex   nature of  self-regulatory   processes  in
          learning with computer-based learning environments. Metacognition and Learning, 2(2-3).
Breazeal, C. (2002). Designing Sociable Robots. Cambridge, MA: MIT Press.
Hadwin, A. F., Jäevelä, S., & Miller, M. (2011). Self-regulated, co-regulated, and socially shared regulation of
          learning. In B. J. Zimmerman & D. H. Schunk (Eds.), Handbook of Self-Regulation of Learning and
          Performance (pp. 65-84). New York, NY: Routledge.
Oshima, R. & Oshima, J. (2011, April). Knowledge building for pre-service teachers through collaborative
          reading comprehension. Paper presented at the Annual Meeting of the American Educational Research
          Association, New Orleans, LA.
Shirouzu, H., Miyake, N., & Masukawa, H. (2002). Cognitively active externalization for situated reflection.
          Cognitive Science, 26, 469-501.

Acknowledgments
This   study was    supported  by  the  Ministry  of  Education, Culture,  Sports, Science,    and Technology     through
Grants-in-Aid for Scientific Research on Innovative Areas (No. 4101-21118001; granted to Naomi Miyake,
University   of  Tokyo),   and  for   Scientific Research  (A)   (No. 24240105;    granted    to Jun Oshima,    Shizuoka
University).

© ISLS                                                                                                               328
