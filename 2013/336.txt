CSCL 2013 Proceedings                                                                Volume 1: Full Papers & Symposia

      Emotion Feedback during Computer-Mediated Collaboration:
      Effects on Self-Reported Emotions and Perceived Interaction
Gaëlle Molinari, Distance Learning University Switzerland & TECFA/University of Geneva, Sierre & Geneva,
                                      Switzerland, gaelle.molinari@unidistance.ch
   Guillaume Chanel, Swiss Center for Affective Sciences, Geneva, Switzerland, Guillaume.Chanel@unige.ch
    Mireille Bétrancourt, TECFA/University of Geneva, Geneva, Switzerland, Mireille.Betrancourt@unige.ch
      Thierry Pun, Computer Science Department/University of Geneva, Switzerland, Thierry.Pun@unige.ch
   Christelle Bozelle, Swiss Center for Affective Sciences, Geneva, Switzerland, Christelle.Bozelle@unige.ch

         Abstract: Emotions play a crucial role in collaboration. They help to make inferences about
         the partner and can strongly influence task performance. Due to limitations of emotional cues
         in computer-mediated collaboration (CMC), the collaborative process can be impacted. In this
         study, we report on the effect of an Emotion Awareness Tool (EAT) designed to facilitate the
         sharing of emotions between partners, on the perceived emotions after collaboration and the
         perceived quality of the interaction. Results showed that the EAT stimulated participants to
         engage in a mutual modeling of emotions. In the EAT condition, the perceived amount of time
         spent on emotion modeling process was positively correlated to the perceived intensity of
         positive emotions after collaboration. The EAT increased the perceived degree of transactivity,
         but   only for  women.      This study   provides   a first step   in exploring    the effect  of emotion
         awareness in CMC tasks including a comparing approach for its gender-specific relevance.

Introduction
There is now a large consensus among researchers on the fact that emotions impact a broad range of cognitive
and social processes, and that humans are able to use emotional information to regulate their activity as well as
to influence others (Van Kleef, 2009). A change in individuals' emotional states can reorient their attentional
focus and induce a change in the way they think, act and interact with others. In cognitive theories, emotion is
defined as   resulting  from  the appraisal    of (external  or  internal)  events,  involving   the   synchronization    of 5
interrelated organismic subsystems. These subsystems underline the 5 components of an emotion, the cognitive,
neurophysiological, motivational, motor expression and subjective feeling components (Scherer, 2005).
         Emotions    are strongly    related  to  people's knowledge      and  goals, especially   in   high-order  activities
(learning, problem-solving,    decision-making...)     in  both   individual    and  group   settings.  For  instance,   when
learning alone from a low cohesion text, or when solving an ill-structured problem together with a partner,
individuals have to cope with many difficulties in, e.g., filling cohesion gaps in the text or converging on a joint
solution in the discussion with the partner. Such coping is even more complex when individuals have low prior
knowledge or when the difference in knowledge between collaborators is relatively high. On the one hand,
encountering    those   difficulties may   result  in  (socio-)cognitive    disequilibrium    than  can    produce   negative
emotions   like confusion,    frustration  or  boredom   in  case    of persistent  failure. On   the  other  hand,  positive
emotions like satisfaction, pride and engagement/flow may occur when learners are successful in coping with
their difficulties and   as a result  converge    to a new     equilibrium   state. Positive  emotions   were   found    to  be
positively related to individual learning (D'Mello & Graesser, 2012). Moreover, a shift towards a more positive
mood can increase flexibility and creativity thinking (Davis, 2009). The relationship between negative emotions
and   (socio-)cognitive  processes    is  not so  obvious:   Whereas     negative   emotional   states  like frustration  and
boredom are detrimental to learning, there is a positive correlation between confusion and learning as it can
stimulate active and deep processing (Lehman et al., 2012). This positive impact of confusion could also partly
explain why in some cases, collaborative learning failure can be productive (Kapur, 2009). Besides studies on
decision-making also found that people in a negative mood are more inclined to seek new information, engage
in  analytical information    processing   and   produce   higher  quality   decisions   (van   Knippenberg     et al., 2010).
Stemming from the field of affective computing (Picard, 1999), recent studies have proposed and shown the
feasibility to build computer interfaces able to react to learners' emotions with the goal of improving learning
outcomes   (Kapoor    et al., 2007).   The    above  results and  technologies      clearly emphasize    the need   to   better
understand the role of emotions in individual and collaborative learning.

Emotions in Social Interaction
The study of emotions in groups becomes an important research area in social psychology, and the focus is on
how   social  processes  influence   the  emotional   feelings   and  expressions,   and    vice-versa. In   an interpersonal
approach   of  emotions,  Van   Kleef    (2009)  proposed    the EASI    (Emotions    as Social  Information)      model  as a
framework to predict when and how the expression of emotions affects observers' behavior. In this model, there
are two  distinct   but  mutually    dependent   ways  individuals      can be  influenced   by  their  partners'   emotional

© ISLS                                                                                                                    336
CSCL 2013 Proceedings                                                              Volume 1: Full Papers & Symposia

expressions in social interaction settings. On one hand, partners' emotions are processed below the conscious
level and such processing results in affective reactions. This is the case when individuals automatically feel the
same emotions   than   those felt  by  their partners  through    emotional  contagion   (Hatfield  et al., 1993).   Such
emotional reactions are also recognized as playing a determinant role in interpersonal liking processes. On the
other hand, individuals strategically and consciously use emotions to make inferences about their partner, and
adapt their behavior in consequence (e.g., providing help when the partner displays frustration). According to
Van Kleef (2009), both emotion-processing paths (affective reactions and inferences) can lead to similar (e.g.,
feeling compassion when seeing the partner in difficulty) or opposite (e.g., keeping calm when facing an angry
partner) behavior. The use of one of these paths when processing emotional expressions also depends on both
observers' epistemic motivation, their cognitive resources as well as the cooperative or competitive nature of the
social situation. Individuals are more likely to engage in inferences about their partner's emotions when they are
motivated to build and update an accurate representation of the situation and/or when this situation is perceived
as competitive. The probability to use inferential paths also decreases with fatigue and time pressure.
          Research also showed that the expression of emotions depend on sets of social (and cultural) rules
determined  by  the    characteristics of  the social interaction,   the nature  of  the   collective work,  as  well as
interpersonal power processes (Ragins & Winkel, 2011). This may explain differences between men and women
in the expression of emotions (Brody, 2000). It has been shown that men are less likely to display emotions they
experience than women ­ especially with other men, while women allow themselves more easily to express
their emotions to a wider range of persons, independent of their gender (Rime et al., 1991). Moreover, Ragins
and Winkel (2011) argued that in work contexts, women are expected to display emotions (compassion, worry
or fear) that are usually related to less interpersonal power than emotions expected of men (confidence, pride or
anger). From a gender/neural perspective, McRae et al. (2008) found no difference between men and women
with regard to emotional reactivity; results suggest rather a discrepancy in the emotion regulation process. Men
seem to be able to regulate their emotions with less effort and greater efficiency than women. Compared to men,
women tend to generate positive emotions to a greater extent when trying to down-regulate negative emotions.

Emotions in Collaborative Tasks
During the past five years, a growing body of research has focused on the role of emotions in collaborative
learning  (CL) situations,  and  more    specifically on  their relation  to students'   social-behavioral  engagement
(Linnenbrink-Garcia et al., 2011) and regulation processes during CL tasks (Järvenoja & Järvelä, 2009). CL
situations can be viewed as being "more challenging than conventional and well-structured learning situations"
(Järvenoja, 2010, p. 68), although the ultimate (shared) goal in such settings - that is, the construction of a
shared understanding    (Roschelle     &  Teasley,  1995)  -  can  be  associated   with   positive emotions   and   high
motivation (Eligio et al., 2012). The CL process can be understood as an interpersonal matching process that
evolves over time, that is, moment-by-moment during the course of interaction (and probably also after that). It
is described as a constant adjustment of tension between interpersonal convergence (necessary for joint actions)
and divergence  (necessary     for flexibility and  creativity)   in terms   of perceptions,  actions,  knowledge    and
emotions. In the same vein, Andriessen et al. (2010) argued that there are two interrelated tuning processes
during CL   tasks,   a cognitive   tuning   (confrontation/differentiation   of ideas)   and  a socio-relational  tuning
(maintaining a collaborative working relationship). The CL experience is therefore characterized by continuous
fluctuations of tensions and relaxations between learning partners. Tension may arise from the expression of
divergent  information    (due  to learners'   differences   in knowledge,      intentions or   cognitive abilities) and
conceptual conflict; the greater is such a tension and "the more potential mutual gain is present in the situation"
(Andriessen et al., 2010, p. 227). However, when the tension is too high and/or when the focus in the group
shifts towards social comparison of competence (Darnon et al., 2006), negative emotions may emerge and as a
result, learners try to protect their own competence (face-saving process and use of competitive strategies).
Since negative emotions can impair learning, emotion regulation processes need to take place during interaction
so as to reduce tension between partners. These emotion regulation processes are both individually and socially
constructed (Järvenoja & Järvelä, 2009), and are motivated by the co-learners' need to converge towards a joint
solution. According    to Järvenoja    and  Järvelä (2009),   the co-learners'   efforts to  overcome   together   socio-
emotional challenges can be viewed as "critical points [...] in terms of successful learning and interaction".

Emotion Awareness and Computer-Mediated Collaboration
Unresolved  socio-relational   tensions   and  the  resulting negative   emotions   may    have  a  dramatic  impact  on
collaborative processes and outcomes. The understanding of the partners' emotions is thus necessary to trigger
emotion   regulation strategies that   will favor  successful   collaboration.  In this  paper, we  argue   that emotion
understanding is part of the mutual modeling process through which collaborators build a representation of what
their partners know, believe and intend to do. In previous research (Molinari et al., 2009; Sangin et al., 2011),
we found a positive correlation between the accuracy of mutual knowledge modeling and learning in Computer-
Supported Collaborative Learning (CSCL) settings. We hypothesize here that individuals' ability to recognize

© ISLS                                                                                                               337
CSCL 2013 Proceedings                                                          Volume 1: Full Papers & Symposia

and understand their partner's emotions also plays a crucial role in the way they communicate and build a
shared understanding; such ability would facilitate processes such as audience design and perspective taking.
          In face-to-face (F2F) situations, people rely on a whole set of explicit and implicit mechanisms to adapt
to their partners and the situation. In computer-mediated collaboration (CMC), contextual non-verbal cues ­
such as facial expressions, head movement, eye gazes ­ are missing or seriously limited. The awareness of
others may therefore be impaired and this may lead to inefficient interactions. In recent years, research has been
conducted to investigate the role of emotions in CMC (Derks et al., 2007). These studies showed no differences
between F2F and CMC settings with respect to expression of positive emotions and even suggest that people
express more freely their negative emotions in CMC. Besides emoticons and acronyms (e.g., "lol") are regularly
used  in  online  interactions to  express    one's  emotional  states. However,    men   rarely use   emoticons in
conversation and feel less satisfied with CMC experiences than women (Lee, 2003).
          The use of group awareness technologies is becoming widespread to circumvent the bottlenecks of
CMC. Such technologies aim at analyzing users' characteristics and behavior and feeding that information back
to the group. In CSCL contexts, group awareness tools are designed so as to improve and expand social and
cognitive processes during collaborative learning (Buder, 2011), by making explicit and visible what is not
directly observable like e.g., the group members' prior knowledge (Sangin et al., 2011) or their participation
level during online discussions (Janssen et al., 2011). To our knowledge, there is still little research on the
effects of emotion awareness tools designed to provide collaborators with information about their partner's
affective states during online   collaboration.  Eligio  et al. (2012)  carried   out experiments  with the aim  to
investigate the relation between emotion understanding and performance in CMC. It is noteworthy to point out
that only women participated in these experiments to "avoid the controversy of gender differences regarding the
interpersonal understanding of emotions" (Eligio et al., 2012, p. 2049). Results showed that collaborators had
difficulties to accurately assess their partner's emotions in CMC situations (Study 1). In order to overcome such
difficulties, collaborators were instructed to share their self-reported emotions with their partner during specific
moments of the task (Study 2). Results showed ­ for remote collaborators ­ both higher group performance and
higher accuracy at estimating their partner's emotions in the emotion awareness condition. This suggests a
positive impact of emotion awareness tools on collaborative processes and outcomes.

Objectives and Research Questions
The aim of our research project is to explore the impact of reciprocal emotion awareness on collaborative
processes and outcomes. The overarching goals are twofold: (1) To shade light on the benefits of providing
emotional  feedback  in  CMC      situations, and   (2) to  resort  on  affective computing   to  develop  adaptive
collaborative "emotionally aware" systems able to automatically provide emotional feedback when necessary.
In the reported study, participants were provided with an emotion awareness tool (EAT) with which they self-
reported and shared their emotions explicitly during a computer-mediated collaborative design task. Our goal in
this paper is to  investigate  the effects of  the   EAT  on the   subjective perception  participants had  of their
collaborative work  experience.    More   precisely, we  wondered   to  what  extent  sharing emotional  awareness
information during  remote    interaction influences  participants' perceptions   (a) of both their own-  and  their
partner's emotional states after collaboration (Question 1), and (b) of the quality of interaction with their partner
(Question 2). By perception of the quality of interaction, we meant participants' perceptions of the frequency
with which they (and also their partner) defended and argued their own ideas, built up on or challenged their
partner's ideas as well as processed and managed emotions during collaboration. Unlike Eligio et al. (2012),
both women and men participated in our study (they were paired in same-gender dyads) and we studied how the
effects of the EAT varied depending on gender. Finally, we examined the relationship between participants'
perceived intensity of emotions after collaboration and their perception of the interaction with their partner, and
also how the EAT can impact this relationship (Question 3).

Method

Participants and Design
Sixty participants (32 women and 28 men, mean age = 23.4 years) took part voluntarily in the study. They were
randomly assigned to 30 same-gender dyads. Fifteen dyads were randomly assigned to each of the 2 following
conditions: (1) experimental (EAT) condition (8 women dyads and 7 men dyads) in which the participant were
provided with the Emotion Awareness Tool; (2) control condition (9 women dyads and 6 men dyads) in which
they were not provided with the EAT. Group members did not know each other, and everything was done so
that they did not see each other before the experiment. Each participant was remunerated 60 Swiss Francs.

CSCL Environment
DREW (Corbel et al. 2003; see also Lund & Molinari, 2007) was used as the CSCL environment in which the
collaborative task had to be performed. Participants were asked to use the argument graph tool (left/blue part of

© ISLS                                                                                                         338
CSCL 2013 Proceedings                                                         Volume 1: Full Papers & Symposia

Figure 1) to construct together a joint map (see the "procedure" section to have a description of the task). In this
map, boxes could be linked to each other using two types of links, "+" or "in favor" links and "-" or "against"
links. Besides, participants had the possibility to express their opinion "for" or "against" for any boxes (or links)
in the map (each participant's opinion appeared in a different color). Boxes for which two opposed opinions
have been expressed, appeared in a "crushed" form. During the construction of the joint map, participants could
communicate with each other through microphone headsets (their verbal interactions were recorded).
         Participants of the experimental condition were asked to self-report and share their emotions to their
collaborative partner using the EAT (right/red part of Figure 1). The lower part of the EAT consisted of a list of
10 positive (e.g., engaged, interested, satisfied, relaxed) and 10 negative (e.g., anxious, frustrated, unsatisfied,
tired) emotions, each of them referring to a button to click. The upper part of the EAT was dedicated to the
display of emotions on which participants clicked. The participants' emotions appeared in the green area, their
collaborative partner's emotions in the blue area. Moreover, in both green and blue areas, the current emotion
was displayed in a box with a lighter color background, immediately followed by the two previously inputted
emotions. Participants could  also enter any emotion  directly   in     the lighter  green  box.  Participants were
instructed that they were free to self-report their emotions at any time they wanted during interaction. They were
however prompted to self-report their initial emotion and a pop-up message appeared 5 minutes after the last
inputted emotion to remind them to indicate the emotion they were experiencing at that moment. Participants of
the control condition were not provided with the EAT (the screen part corresponding to the EAT was shaded).

                             Figure 1. The DREW interface coupled with the EAT.

Procedure
The members of each dyad were separated in two different rooms. Both peers were in front of computers
equipped with (a) webcams, (b) Tobii T120 eye-trackers and (c) BioSemi physiological data acquisition systems
(eye-tracking and physiological data will not be the focus of this paper). They could not see each other, and
could not use  the webcams   to communicate  with each  other  at any       point of time  during the session.  The
experimental session lasted 140 minutes, and consisted of four phases:
         (1) Introduction (60 min): Participants were equipped with BioSemi physiological sensors, and eye-
tracker calibrations were completed. Training was given to get them familiar with DREW (and with the EAT in
the experimental condition).
         (2) Collaborative design task (40 min): Participants were asked to perform (in dyads) a brainstorming
exercise so as to  design together a slogan against violence  in  schools     intended  for teenagers. During    the
brainstorming, they drew a joint map, using the DREW argument graph tool, in 3 steps. In Step 1, both partners
generated as many boxes of slogan ideas as possible in the map. In Step 2, they were asked to debate and argue
slogan ideas depending on four criteria boxes given in the map (persuasive, original, adapted to audience, and
emotion). Slogan ideas should be therefore linked to criteria boxes through argument boxes. After debating,
peers suppressed the less relevant slogan ideas and improved those remaining. In the last step (Step 3), they
were asked to negotiate and find a consensus about the best slogan; the result should appear in a new box
entitled "final slogan" at the end of the brainstorming (see Figure 1).

© ISLS                                                                                                          339
CSCL 2013 Proceedings                                                            Volume 1: Full Papers & Symposia

          (3) Post-test questionnaires (20 min): After collaboration, participants first rated the intensity of their
own- and their partner's emotions. The felt intensities of 20 emotions (the same 10 positive and 10 negative
emotions than those used in the EAT) were measured on 7-points items (ranging from 1 = "very low or not at
all" to 7 = "very high"). They then answered a questionnaire about their perceptions of the interaction they had
with their partners. This questionnaire was constructed based on that developed by Buchs et al. (2004), and
consisted of 5 groups of questions. In this paper, we only reported the analysis of answers to questions of Group
4 and  Group   5. These   questions  referred   to the participants' perceptions  of  their own-    and their partner's
activities during collaboration. Seven-point scales (ranging from 1 = "little time" to 7 = "much time") measured
how much time participants felt they (or their partner) had spent defending ideas and arguing about them,
building up on the other's ideas, comparing their emotions to the other's emotions, communicate on emotions,
etc. (see Table   1 for  the complete   list of items). Finally, three  questionnaires were   administered    to assess
participants' emotional characteristics, the Emotional Expressivity Scale (Kring et al., 1994), the Emotional
Contagion Scale (Doherty, 1997), and the Emotion Regulation Questionnaire (Gross & John, 2003).
          (4) Debriefing (20 min): Participants were provided with a video of their group work (including their
face and the shared screen), and annotated 10 moments where they felt an emotion (and 10 without emotions).

Variables
The   presence of   the EAT   (with vs. without    the EAT)  and  Gender   were   the between-subjects    factors. The
dependent variables were: (a) the participants' ratings of the intensity of their own emotions and their partner's
emotions (the 20 emotion items, 10 positive and 10 negative emotions), and (b) the participants' answers to two
groups of questions (Groups 4 & 5) measuring their perception of their own- (15 items) and their partner's
activity (15 items) during interaction (the "own-activity" and "partner-activity" items were equivalent). They
were requested in the perceived interaction questions to rate the frequency with which they ­ and their partner ­
provided/imposed their own points of view, defended and argued their ideas, understood their partner's points of
view, built up on their partner's ideas, as well as managed emotion during interaction (see Table 1).

Results

Q1: Effect of the EAT on Perception of Emotions after Collaboration
Concerning participants' own emotions, results showed that intensity ratings were higher for positive emotions
(M = 4.51, SD = 0.84) than for negative emotions (M = 1.76, SD = 0.68), t(1, 59) = 20.07, p < .001, Cohen's d =
3.64. The same pattern occurred for the perception of the partner's emotions (positive: M = 4.41, SD = 0.85;
negative: M = 1.64, SD = 0.56), t(1, 59) = 21.59, p < .001, Cohen's d = 3.76. A series of 2 (EAT) x 2 (Gender
participant) ANOVAs were performed on intensity ratings for own/partner positive and negative emotions. The
results did not reveal any significant main effects for the factors studied and their interactions.

Q2: Effect of the EAT on Perception of Interaction with the Partner
Thirty perceived interaction items were used in the analysis (see Table 1). They were submitted to a factorial
analysis (FA) with promax rotation. The Cattell Scree test indicated the presence of three factors that accounted
for 50.72% of the total variance, namely (a) F1: to communicate on emotions and adapt to emotions (27.51%),
(b) F2: to compare emotions and imagine reactions to emotions (12.52%), (c) F3: to argue and build on the
other's ideas (10.69%). The items and their factor loading are presented in Table 1. It is noteworthy that F1, F2
and F3 included both "own-activity" and "partner-activity" items; we thus decided to talk about the activity of
the dyad when presenting the results concerning those factors.
          A series of 2 (EAT) x 2 (Gender participant) ANOVAs were performed on the three factor scores.
Results showed a significant effect of EAT for Factor 2. Participants reported more time spent by their dyad
comparing emotions and imagining reactions to emotions in the EAT condition (M = 0.35, SD = 0.96) than in
the control condition (M = -0.36, SD = 0.84), F(1, 53) = 8.60, p < .01, partial 2 = 0.14. There was also a
significant EAT by Gender interaction for Factor 3, F(1, 53) = 6.51, p = .01, partial 2 = 0.11. Post-hoc tests
revealed  that women     reported spending    more  time  arguing and    building on  the   other's ideas in  the  EAT
condition (M = 0.50, SD = 0.83) than in the control condition (M = -0.18, SD = 1.06); this difference was
marginally significant, t(1, 28) = 1.97, p = .057. The reverse pattern occurred for men (EAT: M = -0.48, SD =
0.51, control: M = 0.05, SD = 1.02), but this difference was not significant, t(1, 25) = -1.65, p = .11. Moreover,
there was  a significant  difference between     women   and men     in terms of  perceived  time   spent arguing  and
building on the other's ideas (timewomen > timemen) in the EAT condition, t(1, 27) = 3.71, p < .001; no significant
difference occurred between men and women in the control condition, t(1, 26) = -0.57, p = .57.

Q3: Relation between Self-Reported Emotions and Perceptions of Interaction
Correlational analyses were performed to test the relation between the participants' ratings of the intensity of
positive/negative emotions after collaboration, and their perceptions of the interaction with their partner (the 3

© ISLS                                                                                                             340
CSCL 2013 Proceedings                                                       Volume 1: Full Papers & Symposia

extracted factors presented in Table 1 were used here). Pearson's correlations were conducted across and within
conditions (i.e., EAT and control conditions). The analysis across conditions showed that the perceived intensity
of positive emotions after collaboration was positively correlated with the perceived amount of time spent (a)
comparing emotions and imagining reactions to emotions (F2: r = .41, p < .05), (b) arguing and building on the
other's ideas (F3: r = .49, p < .05). These positive correlations were significant only in the EAT condition (F2: r
= 0.43; F3: r = 0.58). In the control condition, the perceived intensity of negative emotions after the interaction
was positively correlated with the perceived amount of time spent comparing emotions and imagining reactions
to emotions (F2: r = .65, p < .05).

Table 1. Interaction perception items and their factor loading via FA with promax rotation (pattern matrix)

                                                                                                   F1   F2    F3
                                        provided your own points of view                                      .64
                                        defended and argued your own ideas                                    .70
                                        imposed your own points of view
                                        challenged your partner's ideas
                                        understood your partner's points of view
                                        built up on your partner's ideas                                      .56
                                        understood your partner's emotions                             .51
What is the frequency with whichyou (own-activity items)communicated on your partner's emotions    .95
                                        adapted your behavior to your partner's emotions           .51
                                        understood your own emotions
                                        communicated on your own emotions                          .66
                                        adapted your behavior to your own emotions
                                        imagined your partner's reactions to your emotions             .85
                                        compared your emotions to your partner's emotions              .94
                                        appeared able to control your own emotions                     .63
                                        provided his/her own points of view                                   .58
                                        defended and argue his/her own ideas                                  .63
                                        imposed his/her own points of view
                                        challenged your ideas
                                        understood your points of view                                        .82
                                        built up on your ideas                                                .61
                                        understood your emotions
What is the frequency with whichyour partner (partner-activity items)communicated on your emotions .92
                                        adapted his/her behavior to your emotions                  .53
                                        understood his/her own emotions                            .69
                                        communicated on his/her own emotions                       .66
                                        adapted his/her behavior to his/her own emotions           .57
                                        imagined your reaction to his/her own emotions                 .63
                                        compared his/her emotions to your emotions                     .72
                                        appeared able to control his/her own emotions
Note: F1 = to    communicate on     emotions and adapt to emotions,    F2 = to  compare  emotions  and imagine
reactions to emotion, F3 = to argue and build upon the other's ideas.

Discussion and Conclusion
Successful collaborative work requires group members to build a shared understanding (Roschelle & Teasley,
1995) which is contingent upon effective awareness of what their partners know, believe, feel, do and intend to
do (Sangin et al., 2011). While recent research on computer-mediated collaboration and CSCL has focused on
the effect of the awareness of the partner's knowledge (Dehler et al., 2011; Molinari et al., 2009; Sangin et al.,
2011) or activity level (Janssen et al., 2010), little attention has been given on the role of the awareness of the
partner's emotions (Eligio et al., 2012). On the one hand, emotions are now recognized as being strongly related
to individual and  group  processes    (D'Mello  & Graesser,   2012;   Van  Kleef, 2009).  On  the   other  hand,
collaboration is challenging at the   socio-emotional level (Järvenoja,   2010) since it consists of continuous
fluctuations of tension and relaxation between group members who alternate between performing the task and
maintaining a good working relationship (Andriessen et al., 2011; Baker et al., 2009). One may therefore expect

© ISLS                                                                                                       341
CSCL 2013 Proceedings                                                         Volume 1: Full Papers & Symposia

that the awareness  of   the partner's  emotions  can  play a determinant     role in  collaborative work/learning
situations as it contributes to adaptive and regulatory social processes.
         In this study, an emotion awareness tool (EAT) was developed which provided awareness about the
emotions felt by the partner during a remote (computer-mediated) collaborative design task. Our objective was
to investigate to which extent the explicit emotional feedback could impact participants' subjective perceptions
of their collaborative work experience. With respect to our first question, results showed no effect of the EAT
on participants' perceptions of their own emotions and their partner's emotions after collaboration. In other
terms, raising emotion awareness between collaborative partners by giving them the possibility to explicitly
share their emotions does not seem to influence their perception of emotional states after collaboration. Our
second question concerned the effect of the EAT on participants' perceptions of the quality of their interaction
with their partner. We also examined the relationship between participants' perception of emotional states after
collaboration and their perception of the quality of interaction, and also how the EAT can impact this relation
(Question 3). On the one hand, self-reported measures indicated that the EAT stimulated group members to
engage in a process of mutual modeling of emotions during interaction ­ which is a process by which they
compared their respective emotions and also anticipated their respective reactions to emotions. Moreover, the
perceived amount of time spent on emotion modeling process was positively correlated with the perceived
intensity of positive emotions after collaboration in the EAT condition. This is consistent with results found in
the study conducted by Eligio et al. (2012) where participants reported experiencing more positive affect after
sharing their emotions during computer-mediated collaboration. In contrast, in the condition where participants
did not explicitly share their emotions (control condition), the social comparison of emotions was related to
negative emotional states after collaboration. On the other hand, it seems that the effect of the EAT on the
perceived quality of interaction varied depending on gender. The EAT had a positive effect on the perceived
amount of time spent by the dyad confronting and arguing points of view, building up on the other's ideas ­ or
in other words, on the perceived degree of transactivity (which has been found to be positively correlated with
collaboration outcomes; Weinberger et al. 2007) ­ but only for women. There was no significant difference in
terms of perceived degree of transactivity between women and men in the control condition. Therefore, these
results do not suggest any significant effect of emotion awareness on men's perceived degree of transactivity.
Finally, we found that the perceived degree of transactivity was significantly correlated with positive emotional
states after collaboration, but only in the EAT condition. In the condition where participants explicitly shared
their emotions with their partner, the more they reported focusing and contributing to the ideas proposed by
their partner, the more they reported positive emotional states after collaboration.
         In our study, results support the hypothesis of a beneficial effect of an emotion awareness tool on
(perceived) collaboration ­ but only for dyads of women. This was also the case in the study of Eligio et al.
(2012) who found a positive effect of sharing emotions on group performance, but only with women (since men
were excluded from their study to avoid the controversy of gender differences). In our study, men who shared
their emotions with their partner during interaction reported being engaged in less partner-focused interactions.
Previous research (Brody, 2000) showed that compared to women, men are much less likely to display emotions.
This can be explained by socio-cultural beliefs that the display of emotions (in particular, negative emotions) is
related to less interpersonal power (Ragins & Winkel, 2011). One may thus expect that forcing men to display
and share their emotions during a collaborative work could inhibit them from performing the task with their
collaborative partner.
         To conclude, the present study has potential to enrich our understanding of how emotion awareness
influences collaboration processes, and how to design group awareness tools as means of improving emotion
awareness between coworkers in CSCL settings. It also provides a first step in exploring the effect of emotion
awareness in collaborative tasks including a comparing approach for its gender-specific relevance. As a further
step in the analysis, we will examine verbal interaction data (captured by the microphone headsets) so as to give
a more reliable insight into the quality of the interaction, and we will also assess the effect of the EAT on group
outcomes (e.g., the number of intermediate slogans created by the groups). Additional analyses on eye-tracking
and  physiological data  are also  in progress to better understand   the  effect  of the EAT. Finally,  one main
limitation of the study is the difficulty in disentangling the effect of reflecting upon one's own emotions from
the effect of sharing one's emotions with the partner. In order to overcome this limitation, a new experiment is
planned that will use an additional control group in which participants will state their own emotions through the
EAT but will not have any access to their partner's emotion statements.

References
Andriessen, J., Baker, M. & Van der Puil, C. (2010). Socio-cognitive tension in collaborative working relations.
         In Ludvigsen,   S.  Lund, A.,  Rasmussen,  I. &    Säljö, R. (Eds.).  Learning   across sites: New  tools,
         infrastructures and practices. London Routledge. The Learning series.
Brody, L. R. (2000). The socialization of emotion: Display rules, infant temperament, and differentiation. In A.
         Fischer, (Ed.), Gender and Emotion (pp. 24-47). Cambridge: Cambridge University Press.

© ISLS                                                                                                        342
CSCL 2013 Proceedings                                                        Volume 1: Full Papers & Symposia

Buder,  J. (2011). Group  awareness  tools  for learning:  Current and  future directions.  Computers   in Human
         Behavior, 27(3), 1114-1117.
Darnon, C., Muller, D., Schrager, S., Pannuzzo, N., & Butera, F. (2006). Mastery and performance goals predict
         epistemic and relational conflict regulation. Journal of Educational Psychology, 98(4), 766-776.
Davis,  M.   A.  (2009).  Understanding   the  relationship  between    mood   and creativity:  A meta-analysis.
         Organizational Behavior and Human Decision Processes, 108(1), 25-38.
Dehler, J., Bodemer, D., Buder, J., & Hesse, F. W. (2011). Guiding knowledge communication in CSCL via
         group knowledge awareness. Computers in Human Behavior, 27(3), 1068-1078.
Derks, D., Fischer, A. H., & Bos, A. E. R. (2008). The role of emotion in computer- mediated communication:
         A review. Computers in Human Behavior, 24, 766­785.
D'Mello, S. K. & Graesser, A. C. (2012). Dynamics of affective states during complex learning. Learning and
         Instruction, 22, 145-157.
Eagly, A. H., & Wood, W. (1991). Explaining sex differences in social behavior: A meta-analytic perspective.
         Personality and Social Psychology Bulletin, 17, 306-315.
Eligio, U.  X., Ainsworth, S. F.,  &  Crook,   C.  K. (2012). Emotion    understanding  and  performance   during
         computer-supported collaboration. Computers in Human Behavior, 28, 2046-2054.
Hatfield, E., Cacioppo, J. T., & Rapson, R. L. (1993). Emotional contagion. New York: Cambridge University
         Press.
Järvenoja, H. (2010). Socially shared regulation of motivation and emotions in collaborative learning (Doctoral
         Dissertation). University of Oulu: Acta Univarsitatis Ouluensis.
Järvenoja, H., & Järvelä, S. (2009). Emotion control in collaborative learning situations ­ Do students regulate
         emotions evoked from social challenges? British Journal of Educational Psychology, 79(3),463-481.
Kapoor, A, Burleson, W, & Picard, R. W. (2007). Automatic prediction of frustration. International Journal of
         Human-Computer Studies, 65, 724­736.
Kapur, M. (2009). Productive Failure in mathematical problem solving. Instructional Science, 38(6), 523-550.
Lee, E. J. (2003). Effects of ``gender'' of the computer on informational social influence: the moderating role of
         task type. International Journal of Human-Computer Studies,58(4), 347­362.
Lehman, B., D'Mello, S. K., & Graesser, A. C. (2012). Confusion and Complex Learning during Interactions
         with Computer Learning Environments. The Internet and Higher Education, 15(3), 184-194.
Linnenbrink-Garcia, L., Rogat, T. K., & Koskey, K. L. K. (2011). Affect and engagement during small group
         instruction. Contemporary Educational Psychology, 36, 13-24.
Janssen, J., Erkens, G., & Kirschner, P. A. (2010). Group awareness tools: It's what you do with it that matters.
         Computers in Human Behavior. Elsevier.
MacLeod, C. M., Koster, E. H., & Fox, E. (2009). Whither cognitive bias modification research? Commentary
         on the special section articles. Journal of Abnormal Psychology, 118, 89-99.
McRae,   K., Ochsner,  K.N.,  Mauss,  I., Gabrieli, J.D.E., Gross, J.J. (2008). Gender     differences in  emotion
         regulation: An fMRI study of cognitive reappraisal. Group Processes and Intergroup Relations, 11,
         143-162.
Molinari, G., Sangin, M., Dillenbourg, P., & Nüssli, M-A. (2009). Knowledge interdependence with the partner,
         accuracy  of  mutual knowledge     model   and   computer-supported   collaborative  learning.  European
         Journal of Psychology of Education, 24(2), 129-144.
Picard, R. W. (1999). Affective Computing for HCI. Proceedings HCI. Munich: Germany.
Ragins, B. R., & Winkel, D. E. 2011. Navigating the emotional battlefield: Gender, emotion and power in work
         relationships. Human Resources Management Review, 21, 377-393.
Rime, B., Mesquita, B., Philippot, P., & Boca, S. (1991). Beyond the emotional event: six studies on the social
         sharing of emotions. Cognition and Emotion, 5, 435-465.
Roschelle, J., & Teasley, S. (1995). The construction of shared knowledge in collaborative problem solving. In
         O'Malley,  C.E., (Ed.),  Computer    Supported   Collaborative Learning   (pp. 69-97). Springer-Verlag,
         Heidelberg.
Sangin,  M., Molinari, G., Dillenbourg,   P., &   Nüssli, M-A. (2011).   Facilitating peer  knowledge    modeling:
         effects of a knowledge awareness tool on collaborative learning outcomes and processes. Computers in
         Human Behavior, 27(3), 1059-1067.
Scherer, K. R. (2005). What are emotions? And how can they be measured? Social Science Information, 44(4),
         693­727.
Van Kleef, G. A. (2009). How emotions regulate social life: The emotions as social information (EASI) model.
         Current Directions in Psychological Science, 18, 184-188.
van Knippenberg, D., Kooij-de Bode, J.M. & van Ginkel, W.P. (2010). The interactive effects of mood and trait
         negative affect in group decision making. Organization Science, 21(3), 731-744.
Weinberger,  A.,   Stegmann,  K.,  & Fischer,   F. (2007).  Knowledge    convergence    in collaborative  learning:
         Concepts and assessment. Learning & Instruction, 17, 416-426.

© ISLS                                                                                                       343
