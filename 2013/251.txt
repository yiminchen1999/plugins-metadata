CSCL 2013 Proceedings                        Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

     Formative Assessment Using Repertory Grid Technique via
             Facebook: A Social Media Tool to Support E-Learning
                                              Nobuko Fujita,    Chris Teplovs
                      University of Windsor, 401 Sunset Avenue, Windsor, ON, N9B 3P4, Canada
                                  nobuko.fujita@gmail.com, chris.teplovs@gmail.com

           Abstract:    Designing technologies that enhance formative assessment in e-learning is crucial
           for improving     teaching  and   learning in  these   environments.   Whereas    many   studies   have
           examined     the  effectiveness   of   formative  assessment    in  traditional  classroom    contexts,
           researchers    have  only   recently   begun   to   explore technology-enhanced        assessment.  To
         understand how we can take advantage of existing social media tools to support e-learning, we
         describe a Facebook app called FARGO that offers potential to support teachers and students
         with assessment for learning.

Introduction
Designing technology tools that can enhance assessment in e-learning environments is crucial for improving
teaching   and  learning    in  these contexts.  Innovative  assessment    tools  may  be  embedded    in  the technology-
enhanced   learning    environment.    When     closely  aligned  with instructional   goals and   course   activities, they
provide teachers and students with supports for cognitive and motivational processes. Whereas many studies
have  examined      the  effectiveness    of formative   assessment    and  feedback   in  traditional classroom    settings
(Andrade & Cizek, 2010; Black & Wiliam, 1998; Noyce & Hickey, 2011), less is known about transferring
assessment practices from face-to-face to online environments (Beebe, Vonderwell, & Boboc, 2010). In higher
education contexts, there is a paucity of studies on online formative assessment (Gikandi, Morrow & Davis,
2011). Therefore, our objective is to investigate how tools for formative assessment embedded in Facebook and
course activity structures can support online and blended teaching and learning. Online formative assessment
tools may: 1) provide just-in-time feedback on learning progress to students; 2) help teachers reflect on their
teaching   practices   and   enact change    to optimize   learning; and   3) support  students'   self-regulated  learning
(Zimmerman & Schunk, 2001).

Conceptual Framework and Methodology
Guided by a socio-cognitive knowledge building (Scardamalia & Bereiter, 2003) framework, this design-based
research study explores opportunities for concurrent, embedded and transformative assessment (Scardamalia,
Bransford, Kozma, & Quellmalz, 2009) using a Facebook app called FARGO (Formative Assessment using
Repertory Grid Online). The first iteration analyzed data from 26 participants from a blended undergraduate
marketing   class.    The  second  iteration  analyzed   data  from  13  participants  in  a blended   B.Ed.   instructional
technology course. The third iteration analyzed data from 5 participants in an online M.Ed. e-learning course.

FARGO: Software and Preliminary Findings
FARGO is software designed by Chris Teplovs to elicit repertory grids for the purpose of formative assessment.
It takes advantage      of  the existing  Facebook    infrastructure and   employs   the   well-established repertory   grid
technique (RGT; Fransella, Bell, & Bannister, 2003; Kelly, 1955). RGT has been used successfully not only in
psychology     but  also  in education   and  more   recently, in computer-supported       collaborative learning  research
(Aditomo, Calvo, & Reimann, 2009; Vatrapu, Reimann, & Hussain, 2011). FARGO collects data efficiently and
overcomes the time-consuming nature of conducting interviews using the RGT.
         In    this study,   FARGO     is deployed    as an  exercise  embedded    within    the  broader  course  learning
activities in  a learning    management      system.  FARGO     prompts  participants  to   think  about  the  relationships
between elements of a particular topic. For example, B.Ed. students were asked to think about the relationship
between    six instructional    technologies   in two   steps: 1) the  widely-adopted     triadic sorting of   elements  for
personal   constructs    and   2)  subsequent   five-point  Likert-scale   rating of   the elements    (Fransella, Bell,  &
Bannister, 2003). Constructs are defined as "a way in which some things are construed as being alike and yet
different from others" (Kelly, 1991, p 74). Thus, participants go through a series of prompts that presents three
technologies (e.g., Smartboard, smartphone, tablet) at a time. For each triad, they are asked to identify the
element that is different (e.g. Smartboard) from the other two elements (smartphone, tablet) and to state how it
is different   (e.g., presentation    technology). Then,   the  participant is   asked to  state  how  the  two remaining
elements in the triad are similar to each other (e.g., mobile technologies). These differences and similarities are
used to label the extreme values of the Likert scale (e.g. 1 and 5). The remaining elements (other technologies)
are rated on this construct. The triadic sorting process is repeated a total of eight times, resulting in a total of
eight constructs elicited from each participant.

© ISLS                                                                                                                  251
CSCL 2013 Proceedings                 Volume 2: Short Papers, Panels, Posters, Demos, & Community Events

        After  the construct  elicitation,  each participant is shown    a visual representation  (i.e. table) of the
relationships they identified between different technologies. Showing students their own repertory grid makes
their learning "open" or visible to them and provides formative feedback to encourage students to exercise
cognitive responsibility over their learning. The course instructor also completes the exercise. This enables
students to see how an expert conceptualizes the same topic.
        In the first iteration, 25 of the 80 undergraduate marketing students (31%) completed the FARGO
exercise. The instructor's constructs on the relationships revealed dichotomous, unique constructs with virtually
no overlap  with each  other,  and a spread   of values  (1  to 5) in rating  the elements.  This suggests   that the
instructor, an expert, constructed complex understanding of the relationship between the elements. Student grids
showed a range in quality, with more advanced student grids showing overlap with the expert's grid in features,
and other student grids featuring repeated constructs or constructs with one similar pole. Another characteristic
of less advanced student grids is that the elements were rated only by polar values (i.e., only 1 and 5, not 2, 3, or
4). These qualitative and quantitative features of repertory grids were explored in the following iterations.
        In the second iteration, 13 of the 46 (28%) B.Ed. students who gave informed consent completed the
FARGO    exercise. In  the third iteration, all five M.Ed.   students who    gave informed   consent completed    the
FARGO exercise. To analyze quantitative data from second and third iterations, we counted 1) the number of
non-polar values (i.e., 2, 3, 4) for each of six elements rated on eight constructs and 2) the number of unique
constructs, or "themes." For example, a student might identify three unique constructs ("software-hardware",
"entertainment-educational",   and "big-small")   and  repeatedly  use   the same  construct  when   rating different
triads. The non-polar values were summed for a total non-polar value. The mean number of non-polar values for
B.Ed. students was 13.3 and the mean number of themes was 5.9. The mean number of non-polar values for
M.Ed. students was 14.5 and the number of themes was 6.7. No significant differences were found between
B.Ed. and M.Ed. participants using independent samples t-tests for non-polar values (t(17)=.30, p=0.77) and
mean number of themes (t(17)=.92, p=.37). Confirming our findings from the first iteration, repertory grids
elicited from experts tended to have comparatively fewer polar values and little overlap between constructs.

References
Aditomo, A., Calvo, R. A., & Reimann, P. (2011). Collaborative writing: Too much of a good thing? Exploring
        engineering students' perceptions using the repertory grid. In Proceedings of the Computer Supported
        Collaborative Learning Conference 2011 (pp. 128-135). Hong Kong: ISLS.
Andrade, H. L., & Cizek, G. J. (2010). Handbook of formative assessment. New York, NY: Routledge.
Beebe, R., Vonderwell, S., & Boboc, M. (2010). Emerging patterns in transferring assessment practices from
        F2f to online environments.   Electronic Journal of e-Learning,      8(1), 1-12.
Black, P., &   Wiliam, D.  (1998). Assessment     and classroom    learning. Assessment   in Education:   Principles,
        Policy & Practice, 5(1), 7-74.
Cook, K., Seely, C. & Chaput, L. (2011). Customizing and capture: Online assessment tools for secondary
        mathematics. In P. E. Noyce & D. T. Hickey (Eds.), New Frontiers in Formative Assessment (pp.49-
        68). Cambridge, MA: Harvard Education Press.
Fransella, F., Bell, R., & Bannister, D. (2003). A manual for repertory grid technique. Chichester, UK: John
        Wiley & Sons Ltd.
Gikandi, J. W., Morrow, D., & Davis, N. E. (2011). Online formative assessment in higher education: A review
        of the literature. Computers & Education, 57(2011), 2333-2351.
Kelly, G. (1955). Principles of personal construct psychology. New York: Norton.
Kelly, G. (1991). The psychology of personal constructs (Original work published 1955). London: Routledge.
Noyce,  P. E., &   Hickey,  D. T.  (Eds.).  (2011).  New Frontiers    in Formative  Assessment.   Cambridge,    MA:
        Harvard Education Press.
Scardamalia, M., & Bereiter, C. (2003). Knowledge Building. Encyclopedia of Education (2nd ed.). New York:
        Macmillan Reference, USA.
Scardamalia, M., Bransford, J., Kozma, B., & Quellmalz, E. (2012). New assessments and environments for
        knowledge building. (Eds.) P. Griffin, B. McGaw, & E. Care. Assessment & Teaching of 21st Century
        Skills (pp. 231-300). New York: Springer.
Vatrapu, R., Reimann, P., & Hussain, A. (2012. Towards teaching analytics: Repertory Grids for Formative
        Assessment. In J. v. Aalst, K. Thompso, M. J. Jacobson, & P. Reimann (Eds.) Proceedings of the
        International Conference of the Learning Sciences 2012 (pp. 341-345). Sydney: ISLS.
Zimmerman, B. J., & Schunk, D. H. (2001). Self-regulated learning and academic achievement: Theoretical
        perspectives (2nd ed.). Mahwah, NJ: Erlbaum.

Acknowledgments
Portions of this work were funded by the NEXT-TELL project (www.next-tell.eu). We would like to thank Drs.
Peter Reimann and Ravi Vatrapu for their support.

© ISLS                                                                                                            252
