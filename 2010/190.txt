                                               ICLS 2010    ·  Volume 1

      !"#$%&%&'()*+,+*-%.+(/+#.0+*,1(23%4%56(57(255+&8(#&8(9+,:7&8(
                                       to Student Thinking
           Vicky Pilitsis and Ravit Golan Duncan, Rutgers University, New Brunswick, NJ 08901
                              Email: pilitsisv2@yahoo.com, rgduncan@rci.rutgers.edu

       A bstract: In order to effectively implement inquiry practices in science, teachers must be able to
       attend to student thinking  and adjust     their lessons to  build on and respond to student   ideas.
       Research on experienced teachers suggests that their understandings of learners influence their
       instructional decision-making. However, the research on teacher education has mixed results about
       !"#$#"%&'#( )#*'+#"$,( *-&.&)/( )0( *))#12( )0( $)32#1)$,( &2#*$( 45*%&$( #)( *l, 2006). Although preservice
       teachers may recognize that learners have prior knowledge they usually do not take into account
       $)32#1)$,( &2#*$( &1( )+#&"( )#*'+&16( !"*')&'#$( 47"&#2"&'+$#1( #)( *.8( 9::;<=( ( >1( )+&$( !*!#"8( ?#( "#!0")( 01(
       !"#$#"%&'#()#*'+#"$,(*-&.&)/()0(10)&'#($)32#1)$,(&2#*$(4*$(@*1&A#$)#2(&1(?"&))#1(@02#.$<(*12("#$!012(
       to these ideas in subsequent instructional planning. Our data is drawn from clinical interviews
       conducted with 15 preservice teachers at the end of each of four consecutive methods courses
       (total of 60 interviews) in a two-year certification program.

Introduction
Standards documents and recent policy reports have called for a nationwide emphasis not only on the content and
processes of science but also on the epistemology and the practices of scientific inquiry (AAAS, 1993; NRC, 1996;
Duschl, Schweingruber, & Shouse, 2007). Inquiry based instruction entails a student-centered classroom in which
)#*'+#"$(*))#12()0(*12(?0"B(?&)+($)32#1)$,(&2#*$()0(2#%#.0!(@02#.$(*12(#C!.*1*)&01$(0A(1*)ural phenomena.                    A key
factor in implementing inquiry-based practices is the ability to attend to and interpret student ideas and to use that
interpretation to guide instructional design (Hammer, 2000; van Zee & Minstrell, 1997; NRC, 1996; AAAS, 1993).
Researchers have found that when teachers attend to student understanding and adjust instructional practices this can
help minimize the gap between desired student performance and observed student performance (Bell & Cowie,
2001; Black & William, 1998). Davi$8(D#)&$+8(E(F@&)+#/(49::G<('01'.32#()+*)(*.)+036+(#C!#"&#1'#2()#*'+#"$,(
understanding of learners influences their instructional decision making, the research on preservice teachers does not
have any conclusive findings.
       Some studies report that preservice teachers foresee few student learning difficulties when planning lessons
(De Jong & van Driel, 2001; Simmons, 1999; Geddis, Onslow, Beynon, & Oesch, 1993). Other studies have found
)+*)(!"#$#"%&'#()#*'+#"$(20(*'B10?.#26#()+#($&61&A&'*1'#(0A($)32#1)$, ideas about science (Davis et al, 2006; Russell
& Martin, 2007; Van Driel, De Jong, & Verloop, 2002). However, even when preservice teachers recognize that
.#*"1#"$(+*%#(!"&0"(B10?.#26#()+#/(3$3*../(20(10)()*B#(&1)0(*''031)($)32#1)$,(&2#*$(#C)#1$&%#./(&1(their teaching
practices (Friedrichsen, Abell, Pareja, Brown, Lankford, & Volkmann, 2009). In a 1999 study, Tabachnik and
H#&'+1#"(A0312()+*)(!"#$#"%&'#()#*'+#"$(?#"#(&1)#"#$)#2(&1(31'0%#"&16()+#&"($)32#1)$,(312#"$)*12&16$(0A(!*")&'3.*"(
concepts in science, but they did not take this information into consideration when designing their lessons.
Moreover, Davis et al (2006) concluded that new teachers do not have very clear ideas about what to do with regard
)0($)32#1)$,(&2#*$(01'#()+#/(+*%#($3"A*'#2()+#@=(
       van Es and Sherin (2002) argue that reform based practices call for a new understanding of teaching and
learning which requires teachers to develop new ways of interpreting the classroom. Furthermore, they claim that
current teacher education programs do not focus on helping teachers to interpret interactions that take place in the
'.*$$"00@=((>1(03"("#$#*"'+8(?#(&1%#$)&6*)#()+#(2#%#.0!@#1)(0A(!"#$#"%&'#()#*'+#"$,(*-&.&)/()0(10)&'#($)32#1)(&2#*$(&1(
written work, as well as the ways in which they subsequently respond to student ideas in their instructional plans.

Theoretical Framework
According to van Es and Sherin (2002) the skill of noticing for teaching consisted of three aspects: (a) identifying
what is important in a teaching situation, (b) making connections between specific events and broader principles for
teaching and learning, and (c) using what one knows about the context to reason about the situation. The aspect of
identifying what is important in a teaching situation refers to the ability of the teacher to select what they will attend
and respond to in the class. Because there are so many different things going on in a classroom at any given point,
the teacher must decide what is important and use this information to guide their instruction. Leinhardt, Putnam,
F)#&18(*12(I*C)#"(4J;;J<(A0312()+*)(#C!#"&#1'#2()#*'+#"$(+*%#(K'+#'B(!0&1)$L(*12(3$#()+#$#(K'+#'B(!0&1)$L()0(M326#(

                                                   190    ·  © ISLS
                                                 ICLS 2010  ·  Volume 1

how the lesson is going and decide how to proceed. Therefore, experienced teachers are more capable of recognizing
and attending to what is important in the lesson (van Es & Sherin, 2002).
        The next aspect of noticing, making connections between specific events and broader principles for
teaching and learning, refers to the ability of the teacher to make connections between events that occur in the
classroom and the broader ideas that they represent (van Es & Sherin,   2002). Similarly to the first aspect of
noticing, as a teacher becomes more experienced, he or she will be able to determine how specific events relate to
the process of teaching and learning.  However, given the   same situation, preservice teachers tend to only describe
literal events that take place and miss making the connections to the bigger picture (van Es & Sherin, 2002). The last
component of noticing, using what one knows about the context to reason about the situation, entails being able to
take their knowledge of the subject and knowledge of how students think and apply it in the classroom.   In our     case
&)$(&2#1)&A/&16("#.#%*1)(*$!#')$(0A($)32#1)$,(@02#.$8(.ike accuracy of explanation or representation, explanatory
power, use of evidence, and justification. The preservice teachers then evaluate these identified components to
2#)#"@&1#()+#($)32#1)$,(312#"$)*12&16=(N1'#()+#(!"#$#"%&'#()#*'+#"$(+*%#(#%*.3*)#2()he components in regards to
student thinking than they determine what course of action is necessary, such as a class discussion or experiment, to
clarify any misunderstandings.
        In addition to learning how to notice, it is important for teachers to be able to take what is noticed and
adjust their instructional practices. The activities that teachers undertake during instruction in order to produce
information that can facilitate adaptation to on-going instruction are known as formative assessments (Sadler, 1989).
Formative assessment can take many forms such as asking probing questions or class discussions, but it always
includes a component of attending to and assessing student ideas in relation to the learning objectives and then
adjusting instruction. In 1998, Black and Williams concluded that formative assessments improved student learning,
especially for those students who were having difficulty with the content being taught. Formative assessment helps
to prevent persistent student misunderstanding because the teacher is looking for evidence of student learning and
adjusting instruction as needed (Erickson, 2007).  Friedrichsen et. al (2009) found that teaching experience
influenced the types and timing of assessments and that novice teachers did not readily implement formative
assessments.  For example, more experienced teachers tended to    enact informal questioning throughout the lesson to
check for understanding, while novice teachers waited to grade worksheets and only then revised subsequent
lessons. Similar to the development of noticing, the ability to implement formative assessments are difficult and
novice teachers struggle with making the connections between what students do not understand and what types of
activities would promote student learning. In our study we are trying to help preservice teachers develop the
competencies they would need to engage in the complex practice of formative assessment.     The competencies they
need to have are the ability to notice student thinking in written work and to design instruction that adequately
responds to these interpretations.
        A way to promote the development of noticing student thinking and designing instructional plans that
correspond to these interpretations is through the analysis of student artifacts. The uses of artifacts of practice, such
as video and student work have received a lot of attention in teacher education research (e.g. Kazemi & Franke,
2004). Several studies have advocated the use of student work as a tool for professional growth (e.g. Ball & Cohen,
1999; Little, 2002). Using student work has the potential to engage teachers in a cycle of experimentation and
"#A.#')&01(*12()0($+&A)()#*'+#"$,(A0'3$(A"0@(6#1#"*.(!#2*606/()0(01#()+*)(&$('011#')#2()0()+#&"(0?1($)32#1)$(4O*P#@&(
& Franke, 2004). However, empirical research on this topic is very limited (Kazemi & Franke, 2004).
        In this paper, we hope to expand the research on the use of student work by examining the development of
)#*'+#"$,(*-&.&)/()0(10)&'#(*12(*))#12()0($)32#1)()+&1B&16(*$(@*1ifested in written artifacts. During clinical interviews,
preservice teachers were given a task in which they were asked to   analyze student models. We examined the
2#%#.0!@#1)(0A()#*'+#"$,(*-&.&)/()0(10)&'#(*12(&1)#"!"#)(*12("#$!012(4)+"036+(&1$)"3')&01*. planning alone) to
$)32#1)$,(&2#*$(&1()+#$#($)32#1)(@02#.$=(F!#'&A&'*../8(03"("#$#*"'+(Q3#$)&01$(*"#R(4*<(S+*)(20(!"#$#"%&'#()#*'+#"$(
notice about student thinking as manifesting in student artifacts? (b) In what ways do preservice teachers attend to
student thinking in their instructional design?

Methods
Study Context
This study was conducted in the context of a two-year Ed.M. certification program for secondary biology teachers at
a large public university in the North East. The program included four life science specific methods courses that
were taken in sequence. These courses were geared towards helping preservice teachers develop the knowledge and
practices of inquiry-based teaching.  The first course, Methods I, focused on the nature of scientific research and
theory building. Methods II, the second  course was essentially a design course in which the teachers  worked in

                                                     191  ·  © ISLS
                                                 ICLS 2010  ·  Volume 1

groups to design an extended inquiry based unit. Methods III, which accompanied the teaching internship, focused
on the implementation of inquiry based lessons and on assessment strategies.  Finally, the fourth course, Methods IV,
engaged teachers in action research and the analysis of data collected during the teaching internship. All courses,
especially the last two, included an emphasis on student thinking (including analysis of student work) and the
&@!0")*1'#(0A(*))#12&16(*12("#$!012&16()0($)32#1)$,(&2#*$=((T+#"#(?#"#(JU(!"#$#"%&'#()#*'+#"$(?+0(?#"#(#1"0..#2(&1(
the program and completed all four courses in sequence.

Data Collection and Analysis
At the end of each of the four courses we conducted clinical interviews with all the teachers. A faculty member and
trained graduate students conducted the interviews. Although somewhat different protocols were used in each set of
clinical interviews, there was a common student-model critique task, which is the data source analyzed for this
paper. In this task the teachers were presented with three  student models explaining how a cut heals (cellular
division) or why ice floats (density); two versions were used for counterbalancing purposes. We created the student
models to closely mimic student thinking and representations. The models consisted of a drawing with an
explanation written underneath. Models varied in terms of level of details, scientific accuracy of explanation, use of
#%&2#1'#(4A"0@($)32#1)$,(!"&0"(B10?.#26#<(*12(M3$)&A&'*)&01(0A(+0?()+#(#%&2#1'#("#.*)#$()0()+#(#C!.*1*)&01(!"0%&2#2(
by the model. The teachers were then asked to identify (a) good aspects of the models; (b) problematic aspects of the
model; (c) description of their next instructional move if these were naïve models (done at the beginning of a unit);
and (d) description of their next instructional move if these were revised final models (done at the end of a unit).
Interviews lasted 30-45 minutes and were videotaped and later transcribed verbatim and blinded for analysis.
        We conducted a content analysis and through an iterative process of constant comparison we developed a
coding scheme to capture four emergent themes of the models the teachers critiqued. The four themes were: (a)
model representation (e.g. labeling); (b) mechanism in model (e.g. model shows a before and after or progression);
(c) use of evidence or justification in models (e.g. student supports belief with data); and (d) accuracy of ideas of the
@02#.$=(T0('*!)3"#()+#(Q3*.&)/(0A()+#(!"#$#"%&'#()#*'+#"$,('"&)&Q3#$(0A()+#(@02#.$8(?#(A0'3$#2(01()?0(*$!#')$(0A()+#(
critique: (a) the specificity of information they provided and (b) the noticing aspect- what themes were noted by
#*'+()#*'+#"=(>1()#"@$(0A($!#'&A&'&)/8()+#(!"#$#"%&'#()#*'+#"$,("#$!01$#$(?#"#('02#2(*$(01#(0A()+"##('*)#60"&#$R(4*<(
identification; (b) description; or (c) interpretation of student thinking. A statement was coded as identification if the
teacher stated what was good or problematic about the model without providing any additional details about why
)+*)(*$!#')(0A()+#(@02#.(?*$(6002(0"(!"0-.#@*)&'(4#=6=(K)+#(#C!.*1*)&01(&$(6002L<=(V('0@@#1)(?*$('02#2(*$(*(
description if it involved both identifying an aspect of the model and describing what was positive or negative about
this aspect (e.g. K)+#(#C!.*1*)&01(&$(6002(-#'*3$#(&)('01)*&1$($0@#(#@!&"&'*.(#%&2#1'#L<(=((7&1*../8(*1(&1)#"!"#)*)&01(
comment involved identifying, describing, and interpreting a certain aspect of the model in regards to student
312#"$)*12&16=(V($)*)#@#1)($3'+(*$(K)+#(#C!.*1*)&01(&$(.*'B&16(-#'*3$#('#..$(do not stretch in the healing process;
)+#($)32#1)(&$(@&$$&16()+#('01'#!)(0A('#..3.*"(2&%&$&01L(?03.2(-#('02#2(*$(&nterpretation since the preservice teacher
identified an aspect of the model (explanation), described the problem (cells do not stretch), and interpreted what
)+&$(@#*1$(&1()#"@$(0A()+#($)32#1),$(312#"$)*12&16(4@&$$&16('01'#!)(0A('#..3.*"(2&%&$&01<=((We also counted how
many of the themes described above were discussed in the critique to obtain a value for the noticing aspect of our
analysis. At the end of the analysis for the critique part of the model, each interview had a two part code (specificity
code and a count of themes mentioned).
        We then analyzed the last two parts of the interview task, in which the teachers were asked about their next
instructional move given two conditions: students models were naïve or students models were final models. We
developed a coding scheme that captured three aspects of these revisions: (a) attention to student ideas, (b)
specificity of instructional moves, and (c) alignment with model based inquiry. The first aspect, attention to student
ideas was coded as: (a) no men)&01(0A($)32#1)(&2#*$(?+&'+(?*$('02#2(*$(*(KJLW(4-<(@#1)&01#2($!#'&A&'($)32#1)$(&2#*$(
&1("#6*"2()0(*(!*")&'3.*"(@02#.(?+&'+(?*$('02#2(*$(*(K9LW(*12(4'<(@#1)&01#2($!#'&A&'($)32#1)(&2#*$(*12(!"0%&2#2(*n
instructional move that addresses these ideas which was coded *$(*(KXL(4#=6=(K@02#.(YJ(2&2(10) understand
molecules so I would have the students draw out the molecular structure of water to show the polar bonds of
?*)#"L<=(T+#($#'012(*$!#')8($!#'&A&'&)/(0A(&1$)"3')&01*.(@0%#$8(?*$('02#2(*$R(4*<($)*)#2(6#1#"*.(activity with no
A3")+#"(#C*@!.#(?+&'+(?*$('02#2(*$(*(KJLW(4-<($)*)#2(*($!#'&A&'(*')&%&)/(?+&'+(?*$('02#2(*$(*(K9LW(*12(4'<($)*)#2(*(
$!#'&A&'(*')&%&)/()+*)(+*$(*(.06&'*.(!"06"#$$&01(&1(*))*&1&16()+#(.#$$01(0-M#')&%#$(?+&'+(?*$('02#2(*$(*(KXL(4#=6=(>(
would give the students data and have them work in groups to make a group model from this data and then present
these models to the class and come up with a class model so that all the students are on the same page). The third
aspect, alignment with model based &1Q3&"/8(?*$('02#2(*$R(4*<(10(*.&61@#1)(?+&'+(?*$('02#2(*$(*(KJL(4#=6=(.#')3"#8(
)#*'+#"('#1)#"#2(Q3#$)&01&16<W(4-<($.&6+)(*.&61@#1)(?+&'+(?*$('02#2(*$(*(K9L(4#=6=(2#@01$)"*)&018('00B-00B(.*-<W(4'<(
*.&61@#1)(?+&'+(?*$('02#2(*$(*(KXL(4#=6=('0..*-0"*)&01(?&)+ peers, argumentation).

                                                     192  ·  © ISLS
                                                 ICLS 2010  ·  Volume 1

Results and Discussion
;0#5()*+,+*-%.+(/+#.0+*,(<75%.+(%&(=5>8+&5,1(?78+4,(
N3"(*1*./$&$(0A()+#()#*'+#"$,('"&)&Q3#(0A()+#($)32#1)(@02#.$8(*..0?#2(3$()0(2#)#"@&1#(?+*)()#*'+#"$(10)&'#2(&1(
$)32#1)$,(?0"B(*12(&1(?+*)(?*/$()+#/('03.2(&1)#"!"#)()+#(@02#.$(&1("#.*)&01()0($)32#1)$,(312#"$)*12&16=(>1()#"@$(0A(
)+#(*$!#')$(0A($)32#1)$,(?0"B()#*'+#"$(*))#12#2()08(?#(A0312()+*)()+#&"('0@@#1)$(!#")*&1#2(@0$)./()0()+#(@#'+*1&$@(
*12(#C!.*1*)0"/(1*)3"#(0A()+#(@02#.(4#=6=(K@02#.(+*$(10(#C!.*1*)&01LW K@02#.($+0?$(?"016(6"*&1($&P#LW(K@02#.(+*$(
*(-#A0"#(*12(*A)#"L<=((Z0@@#1)$()+*)(!#")*&1#2()0(@02#.("#!"#$#1)*)&01(?#"#($)*)#@#1)$(*-03)()+#('0@!01#1)$()+*)(
made up the    model (e.g. labeling) and were the second most frequent theme.    Finally, statements about the use of
#%&2#1'#(*12(M3$)&A&'*)&01(4#=6=(K@02#.(&$($3!!0")#2(-/(2*)*LW(K$)32#1)(M3$)&A&#$()+#&"(@02#.L<(*12(*''3"*'/(0A(&2#*$(
&1()#"@$(0A()+#()+036+)$(#C!"#$$#2(&1()+#(@02#.$(4#=6=(K$)32#1),$()+&1B&16(*-03)('#..$($)"#)'+&16(&$(&1'0""#')LW(
K$)32#1)(312#"$)*12$()+#('01'#!)(0A(2#1$&)/L<(?#"#(.#$$(A"#Q3#1)./(10)#2(4$##(T*-.#(J<=(
       S#()+#1(#C*@&1#2(+0?(@*1/(2&AA#"#1)()+#@#$()#*'+#"$(10)#2(&1(*1*./$&$(0A($)32#1)$,(@02#.$=(N1(*%#"*6#8(
we found that there were approximately 2.3 themes noted per interview; thus teachers, on average, discussed two
$3'+(*$!#')$(0A($)32#1)$,(@02#.$=(S#(A0312(10(2&AA#"#1'#(&1()#"@$(0A(?+#)+#"()+#&"('0@@#1)$(?#"#(01(!0$&)&%#(4#=6=(
K&)(&$(6002()+*)(*..()+#($)32#1)$(B10?()+*)(&'#(20#$(A.0*)L<(%#"$3$()+#(1#6*)&%#(*$!#')(0A($)32#1)$,(?0"B(4#=6=(K@02#.(
YJ(20#$1,)(#C!.*&1(?+*)(+*!!#1$()0(*(@0.#'3.#(?+&'+(&$(?+*)()+#(Q3#$)&01(&$(*$B&16L<=(V.)+036+()+#"#(?*$(01./(
slightly more themes mentioned in Methods III, overall the number of themes mentioned by teachers at the end of
each course was the same.  The preservice teachers tended to focus more on representational aspects of the   models
(e.g. labeling) in the first methods course and did not attend to the accuracy of the ideas or the use of evidence and
justification. However, after Methods II, the teachers began  to focus more on   accuracy of ideas and use of evidence
and justification.

Table 1: Frequency count of themes noticed in the students models by methods course

       Themes                        Methods I             Methods II          Methods III     Methods IV
Mechanism in Model                         15                   12                  14             14

Model Representation                       12                    4                  7               7

Accuracy of Ideas                           0                    9                  8               7

Use of Evidence and Justification           4                    6                  8               7

       Aside from analyzing what teachers noticed we also wanted to understand how teachers discussed what
they noticed. Specifically, did they merely identify a problem (or leverage) in student thinking, or were they able to
reason about, or explain, how what they noticed relates to student learning (for example, explaining what exactly the
student confused about based on their model). We found that m0$)(0A()+#()#*'+#"$, comments were of the
identification and description type (91 comments out of a total of 120) and that there were far fewer comments in
which they elaborated upon and explained student thinking (29 comments out of a total of 120).     Thus, the
preservice teachers seemed to be more facile with describing what is problematic about a specific model, but were
less ab.#()0(#C!.*&1(?+*)()+&$(@#*1$(&1()#"@$(0A()+#($)32#1),$($)*)#(0A(312#"$)*12&16=([0?#%#"8(&)(&$()+#(.*))#"(
'*!*-&.&)/()+*)(&$('"3'&*.()0(2#$&61&16(.#$$01$()+*)(*22"#$$($)32#1)$,(&2#*$=(
       We also looked at whether teachers tended to provide more elaborate comments about positive or negative
aspects of student models. We wanted to explore this to see if there was a significant difference between the good
versus the problematic components noticed.  There was a small, but consistent,      difference between the number of
identification comments  made about positive versus negative aspects of the models (21 positive vs. 25 negative)
and the interpretive comments made  about the positive and negative     aspects of the models (13 positive vs. 16
negative).  However, we noticed that there were many more descriptions of positive aspects of the models provided
by the teachers than descriptions about negative aspects (32 positive vs. 13 negative).    Therefore, it seems that the
preservice teachers were able to describe the positive aspects of the models more readily than the negative aspects,
even though they generally did not notice many more positive aspects.
       Our findings reveal that preservice teachers tended to focus on identifying and describing components of
the student models rather than interpreting the models in regard to student understanding. In reference to van Es and
F+#"&1(\$(49::9<('0@!01#1)$(01()+#(*$!#')$(0A(10)&'&168(&)($##@$()+*)()+#(!"#$#"%&'#()#*'+#"$(*"#(10)(@*B&16()+#(

                                                     193  ·  © ISLS
                                                  ICLS 2010   ·  Volume 1

connections between the specific events, or ideas, in the models and how that relates to the broader principles of
teaching in learning. Our teachers did not seem  to be attending to written responses as evidence of specific
cognitive obstacles (or leverages) in student learning, rather many of them tended to analyze the models in a very
literal and contextual manner. Additionally, it was evident that the teachers struggled to interpret what they saw in
the models in relation to student understandings of the phenomenon. For example, one of the teachers realized that
the model did not portray the phenomenon at the correct grain size, but was unable to see this was potentially due to
a lack of knowledge about molecular structures.  A plausible explanation for this trend was that the teachers may not
have had strong subject matter knowledge about the modeled phenomenon (e.g. density and cellular division).

Attending to Student Thinking in the Instructional Design
We next focused on whether and how the preservice teachers took into account and addressed student thinking in
their instructional plans. In order to answer this question,  we focused  on the last part of the interview task in which
the teachers were asked what they would do the next day in the classroom if the student models presented were (a)
typical naïve models (created prior to formal instruction) and (b) typical final models (created after formal
&1$)"3')&01<=(S#(*1*./P#2()+"##(*$!#')$(0A()#*'+#"$,(&1$)"3')&01*.(2#$&61$R(4*<(*))#1)&01()0($)32#1)(&2#*$W(4-<(
specificity of activities suggested; and (c) alignment with the model based inquiry pedagogical approach.
         In regards to attention to student ideas, we gave each teacher a score, from 1-3, to reflect the extent to
which they took into account student ideas in their plans.    We found that, for the most part, teachers did not attend
much to student thinking and that they did not substantially improve, in this regard, over time. The average scores
for each course (for both naïve and final model questions) had only a slight difference (1.25-1.8). For example,
during Methods III Sean was presented with the student models about why ice floats. He commented that the
students were not using the correct grain size to represent the phenomenon that ice is less  dense than water.   When
asked what +#(?03.2(20(&1('.*$$()+#(1#C)(2*/(&A()+#$#(?#"#(1*]%#(@02#.$8(+#($)*)#2(K>()+&1B()+#(A&"$)()+&16(>(?03.2(20(
is ask them to collaborate with each other. Some have better ideas than others and after that perhaps the groups can
20(#C!#"&@#1)$()+#@$#.%#$L=((S+&.#(F#*1(A#.)()+*)(*(@*M0"(!"0-.#@(?&)+($)32#1)$,(@02#.$(?*$()+*)()+#/(?#"#(10)(*)(
the molecular structure of ice and water (and hence their models were not at the correct grain size); his instructional
move does not relate to this analysis in any specific way. The instructional move he suggested is a viable one (and
we suspect that such a move may result in some discussion of molecular structures in some groups); however, it is a
"*)+#"(6#1#"&'(@0%#(*12(&)(20#$1,)()*B#(&1)0(*''031)(?+*)(+#(10)&'#2(*-03)($)32#1)$,()+&1B&16=
         In contrast, during Methods II, Catherine evaluated student models that focused on the healing of a cut.
She commented that all the models had    explanations but that some were incorrect.   Catherine described her    next
instructional move a$($)#@@&16(A"0@(+#"(&1)#"!"#)*)&01(0A($)32#1)$,(312#"$)*12&16$R(K^02#.(YJ(@*/(312#"$)*12()+*)(
'#..$(*"#(&1%0.%#2(_-*$#2(01()+#(?"&))#1(!*")(0A()+#(@02#.`(-3)(2&21,)(&1'0"!0"*)#(&)(&1()+#(@02#.=((>)(&$(&@!0")*1)()+*)(
they know cells are involved so that is ?+#"#(>(?03.2($)*")(0AAL=((Z*)+#"&1#(&2#1)&A&#2(K'#..$L(*$()+#(@&$$&16(!&#'#(0A(
the puzzle, and thus noted that her next instructional move would address the role of cells in the phenomenon.
a1.&B#(F#*18(Z*)+#"&1#(3$#2(+#"(&1)#"!"#)*)&01(0A($)32#1)$,(312#"standing based on the models to inform her next
instructional move, this sort of response was infrequent in our data set. Table 2 shows the teachers that received at
.#*$)(01#($'0"#(0A(KXL(&1("#6*"2$()0()*B&16(&1)0(*''031)($)32#1)()+&1B&16(4*($'0"#(0A(X('0rresponds to comments that
mentioned specific student ideas and provided an instructional move that addresses these ideas). Out of the fifteen
teachers, only eight of them received  at least one score of 3.  In comparing the different courses, the lowest average
score (1.25) was during Methods I   and the highest average (1.8) during Methods IV.   We then calculated the    overall
average for all four courses for the instructional move after being presented with the naïve model and the
instructional move after bei16(!"#$#1)#2(?&)+()+#(A&1*.(@02#.8(*12(A0312()+*)()+#()#*'+#"$()00B($)32#1)$,(&2#*$(&1)0(
consideration slightly more  when the plan  was for the naïve versus final models (1.65 vs. 1.48).  However, overall
the teachers did not readily take into account student thinking when planning their next move in the classroom. This
mirrors findings by Friedrichsen et al (2009) and Tabachnik & Zeichner (1999).

Table 2: Selected teachers that did attend to student thinking in their instructional design

Teachers       Methods I             Methods II        Methods III          Methods IV
(pseudonyms)    Naïve      Revised    Naïve  Revised   Naïve      Revised    Naïve  Revised
Catherine        2            2        3       1            3        1        2        2
Anna             1            2        3       1            3        2        1        2
Ava              1            1        1       3            1        2        1        3
Patrick          1            2        1       1            1        3        1        1

                                                      194  ·  © ISLS
                                                  ICLS 2010   ·  Volume 1

Jackie              1         1        3       1            3        1        1        1
Nina                1         1        1       3            1        1        2        1
Jack                1         2        3       1            3        3        3        2
Claire              2         2        1       1            1        1        2        3

        We next analyzed the specificity of their next instructional move; that is, how clear and specific were they
about what they planned to do.     We found that the last two methods courses had higher average specificity scores
compared to the first two, with the highest average score of 2.07 for the instructional plan for final models in
Methods IV.   For example, after being presented with the student models about why ice floats during Methods IV,
Bani disc3$$#2(+#"(1#C)(&1$)"3')&01*.(!.*1(A0"()+#$#(1*]%#(@02#.$(*$R(K>(?03.2(6&%#()+#@(@0"#(2*)*L(*("*)+#"(
31$!#'&A&#2(@0%#W(I*1&(2&21,)(#C!.*&1R(4*<(?+*)()/!#(0A(2*)*(0"(4-<(?+*)($+#(?03.2(+*%#()+#($)32#1)$(20(?&)+()+*)(
data. However, Sean, after critiquing student models during Methods III, was much more specific with his
&1$)"3')&01*.(2#$&61=(([#($)*)#2()+*)(K>(?03.2(+*%#()+#(B&2$(6#)(&1($@*..(6"03!$(*12($+*"#()+#&"(@02#.$(&1($@*..(
groups. I would then have the group create a consensus      model and share them in front of the room and we would
*"63#()+#@L=(((F#*1,$(2#$'"&!)&01(0A(+&$(1#C)(&1$)"3')&01*.(@0%#(&1'.32#2(&1A0"@*)&01(*-03)()+#($!#'&A&'(*')&%&)&#$(
that would be performed in the classroom and these activities followed a logical progression.
        We expected that the teachers may tend to be more specific about what they planned when confronted with
KA&1*.(@02#.$L(-#'*3$#(had the teachers attended to student thinking the specifics of the instructional designs would
probably have related to specific challenges stu2#1)$,(2#@01$)"*)#2(&1()+#&"(@02#.$=(T+#"#A0"#8()+#(*')&%&)&#$(-#&16(
described in their next instructional move would be specific to the misunderstandings in the student model. For
example, if the teacher critiques the models for not being the correct grain size, an activity that would be coded as a
KXL(A0"($!#'&A&'&)/(?03.2(03).&1#(+0?(20&16(b(?03.2(&@!"0%#($)32#1),$(312#"$)*12&16(0A(6"*&1($&P#=(However, there
were very small differences (1.85 vs. 1.80) in terms of the specificity with which teachers described their next
instruction in the context of the  naive versus final models.   This could be because the teachers did not readily attend
to student thinking or understanding, and therefore, the specificity of the activities did not change during moves for
the naïve versus final models because the teachers were not evaluating the models in regards to student
understanding. Thus,  the activities that the teachers described were most likely common activities, for that content,
that they had implemented successfully before.
        T+#(.*$)(*$!#')$(0A()#*'+#"$,(1#C)-instructional-moves we examined were the alignment of these plans to
the model-based inquiry approach which is the focus pedagogy of the teacher education program. This method
entails a student centered clas$"00@(&1(?+&'+()#*'+#"$(*))#12()0(*12(?0"B(?&)+($)32#1)$,(&2#*$()0(2#%#.0!(@02#.$(
and explanations of natural phenomena. When looking at each of the four methods courses in turn, we found that
23"&16()+#(A&"$)('03"$#()+#()#*'+#"$,(!.*1$(?#"#(10)(*.&61#2(?&th inquiry-based practices but were mostly teacher
centered in nature (e.g. lecture). During the second and last course, the instructional plans were much better aligned
with model-based inquiry practices (2.85 and 2.57 respectively).     For  example, during Methods I, Ava described her
1#C)(&1$)"3')&01*.(@0%#(*$(K>(?03.2()*.B(*-03)(+0?(*($'*-(A0"@$($0()+*)()+#/(_$)32#1)$`(312#"$)*12()+*)()+#($'*-(&$1,)(
20&16()+#(+#*.&16L=((V%*,$(!"*')&'#$(*"#()#*'+#"('#1)#"#2(and showed no connection to model based practices.
[0?#%#"8()+#()#*'+#"$,(.#$$01$(-#6*1()0(*.&61(@0"#(?&)+(@02#.(-*$#2(&1Q3&"/(23"&16(Methods II and Methods IV.
Patrick, during Methods II, $)*)#2()+*)8(KT+#(-#$)()+&16()0(20(&$(+*%#()+#($)32#1)$(#C!.*&1()+#&"(@02#.$()0()+#("#$)(0A(
the class and justify them. The class could work out the rest   of the problems and allow them [students] to argue and
*..0?(0)+#"($)32#1)$()0(*"63#(?+/()+*)(@02#.(?03.2(-#(&1'0""#')L=((D*)"&'B,$($0.3)&01(0A('0..*-0"*)&01(*12(
argumentation are consistent with the principles put forth in the heuristic for progressive disciplinary discourse
4[D55<(A"*@#?0"B()+*)(*&@$()0(A0$)#"(.#*"1#"$,(!*")&'&!*)&01(&1(@*)#"&*.(*12(2&$'3"$&%#(*')&%&)&#$('+*"*')#"&P&16()+#(
work of scientists (Windschitl, Thompson, and Braaten, 2008).
        Comparison of the overall averages for the naïve-models instructional move and final-models instructional
@0%#8("#%#*.#2()+*)()+#()#*'+#"$,(!.*1$(?#"#($.&6+)./(@0"#(*.&61#2(?&)+(@02#.-based inquiry practices for the naïve-
models condition (2.36 average) versus the final-models condition (2 average). Thus the preservice teachers tended
to suggest more model based inquiry practices when they were designing lesson activities assuming their students
were just beginning to study the topic.  For example, Molly discussed her instruction after the naïve models during
Methods I as:

        K>(?03.2(+*%#(*('.*$$(2&$'3$$&01(*12(#%#"/01#($+*"#$()+#&"(1*]%#(@02#.$()0(6#)(#%#"/)+&16(03)(*12(
        then  after the discussion    we would   do some      sort of  introduction or look at some   kind of
        experiment.   We will draw the raw models, discuss it, and then change the models after the class
        2&$'3$$&01(*12()+#1(+*%#()+#@(_$)32#1)$`(20($0@#($0")(0A(#C!#"&@#1)=L

                                                      195  ·  © ISLS
                                                  ICLS 2010  ·  Volume 1

Implementing practices that Molly has outlined above, such as peer collaboration and interpreting data, are part of
model-based inquiry instruction=([0?#%#"8(A0"(+#"(&1$)"3')&01*.(@0%#(6&%#1()+#(A&1*.(@02#.8(^0../($)*)#2(K>(?03.2(
need to go back. I feel that I should go back and do some    kind of activity or discussion with them even if it is a five
to ten @&13)#(.#')3"#L=(^0../8(?+0(!"#%&03$./(*2%0'*)#2(A0"($)32#1)('#1)#"#2(*')&%&)&#$8(10?('+*16#2()+#(A0'3$(0A(
+#"(&1$)"3')&01()0(.#')3"&16=L((^0../,$("#$!01$#$(*"#(10)(31&Q3#(*12(&1(A*')(@*1/(0A()+#()#*'+#"$("#%#")#2(-*'B()0(
teacher-centered activities after they assumed that an initial constructivist approach did not work. Grossman,
Wilson, and Shulman (1989) concluded that teachers may revert back to the way they were taught if they are
uncomfortable or uncertain of their abilities. Therefore, many of the teachers, including Molly, were unsure of other
constructivist approaches to implement; thereby, reverting back to their comfort zone, teacher centered approaches.
        In summary, our analyses suggest that the preservice teachers tended not to take students thinking into
account when designing their next instructional practice, which could be due to a lack of content knowledge and/or
pedagogical content knowledge. Without such knowledge, the teachers may not recognize problematic ideas
expressed in the models, and they would not know what types of activities could help address the misconceptions
they did identify in the student models. Erickson (2007) contends that teachers fail to make formative use of
assessment data because the teachers do not know how to interpret the information to pinpoint alternative
!#2*606&'*.(K@0%#$=L( Additionally, Davis and Smithey (2009) argue that further support is needed to help
!"#$#"%&'#()#*'+#"$('01$&2#"()+#(A*')0"$()+*)('01)"&-3)#()0($)32#1)$,(&2#*$(0"()+#("#$&.&#1'#(0A()+0$#(ideas, as well as to
connect student ideas to instructional experiences. This resonates with our findings in this study. We did notice a
slight increase in attention to student ideas during Methods IV which may be attributed to the action research
activities teachers engaged with during this course. As part of their research projects teachers analyzed student
artifacts from their class and had to relate their analyses back to their research questions and learning theories.
           The instructional practices discussed by the teachers were often well aligned with model based inquiry
practices. One important aspect to note is that after Methods III, the alignment to inquiry practices slightly
decreased in comparison to Methods II and Methods IV. It was during Methods III that the preservice teachers were
completing their student teaching practicum. Through several class discussions it was apparent that many mentor
teachers did not implement these inquiry practices in their class and some were overtly against their use. It could be
that some of the preservice teachers were influenced by this and may have begun to mimic the practices of their
cooperating teacher. Therefore, this drop in inquiry practices could be contributed to the experiences they were
facing during their student teaching, and perhaps a shift in their philosophical stance regarding effective pedagogy.
Overall, during Methods IV showed improvements in all three categories- attention to student thinking; specificity of
activities; and alignment with inquiry based practices.   Although the improvement was small, it does show promise
)+*)(*')&01("#$#*"'+(!"0M#')$(20(!"0@0)#('+*16#$(&1(!"#$#"%&'#()#*'+#"$,(*))#1)&01()0($)32#1)()+&1B&16(&1(&1$)"3')&01*.(
design.

Conclusions and Implications
Research has shown that beginning teachers typically focus on themselves as teachers, often at the expense of
paying close attention to student learning (Meskill et al, 2002). Our findings support this assertion and illustrate the
ways in which preservice teachers may begin to develop this skill. We believe that teacher education programs can
encourage the shift from teacher (self) to student learning by engaging teachers in the practice of looking for
evidence of student understanding in written artifacts as well as classroom discourse. In our methods courses we
provide opportunities for teachers to evaluate student work and student discourse. However, our findings suggest
that these opportunities were either not substantive or not frequent enough to engender the kind of evidence-based
approach to instructional design we had hoped teachers would develop.
        >)($##@$()+*)()+#($&16.#(@0$)(&1A.3#1)&*.('03"$#(01()#*'+#"$,(*-&.&)/()0(*))#12(*12("#$!012()0($)32#1)()+&1B&16(
was the last methods course with its action-research focus. During this course, teachers analyzed various student
artifacts for student understanding that they had collected during their student teaching internship the previous
semester. In follow up studies, we would like to engage the teachers in analysis of student work and help them
develop more robust strategies for looking at evidence of student understanding and relating such interpretations to
potential instructional strategies.

References
American Association for the Advancement of Science (1993). Benchmarks for Science Literacy, New York:
        Oxford University Press.

                                                      196  ·  © ISLS
                                                 ICLS 2010  ·  Volume 1

Ball, D. & Cohen, D. (1999). Developing practice, developing practitioners: Toward a practice based theory of
      professional education. In L.Darling-Hammond & G. Sykes (Eds.), Teaching as a learning profession (pp.
       3-31). San Francisco: Jossey-Bass.
Bell, B., & Cowie, B. (2001). Formative assessment and science education. Dordrecht: Kluwer.
Black, P., & William, D. (1998). Assessment and classroom learning.      Assessment in Education, 5, 7-74.
Davis, E.A., Petish, D., & Smithey, J. (2006). Challenges new science teachers face. Review of Educational
      Researcher, 34 (3), 607-651.
Davis, E.A., & Smithy, J. (2009). Beginning teachers moving toward effective elementary science teaching. Science
       Education, 93(4), 745-770.
5#c0168(N=8(E(d*1(5"&#.8(c=(49::J<=(T+#(2#%#.0!@#1)(0A(!"0$!#')&%#()#*'+#"$,('01'#"1$(*-03)()#*'+&16('+#@&$)"/(
       topics at a macro-micro-symbolic interface. In H. Behrednt, H. Dahncke, R. Duit, W. Graber, M. Komorek,
      A. Kross, & P. Reiska (Eds.), Research in Science Education: Past, Present,and Future. Dordrecht:
       Kluwer.
Duschl, R.A., Schweingruber, H.A. & Shouse, A. W. (Eds.) (2007). Taking Science to School: Learning and
      Teaching Science in Grades K-8. Washington, DC: National Academies Press.
Erickson, F. (2007). Some thoughts on proximal formative assessment of student learning. In P. Moss (Ed.), NSSE
      Yearbook. Hoboken: Wiley.
Friedrichsen, P., Abell, S., Pareja, E., Brown, P., Lankford, D., & Volkmann, M. (2009). Does teaching experience
       @*))#"e(fC*@&1&16(-&0.06/()#*'+#"$,(!"&0"(B10?.#26#(A0"()#*'+&16(&1(*1(*.)#"1*)&%#('#")&A&'*)&01(!"06"*@=(
      Journal of Research in Science Teaching, 46, 357-383.
Geddis, A.N., Onslow, B., Beynon, C., & Oesch, J. (1993). Transforming content knowledge: Learning to teach
      isotopes. Science Education, 77, 575-591.
Grossman, P., Wilson, S., & Shulman, L. (1989). Teachers of substance: Subject matter knowledge for teaching. In
      M.C. Reynolds (Ed.) Knowledge base for the beginning teacher (pp. 23-36). Oxford: Pergamon Press.
Hammer, D. 2000. Teacher inquiry. In J. Minstrell & E. van Zee (Eds.), Inquiring into inquiry learning and teaching
      in science (pp. 184-215). Washington, DC: American Association for the Advancement of Science.
Kazemi, E., & Franke, M.L. (2004). Teacher learning in mathematics: Using student work to promote collective
      inquiry. Journal of Mathematics Teacher Education, 7, 203-235.
Leinhardt, G., Putnam, R.T., Stein, M., & Baxter, T. (1991). Where subject knowledge matters. In P. Peterson, E.
      Fennema, & T. Carpenter (Eds.). Advances in research on teaching. Greenwich: JAI Press.
g&)).#8(c=(49::9<=(g0'*)&16(.#*"1&16(&1()#*'+#"$,('0@@31&)/(0A(!"*')&'#R(N!#1&16(3!(!"0-.#@$(0A(*1*./$&$(&1("#'0"2$(
      of everyday work. Teaching and Teacher Education, 18, 917-946.
Meskill, C., Mossop, J., DiAngelo, S., and Pasquale, R. (2002). Expert and novice teachers talking technology:
      Precepts, concepts, and misconcepts. Language Learning and Technology¸6, 46-57.
National Research Council. (1996). National science education standards. Washington, DC: National Academic
       Press.
Russell, T., & Martin, A.K. (2007). Learning to teach science. In S.K. Abell & N.G. Lederman (Eds.), Handbook of
      Research in Science Education. Mahwah: Lawrence Erlbaum Associates.
Sadler, D. (1989). Formative assessment and the design of instructional systems. Instructional Science, 18, 119-144.
Simmons, P.E., Emory, A., Carter, T., Coker, T., Finnegan, B., Crockett, D. Richardson, L., Yager, R., Craven,
       J., Tillotson, J., Brunkhorst, H., Twiest, M., Hossain, K., Gallagher, J., Duggan-Haas, D., Parker, J., Cajas,
       F., Alshannag, O., McGlamery, S., Krockover, J., Adams, P., Spector, B., LaPorta, T., James, B., Rearden,
      K., & Labuda, K. (1999). Beginning teachers: Beliefs and classroom actions. Journal of Research in
      Science Teaching, 36, 930-954.
Tabachnick, B.R., & Zeichner, K.M. (1999). Idea and action: Action research and the development of conceptual
      change teaching of science. Science Education, 83, 309-322.
Van Driel, J., DeJong, O., & Verloo!8(h=(49::9<=(T+#(2#%#.0!@#1)(0A(!"#$#"%&'#('+#@&$)"/()#*'+#"$,(!#2*606&'*.(
      content knowledge. Science Education, 86, 572-590.
%*1(f$8(I=8(E(F+#"&18(^=(49::9<=(g#*"1&16()0(10)&'#R($'*AA0.2&16(1#?()#*'+#"$,(&1)#"!"#)*)&01$(0A('.*$$"00@(
      interaction. Journal of Technology and Teacher Education, 10, 571-596.
van Zee, E., & Minstrell, J. (1997). Using questioning to guide student thinking. Journal of the Learning Sciences, 6
       (2), 227-269.
Windschitl, M., Thompson, J., & Braaten, M. (2008). How novice science teachers appropriate epistemic discourses
      around model-based inquiry for use in classrooms. Cognition and Instruction, 26, 310-378.

                                                    197  ·   © ISLS
                                                ICLS 2010  ·  Volume 1

!

                                                    198  ·  © ISLS
