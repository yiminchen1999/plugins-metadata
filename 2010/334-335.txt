                                                ICLS 2010   ·   Volume 2

    Structural validation of a feedback perceptions questionnaire
   Jan-Willem Strijbos, Institute of Education and Child Studies, Leiden University, P.O. Box 9555, 2300 RB
                                Leiden, the Netherlands, jwstrijbos@fsw.leidenuniv.nl
Ron J. Pat-El, Institute of Education and Child Studies, Leiden University, P.O. Box 9555, 2300 RB Leiden, the
                                       Netherlands, rpatel@fsw.leidenuniv.nl
Susanne Narciss, Centre for Psychology of Learningand Instruction, Technical University Dresden, Zellescher
                       Weg 17, D-01069, Dresden, Germany, susanne.narciss@tu-dresden.de

          Abstract: The efficiency of feedback content has received much attention in prior feedback
          research, but students' feedback perceptions have hardly been studied. A structural validation
          was conducted     of  a feedback perceptions  questionnaire  amongst    1535  secondary  education
          students. The structural validity of the scales was confirmed: fairness (FA), usefulness (US)
          and acceptance     (AC)  constitute the  joined component    `Perceived   Adequacy   of Feedback'
          (PAF), which in turn positively predicts willingness to improve (WI) and affect (AF).

Feedback content and perceptions
In instructional contexts the term "feedback" refers to all post-response information which informs the learners
on their  actual state of   learning and/or   performance   (Narciss, 2008).   Several recent  reviews of  research on
feedback adopt a multidimensional view of feedback (Hattie & Timperley, 2007; Narciss, 2008; Shute, 2008).
Widely investigated types of feedback are (a) simple feedback types providing outcome-related information, and
(b) elaborated feedback types providing additional information besides outcome-related information (Narciss,
2008). The question of which feedback content is most efficient (i.e., which has the most beneficial effects on
performance)   has received     much  attention in prior  feedback    research. The  issues of how  learners perceive
feedback content and how the perceptions relate to performance have not been addressed explicitly.
          The perception of feedback ­ if measured ­ is commonly measured in terms of the single dimension
`usefulness', after the feedback has been applied and/or at the end of the task (Kwok, 2008). Yet, several authors
have emphasised the `mindful processing' of feedback as a critical factor for feedback efficiency (Kluger &
DeNisi, 1996; Narciss, 2008). In instructional contexts there are at least five feedback sources, i.e. the teacher,
peer, parents, book and/or computer-based environment, and the task (Hattie & Timperley, 2007). Depending on
the source's characteristics, feedback content might be perceived as less useful or less credible, and affect task
completion or learning differentially. Thus far the measurement of feedback perception has been neglected in
feedback research. This study investigates the structural construct validation of a multidimensional feedback
perceptions questionnaire.

Method
The sample consisted of 1535 pre-university and senior general secondary education students in the Netherlands
from 130 schools. There were 817 female and 713 male students and their mean age was 15.75 (SD = 1.19).
Participation to the study was based on informed consent. Students were presented with a scenario in which a
fictional student received feedback by a fictional peer (in the context of the task of `writing a business letter').
Feedback   content was      Concise General   (CGF) or  Elaborated    Specific  (ESF). CGF   contained solely general
remarks regarding the quality of the performance, whereas ESF provided the position and error type, as well as
information on how to proceed. We used the Strijbos, Narciss and Dünnebier (in press) multidimensional 18-
item feedback perceptions questionnaire. This questionnaire measures feedback perceptions in terms of fairness
(FA), usefulness (US), acceptance (AC), willingness to improve (WI) and affect (AF). Questionnaire items were
measured on a 10 cm bi-polar scale from 0 (fully disagree) to 10 (fully agree). Four scales consist of three items
(FA, US, AC and WI). Affect was measured with three positive items and three negative items.

Confirmatory factor analysis
We conducted confirmatory factor analyses using Structural Equation Modelling (SEM) in EQS version 6.1. To
interpret a model's    fit, the following  indicators were    used: SRMR    and   RMSEA     below 0.10  is considered
adequate fit and below 0.05 an excellent fit, and CFI scores above 0.90 indicate adequate fit and above 0.95
excellent fit; and as the !2 statistic becomes increasingly unreliable in sample sizes > 250 it was not used as a
criterion for model fit (Byrne, 2006).
          SEM on all 18-items ­ with a common factor PAF for FA, US and AC items, and a common factor for
all AF items ­ yielded a very weak fit, !2(127) = 2752.36, CFI = .799; SRMR = .189; RMSEA = .116. We then
conducted a separate analysis for the common factor PAF and a separate analysis for WI+AF. SEM was used to
confirm the second-order factor structure of PAF (with correlated errors for negatively worded items AC2 and
AC3). The   proposed   second-order    factor structure  fitted adequately,  but  a high RMSEA    indicated  poor   fit,

                                                    334   ·  © ISLS
                                            ICLS 2010  ·  Volume 2

!2(22) = 576.07, CFI = .929, SRMR = .051, RMSEA = .128. Inspection of LM-multipliers suggested that item
FA1 was more indicative of the US scale. This change resulted in a excellent model fit, !2(22) = 350.52, CFI =
.958, SRMR = .039, RMSEA = .098. We then tested the proposed correlated first-order structure of WI+AF.
The initial correlated factor model fitted poorly, !2(26) = 1390.903, CFI = .612, SRMR = .143, RMSEA = .185.
Inspection of the LM-multipliers suggested a positive wording effect in the AF scale due to both negatively and
positively worded items. Correlating errors for the positively worded AF items yielded an excellent fit, !2(23) =
278.26, CFI = .927, SRMR = .070, RMSEA = .085). Tests for measurement invariance for type of feedback
(CGF vs. ESF) and gender (Male vs. Female) revealed strong factorial invariance. Finally, to test thetheoretical
relationship between PAF, WI and AF, a path analysis was conducted using SEM (Figure 1). Modelling PAF as
a predictor of WI and AF yielded a good fit, !2(122) = 1636.07, CFI = .884, SRMR = .074, RMSEA = .090.

Figure 1. Path estimates and first and second order loadings [FA = fairness; US = usefulness; AC = acceptance;
PAF = perceived adequacy of feedback; WI = willingness to improve; AF = affect].

Discussion
The results clearly reveal that students' feedback perception ­ in terms PAF, WI and AF ­ can be adequately
captured. In addition, WI and AF were correlated ­ yet distinct measures. PAF was confirmed as a predictor of
WI and AF. Both the PAF and WI+AF part of the questionnaire were invariant across both types of feedback as
well as gender. Given the increased recent interest for feedback practices (between peers or by a teacher) in
view of formative purposes   of assessment, students'  perception of feedback  they receive  could be   a crucial
determinant of how they treat the feedback and possibly help to uncover why elaborated feedback typesare not
always  more efficient. With this questionnaire researchers can now   reliably and  validly investigate possible
relations between feedback perceptions, subsequent performance and feedback efficiency.

References
Byrne, B. M. (2006). Structural equation modelling with EQS. Mahwah, NJ: Erlbaum.
Hattie, J., & Timperley, H. (2007). The power of feedback. Review of Educational Research, 77, 81-112.
Kluger, A. N., & DeNisi, A. (1996). The effects of feedback interventions on performance: A historical review,
        a meta-analysis, and a preliminary feedback intervention theory. Psychological Bulletin, 119, 254-284.
Kwok, L. (2008). Students' perception of peer evaluation and teachers' role in seminar discussions. Electronic
        Journal of Foreign Language Teaching, 5, 89-97.
Narciss, S. (2008). Feedback strategies for interactive learning tasks. In J. M. Spector, M. D. Merrill, J. J. G.
        Van Merriënboer, & M. P. Driscoll (Eds.), Handbook of research on educational communications and
        technology (3rd ed., pp. 125-143). Mahwah, NJ: Erlbaum.
Shute, V. J. (2008). Focus on formative feedback. Review of Educational Research, 78, 153-189.
Strijbos, J. W., Narciss, S., & Dünnebier, K. (in press). Peer feedback content and sender's competence level in
        academic writing revision tasks: Are they critical for feedback perceptions and efficiency? Learning
        and Instruction.

                                                335  ·  © ISLS
