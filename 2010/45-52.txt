                                               ICLS 2010   ·  Volume 2

 Qualitative, Quantitative, and Data Mining Methods for Analyzing
       Log Data to Characterize Students' Learning Strategies and
                                                   Behaviors

               Co-Chairs: Ryan S.J.d. Baker & Janice D. Gobert , Worcester Polytechnic Institute

                             Discussant: Wouter van Joolingen, University of Twente

                           Presenters: Janice D. Gobert, Worcester Polytechnic Institute
                                        Ryan S.J.d. Baker, Worcester Polytechnic Institute
                                        Roger Azevedo, University of Memphis
                                        Ido Roll, University of British Columbia

          Abstract: This symposium addresses how different classes of research methods, all based
          upon the use of log data from educational software, can facilitate the analysis of students'
          learning strategies and behaviors. To this end, four multi-method programs of research are
          discussed, including the use of qualitative, quantitative-statistical, quantitative-modeling, and
          educational   data  mining    methods.   The    symposium    presents  evidence   regarding    the
          applicability of each    type of method   to  research  questions  of different  grain sizes, and
          provides several examples of how these methods can be used in concert to facilitate our
          understanding of learning processes, learning strategies, and behaviors related to motivation,
          meta-cognition, and engagement.

Symposium Topic

Increasingly, students' educational experiences occur in the context of educational technology. A trend with
importance    for the Learning   Sciences  is that this usage  is  increasingly being  logged   in very  fine-grained
fashions, providing a trace of students' conceptual and strategic learning processes and behaviors. As these data
become increasingly available to the broad Learning Sciences research community, in some cases through large
public   data repositories such    as the  Pittsburgh Science  of   Learning  Center  (cf. Koedinger    et   al, 2008),
researchers are increasingly asking the questions: What can we learn from log data (in particular, what can we
learn from log data, that is difficult to learn from other types of log data)? And how can we best learn from log
data?

The emergence     of  the  Educational  Data  Mining    conference  and journal  (cf. Baker    & Yacef,  2009)    have
provided one perspective about how to use log data to study education research questions. In Educational Data
Mining, automated methods are used to explore and model educational data. However, researchers have also
utilized  analytical  quantitative methods,   such as cognitive   modeling   (Anderson, 1993)    ­ the  production   of
quantitative models within a cognitive architecture to represent student cognition ­ and human-driven statistical
analysis, to explore log data. Similarly, case study and qualitative analysis methods have been used to explore
log data.

In this symposium, we bring researchers experienced in the use of these methods to discuss the relative benefits
of each of these categories of method for analyzing log data. We focus the discussion on the methods' use to
study students' learning processes, learning strategies, and behaviors related to motivation, meta-cognition, and
engagement. The progress in methods for analyzing log files has enabled more sophisticated analysis of how
students choose to interact with learning software, in turn allowing fine-grained investigation of which students
choose which learning strategies, in what situations these strategies manifest themselves, and how the behaviors
impact learning. The set of talks demonstrates how each of these methods can help elucidate learner strategies
and processes,    and  how   these  impact  learning,  and   then discussion  illuminates  the relative benefits   and
drawbacks of each of these methods.

Structure of Symposium and Potential Significance of the Contributions

The   symposium,     chaired by    Ryan  Baker and    Janice Gobert   (Worcester  Polytechnic    Institute), has   four
presentations:    one by  Janice   Gobert  (using  quantitative/statistical and qualitative  methods    to   study  the
relationship between learner characteristics and inquiry skills), one by Ryan Baker (using educational data
mining methods and quantitative/statistical methods to study why students game the system), one by Roger

                                                    45  ·  © ISLS
                                           ICLS 2010    ·  Volume 2

Azevedo (using qualitative and quantitative/modeling methods to study self-regulated learning processes), and
one by Ido Roll (using quantitative/modeling and qualitative methods to study student thinking during invention
tasks). The four presentations are followed by commentary from our discussant, Wouter van Joolingen, and in
turn by vigorous group discussion as to what research questions each methodology is most appropriate for, and
what conditions are necessary for each research method to succeed. For example, educational data mining
methods often require significant amounts of data to be utilized, whereas qualitative methods are difficult to
scale to massive amounts of data. Similarly, Quantitative/modeling methods enable closer understanding of the
constructs being studied, whereas educational data mining methods can support higher construct validity, in
terms of supporting closer matches between models and "common sense" notions of the constructs, and can
integrate model validation explicitly into the model creation process.

The discussion of the issues are brought into context by the multi-methodological experience of each of the
presenters, enabling the presenters to speak with insight on the relative merits of different approaches. Given the
mixed-method approaches represented, the symposium contains several examples of how these methods can be
used in concert to promote valid and innovative research that is only possible through the analysis of log data.

Each of the presentations concerns work that contributes to a deeper understanding of why specific students
choose specific learning strategies or behaviors, and how a student's learning strategies and behaviors impact
their learning and/or the depth of their learning. These features make the presentations relevant to attendees for
whom the methodological issues are of lesser import.

At the same time, the presentations provide insight as to what types of research questions each type of method
can best be used to address, including which ways of using educational data mining methods are optimal, what
types of research questions are better addressed through non-automated methods such as cognitive modeling,
and when qualitative analysis enables richer understanding than other methods support.

Presentations

Studying the interaction between learner characteristics and inquiry skills in
microworlds
Janice Gobert, Michael São Pedro, Juelaila Raziuddin, Nathan Krach & the Science Assistments Team
Department of Social Science and Policy Studies, and Department of Computer Science, Worcester Polytechnic
Institute, USA
Email: jgobert@wpi.edu

It is broadly recognized that science literacy means that learners have content knowledge, have process skills for
conducting inquiry, and have an epistemological understanding of the nature of science (Perkins, 1986).
Although this definition prescribes the knowledge ontologies learners need, it is not clear that these forms of
knowledge are sufficient to characterize the variance observed in students' scores on conceptual post-test scores.
More recently, there has been interest within the intelligent tutoring community in obtaining data on important
student characteristics in order to better explain the variance observed in conceptual learning scores.

In this presentation we describe research conducted to study the relationship between learner characteristics and
inquiry skills in the Science Assistments project, a free, online, intelligent tutoring system that "assists students
while assessing them". The Assistments approach was previously used only in mathematical content domains.
The Math Assistments project has been successful at modeling student learning and tutoring students on math
skills. Some key findings are: 1) Students' responses to scaffolding are helpful in tracking students' knowledge,
and 2) By taking into account the scaffolds requested by students, state scores can be more reliably predicted
when compared to using correctness information only. As an extension to this system, the Science Assistments
system tutors students on their inquiry skills with the goal of supporting both skill development as well as
content knowledge. We have shown that the system can be successfully used to tutor students' understanding of
the control for variables strategy (CVS), a key strategy under the larger skill named "design and conduct
experiments" (Sao Pedro et al, 2009). In the Science Assistments project, we are also using data on learner
characteristics to design individualized instruction and adaptive scaffolding.

In the talk, we discuss qualitative and quantitative-statistical analyses conducted to investigate the relationship
between learner characteristics and inquiry skills. Baseline learner characteristic data were gathered from large
cohorts of 5th through 8th grade students (n=1000) from three different public middle schools in central
Massachusetts. Schools vary in their performance on the state standardized science test (MCAS) from 50% to

                                               46    ·  © ISLS
                                               ICLS 2010   ·  Volume 2

90% of students scoring in the "below proficient" category. Our measures for learner characteristics included
GRIT, i.e., perseverance (Duckworth & Seligman, 2005), learning orientation, i.e., mastery/performance
orientation (Midgley et al, 2000), self-efficacy (Kettelhut, 2007) for science, and epistemologies of models in
science (Treagust et al. 2002). Our measures for inquiry learning included students' skills at formulating
hypotheses (IV, DV, and a relationship between them), planning and conducting experiments within the
learning environment, interpreting data from these trials, and linking data back to their hypotheses. Our results
indicate statistically significant relationships between both conceptual post-test knowledge (time1) and
conceptual post-test knowledge (time 2) with inquiry skills, adaptive learning (PALS scales 1 & 4), and self-
efficacy (for science inquiry and computer use). Results are discussed with regard to the interaction between
learner characteristics and inquiry skills.

Educational Data Mining Methods For Studying Student Behaviors Minute by Minute
Across an Entire School Year

Ryan S.J.d. Baker
Department of Social Science and Policy Studies, Worcester Polytechnic Institute, USA

Adriana M.J.B. de Carvalho, Jay Raspat, Vincent Aleven, Albert T. Corbett, Kenneth R. Koedinger
Pittsburgh Science of Learning Center, Human-Computer Interaction Institute, Carnegie Mellon University,
USA

Mihaela Cocea
London Knowledge Lab, Birkbeck College, University of London, UK

Arnon Hershkovitz
Knowledge Technology Lab, School of Education, Tel Aviv University, Israel

Email: rsbaker@wpi.edu

In this talk, we discuss how educational data mining methods (cf. Baker & Yacef, 2009), conducted using log
files of  student use  of   Cognitive Tutor    software   for mathematics  (Koedinger  &  Corbett,  2006),   have
significantly increased our scientific understanding of two behaviors that students engage in. The two behaviors
studied are gaming the system and off-task behavior. Gaming the system is defined as attempting to succeed in
an interactive learning environment by exploiting properties of the system rather than by learning the material
(cf.  Baker, Corbett, Koedinger,  &   Wagner,    2004).   Examples  of  gaming within Cognitive   Tutors   include
systematically guessing or abusing hints. Beyond Cognitive Tutors, gaming the system has been observed in
assessment software (Walonoski & Heffernan, 2006), graded-participation newsgroups (Cheng & Vassileva,
2005), and educational games (Miller, Lehman, & Koedinger, 1999; Rodrigo et al, 2007). Off-task behavior
(engaging in behavior that does not involve the system or the learning task) has been shown to occur with
comparable frequency in Cognitive Tutors and traditional classrooms (cf. Baker et al, 2004). Both off-task
behavior and gaming the system have been shown to be associated with poorer learning in Cognitive Tutors
(Baker et al, 2004; Baker, 2007).

We discuss two analyses where educational data mining shed light on the nature, causes, and impacts of these
behaviors. Each analysis can be considered an example of "discovery with models", where a model developed
using educational data mining methods is then applied to a more extensive data set, and utilized to make
inferences about how data from factors available in the larger set (additional measures or contextual factors)
associate with the predictions from the model (cf. Baker & Yacef, 2009).

In the first analysis, log file data was obtained for 58 students using a Cognitive Tutor for Algebra in 22 topics,
across the course of an entire school year. The 58 students solved 73,880 problem steps within the tutoring
software, and data on the timing and semantic meaning (wrong, wrong-indicating-misconception, correct, and
help; also, the relevant cognitive skill) of their actions was collected. A model validated to accurately infer off-
task behavior (cf. Baker, 2007) was applied to each action in the data set. Gaming the system was assessed by
"text replays", rapid hand-coding of distilled log files (cf. Baker, Corbett, & Wagner, 2006). An enumeration of
the  ways intelligent tutor lessons vary    from each   other  was developed  via a collaborative design   process
involving both researchers and practitioners, and was applied to each of the 22 tutor units. The assessments of
student behavior and the information on the design of each tutor lesson were combined to discover factors in the
design of Cognitive Tutors that predicted the incidence of the behaviors. The resultant models predicted over

                                                    47  ·  © ISLS
                                             ICLS 2010   ·  Volume 2

50% of the variance in each behavior. One example finding is that problems with many seductive details (cf.
Harp & Mayer, 1998) are gamed less, and problems with no cover story at all are gamed less, but problems with
sparse ("hokey") cover stories are heavily gamed.

In the second analysis, log file data was obtained for 296 students using a Cognitive Tutor for middle school
mathematics in three topics, Geometry, Percents, and Scatterplots. The 296 students solved 72,845 problem
steps within the tutoring software, and data on the timing and semantic meaning of their actions (as described
above) was collected. Models validated to accurately infer off-task behavior and gaming the system (cf. Baker,
Corbett, Roll, & Koedinger, 2008; Baker, 2007) were applied to each action in the data set. Next, we developed
logistic regression models to investigate two hypotheses about the mechanisms that led to reduced learning: (a)
the behaviors lead to less learning within individual problem steps (immediate harmful impact) and (b) the
behaviors lead to overall learning loss due to fewer opportunities to practice (aggregate harmful impact). Our
findings suggest that gaming has      immediate harmful    impact on  learning, whereas off-task behavior      has
aggregate harmful impact on learning.

Deciphering the complex nature of log-file data collected during self-regulated
learning with MetaTutor

Roger Azevedo, Amy Witherspoon, Amber Chauncey, Mihai Lintean, Zhiqiang Cai, Vasile Rus, Arthur
Greesser
Departments of Psychology and Computer Science, Institute for Intelligent Systems, University of Memphis

Email: razevedo@memphis.edu

MetaTutor is a multi-agent, adaptive hypermedia learning environment that trains and fosters high school and
college students' use of self-regulatory processes in the context of learning about science topics such as human
body systems. The purpose of the MetaTutor environment is to examine the effectiveness of pedagogical agents
(PAs) as external regulatory agents used to detect, trace, model, and foster students' self-regulatory processes
during science learning with multiple representations of information. The multi-agent system provides adaptive
tutoring based on students' evolving conceptual understanding of the topic and their strategic use of cognitive
and metacognitive processes. Each of the four agents is responsible for specific aspects of SRL, including task
definition, planning, metacognitive processes, and learning strategies. Based on their specialized roles, each PA
has been designed to detect a specific set of SRL processes. For example, Mary the Monitor is in charge of
detecting when students deploy metacognitive processes and make metacognitive judgments such as expressing
a judgment of learning (JOL; e.g., used in relation to judging one's understanding of the current content) and
also in determining the valence (e.g., JOL - or JOL +) associated with the metacognitive judgment. The
presupposition of an accurate detection method (by each agent) leads the agent to model the temporal dynamics
associated with each SRL process, across all SRL processes, and how they relate to several learning outcomes
such as declarative, procedural, and inferential knowledge and mental models of the science topic. This
evolving model is then used to foster SRL and content understanding by providing several levels of scaffolding.
Instructional scaffolding involves the coordination of other architectural modules of MetaTutor that coordinate
and manage the dialogue system between agents and the learner. Instructional scaffolding is provided based on
current research on human and computerized tutoring research (Chi et al., 2004; Graesser, D'Mello & Person, in
press; VanLehn et al., 2007; Wolff, 2009) and recent studies comparing SRL with ERL (externally-regulated
learning; Azevedo et al., 2007, 2008). The types of scaffolding range from having the learner vicariously watch
as the agent models the SRL process to having the student use a specific SRL process while being provided with
elaborate feedback regarding the effective use of the process (based on Zimmerman & Moylan, in press).

We present quantitative and qualitative analyses of log-file data from a mixed-method study with sixty (N = 60)
college students using MetaTutor to learn about the circulatory system. Our analyses focus on the various data
analytic techniques used to make inferences from the complex log-file data. The quantitative analyses focus on
comparisons between frequency use of SRL processes, duration of SRL processes during learning, amount of
time spent on each type of informational source, strategic moves made during each session, navigation patterns,
and learning outcomes and their relation to specific type of scaffolding and agent moves during the learning
session. We also provide descriptive and qualitative data focusing on the quality and cyclical nature of learners'
deployment of SRL processes and the agents' use of ERL processes. Overall, this study stands to contribute to
theoretical conceptions of SRL and ERL, examination of the cyclical nature between SRL and ERL, and the role
of various scaffolding methods to foster learning. Lastly, we also derive instructional implications for the design
of intelligent learning environments.

                                                  48  ·  © ISLS
                                               ICLS 2010  ·  Volume 2

Analysis of students' actions during online invention activities - seeing the thinking
through the numbers.

Ido Roll
Carl Wieman Science Education Initiative and the Department of Physics and Astronomy, University of British
Columbia, Canada

Vincent Aleven, Kenneth R. Koedinger
Pittsburgh Science of Learning Center, Human-Computer Interaction Institute, Carnegie Mellon University,
USA

Email: idoroll@gmail.com

Intelligent Tutoring Systems are widely used coached problem-solving environments (Koedinger, Anderson,
Hadley & Mark, 1997; VanLehn, Lynch, Schulze, Shapiro & Shelby, 2005). They are successful, in part, due to
their ability to give adaptive feedback (Corbett & Anderson, 2001; Koedinger & Aleven, 2007). More
specifically, Intelligent Tutoring Systems adapt to students' behavior and knowledge by tracing students'
learning trajectories using a cognitive model of the domain (Corbett & Anderson, 1995). A different family of
educational technologies supports students during discovery and scientific inquiry tasks (de Jong & van
Joolingen, 1998). However, the large solution space in these tasks, among other reasons, make the model tracing
approach very hard to design and implement in these environments (van Joolingen, 1999; Veermans, de Jong &
van Joolingen, 2000).

In this symposium we discuss data from the Invention Lab, an intelligent tutoring environment for invention
tasks in the domain of Variability, built using the Cognitive Tutor Authoring Tools (Aleven, McLaren, Sewall &
Koedinger, 2006). Invention tasks are a form of scientific inquiry activities, in which students are asked to
invent solutions to novel mathematical problems without prior instruction (Roll, Aleven & Koedinger, 2009;
Schwartz & Martin, 2004). In order to tailor the support students receive to their knowledge, the Invention Lab
analyzes students' responses and identifies features that are apparent or missing from their solutions. To deal
with the unique challenges of inquiry tasks, the lab uses two cognitive models - a metacognitive model of the
inquiry process, and a domain-level model of variability. The domain-level model combines two approaches,
model tracing (Corbett & Anderson, 1995) and constraint based models (Mitrovic, Koedinger & Martin, 2003),
in order to extract the conceptual features of students' solutions. We present qualitative and quantitative results
from an in-vivo evaluation of the Invention Lab with 92 students in a public middle school. Specifically, we
focus on how the Invention Lab analyzes students' inventions, and how its log files open a window into students
thinking, giving us an opportunity to identify a-ha moments at the domain and metacognitive levels as the data
unfolds students' learning trajectories.

Discussant

The session discussant is Wouter van Joolingen. Wouter van Joolingen is Professor of Instructional Technology
at the University of Twente, The Netherlands. His main research interest is the use of technology to support
inquiry learning, which includes the design of cognitive tools to support inquiry processes and modeling with
intuitive interfaces, such as freehand drawings. He studies the influence of cognitive tools and/or the interaction
with learner  characteristics such as    motivation and   or  epistemological  beliefs. Currently he is technical
coordinator of the European SCY (Science Created by You) project in which science learning is modelled as the
creation and exchange of Emerging Learning Objects. An important role is seen for pedagogical agents that
base their behavior on the real-time analysis of learner interaction data.

References

Aleven,  V., McLaren,  B. M.,   Sewall,   J., & Koedinger,   K.  R. (2006).  The cognitive  tutor authoring   tools
(CTAT): Preliminary evaluation of efficiency gains. Proceedings of the International Conference on Intelligent
Tutoring Systems. Berlin: Springer Verlag.

Anderson, J.R. (1993) Rules of the Mind.   Hillsdale, NJ: Lawrence Erlbaum Associates.

Azevedo, R., Greene, J. A., & Moos, D. C. (2007). The effect of a human agent's external regulation upon
college students' hypermedia learning. Metacognition & Learning, 2(2/3), 67­87.

                                                   49  ·  © ISLS
                                             ICLS 2010    ·  Volume 2

Azevedo, R., Moos, D. C., Greene, J. A., Winters, F. I., & Cromley, J. G. (2008). Why is externally-regulated
learning more effective than self-regulated learning with hypermedia? Educational Technology Research &
Development, 56(1), 45­72.

Baker, R.S.J.d.   (2007) Modeling    and  Understanding     Students' Off-Task  Behavior   in Intelligent Tutoring
Systems. Proceedings of ACM CHI 2007: Computer-Human Interaction, 1059-1068.

Baker, R.S., Corbett, A.T., Koedinger, K.R., Wagner, A.Z. (2004) Off-Task Behavior in the Cognitive Tutor
Classroom:    When   Students  "Game     The System". Proceedings       of ACM      CHI  2004:  Computer-Human
Interaction, 383-390.

Baker, R.S.J.d., Corbett, A.T., Roll, I., Koedinger, K.R. (2008) Developing a Generalizable Detector of When
Students Game the System. User Modeling and User-Adapted Interaction, 18, 3, 287-314.

Baker, R.S.J.d., Corbett, A.T., Wagner, A.Z. (2006) Human Classification of Low-Fidelity Replays of Student
Actions. Proceedings   of the Educational    Data  Mining    Workshop   at  the 8th  International   Conference  on
Intelligent Tutoring Systems, 29-36.

Baker, R.S.J.d.,  Yacef, K. (2009)   The  State of  Educational   Data  Mining   in  2009: A   Review   and Future
Visions. Journal of Educational Data Mining, 1 (1), 3-17.

Beckley, R. (2008). Practice Test for Scientific Inquiry #1 with Scientific Ways of Knowing #1 and #2.
Retrieved July 2, 2009, from Robert Beckley's Science Web Page:
http://www2.olentangy.k12.oh.us/~robert_beckley/Science%20Web%20Pages/practice%20Summative%20Test
2.pdf

Cheng, R., Vassileva, J. (2005) Adaptive Reward Mechanism for Sustainable Online Learning Community.
Proceedings of the 12th International Conference on Artificial Intelligence in Education, 152-159.

Chi, M. T. H., Siler, S., & Jeong, H. (2004). Can tutors monitor students' understanding accurately? Cognition
and Instruction, 22, 363­387.

Corbett, A.   T., &  Anderson,   J.  R. (1995). Knowledge      tracing: Modeling    the  acquisition of procedural
knowledge. User Modeling and User-Adapted Interaction, 4(4), 253-278.

Corbett, A. T., & Anderson, J. R. (2001). Locus of feedback control in computer-based tutoring: Impact on
learning rate, achievement  and  attitudes. In  J. Jacko,   A. Sears,  M.  Beaudouin-Lafon,   &  R.   Jacob (Eds.),
CHI'2001 conference on human factors in computing systems. New York: ACM Press.

de Jong,  T.,  &  van Joolingen, W.   R.  (1998).  Scientific  discovery   learning with computer    simulations of
conceptual domains . Review of Educational Research, 68, 179-201.

Duckworth, A. & Seligman, M. (2005). Self-Discipline Outdoes IQ in Predicting Academic Performance of
Adolescents. Psychological Science, 16(12), 939-944.

Feng, M., Beck, J,. Heffernan, N. & Koedinger, K. (2008). Can an Intelligent Tutoring System Predict Math
Proficiency as Well as a Standardized Test? In Baker & Beck (Eds.). Proceedings of the 1st International
Conference on Education Data Mining, 107-116. Montreal, 2008.

Feng, M., Heffernan, N.T., & Koedinger, K.R. (2006a). Addressing the assessment challenge in an Online
System that tutors as it assesses. To appear in User Modeling and User-Adapted Interaction: The Journal of
Personalization Research (UMUAI).

Feng, M., Heffernan, N.T, Koedinger, K.R. (2006b). Predicting State Test Scores Better with Intelligent
Tutoring Systems: Developing Metrics to Measure Assistance Required. In Ikeda, Ashley & Chan (Eds.).
Proceedings of the 8th International Conference on Intelligent Tutoring Systems, 31-40.

Gobert, J., Heffernan, N., Ruiz, C., & Kim, R.     (2007). AMI: ASSISTments Meets Inquiry. Proposal funded by
the National Science Foundation (NSF-DRL# 0733286).

                                                   50  ·  © ISLS
                                            ICLS 2010   ·  Volume 2

Gobert, J., Heffernan, N., Koedinger, K. & Beck, J. (2009). ASSISTments Meets Science Learning (AMSL;
R305A090170). Proposal funded by the U.S. Dept of Education.

Graesser, A., D'Mello, S., & Person, N. Meta-Knowledge in tutoring. In D. Hacker, J. Dunlosky, & A. Graesser
(Eds.), Handbook of metacognition and education.

Harp, S.E., Mayer, R.E. (1998) How seductive details do their damage: A theory of cognitive interest in science
learning. Journal of Educational Psychology, 90, 414-434.

Ketelhut, D. (2007). The Impact of Student Self-efficacy on Scientific Inquiry Skills: An Exploratory
Investigation in River City, a Multi-user Virtual Environment. Journal of Science Education and Technology,
16(1). DOI: 10.1007/s10956-006-9038-y

Koedinger, K. R., & Aleven, V. (2007). Exploring the assistance dilemma in experiments with cognitive tutors.
Educational Psychology Review, 19 (3), 239-264.

Koedinger, K. R., Anderson, J. R., Hadley, W. H., & Mark, M. A. (1997). Intelligent tutoring goes to school in
the big city. International Journal of Artificial Intelligence in Education, 8, 30-43.

Koedinger,  K.R. &   Corbett, A.T.,  (2006) Cognitive     tutors: Technology bringing     learning sciences to  the
classroom, in The Cambridge handbook of the learning sciences, R.K. Sawyer, Editor. Cambridge University
Press: New York, NY, 61-77.

Koedinger, K., Cunningham, K., Skogsholm A., & Leber, B. (2008) An open repository and analysis tools for
fine-grained, longitudinal learner data. Proceedings of the 1st International Conference on Educational Data
Mining, 157-166.

Midgley, C., Maehr, M.L., Hruda, L., Anderman, E.M., Anderman, L., Freeman, K.E., Gheen, M., Kaplan, A.,
Kumar, R., Middleton, M.J., Nelson, J., Roeser, R., & Urdan, T. (2000). Manual for the Patterns of Adaptive
Learning Scales (PALS). Ann Arbor, MI: University of Michigan.

Miller, C., Lehman, J., & Koedinger, K. (1999). Goals and learning in microworlds. Cognitive Science, 23, 305­
336.

Mitrovic, A., Koedinger,   K. R., &  Martin,  B. (2003).   A   comparative   analysis    of cognitive tutoring and
constraint-based modeling. Proceedings of User Modeling 2003, 313-322

Pardos, Z. A., Heffernan, N. T., Anderson, B. & Heffernan, C. (2007). The effect of model granularity on
student performance prediction using Bayesian networks. Proceedings of User Modeling 2007.

Perkins, D. (1986). Knowledge as design. Hillsdale, NJ:   Erlbaum.
Razzaq, L., Feng, M., Nuzzo-Jones, G., Heffernan, N., Koedinger, K., Junker, B., Ritter, S., Knight, A.,
Aniszczyk, C., Choksey, S., Livak, T., Mercado, E., Turner, T., Upalekar. R, Walonoski, J., Macasek. M., &
Rasmussen, K. (2005). The Assistment Project: Blending Assessment and Assisting. In C. Looi, G. McCalla, B.
Bredeweg, & J. Breuker (Eds.). Proceedings of the 12th International Conference on Artificial Intelligence In
Education. Amsterdam: ISO Press. pp. 635-644.

Rodrigo,  M.M.T.,   Baker, R.S.J.d., Lagud,  M.C.V.,    Lim,   S.A.L.,  Macapanpan,       A.F., Pascua, S.A.M.S.,
Santillano, J.Q., Sevilla, L.R.S., Sugay, J.O., Tep, S., Viehland, N.J.B. (2007) Affect and Usage Choices in
Simulation Problem Solving Environments. Proceedings of Artificial Intelligence in Education 2007, 145-152.

Roll, I., Aleven, V., & Koedinger, K. R. (2009). Helping students know 'further' - increasing the flexibility of
students' knowledge using symbolic invention tasks. Proceedings of the 31st annual meeting of the cognitive
science society, 1169-1174. Austin, TX: Cognitive Science Society.

São Pedro, M., Gobert, J., Heffernan, N., & Beck, J. (2009). Can an Intelligent Tutor Teach the Control of
Variables Strategy for Scientific Inquiry? Proceedings of the 31st Annual Meeting of the Cognitive Science
Society.

                                                 51  ·  © ISLS
                                             ICLS 2010  ·  Volume 2

Schwartz, D. L.,  & Martin, T.  (2004).   Inventing  to prepare for future  learning: The hidden  efficiency     of
encouraging original student production in statistics instruction. Cognition and Instruction, 22(2), 129-184.

Treagust, D., Chittleborough, G., & Mamiala, T. (2002). Students' understanding of the role of scientific models
in learning science. International Journal of Science Education, 24(4), 357-368.

van Joolingen, W.   R. (1999).  Cognitive  tools for    discovery learning. International Journal of Artificial
Intelligence in Education, 10, 385-397.

VanLehn, K., Graesser, A. C., Jackson, G. T., Jordan, P., Olney, A., & Rose, C. P. (2007). When are tutorial
dialogues more effective than reading? Cognitive Science, 31(1), 3­62.

VanLehn, K., Lynch, C., Schulze, K., Shapiro, J. A., & Shelby, R. (2005). The andes physics tutoring system:
Five years of evaluation. Proceedings of the international conference on artificial intelligence in education.

Veermans, K., de Jong, T., & van Joolingen, W. R. (2000). Promoting self-directed learning in simulation-based
discovery learning environments through intelligent support. Interactive Learning Environments, 8(3), 229-255.

Walonoski, J.A. and Heffernan, N.T. (2006). Detection and analysis of off-task gaming behavior in intelligent
tutoring systems. Proceedings of the 8th International Conference on Intelligent Tutoring Systems, 382-391.
Jhongli, Taiwan.

Woolf, B. (2009).  Building intelligent  interactive tutors: Student-centered strategies  for revolutionizing    e-
learning. Amsterdam: Elsevier.

Zimmerman, B. & Moylan, A. (in press). Self-regulation: Where metacognition and motivation intersect. In D.
Hacker, J. Dunlosky, & A. Graesser (Eds.), Handbook of metacognition and education.

                                                 52  ·  © ISLS
