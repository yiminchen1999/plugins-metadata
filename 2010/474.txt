                                                 ICLS 2010    Volume 2

       21st Century Assessment: Redesigning to Optimize Learning

                     Vanessa Svihla, University of California, Berkeley, vsvihla@hotmail.com
      Drue Gawel, Megan Brown, Allison Moore, Nancy Vye, and John Bransford, University of Washington
             djgawel@u.washington.edu, megantbrown@hotmail.com, amoore2@u.washington.edu,
                              nancyvye@u.washington.edu, bransj@u.washington.edu

        Abstract: This poster presents design implications related to findings from research on the
        development of Interactive Learning Assessments (ILAs). Standardized assessments using
        multiple choice questions cannot measure the most critical aspects of learning for the 21st
        century. ILAs place students in advisory roles, leveraging a place-based metaphor to navigate,
        learn, then give counsel in situations in which they do not already know how to solve the
        problem; we assess how students learn to learn.

"I think it was because it's like it's a real thing, like genetic counseling is a real thing in the world and then if you
know that what you're learning in class can actually help somebody it just gives you more of a reason to learn it."

Introduction
The above quote highlights the potential for successful integration of learning and assessment in the 21st century
context. Rather than emphasizing facts and fragmenting the curriculum, students should see connections to their
everyday and professional future selves. Preparing students for diverse and technologically demanding lives requires
a substantively different skill set than has been traditionally in school curricula (Partnership for 21st Century Skills,
2002). Towards this goal, we have been designing assessments and related curriculum practices. Our work builds on
theories of teaching, learning, transfer and assessment (Bransford, Brown, & Cocking, 2000; Bransford & Schwartz,
1999). While being assessed, students should have the opportunity not only to demonstrate what they already know,
but also how prepared they are to learn in the future. Learning should pause while students are assessed. Though
strides have been made with respect to teaching practices and the use of formative assessments to improve teaching
and learning (Black & Wiliam, 1998), we envision major changes in what we assess. Most assessments emphasize
factual knowledge rather than problem solving and thinking skills, or attempt to measure these skills in the absence
of content, leaving out key elements of what is known about the development of expertise (e.g., Ericsson, 2006).
Therefore, if the assessment of 21st century learning is to reveal and drive meaningful learning, it must be authentic
and occur at the nexus of skills and content.

Learning Assessment Design Principles
With  these issues  in  mind,  we   have engaged     in  design-research, iteratively    designing  Interactive  Learning
Assessments (ILAs). As an illustration, the learning assessment we designed for the domain of human genetics has
three cases that relate to a common    scenario, in  which  students   assume   the role of  an  intern genetic counselor
(Svihla, et al., 2009). Each case involves a simulated meeting between the student-as-intern, a virtual mentor and
client(s) seeking genetics counseling. Clients have authentic presenting circumstances--for example, in one case the
clients, a Mr. and Mrs. Jones, wish to start a family but are concerned about the risk of their children inheriting
sickle cell disease. To successfully counsel these virtual clients, students need to understand and be able to apply a
set of core genetics concepts and skills and to communicate with their clients in ways that are professional and
appropriate to the role of genetics counselor. Sickle cell disease was chosen because it is frequently included in
high-school biology  curricula and  is  sufficiently nuanced,   providing   many    layers   for exploration:  inheritance,
evolution, gene-environment interactions, protein structure-function, political policy and bioethics. Each of the cases
is organized into three phases: preparation, in which students familiarize themselves with the case and conduct
research prior to counseling their virtual clients; formative assessment plus feedback in which students interact with
a virtual mentor  to review   their preparation,  and    as needed,    further prepare   for meeting    their clients; and
performance and reflection, in which students counsel their clients and reflect on their learning.

Findings from Design Cycles
Design cycles have been conducted in high school biology classrooms in a rural North Carolina community and in a
suburban,  high-SES  Washington   state  community.     Our   research with this  learning   assessment  shows   that  this

                                                     474     ISLS
                                                 ICLS 2010    Volume 2

approach provides a rich source of information about students' learning related to content and ability to synthesize
across resources, especially as compared to traditional assessments (Gawel, Philips, et al., 2008;    Gawel, Phillips,
Svihla, Vye, & Bransford, 2008; Svihla, et al., 2009). Teachers appreciated that it changed their perspective of how
they interacted with students.
         Although   pleased  with aspects  of the design,   classroom   iterations highlighted  redesign opportunities,
presented in Table 1. The most significant change involved moving from linear, programmed instruction to a place-
based metaphor, which provides virtual locations for types of activities and allows the student to make decisions
about when she or he is prepared to counsel clients. The place-based metaphor includes the Lobby, where students
can learn about general aspects or get a new case, Mentor's office, where students can be mentored, an Intern room,
where students can interact and give and get peer feedback, and a Consultation room, where students can answer
questions from their virtual clients. Also provided are tools to scaffold students in making effective and responsible
use of internet resources, and for professional writing. This place-based metaphor requires that students take greater
control  of their learning, allowing assessment   of metacognitive    aspects in   addition to contextualized  problem
solving.

Table 1. Emergent design needs and directions

Needs                                             Design directions
Students did not do initial research to prepare   Provide more explicit scaffolding and expectations;
themselves to meet with their clients.            Block access to client if student has not prepared;
                                                  Show "final product" example to hint at scope of expectations.
Students did not use internet to revise answers.  Provide case report tool to scaffold writing;
                                                  Include opportunity for peer review;
                                                  Add bibliographic tool to store notes, rate reliability of sources,
                                                  tag with key words, and cite sources.
Students didn't understand what an internship     Provide explicit introduction to what an internship is.
is.
Students wanted to be told what to do.            Provide guidance that puts students in control, leveraging game-
                                                  like atmosphere;
                                                  Allow time for implementation dip.
Linear structure limited ability to assess        Shift to place-based metaphor.
students' judgments about their preparedness
Teachers were uncertain about placement in        Provide teacher guide showing options (e.g., as formative
curriculum.                                       introduction or summative conclusion to a unit).

References
Black, P., & Wiliam, D. (1998). Assessment and classroom learning. Assessment in Education, 5(1), 7-74.
Bransford, J. D., Brown, A. L., & Cocking, R. R. (2000). How People Learn: Brain, Mind, Experience, and School.
         Expanded Edition. Washington, D.C.: National Academy Press.
Bransford, J. D., & Schwartz, D. L. (1999). Rethinking Transfer: A Simple Proposal with Multiple Implications.
         Review of Research in Education, 24, 61-100.
Ericsson, K. A. (2006). The Cambridge Handbook of Expertise and Expert Performance: Cambridge University
         Press.
Gawel, D. J., Philips, J. L., Svihla, V., Vye, N. J., Brown, M., & Meyers, E. (2008). New approaches to 21st century
         schooling: Preparation for future learning assessments and their instructional implications. Paper
         presented at the CAESL 2008: International Conference on Assessment for Learning in Science, San
         Francisco, CA.
Gawel, D. J., Phillips, R., Svihla, V., Vye, N. J., & Bransford, J. D. (2008). Considerations for the development of a
         Preparation for Future Learning Assessment. Paper presented at the ICLS, Utrecht, Netherlands.
Partnership for 21st Century Skills (2002). Learning for the 21st Century: a Report and Mile Guide for 21st Century
         Skills.
Svihla, V., Vye, N. J., Brown, M., Phillips, R., Gawel, D. J., & Bransford, J. D. (2009). Interactive Learning
         Assessments for the 21st Century Education Canada.

                                                     475     ISLS
