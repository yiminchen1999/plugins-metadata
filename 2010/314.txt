                                               ICLS 2010    Volume 2

Anomalous Graph Data and Claim Revision During Argumentation
 Leema K. Berland, University of Texas, 1 Univ. Station, Austin, TX 78712, leema.berland@mail.utexas.edu
      Victor R. Lee, Utah State University, 2830 Old Main Hill, Logan, UT 84322, victor.lee@usu.edu

        Abstract: The discourse practice of scientific argumentation requires individuals to consider
        anomalous data in light of existing claims that have been made. The extent to which students
        must be taught to revise their claims has been a subject of disagreement in the literature. In
        this poster, we use correlations and transcript excerpts to examine the relationship between the
        physical presence of referenced data and students' willingness to respond to anomalous data
        by revising their claims.

Introduction
Scientific argumentation is seen as an important disciplinary discourse practice for students of science because it
facilitates students' collaborative sensemaking (Duschl, Schweingruber, & Shouse, 2007).          However, it rarely
occurs in science classrooms (Driver, Newton, & Osborne, 2000). One challenge facing students as they engage
in this complex practice rests in their response to anomalous data. In particular, when presented with anomalous
data, students reinterpret the data to align with their original claims rather than revising them (e.g., Kuhn, 1989).
This suggests that students will not successfully use scientific argumentation as a context for collaborative
sensemaking. Instructionally, this implies that students must be explicitly taught to reconcile their initial claims
with anomalous data so that they can learn from argumentative interactions.       However, other researchers (e.g.,
Engle & Conant, 2002) have witnessed students productively working with and incorporating anomalous data
during argumentative discussions, without explicit instruction on how to do so. In addition, Hammer and van
Zee (2006) have     documented  students as young  as    kindergartners "reconciling  inconsistencies"    when their
personal theories contradict their observations of particular phenomena; the students they observed were quite
capable of revising their claims in response to contradictory evidence.
        The  current   study  takes some  initial steps   towards   reconciling these  opposing     observations  by
examining the context in which students are faced with and respond to anomalous data. We enter this study with
the hypothesis that the source of the anomalous data will influence the students' responses to it. In particular,
work such as Hug and McNeill (2008) demonstrates that students work with first- and second-hand data in very
different ways. Thus, this poster focuses on whether and how the presence of the data (if it is something the
students can see first-hand or if it is something that is reported to them by another individual) affects their
response to and engagement with anomalous data.

Data Sources
The data for this    analysis comes  from   video-recorded    observations of   a researcher-designed,    6th  grade
ecosystems unit (Finn et al., 2006) that was implemented in a self-contained classroom at a 100% African-
American charter school. As part of the curriculum, students worked with a simulated ecosystem built in the
NetLogo  modeling    environment   (Wilensky,  1999).  Toward     the end of their  work with     NetLogo,  pairs of
students used NetLogo's dynamically generated population graphs to determine what organism in that simulated
ecosystem (foxes, rabbits, or grass) was being eaten by an unknown invasive species. Following this, the pairs
joined with another pair in the class. That foursome was then asked to agree on what the invader ate. Video
recordings of two pairs and two foursome discussions were transcribed and analyzed for this current study.

Analytic Process
Data analysis consisted of a line-by-line examination of the students' evolving arguments about the model. We
began by identifying instances in which students presented counter or anomalous evidence. We then coded the
students' responses to that evidence. Based on the students' general tendencies, we identified 4 responses to the
anomalous evidence: ignoring it, rejecting it, reinterpreting it so that it supported the original claim and revising
the original claim. These correspond to a subset of the responses identified in Chinn and Brewer's study (1998).
In addition, we coded for whether the students were discussing first- or second-hand data. Second-hand data
included graphs individual students had observed earlier and were reporting to their group without showing
them. First-hand data were visible graphs displayed on the simulation software; they were public objects that
were physically present for discussion by the group. Coding of both the origins of the data and student responses
to data was done in a binary fashion: an utterance was given a "1" or a "0" for whether each possible behavior
(i.e., rejecting anomalous data, presenting first-hand data, etc.) was present in the utterance.
        Once  coding    had   been  completed, un-coded      utterances  (typically involving     content related to
classroom management or digressions) were removed.          This produced a large matrix of 1's and 0's. We used
this matrix and devised a `moving window' analysis in which we examined each turn of talk in combination

                                                   314     ISLS
                                              ICLS 2010    Volume 2

with the four turns of talk that followed it. For each `window' we calculated the total number of each possible
discursive behavior present in the window. This moving window analysis was key to examining the relationship
between the students' responses to anomalous data and the form of that data: the anomalous data was invariably
presented by one student and responded to by another. Summing across a span of utterances enabled us to
examine  these interactions. Correlations were run    on   the `moving        window'  sums, and passages with high
moving window scores were revisited for further interpretive analysis.

Findings
This analysis reveals that utterances that involved first-hand data (i.e., "the population is dropping here in this
graph") were positively correlated with student reinterpretation of anomalous data (r = 0.224; n = 188; p <
0.005). Moreover, there was a positive correlation between students discussing second-hand data (i.e., "when I
did it earlier, the population dropped") and students rejecting anomalous data points (r = 0.456; n = 188; r <
0.005). For example, when one student pair was working with the model, Tyler said he had seen a graph earlier
in which the rabbit population decreased (implying that the invasive species was eating rabbits), Kendra (who
believed the invader ate grass) responded, "okay, I don't need to hear yo' story no more." In this, and similar
instances, second-hand reports of data were dismissed or disregarded even if relevant to the current discussion.
This suggests that students were more willing to discuss their various interpretations of data they could see than
they were of data that one member was reporting.
        In addition, there was a positive correlation between first-hand data and student revision of their claims
(r = 0.153; n = 188; p < 0.05). For example, once directed toward first-hand data by his partner, Jonathan
revised his claim: he began claiming that the invader ate grass and concluded that it ate rabbits and grass. In
contrast there was a negative correlation between the students' second-hand reports of data they had observed
and student revision of claims (r = -0.218; n = 188; p < 0.005). This suggests that students were more likely to
find first-hand data compelling and revise their claims accordingly than they were with second-hand data

Discussion
Combining these relationships suggests that the context and materials present in the discussion influence the
frequency with which students engage with and discuss contradictory data. In these classroom observations, we
see that the presence of the data impacted whether students are more likely to engage with competing data
points or to reject them out of hand. Thus, this paper suggests that students can and do revise their ideas in light
of the evidence. That is, this is not a skill that they must be taught explicitly. It is, instead, something that we, as
educators, must work to motivate by creating contexts in which it makes sense for students to substantively
engage with the contradictory evidence. In this case, the presence of immediately accessible data seemed to
positively influence this whereas second-hand reports of data appeared to have a limited observable influence.

Endnotes
(1) Both authors contributed equally and are listed in alphabetical order.

References
Chinn, C. A., & Brewer, W. F. (1998). An empicircal test of a taxonomy of responses to anomalous data in
        science. Journal of Research on Science Teaching, 35, 623-654.
Driver, R., Newton, P., & Osborne, J. (2000). Establishing the norms of scientific argumentation in classrooms.
        Science Education, 84, 287-312.
Duschl, R. A., Schweingruber, H. A., & Shouse, A. E. (Eds.). (2007). Taking science to school:         Learning and
        teaching science in grades K-8. Washington, DC: National Academies Press.
Engle, R. A., & Conant, F. R. (2002). Guiding principles for fostering productive disciplinary engagement:
        Explaining an emergent argument in a community of learners classroom. Cognition and Instruction,
        20(4), 399-483.
Finn, L.-E., Kuhn, L., Whitcomb, J. L., Bruozas, M., & Reiser, B. J. (2006). Where have all the creatures gone?
        In J. Krajcik & B. J. Reiser (Eds.), IQWST: Investigating and questioning our world through science
        and technology. Evanston, IL: Northwestern University.
Hammer, D., & van Zee, E. H. (2006). Seeing the science in children's thinking: Case studies of student inquiry
        in physical science. Portsmouth, NH: Heinemann.
Hug, B., & McNeill, K. L. (2008). Use of first-hand and second-hand data in science: does data type influence
        classroom conversations? International Journal of Science Education, 30(13), 1725-1751.
Kuhn, D. (1989). Children and adults as intuitive scientists. Psychological Review, 96(4), 674-689.
Wilensky, U.   (1999). NetLogo  [Computer   Program]:    Center   for        Connected Learning and Computer-Based
        Modeling. Northwestern University, Evanston, IL.

                                                  315     ISLS
