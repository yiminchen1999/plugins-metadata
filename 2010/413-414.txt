                                                     ICLS 2010         Volume 2

                            Reflection Tools in Modeling Activities
  Nora Siewiorek,       Mary Besterfield-Sacre, Larry J. Shuman, University of Pittsburgh, 1048 Benedum Hall,
                                                   Pittsburgh, PA 15261
                                norasiew@pitt.edu, mbsacre@pitt.edu, shuman@pitt.edu
                  Eric Hamilton, Pepperdine University, 6100 Center Drive, Los Angeles CA 90045,
                                              eric.hamilton@pepperdine.edu

          Reflection and self-regulated learning are important skills for college level students to learn.
          We   have    developed   Model   Eliciting   Activities        (MEAs)   to  integrate these  activities while
          teaching students engineering concepts. A multi-tier design approach is used with MEAs as an
          element of change for students, instructors and researchers. Three generations of reflection
          !""#$%&'()%)("#()*%!"%*"+,-).!%&"/%$!,*).!%!)'-$0%/"12%".%resolving a posed problem and
          what have they learned from the experience.

Introduction
Reflection is seen increasingly as a valuable part of a portfolio of self-regulatory competencies in learning. One
of the most promising research topics in fields such as complex reasoning, problem-solving, critical thinking, or
modeling involves reflective activity. This poster addresses research on reflection in modeling. A focus on
modeling in problem-solving (creating structured and manipulable representations of a problem-situation) has
proven   productive     in  research  on   mathematical          cognition   in   applied  or   real-world  settings,     including
engineering.   In   particular, the  paper    reviews    how        devices  called   Reflection   Tools,  or  RTs,       have been
conjectured    to improve     modeling  competencies,     or      the  abilities of  students  to draw  upon,  use,  and     change
models in mathematical and engineering team problem-solving.
          A    companion    website  (http://modelsandmodeling.net/icls2010)               furnishes a  fuller set  of    modeling
scenarios and the data to which this paper refers. The research is supported by a Type III Collaborative Scale-
34% 51'.!% 61"-% 7890$% :",1$);% :,11<+,#,-% '.*% ='>"1'!"1?% @-41"()-).!% A::=@B% C1"51'-% ANSF                             Award
0717861). The instructional improvements sought involve the use of model-eliciting activities, or MEAs D in
undergraduate     learning.   MEAs   are  specialized   problem          simulations  that are  treated at length   in    numerous
sources recapped at http://modelsandmodeling.net. They were originally developed as tools to understand the
micro-evolution    of   mathematical   cognition.    That     is,   they were    used to trace  how,   in small   teams,    learners
expressed conceptual models as ways to describe a problem, and then manipulated or revised their models to
create a better fit to the problem and to test solutions to it. Over the course of a first generation of research in
modeling    eliciting  activities, several   crucial observations        became    foundational   to the  current   generation         of
research. One is that although MEAs were useful for exposing conceptual models and their evolution, they also
proved   to have    intrinsic  instructional value.   That    is,     as students   participated  in MEAs,     they grew     in the
modeling competence. Indeed, some of the strongest performance changes came from youngsters for whom
little was expected in terms of mathematical achievement. The applied problem-solving settings of model-
eliciting activities and the opportunity to express, test and revise models nourished and expanded mathematical
skills while   students   were  serving   as research   subjects.       Eventually,   MEAs    were   developed  for  engineering
students, and introduced in the first year curriculum of one of the largest engineering programs in the nation, at
Purdue University, as an instructional approach. Not only did students develop new expertise as they were
immersed    in MEAs,      but teachers  and   p r of esso r s who
focused   on    learner    modeling   and    changes     therein
changed   their   own   approaches   to   instruction. A      third
observation    is that  the various  r esea r ch  teams   began
altering their  own    models   of modeling.    The  collective
observation    of  multiple    dynamic     levels of   progress
towards   greater  expertise   (in modeling   by   students;        in
focusing    on    student  modeling    and   development          by
teachers;   and   in  recasting  the  type   of   emphases        on
problem-solving studies by researchers) eventually gave
rise to  what   has  been   referred to   as multi-tier  design
methodology.                                                                          Figure 1: The Tires Reliability MEA
          One     other observation    became     incorporated              (fully appearing at http://modelsandmodeling.net/icls2010)
into current   model-eliciting-activity    research.   Students
engaged     in MEAs       began    sharing   reflections  about
modeling    in    small     groups   that    mimicked,        at    a
metacognitive level, the phenomena of teachers become
more   astute  observers    of student  learning.  That   is,     as
students became more sophisticated in reflecting on their

                                                         413         ISLS
                                                    ICLS 2010    Volume 2

modeling, they became more sophisticated modelers. This led to theorizing about the role of guided reflection
and theorizing about using formal reflection tools as part of or subsequent to modeling activities. The focus
entails emphasizing how representations of the structure of a problem-situation D that is, a model - can evolve
through short-term cycles of expressing, testing and revising the representations in a team.

The Tires Reliability MEA and Associated Reflection Tool
The Tires Reliability MEA depicted in Figure 1 entails a set of reliability statistics that a team of three students
are expected to analyze in advance of preparing a report on the safety of a line of automotive tires. T he website
for this  wor k-in-progress    paper   includes     the full   problem,   data,   reflection tool   versions,   and    student
reflections. The Tires MEA requires students to develop a general model for determining if a tire production
run meets acceptable reliability and then apply that model to specific cases: three different grades of tires to
*)!)1-<.)% <6% !&)?% '1)% /<!&<.% '% E5"#*F% $!'.*'1*. Students must use the data set to determine the shape of the
distribution, use   probability  plots and    fully  understand   the   concept   of  variance.   A grading     rubric  is also
available on the website. Of interest here is the use of a reflection tool that evolved through three generations of
administering the MEA. Table 1 reflects each generation of the tool, the rationale for revising the tools, and the
strengths  and   weaknesses   that emerged     from   the revision. We    are  using  reflection   in two  ways:   both    as a
learning intervention and as an assessment tool.
         As instructors and researchers we are searching for deeper understanding of the use of reflection tools
in concert   with  MEAs.    Do  student reflections     help  researchers   suggest   the most    productive  ways   to  guide
students and when to let them struggle with ambiguity?            Can reflection tools be designed to provide a fuller
picture of the   team problem  solving and modeling      processes?    The revision   of  the reflection tools  will also  help
researchers elaborate on whether and to what degree reflection tools help students think about modeling, and
whether it leads to stronger modeling competencies.

Table 1:  Summary of Revisions in Three Generations of a Reflection Tool

   Refl. Tool !     Generation 1                     Generation 2                         Generation 3
   Where Used       Technical elective, upperclass students, during lecturetime; experienced instructorto MEAsStats course, required for somestudents; new instructor toMEAsRequired Stats course, sophomores;experienced instructor to MEAs;also branched out into otherengineering courses
                    Focus on team process,                                                Identify misconceptions in learning;
   Characteristicsof reflectiontoolthrough Wiki statistics(number of contributors,number of edits, questionsposed in postings, number ofConcept learning assessedthrough exam questions; inprocess assessment; on paper; 6question format, See Figure 1pre/post concept inventories used;provide high quality and timelyfeedback to students; focus onmodeling skills; 12 question format
                    drafts)                                                               online.
   Strengths        Rubric focused on: iteration     Individual reflections blended(express-test-revise), ethics,into team narratives; short,mathematical concepts,concise; drawing graph andproblem solving)label it provided rich insightLearning experience for student;defined important terms; guides$!,*).!$0%!&<.2<.5%"6%!)'-/"12;%concepts learned and skills used;reinforcing targeted concepts
                                                     In process assessment very
                                                     difficult; used unfamiliar terms
   Weaknesses       Instructor interpretation ofprocesswith open ended questions, wide    Long, almost all open endedvariety of responses; closedquestions with multiple parts
                                                     question made assumptions
                                                     about student feelings
                    More insight needed into
   Reason fornewgenerationteam process ; try to userepetition to move studentsfrom novice to expertMove to standardization andeasier implementation; move toelectronic versionReintroduce draw team progresschart and description
                    problem solvers

References
E. Hamilton, R. Lesh, F. Lester, and C. Yoon. (2007)           The use of reflection tools to build personal models of
    problem-solving. In R. Lesh, E. Hamilton, J. Kaput, J. (Eds.), Models & Modeling as Foundations for the
    Future in Mathematics Education., Lawrence Earlbaum Associates, NJ, Inc.
Shuman,    L.J., and    M. Besterfield-8'+1)% EE-MEAS:        Introducing   An    Ethical Component    To  Model     Eliciting
    ActivitiesF;%2009 ASE E Annual Conference & Exposition, Austin TX, June 2009.
Yildirim,  T.P.,   L.J. Shuman,  and   M.   Besterfield-8'+1);% EG"*)#% H#<+<!<.5% I+!<(<!<)$J% I$$)$$<.5% H.5<.))1<.5%
    8!,*).!%C1">#)-%8"#(<.5%'.*%82<##%@.!)51'!<".%C1"+)$$)$;F%'++)4!)*%6"1%4,>#<+'!<".%International Journal of
    Engineering Education.

                                                        414     ISLS
