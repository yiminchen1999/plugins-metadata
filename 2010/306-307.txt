                                               ICLS 2010     Volume 2

 Improving the Language Ability of Deaf Signing Children through
       an Interactive American Sign Language-Based Video Game
Kimberly A. Weaver, Harley Hamilton, Zahoor Zafrulla, Helene Brashear, Thad Starner, Peter Presti, and Amy
                          Bruckman, Georgia Institute of Technology, Atlanta, GA 30332
          Email: kimberly.weaver@gatech.edu, {harley.hamilton, zahoor, brashear}@cc.gatech.edu,
                            peter.presti@imtc.gatech.edu, {asb, thad}@cc.gatech.edu

         Abstract: We present the design of an interactive computer game-based intervention,
         CopyCat, in which deaf children use sign language to direct the actions of a character
         in the game.     We conducted a study to quantify the game's impact on expressive
         language    development    using    twelve participants     from  a local  school for   the deaf.
         Learners    in   the   experimental  group     improved     significantly  in  their    receptive,
         expressive, and sentence repetition abilities as opposed to those in the control group.

Motivation
Ninety percent of deaf children are born to hearing parents (Gallaudet, 2001).    These parents may not know sign
language, or have low levels of proficiency.    Deaf children of hearing parents develop language in the same
sequence as deaf children of deaf parents and hearing children of hearing parents, but at a much slower pace.
The slow language development for these children has been attributed to incomplete language models and a lack
of linguistic interaction (Spencer & Lederberg, 1997). CopyCat seeks to create an interactive, entertaining way
to provide additional language exposure and practice for deaf children.

Game Design and Interaction Model
CopyCat includes six language learning games for children ages six to eleven.           We used computer-assisted
language learning practices (Warschauer, 1996) and research on child-adult interactions (Spencer & Lederberg,
1997;  Schiefulbusch    & Bricker, 1981)  to help design   these   games.  Each game entails a quest by the main
character to collect items to remedy a problem, such as rescuing kittens from a villain. Children tell the main
character what to do via sign language.      Figure 1 shows the CopyCat interface.      The main game screen is
indicated by the letter A. The obstacle the child must help the main character overcome (the phrase that the child
must sign) is indicated by B.    In this case, the child must sign, SNAKE-UNDER-CHAIR. Before signing, the
children must   push  a  "talk" button (C) to "attract  the   hero's attention" and to  activate the automatic  sign
language recognition system. The children can view themselves directly on the computer as they are signing
(D). When they are finished, they push the "talk" button (C) again, stopping the automatic recognition system.
If the children are uncertain what to sign, they can click a "help" button (E) to see the "tutor" (F) demonstrate
the required phrase.    Our tutor performs the role of the good adult language model (Schiefulbusch & Bricker,
1981).   The   tutor is always  available and responds     in an appropriate linguistic manner.   The  tutor is also
extremely patient as the children can ask for help as many times as they like, and the tutor never becomes tired
or frustrated.

                           Figure 1. The CopyCat Interface (see text for description).

         After the child signs a phrase, the sign language recognition system evaluates the child's utterance to
determine its accuracy.   Features derived from computer vision, and motion sensors embedded in gloves worn
by the child, supply the recognizer with information of the child's signed phrase, similar to (Brashear et al.,
2006). If the child's utterance is incorrect, a question mark appears above the character's head, indicating that

                                                    306     ISLS
                                                ICLS 2010    Volume 2

the he  did not  understand  the  child's sign.  The child   must   try again to  communicate     until the  computer
recognition system judges the sign to be of sufficient clarity, but is limited to five attempts to prevent the child
from becoming frustrated.    All game sentences are of the structure Subject-Preposition-Object. There were
twenty 3-sign sentences, twenty 4-sign sentences, and twenty 5-sign sentences.

Study
Twelve participants between the ages of six and eleven were recruited at a local residential school for the deaf.
Participants were asked to configure toys based on signed instruction (receptive); express an event depicted in a
stop-motion animation (expressive); and repeat a signed phrase (sentence repetition), at both the beginning and
end of the study. Most vocabulary used in the pre and post tests was not used within CopyCat.           A one-tailed,
one-way between-groups analysis of covariance was conducted to compare the effect of using CopyCat on the
learners' receptive, expressive and repetition test scores.  After adjusting for pre-intervention scores, there  was a
significant difference between the control and experimental groups on post-intervention scores for all three
tests: the receptive language test F(1, 9) = 11.83, p < 0.05, partial eta squared = 0.57, expressive language test
F(1, 9) = 8.29, p < 0.05, partial eta squared = 0.48, and the sentence repetition test F(1, 9) = 3.6, p < 0.05, partial
eta squared = 0.29.   There was a strong relationship between the pre-intervention and post-intervention scores
on  all three tests.  The   learners who   played   CopyCat    improved    their test scores   on all  three measures
significantly more than the learners who did not.   Table 1 shows the mean scores on each of the three tests for
both groups at the beginning and end of the study.

                          Table 1. Table of Means for Pre and Post Intervention Scores
 Test                       Group                 N          Pretest M (SD)                Post-test  M (SD)
 Receptive Language         Control               6          4.00 (4.69)                   4.50 (5.21)
                            Experimental          6          5.17 (3.66)                   8.83 (5.04)
 Expressive Language        Control               6          5.50 (6.32)                   7.33 (5.05)
                            Experimental          6          4.50 (3.39)                   10.33 (4.37)
 Sentence Repetition        Control               6          6.67 (4.84)                   7.33 (5.05)
                            Experimental          6          5.17 (2.79)                   7.83 (3.37)

Conclusion
CopyCat demonstrates that automatic sign language recognition is of sufficient quality to be used in interactive
games with positive educational effects. While CopyCat is intended to supplement, not replace, high-quality
adult-child sign language   interaction,  its interaction  method   provides  a  useful  computer-based    method  for
rehearsing language skills.

References
Gallaudet Research Institute. Regions regional and national summary report of data from the 1999-2000 annual
         survey  of  deaf and   hard  of  hearing  children   and   youth. Technical   report, Gallaudet   University,
         Washington, D. C., January 2001.
Spencer, P. & Lederberg, A. (1997). Different modes, different models: Communication and language of young
         deaf children and their mothers. In L. Adamson and M. Romski (Eds.) Communication and Language:
         Discoveries from atypical development (pp. 203-230). Baltimore: Paul H. Brookes.
Schiefulbusch,   R.L.  &  Bricker,   D.D.  (1981).  Early    Language:   Acquisition  and    Intervention. Baltimore:
         University Park Press.
Warschauer M. (1996). "Computer Assisted Language Learning: an Introduction". In Fotos S. (Ed.),Multimedia
         Language Teaching (pp. 3-20). Tokyo: Logos International.
Brashear, H., Henderson, V., Park, K., Hamilton, H., Lee, S., & Starner, T. (2006). American sign language
         recognition  in game   development    for  deaf  children. In  Proceedings   of the 8th  International  ACM
         SIGACCESS Conference on Computers and Accessibility (pp. 79-86). Portland, Oregon, USA: ACM.

Acknowledgements
This work   has  been  supported   by  the U.S.    Department   of  Education    Institute for Sciences    under grant
R324A070196; the Rehabilitation Engineering Research Center for Wireless Technologies (sponsored by the
National Institute on Disability and Rehabilitation Research of the U.S. Department of Education under grant
H133E060061).    Thanks also to the Atlanta Area School for the Deaf, Georgia School for the Deaf, and Minor
Elementary School in Gwinnett.

                                                    307     ISLS
