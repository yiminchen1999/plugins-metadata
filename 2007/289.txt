         The Relationship Between Student Interaction and Message
                    Readability in Asynchronous Online Discussions

            Jim Hewitt, Vanessa Peters, OISE University of Toronto, 252 Bloor St. W. Toronto ON Canada
                                 Email: jhewitt@oise.utoronto.ca, vpeters@oise.utoronto.ca

         Abstract:    The    current   study   explores the  relationship   between   the readability  of  computer
         conferencing messages and the level of student interaction in asynchronous online discussions.
         Large-scale quantitative analyses were performed on the activity logs of 37 graduate-level distance
         education courses at the University of Toronto. The mean Reading Ease and Grade Level scores of
         student messages were found to be significantly correlated with the mean number of messages that
         students write, the percentage of student messages that reply to other messages, and mean message
         size.  A   correlation  was  also  found  between   the  readability of  instructor messages     and student
         messages. Consequently, the data suggest that a positive relationship exists between readability
         and the level of student online interactivity. Possible explanations for these results are discussed.

Introduction and Objectives
         The    current  study   examines   the  readability   of messages    in computer-mediated     conferencing    (CMC)
courses, and    the role that   readability plays  in online  discussions.  What    relationship, if any,  exists between  the
readability of conferencing messages and online activity patterns?         Does writing style affect the volume of messages
that students   contribute  to  their online   course?  Is  there  greater interaction in courses    that have  more  readable
messages?    How     does   the readability  of student   messages   relate to   the readability  of teacher  messages?     By
exploring these questions it is hoped that we can develop a deeper understanding of some of the factors that promote
and sustain collaborative online discourse.

Background
         Readability formulas predict the difficulty level of a text using mathematical equations. Two widely used
systems for scoring   readability  are the Flesch  Reading    Ease score and   Flesch-Kincaid Reading Level       (Friedman &
Hoffman-Goetz, 2006). The Flesch Reading Ease score rates text on a 100-point scale, with lower scores being more
difficult to read than higher scores. The Flesch-Kincaid Grade Level formula is similar to the Flesch Reading Ease
score, but it is converted to a U.S. grade level equivalent (Friedman & Hoffman-Goetz, 2006). Both algorithms are
based  on   the word  and    sentence  length   of a  text.  Although  other  types   of tests are   available, these two  are
extensively used, in part because they are features of Microsoft Word and are thus easily obtained.

         Despite their widespread popularity, readability formulas have been the subject of much academic scrutiny.
Klare (1963) identified a number of limitations associated with readability measures. Since readability assessment
involves the quantification of textual features, important elements such as word order, content, and organization are
left unaccounted for. Redish (2000) suggests this problem is exacerbated by the fact that formulas consider only one
or two textual features, usually word and sentence length. Readability may also be dependant on readers' topic
preferences, resulting in scores that are highly variable (Dufty, Graesser, Louwerse, & McNamara, 2006), or scores
that differ between   parts   of the  same   text (Redish,   2000). In spite  of  these  criticisms, many   researchers view
readability formulas as valuable tools. Of particular appeal is their simplicity and ease of use.         Readability measures
also serve purposes other than assigning appropriate grade-levels. For example, readability formulas have become
standard features on many word processing programs, making it possible for authors to measure the difficulty of a
text while still in the process of writing it.

         Readability     is arguably   associated    with  online  CMC     culture.  Many  researchers     have   explored the
importance   of  community      on student  interaction   in online discussions   (Wegerif,  1998;   Garrison,    Anderson, &
Archer, 2001). Romanoff (2003) observes that although online discourse increases the physical distance between
conferencing members, "...it can also serve to reduce that distance by enhancing the sense of community among
students and teachers" (p. 58). In addition to learning from each other (Brown, 2001) students establish relationships
with other  members     of  the class, resulting  in  feelings of  acceptance  and   well-being   (Wellman    & Guila, 1999).
According to Collison, Elbaum, Haavind, and Tinker (2000), regular participation and a demonstrated concern for

                                                               289                                                   CSCL 2007
others are hallmarks of a healthy online community. Regular participation is a reflection of open communication,
and indicates intellectual trust between participants (Collison, et al., 2000).   Message readability would be expected
to influence  the openness    of communication    and mutual      trust  within  such a  community.   However,     message
readability, which is presumably an important influence on online collaboration and communal development, has
not  been examined   in  the research literature. The current     study  begins  to address  this issue by  examining  the
relationship between readability and interaction using a large dataset of 37 computer conferencing courses.

Method and Data Sources
          Data were collected from 37 graduate-level distance education courses offered at the University of Toronto
between   January 2003   and  December     2005.  To be considered       for the study,  a course  had  to satisfy  several
conditions. First, the course had to be delivered purely online, without any face-to-face components. Second, the
course had to utilize the course web-based conferencing system Knowledge Forum, which maintains time-stamped
logs of student's online activity. Lastly, the central activity of the course had to be participation in the asynchronous
discussion forum. Adherence to the preceding conditions ensured that the courses were comparable in design and
pedagogy, making it easier to study message readability across courses.

          The class sizes in the dataset ranged from 5 to 21 students and all courses were 13 weeks in length. They
took the form of a series of weekly seminars in which learners were expected to discuss assigned class readings in a
shared asynchronous threaded environment. Fourteen different instructors taught the 37 courses. Web Knowledge
Forum records detailed time-stamped logs of each time that an online participant opens or saves a message.          The full
text of all messages  is also preserved. The  current study      used this  data to explore  the  relationship between the
following measures in each course:

          1.  Readability Measures:     Two  common     measures      of readability  were adopted  for the  study:  Flesch
              Reading Ease score (ranges from 0 to 100) and the Flesch-Kincaid Grade Level.
          2.  Message Count: The message count is the total number of messages contributed to an online course
              by a student.
          3.  Interactivity  Ratio: The  student  interactivity    ratio is  the percentage  of   messages  that  a student
              contributes as "replies" to one of their classmate's contributions. The Interactivity Ratio is calculated
              for each participant by dividing the number of "replies" by the total number of messages written. A
              high ratio (a value close to 1.0) suggests a high degree of interactivity.
          4.  Message Size: The message size is the average size of all messages written by a student, in words.

          Course averages were computed for each of the preceding measures by averaging the scores of individual
students. Thus, for each of the thirty-seven courses, the following student and teachers mean scores were calculated:
Reading Ease, Grade Level, Message Count, Interactivity Ratio, and Message Size.

Results
          An analysis of the data revealed a number of statistically significant correlations involving the readability
of conferencing   messages.   Since the correlations used data     from   37 courses,  there were  35   (N ­ 2)  degrees of
freedom for all statistical tests. The findings are as follows:

Readability and Messages Written
          The number of messages written by students was strongly correlated with their Reading Ease scores (r =
.62, p < .01), and negatively correlated with their Grade Level scores (r = -.55, p < .01).  Accordingly, the results
suggest that a relationship exists between the readability of student messages and the number of messages they
write.  Productivity, at least in terms of message generation, appears to be associated with more readable text.

Readability and Interactivity
          The student interactivity  ratio correlated positively      with  both  the Reading    Ease scores   of students'
messages (r = .25) and teachers' messages (r = .38, p < .05), although only the latter was statistically significant.
Student interactivity was also negatively correlated at a statistically significant level with both student (r = -.42, p <
.05) and teacher (r = -.43, p < .01) Grade Level scores.        All of these correlations offer evidence of a relationship
between readability and interactivity. (Note that low Grade Level scores are an indicator of highly readable text).
These findings suggest that levels of interaction are tightly tied to the readability of student and teacher messages.

                                                          290                                                     CSCL 2007
Higher proportions     of  learner interaction  are  associated   with a class-wide   tendency  to  produce   more  readable
messages.

Readability and Message Size
         The   mean  message     size of student  conferencing    messages  correlates   positively with their Grade    Level
scores (r = .75, p < .01), and negatively with their Reading Ease scores (r = -.62, p < .01). Both correlations were
strongly  significant, suggesting     that courses   containing   longer students   messages   also  contain   less readable
messages, on average.      In contrast, the mean message size of instructor messages was not significantly correlated
with readability measures. Thus, while students often use more complex language when writing longer messages,
teachers do not share this tendency.     The combined results of this analysis and the first analysis (i.e., "Readability
and Messages Written") suggest that courses that contain highly readable messages tend to contain a significantly
greater number of messages, but messages that are shorter in length.

The Relationship Between the Readability of Teacher and Student Messages
         Student and teacher Reading Ease scores were significantly correlated (r = 0.35, p < .01). The correlation
between teacher and student Grade Level scores was also positive (r = 0.24), but it was not statistically significant.
These results offer some evidence that a relationship exists between the students' style of writing and that of their
instructor. That is, if a teacher produces highly readable text, then the students in the class are also likely to produce
readable text.   Whether    this relationship  is causal (e.g., the teacher  serves   as  a model   of writing practices    for
students) or due to other factors (e.g., complexity of content) is unclear.

Conclusions
         The preceding analyses uncovered a number of relationships between readability and online interaction.
Statistically  significant relationships   were discovered    between   the readability  of  student messages   and    (i) The
number of messages students write (positive correlation); (ii) The size of student messages (negative correlation);
and (iii) The percentage of messages that reply to other messages (positive correlation).        In other words, in courses
in which    student messages     score higher  on  the two  readability  metrics,   there is greater   interaction and  more
message-writing (although the messages are significantly shorter in length).

References
Brown, R. E. (2001). The process of community -building in distance learning classes [Electronic version]. Journal
         of Asynchronous Learning Networks, 5(2), 18-35.
Collison, G., Elbaum, B., Haavind, S., & Tinker, R. (2000). Facilitating online learning: Effective strategies for
         moderators. Madison, WI: Atwood.
DuBay,   W.   H. (2002).   Using   readability tools. Paper   presented  at the  fourth biennial conference    of  the PLAIN
         Language Association International, Toronto, Canada.
DuBay, W. H. (2004). The principles of readability. Costa Mesa, CA: Impact Information Plain-Language Services.
Dufty, D. F., Graesser, A. C., Louwerse, M., & McNamara, D. S., (2006). Is it just readability, or does cohesion play
         a role? In R. Sun & N. Miyake (Eds.), Proceedings of the 28th Annual Conference of the Cognitive Science
         Society (pp. 1251). Mahwah, NJ: Erbaum.
Friedman, D. B., & Hoffman-Goetz, L. (2006). A systematic review of readability and comprehension instruments
         used for print and web-based cancer information. Health Education & Behaviour, 33(3), 352-373.
Garrison,   D. R.,  Anderson,    T., & Archer,    W.  (2001). Critical   inquiry in a text-based    environment:   Computer
         conferencing in higher education      [Electronic version]. The Internet and Higher Education, 2(2/3), 87-105.
Klare, G. R. (1963). The measurement of readability. Ames, IA: Iowa State University Press.
Redish, J. (2000). Readability formulas have even more limitations than Klare discusses. ACM Journal of Computer
         Documentation, 24(3), 132-137.
Wegerif,  R.   (1998). The  social    dimension   of asynchronous   learning  networks    [Electronic  version].   Journal  of
         Asynchronous Learning Networks, 2(1), 34-49.
Wellman, B., & Gulia, M. (1999). Net-surfers don't ride alone: Virtual communities as communities. In B. Wellman
         (Ed.),  Networks   in the   global village:  Life in contemporary    communities    (pp.   331-366).  Boulder,    CO:
         Westview Press.

                                                              291                                                   CSCL 2007
