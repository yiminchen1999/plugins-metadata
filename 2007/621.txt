                                        Partner Modeling Is Mutual

                          Mirweis Sangin, Nicolas Nova, Gaëlle Molinari, Pierre Dillenbourg,
  Ecole Polytechnique Fédérale de Lausanne (EPFL), School of Computer and Communication Sciences, CRAFT,
                          EPFL-CRAFT CE 1 631 Station 1 CH-1015 Lausanne Switzerland,
                     {mirweis.sangin, nicolas.nova, gaelle.molinari, pierre.dillenbourg}@epfl.ch

          Abstract. It has been hypothesized that collaborative learning is related to the cognitive effort
          made  by co-learners    to build a  shared   understanding.    The   process  of  constructing   this shared
          understanding requires that each team member builds some kind of representation of the behavior,
          beliefs, knowledge or intentions of other group members. In two empirical studies, we measured
          the accuracy of the mutual model, i.e. the difference between what A believes B knows, has done
          or intends to do and what B actually knows, has done or intends to do.         In both studies, we found a
          significant correlation between the accuracy of A's model of B and the accuracy of B's model of
          A. This  leads  us  to  think that the  process    of modeling   one's   partners does   not simply   reflect
          individual attitudes or skills but emerges as a property of group interactions. We describe on-going
          studies that explore these preliminary results.

Introduction
          It is now broadly admitted that learners do not benefit from collaboration simply because they are in a
group  but   because collaboration      triggers additional   activities  such  as  explanation,   disagreement    and   mutual
regulation (Dillenbourg, 1999). According to Roschelle and Teasley (1995), many CSCL scholars conceptualized
collaborative learning as an activity in which shared knowledge is constructed by peers through their interactions
with each other and also with their environment. The notion of shared knowledge is derived from psycholinguistic
concept of "grounding" (Clark &Wilkes-Gibbs, 1986): during interactions, the "interactants" constantly try to ensure
a good    mutual  understanding.     Grounding    is the  collective   process   through    which  individuals   engaged   in a
conversation try to ensure their mutual understanding. 'Shared understanding' or 'mutual understanding' is a very
intuitive concept, both   for  analyzing  interactions   and    for designing   applications, which    probably  explains  their
impact on CSCL. However, the notion of shared understanding is questioned both within psycholinguistics (Sperber
& Wilson, 1986) and within CSCL (Baker, Hansen, Joiner & Traum, 1999; Koschmann & LeBaron 2003). Our
research  questioned mutual    understanding     in  a different    way: we zoom     in on  the   mechanics   of grounding    by
analyzing how a shared solution emerges from the sum of a long sequence of contributions (Dillenbourg & Traum,
2006). We further attempt to understand the socio-cognitive benefits of co-constructing a shared understanding. We
investigate  a mechanism     that is hypothesized    to  lie at the  heart of   grounding.  For   Clark and   Brennan   (1991),
common    grounds  are  a set  of mutual   beliefs   defined as  the   amount   of information   shared (e.g.   presuppositions,
knowledge,     assumptions,   beliefs). Establishing    this  set   of beliefs  requires    that the  co-learners  build  some
representation of their partners' knowledge, beliefs and goals. We refer to the process of building assumptions about
the beliefs and the knowledge of their partner(s) as mutual modeling (Dillenbourg, 1999). However, the abstract
and unobservable     aspect   of  this  process   raises methodological      challenges     regarding  its comprehension      by
researchers. Therefore,   this paper   attempts  to  ask a   general   question about   the socio-cognitive   nature of  mutual
modeling by assessing whether the process of modeling one's partner is grounded at the individual or the group
level.

          The paper does not describe environments for collaborative learning but reports basic research on the socio-
cognitive mechanisms related to mutual modeling. The first section explores the concept of mutual modeling and its
relationship with CSCL features such as scripts and awareness tools. The second and third sections describe two
empirical studies in which the accuracy of mutual models is measured. The concluding section describes how the
hypotheses arising from these two studies are currently being investigated through two other studies, which focus on
a CSCL setting with a stronger educational flavor.

Mutual modeling in collaborative tasks
          The ability to perceive a partner's understanding and to adapt to his/her viewpoint has been investigated
under the labels of intersubjectivity (Wertsch, 1985; Bromme, 2000) and audience design (Lockridge & Brennan,
2002).  Suthers  (2006)  recently  proposed   "the   technology     affordances  of intersubjective   meaning-making"     as  an
integrative agenda for CSCL research. For him, a common denominator of understanding learning in a collaborative

                                                                621                                                   CSCL 2007
setting is the peers' attempt to make sense of situations and of each other. Intersubjectivity is played in the field of
the physical and historical context available to the participants to jointly compose interpretations, which could be
considered as a new gist for collaborative learning, an alternative to the notion of producing mutual-beliefs about
making  unshared   information   shared.  To  sum   up, taking   into  account  the  peer's perspective  is a  crux  facet   of
intersubjectivity on  which  most   of the  social  activities depend.  As   highlighted  by   Malle (2003),   the   ability to
represent  and reason   about    self and   other's  mental    states (e.g. beliefs,  desires,  intentions, mere     thoughts,
experiences, emotions, attitudes) is a great achievement in the evolution of the human mind and is considered a
prerequisite for  many  social   and  cognitive  processes     such as  natural language    acquisition,  social  interaction,
reflexive thought, and moral development.

          The term "mutual modeling" does not imply that collaborators maintain a detailed representation of their
partner's knowledge, nor an explicit one. Simply stated, if A is able to (dis-)agree with B, it means that A needs has
representation of B's intentions; if A wants to repair B's misunderstanding, A needs some representation of what B
has understood. Mutual modeling is as functional as the grounding process: the degree of accuracy depends on the
task requirements; an extremely high level of accuracy is demanded if two pilots collaborate on landing a plane, as
in Hutchins' (1995) observations, but the level of accuracy can be much lower if the pilots are discussing their last
party. Moreover,   mutual   modeling   does  not occur  in  a  vacuum   but is  based  on multiple  inference   mechanisms.
Common     grounds  are initialized by  the assumptions    people   make    about their partner  from cues  such   as his/her
community membership (age, culture, profession, ...) and from co-presence (e.g. common ground includes any event
to which A and B attended together) (Clark & Marshall, 1981). Several scholars studied how this initial modeling
impacts   communication,  namely    because  it  can easily   be manipulated.   For  instance,  Slugoski,  Lalljee,  Lamb    &
Ginsburg   (1993)  pretended  to their research  subjects   that their (fake)  partner  had or  had  not received    the same
information. They observed that the subjects adapted to their partner by focusing the explanation on the items that
(s)he was supposed to ignore. Brennan (1991) showed that the subjects used different initial strategies in forming
queries depending on who they were told their partner was. Other simpler inference mechanisms such as default
reasoning rules (e.g. B agrees with me unless he disagrees) are developed according to the conversational context.
Mutual modeling could not occur independently from culturally acquired interaction schemata that constrain the
space of interpretation of the other's behavior. Actually, the CSCL notion of 'scripts' (Dillenbourg, 2002) can be
conceptualized as providing co-learners with an explicit schema that narrows down the space of interpretations and
therefore  serves  as prosthesis for   mutual   modeling.   Another    prosthesis for   mutual  modeling    is the  notion   of
awareness tools (Greenberg & Roseman, 1996); these are features of CSCW environments in which A is informed
about the actions of B that A has not directly perceived.

          Even when    mutual modeling    is not   detailed and  explicit,  reasoning   about  what  one's  partner  believes
involves some cognitive load. For Clark & Wilkes-Gibbs (1986), what is important is not the individual effort made
by the receiver of a communicative act, but the overall least collaborative effort. The cost of producing a perfect
utterance  may    be  higher  than    the  cost  of  repairing    the  potential   problems    which  may      arise  through
misunderstandings. For instance, subjects are less careful about adapting utterances to their partner when they know
they can provide feedback on his/her understanding (Schober, 1993). We introduce instead the notion of `optimal
collaborative effort' (Dillenbourg et al, 1996) to stress that misunderstanding should not be viewed as something to
be avoided (even if this were possible), but as an opportunity to explain, to justify, and so forth. Here we enter the
global argument regarding cognitive load in learning activities, namely in discovery learning environments: there is
no learning without cognitive load, but overload may hinder learning (Paas, Renkl & Sweller, 2003). In the context
of collaborative  learning, we   understand  the  cognitive    load induced  by   mutual  modeling   as  part  of Schwartz's
(1995) notion of effort towards a shared understanding. For instance, conflict-resolution scripts or JIGSAW scripts
are purposely designed for augmenting (reasonably) the effort group members have to engage to reach a shared
solution.

          Mutual   modeling  has  many    dimensions,   from   which   we   dissociated  'dispositional' versus   'situational'
aspects. The 'dispositional' aspects refer to A's representation of B's long term knowledge, skills or traits. It is thus
closely related to the notion of transactive memory (Wegner, 1987; Moreland, 2000). 'Situational' aspects refer to
A's representation of B's knowledge, behavior or intention specifically activated in the situation in which A and B
are collaborating.

          This leads us to the long term research question that underlies our work: does the mutual modeling process
contribute to  the learning  outcomes    of collaborative   problem    solving?   This  question is  difficult to  investigate

                                                            622                                                      CSCL 2007
because the degree of mutual modeling is both difficult to manipulate as an independent variable, and difficult to
measure as a dependent variable. Measuring it is difficult because, as soon as one asks learners what their partner
knows, is doing or intends to do, we trigger a modeling process beyond what it would 'naturally' be. Controlling the
degree of mutual  modeling is also difficult. As   we  mentioned   earlier, scripts and  awareness    tools potentially
influence the mutual modeling process, acting as a kind of prosthesis. Now, like any prosthesis involved in learning,
we ignore whether scripts and awareness tools will augment the mutual modeling process (by scaffolding it) or
inhibit it (by making it useless). Moreover, it is difficult to estimate the accuracy of a mutual model in absolute
terms. Thus, this study focuses on a simple question: considering M(A,B) as being A's representation of B, what is
the relationship between M(A,B) and M(B,A)?

        An alternative hypothesis is that participants do not build a representation of their partners' mental states
but instead build a representation of the interaction process at the group level: instead of modeling who knows what,
who does what or who said what, the team members could maintain a representation of what the team knows, has
done or has said. We refer to this as the group model. This alternative is directly inspired by distributed cognition
theories (Pea, 1993; Salomon, 1993; Hutchins 1995) and the team mental model (Canon-Bowers, Salas, Converse,
1993). The two hypotheses are of course complementary since these two models feed each other.

        This paper does not directly examine these general research questions but reports results collected in two
empirical studies on mutual modeling, one occurring in a virtual environment and the second in real space. These
results are discussed in light of social and cognitive theories. The discussion also mentions on-going studies on the
mutual modeling process within more traditional collaborative learning settings.

Study 1
        We attempted to measure mutual modeling by using awareness tools in a collaborative video game called
Spaceminers. The research question was to study the impact of an awareness tool on group performance and mutual
modeling. The availability of an awareness tool was our independent variable. The main results have been published
in (Nova, Wehrle,  Goslin, Bourquin,  Dillenbourg,    2006).   We  focus    here on  the question    addressed in   the
introduction, that is, the relation between the modeling performed by each user or the relation between M (A,B) and
M (B,A). Our main dependent variable is the mutual modeling accuracy, henceforth referred to as MM-accuracy

Experiment design
        SpaceMiners is a 3D computer game that involves two players in space missions in which they have to
collect minerals located in asteroids and bring them to a space station.    To do so, they shoot drones through the
space after choosing their initial direction and speed. Once launched, the trajectory of drones is only influenced by
the gravity of planets and by specific tools that players collaboratively position between planets.

        During the  experiment, the teams     were  confronted  with three   increasingly  complex     situations. The
experiment was 2 hours long, with a 30 minutes tutorial and 3 levels of 30 minutes. Thirty-six persons participated
in this study, all native French speakers. We constituted 18 pairs of participants (N = 18) who were not familiar with
each other. The pairs were assigned randomly to either the control condition (without the awareness tool) or the
awareness condition (with the awareness tool). In the awareness condition, team members could view what their
partner was looking at and were therefore expected to more accurately infer his/her teammate's intentions. Each
player sat in front of a distinct computer located in different rooms. They interacted with the game using a regular
Logitech joystick and communicated with each other through an audio channel.

Measures
        Task performance was measured by the score reached by the subjects after three situations. In order to
evaluate the mutual modeling accuracy during the task, we used two questionnaires as shown on Figure 1. Both of
them were displayed during each of the three phases of the game, as a transparent layer appearing on the game level.
The first questionnaire concerned the player's intended actions. It asked each player about what they were intending
to do at the moment (guide his partner, try to understand his strategy, try to establish a common strategy, adjusting a
shot, etc.). The second questionnaire asked each player about what he thought the partner was intending to do. Some
answers were identical in both questionnaires (like "adjusting a shot") while others were reversed. For instance, the
answer "guide him" was reversed  as "guide    me"  and vice-versa. Each  questionnaire   then had    10 questions  that
covered the basic actions that could be performed.

                                                         623                                                  CSCL 2007
                    Figure 1: Crossed questions for measuring mutual modeling accuracy.

        These questionnaires gave us the possibility of comparing player A's prediction about B's intentions with
B's self-declared intentions. Of course, this method presents the same limitations of any questionnaire in which
somebody   has  to self-declare his or her  intentions. We   compared   the first answer  of a player (about    what A   is
intending  to do)  to the answer   of his  partner to the  second  question (about  what  B  believes A   is doing).  Our
estimation of MM -accuracy has been computed as the number of common answers given by the two players to
those  two questionnaires:  does   A's prediction   of  B's answer  matches   B's  actual answer? Since    there   were  3
evaluations (one per level), we computed the MM-accuracy per individual for each level of the game. The global
MM-accuracy is the sum of these 3.

Findings and Discussion
        The awareness tool permitted higher group performance, but it did not improve the accuracy of the mutual
model.  However,   within  the experimental   group,   the pairs who intensively  used the   awareness tools    obtained a
significantly higher MM accuracy (for more details, see Nova et al., 2006). In order to compare M (A,B) and M
(B,A), we  computed    intraclass correlation as   described by  Kenny   et al. (1998) from  the answers     to the cross-
questionnaires. We found a positive and significant correlation (r = .38, p < .05) between M (A,B) and M (B.A).
This sounds like a minor result for this particular study but actually conveys an important outcome: mutual modeling
appears to be   a  group  variable  rather than  a  personal  activity. We  expected   MM-accuracy     to be    a personal
parameter, i.e. that some participants spontaneously pay more attention or engage more effort in monitoring their
peer. This could be due to some social attitude or to specific cognitive skills required to build a mutual model. This
strong correlation between M (A,B) and M (B.A) supports a different hypothesis in which mutual modeling emerges
as a property of the quality of interactions among peers: some pairs seems to collaborate in such a way that their
verbal and non-verbal interactions produce more cues available to both partners so that they can build a mutual
model. This does not remove individual variability (correlation was not 1). Interestingly, we found that the relation
between M(A,B) and M(B,A) was not very different in the two conditions: the average absolute difference between
MM-Accuracy (A,B) and MM-accuracy (B,A) is not significantly different with or without the awareness tool ( F
[1,13]= 0.1445, p-value = 0.7097)

Study 2
        In this second study, instead of evaluating mutual modeling during the task, we chose to measure it after
task completion. This experiment was based on a pervasive game called Catchbob. As in the previous experiment,
this game was used to evaluate the influence of awareness tools on group performance and MM-accuracy, but we
will focus here on the results concerning the relationship between M(A,B) and M (B,A).

Experimental design

                                                            624                                                   CSCL 2007
          Catchbob is an experimental platform implemented as a mobile game in which groups of 3 players have to
solve a joint task. The game was played on the school campus and participants had to find a virtual object ('Bob')
and catch it by forming a triangle around it. Players used a Tablet PC that displays a map of the campus and an
indication of their personal distance from Bob. Their annotations on the map were shared with the two other players,
but fadeout after a few minutes. The awareness tool displayed the location of the two other players on the map.
Henceforth, we will refer to this information as mutual location awareness (MLA). It constituted our independent
variable.

          In this  study, we selected  groups of students   from   the  same  class and  who  therefore  knew  each  other.
Ninety   students  participated in  this experiment.   We     assigned  10 groups   of  3 persons  to each    of our three
experimental conditions: the control condition (without MLA) and two experimental conditions: synchronous MLA
(display current position of each player) and asynchronous MLA (display current position of each player and their
spatial trace). We controlled group gender so that each condition was made up of 25% of female and 75% of male.

Measures
          As a dependent variable, we measured MM-accuracy by asking players to draw their own path and the one
of  each  of their partners after the game.  This enabled     us to calculate the  number  of errors  players made   while
drawing the path of their partners. We compared the path player A attributed to B with B's real paths recorded by the
system and the same for A&C or B&C as depicted on Figure 2.

    Figure 2. (Left) Drawing A made of B's path; (Right) Real path followed by B as extracted from the logfile.

          We computed the number of errors between M(A, B) and M(system, B). What we counted as an error was
either drawing a place where the partner had not been or not drawing a place where he/she had gone. Three criteria
were defined    to describe  these errors: distance   (if the line  was  longer than the  maximum     size of our  campus
corridor), presence of an obstacle (door/wall/glass), and walking back (not perceived as an error). An individual
MM-accuracy is the sum of errors made by a player about his/her two partners' paths. We calculated MM-accuracy
for each  individual  (M   (A,B), M   (B,A), M (A,  C),   M   (B,C),...) and  for each group  (the sum   of the  individual
measures).   It is important to stress that  subjects made    very  few  mistakes   when  drawing  their own  path  on the
campus (85% made 0 errors). This enables us to consider mistakes in their partners' path as being due to a lack of
mutual modeling accuracy instead of being due to spatial skills (e.g. a difficulty in reporting trajectories on a map).

Findings and Discussion
          We did not find any significant difference regarding the task performance between the three experimental
conditions. However, our surprise was that the absence of the awareness tool led player to higher MM-accuracy:
players better remembered their partners' path if they did not see their position permanently. We will not enter into
the details of these results but simply stress that teams without MLA made more annotations on the map. It seems
that permanent MLA has an underwhelming effect (Nova et al., 2005). Let us now focus on the relationship between

                                                             625                                                  CSCL 2007
M (A,B) and M (B,A). We checked the intra-group dependence of the results through the computation of intra-class
correlation: the correlation is again positive (r = .41) and significant (p = .01). The number of errors made by the
subjects is correlated with the number of errors made by the other partners. This result confirms the correlation
found   in  the  first study.  This second   result is  even more   surprising  for   us  than   the former:    despite   the high
heterogeneity of spatial representation skills among adults (see for instance Liben et al, 1981), this high correlation
indicates again that MM-accuracy reflects more group processes than personal features. Since team members did not
interact massively     during  the task, the  intra-group  correlation  may   not    be  explained   by  the  quality   of  verbal
interactions but by other aspects of their collaboration, probably the quality of the task strategy that emerged in the
group. However, the relation between strategy and MM-accuracy is complex: if we do a post-hoc split, groups with
a high level of MM-accuracy do not perform better than pairs with low MM-accuracy ( F[1,17] = 1.4456,                          p=
0.2452).

Discussion and further studies
           The results of these two studies revealed a correlation between the model peers built about each others'
behaviors and intentions. Simply stated, if team member A builds an accurate model of nember B, then B also tends
to build an accurate model of A. The conclusion we draw at this point is that the activity of modeling the partner is
not reciprocal but mutual. A reciprocal relationship means that modeling is an individual activity where A infers M
(A,B)   from     B's actions  and  utterances. A   mutual   relationship implies     that M(A,B)       and M(B,A)      are jointly
constructed through interactions. The term 'mutual' may mean not only that A builds M(A,B), but he also builds
M(A, M (B,A)). We will not enter in the long debate on an infinite regress of nested models (discussed in Smith,
1982  or   in Clark,   1996). Another   interpretation  is that team   members   actually   build    a model    of the  group-in-
interaction, something like M (A, AB).      We are not able to choose among different hypotheses at this stage.

These findings are not very robust because they emerged as side-effects of other research questions, but, nonetheless
convincing since the same correlation has been observed in two different contexts: virtual space in study 1 versus
real space in study 2; groups of 2 in study 1 versus groups of 3 in study 2. Moreover, these results have been found
using different methods: on-task in study 1 versus off-task in study 2, subjective validation (comparing A's model to
B's answer) in study 1 versus objective validation in study 2 (comparing A's model with B's behavior). This diversity
somewhat consolidates our results but these results are still preliminary: the selected tasks were not proper learning
tasks and, overall, we still face serious methodological difficulties. On the one hand, asking learners `on task' what
their partner knows, is doing or intends to do triggers a modeling process which could alter the natural modeling
process. On the other hand, providing learners with an `after-task' survey implies mnemonic and rationalization
biases.  In other    words,  the nature  of mutual  modeling    implies  methodological    challenges      that call  for  indirect
measures and assessment methods. Furthermore, mutual modeling in everyday life involves a large variety of mental
states to be represented such as knowledge, behaviors, beliefs, desires, intentions, emotions, traits, attitudes, etc.
Three of these mental states are particularly relevant in collaborative learning situations, namely inferences about
partners' knowledge, behavior, goals (intentions). Study 1 focused essentially on inferences about peers' intentions
while study 2 investigated inferences about peers' behavior. Our on-going study focuses on the inferences about
peers' knowledge that is expected to be important in collaborative learning.

Our  current  empirical    studies investigate the  mutual  modeling    process in   conceptual   learning.  The   goal   of  these
experiments is twofold. Our theoretical question is whether or not the mutual modeling effort enhances collaborative
learning gains. Our methodological question is to capture the mutual modeling mechanisms. In order to avoid the
`anticipation' and `rationalization' biases, we use interaction analyses and parallel gaze analysis. We are therefore
using two eye-tracking machines and we perform an automatic comparison of the eye paths of both learners as in
(Richardson      &   Dale, 2005).   These   experiments    use  the two   mutual     modeling    prostheses     described   in   the
introduction, awareness tools and scripts. In both cases, subjects start by reading a text individually (Phase 1) and
then  have    to build  a  concept  map  together   (Phase  2). In  the first experiment,     the independent      variable   is an
awareness tool available during Phase 2: A is informed of B's knowledge on three different chapters of the learning
material;  this  knowledge    has  been  previously measured    through  a pre-test   at  the end  of  Phase    1. In  the second
experiment, different scripts are implemented by providing subjects with complementary partial texts (jigsaw script)
or conflictual texts (argumentation scripts) in phase 1. Both of these experiments manipulate the mutual modeling
process  in   complex   collaborative learning  situations.  Awareness   tools  about    peer's  knowledge      (and  behavior   in
general)   may   trigger   mutual  modeling  facilities whereas   the  `collaborative   scripts'  may  strain   effort of  mutual
understanding and by extension, enhance mutual modeling and perspective taking and making efforts. In a circular
(if not  spiral)  manner,   this increased  mutual  modeling    effort may    elicit interaction  processes   such   as audience

                                                              626                                                       CSCL 2007
design, mutual     regulation, elaborated   explanation asking   and providing,  which   are known   to be  beneficial for
learning.

References
Baker, M., Hansen, T., Joiner, R. & Traum, D. (1999) The role of grounding in collaborative learning tasks. In P.
          Dillenbourg (Ed) Collaborative learning: Cognitive and Computational Approaches (pp. 31-63) Oxford:
          Pergamon.
Brennan,    S. E.  (1991)   Conversation    with and  through    computers.    User  Modeling   and  User-Adapted
               Interaction, 1, pp. 67-86.
Bromme (2000) Beyond one's own perspective: The psychology of cognitive interdisciplinarity. In P. Weingart & N.
          Stehr, (Eds), Practicing interdisciplinarity. (pp. 115-133)Toronto: Toronto University Press.
Canon-Bowers, J.A, Salas, E. & Converse, S.A. (1993). Shared mental models in expert team decision making. In
          N.J. Castellan   (Ed.). Individual  and   group   decision making.   (Pp.  221-246).  Hillsdale, N.J:  Lawrence
          Erlbaum.
Clark, H.H (1996), Using Language. Cambridge: Cambridge University Press.
Clark, H.H. & Brennan S.E. (1991) Grounding in Communication. In L. Resnick, J. Levine & S. Teasley (Eds.),
          Perspectives  on     Socially Shared   Cognition    (127-149).    Hyattsville, MD:    American    Psychological
          Association.
Clark, H.H. & Marshall, C.R (1981) Definite reference and mutual knowledge In A. K. Joshi, B. L. Webber, and I.
          A. Sag (Eds), Elements of Discourse Understanding. Cambridge University Press.
Clark, H.H. & Wilkes-Gibbs, D (1986). Referring as a collaborative process. Cognition, 22:1­39.
Dillenbourg,   P.  (1999).  What  do    you mean  by  collaborative  learning?   In P.   Dillenbourg (Ed.), Collaborative
          learning: Cognitive and Computational Approaches (pp. 1-19). Oxford: Elsevier.
Dillenbourg, P. (2002). Over-scripting CSCL: The risks of blending collaborative learning with instructional design.
          In P. A.  Kirschner   (Ed).   Three worlds    of CSCL.  Can    we  support  CSCL   (pp. 61-91).  Heerlen, Open
          Universiteit Nederland.
Dillenbourg,   P., &  Traum,   D. (2006).   Sharing solutions:   Persistence and grounding   in multimodal   collaborative
          problem solving. Journal of the Learning Sciences, 15 (1), 121-151.
Dillenbourg, P., Baker, M., Blaye, A., & O'Malley, C. (1996) The evolution of research on collaborative learning. In
          E. Spada & P. Reiman (Eds.), Learning in Humans and Machine: Towards an interdisciplinary learning
          science (pp. 189-211). Oxford: Elsevier.
Greenberg, S., Roseman, R. (1996). Supporting Awareness of Others in Groupware. A short paper suite, in ACM
          SIGCHI'96 Conference on Human Factors in Computing System, Companion Proceedings, p205-215.
Hutchins, E. (1995). How a cockpit remembers its speeds. Cognitive Science, 19, 265-288.
Kenny, D.A., Kashy, D. and Bolger, N. (1998): Data analysis in social psychology. In D. Gilbert, S. Fiske,          & G.
          Lindzey (eds.) Handbook of Social Psychology, vol. 1, Boston: McGraw-Hill, pp. 233-265.
Koschmann, T., & LeBaron, C. (2003). Reconsidering common ground: Examining Clark's contribution theory in
          the OR. In K. Kuutti, E. Karsten, G. Fitzpatrick, P. Dourish, & K. Schmidt (Eds.), ECSCW 2003: Proc.
          EighthEuropean Conference on Computer-Supported Cooperative Work. Amsterdam: Kluwer.
Liben, L.S., Patterson, A.H, and Newcombe, N. (1981), Spatial Representation and Behavior Across the Life Span,
          New York: Academic Press.
Lockridge    C.B.   &  Brennan,    S.E.  (2002),  Addressees'    needs    influence  speakers'  early  syntactic choices,
          Psychonomic Bulletin & Review, 9 (3), 550-557
Malle,  B.F.   (2003)  Folk Theory  of   Mind:  Conceptual   Foundations    of Social  Cognition, in Hassin, Ran  R.   and
          Uleman, James S. and Bargh, John A., Eds. The new unconscious. Oxford University Press.
Moreland R.L. 2000. Transactive memory: learning who knows what in work groups and organizations. In Shared
          Cognition in Organizations: The Management of Knowledge, Thompson L, Messick D, Levine J (eds).
          Lawrence Erlbaum: Hillsdale, NJ; 3±31.
Nova N., Wehrle, T., Goslin, J., Bourquin, Y. & Dillenbourg, P. (2006): Collaboration in a Video Game : Impacts of
          Location Awareness. Journal of Multimedia, Tools and Applications.
Nova,   N.,  Girardin, F.  &   Dillenbourg,  P. (2005): `Location    is not  enough!': an  Empirical  Study  of  Location-
          Awareness in Mobile Collaboration. Proceedings of the third IEEE International Workshop on Wireless
          and Mobile Technologies in Education, November 28-30, 2005, Tokushima, Japan, pp. 21-28, IEEE Press:
          Los Alamitos, California

                                                             627                                                 CSCL 2007
Paas, F., Renkl, A., & Sweller, J. (2003). Cognitive load theory and instructional design: Recent developments.
        Educational Psychologist, 38, 1-4.
Pea, R. (1993)  Practices of  distributed intelligence and designs   for education. In G. Salomon.  (Ed). Distributed
        cognitions. Psychological   and     educational  considerations   (pp. 47-87)  Cambridge,   UK:   Cambridge
        University Press.
Richardson, D.C & Dale, R. (2005). Looking To Understand: The Coupling Between Speakers' and Listeners' Eye
        Movements and its Relationship to Discourse Comprehension. Cognitive Science, 29, 1045­1060.
Roschelle, J. & Teasley S.D. (1995) The construction of shared knowledge in collaborative problem solving. In C.E.
        O'Malley (Ed), Computer-Supported Collaborative Learning. (pp. 69-197). Berlin: Springer-Verlag
Salomon, G. (1993) No distribution without individual's cognition: a dynamic interactional view. In G. Salomon.
        (Ed). Distributed cognitions. Psychological and educational considerations (pp. 111-138) Cambridge, USA:
        Cambridge University Press.
Schober, M.F. (1993) Spatial perspective-taking in conversation. Cognition, 47, 1-24.
Schwartz, D.L. (1995). The emergence of abstract dyad representations in dyad problem solving. The Journal of the
        Learning Sciences, 4 (3), pp. 321-354.
Slugoski, B.R., Lalljee,  M., Lamb, R.    & Ginsburg,   G.P.  (1993) Attribution in conversational context: Effect of
        mutual knowledge on explanation giving. European Journal of Social Psychology, 23 (219-238).
Smith, N. (1982) Mutual Knowledge, New York: Academic Press.
Sperber, D. & D. Wilson (1986/1995) Relevance: Communication and Cognition. 2nd edition.
Suthers, D. D. (2006). Technology affordances for intersubjective meaning making: A research agenda for CSCL.
        To appear in International Journal of Computer-Supported Collaborative Learning (ijCSCL), 1(3).
Wegner  DM.   1987.  Transactive  memory:    a contemporary    analysis   of the group  mind. In Theories   of Group
        Behavior, Mullen IB, Goethals GR (eds). Springer-Verlag: New York; 185±208.
Wertsch, J.V. (1985) Adult-Child Interaction as a Source of Self-Regulation in Children. In S.R. Yussen (Ed).The
        growth of reflection in Children (pp. 69-97). Madison, Wisconsin: Academic Press.

Acknowledgments
We gratefully acknowledge the contribution of Fabien Girardin, Khaled Bachour and Kamni Gill. These researches
are funded by the Swiss National Science Foundation (grant #102511-106940).

                                                          628                                                CSCL 2007
