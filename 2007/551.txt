Argumentation Vee Diagrams (AVDs) Enrich Online Discussions
E. Michael Nussbaum, Denise L. Winsor, Yvette M. Aqui, & Anne M. Poliquin, University of Nevada, Las
                                 Vegas, Box 453003, Las Vegas, NV 89141
    nussbaum@unlv.nevada.edu, dwinsor1@cox.net, yvette.aqui@unlv.edu, poliquin@unlv.nevada.edu

         Abstract:     With   online  Argumentation    Vee    Diagrams  (AVDs),     students   compose
         arguments   on   both sides    of a controversial    issue and then    develop an     integrated
         conclusion.   In this study, students used AVDs prior to composing discussion notes,
         and--at the end of each discussion--jointly created a group AVD.         AVDs significantly
         enhanced   the number     of arguments/counterarguments      and   compromises     in students'
         discussion notes,  and  promoted    opinion change.    However, for AVDs to be effective,
         students also needed instruction on evaluating argument strength.

Introduction
         A frequent problem with online discussions is that students often superficially agree with one
another rather than exploring alternative views (Koschmann, 2003).           Although interventions exist that
promote disagreement (Baker, 2003), that is only half the problem.     Students also need to critically evaluate
both sides of controversial issue and to "put the pieces together" in formulating a final conclusion.

         Nussbaum    and  Schraw    (in press)  termed   this process argument/counterargument        integration.
Rooted in contemporary models of argument (Walton, 1996), integration can involve refuting arguments on
one side  ("refutation strategy"),  finding  a compromise/creative    solution  between  two    sides  ("synthesis
strategy"), or weighing   advantages/disadvantages     of  the two   sides  ("weighing  strategy").    Nussbaum
(2006) found that students use weighing strategies the least because of the number of separate elements that
must  be coordinated   in working   memory.     The  most   common    strategy  was pseudointegration,     where
students simply picked an argument they "felt" was strongest but did not respond to counterarguments.

         Nussbaum    (2006)   also  assessed   the effect  of  "Argumentation     Vee  Diagrams"      (AVDs)   on
argument/counterargument integration, but in the context of writing opinion essays.            The present study
explores the effect of AVDs in online discussions.    AVDs involve students listing arguments on both sides
of an issue (specifically on different sides of a large "V"), but then, at the bottom of the figure, developing
an integrated conclusion, which is subsequently used to compose a discussion note.          Two questions were
included at  the base  of the  V to   scaffold students'  thinking:  (a) "Which side is stronger, and why?"
(weighing strategy) and (b) "Is there a compromise or creative solution?" (synthesis strategy).

         AVDs were provided to student in two ways.           First, students received blank AVDs (in WORD)
and individually completed them before their discussions.       (Schwarz & Glassner, 2003, found individual
brainstorming  before  group   discussion  improved  discussion     quality by facilitating a  greater variety of
ideas.) After  composing their initial notes, students were required  to post additional notes indicating points
of agreement and disagreement with others.     Discussion groups contained three students each.       Then, at the
conclusion of their discussion, students used Wiki's to compose a joint AVD and summary note.             (Wiki's
are a Webpage    that  anyone  in  the  group  can edit.)   Students  learn  more from  discussions    when  they
summarize the various points made (Schwarz & Glassner, 2003).           In addition, because group roles can
facilitate participation (Webb & Palincsar, 1996), we assigned three different roles: (a) Composer, who
completed the initial group AVD, summarizing the discussion, (b) Elaborator, who added clarification, and
(c) Integrator, who used the group AVD to compose a summary discussion note.            This study investigated
whether     AVDs   improved     the   quality   of   online   discussions,   as   measured     by   numbers    of
arguments/counterargument, and extent of argument/counterargument integration.

Method
         The study was a design experiment, which recognizes that complex interventions may need to be
modified during implementation.     To provide rigor, we also conducted the study as a quasiexperiment. The

                                                       551                                                   CSCL 2007
study used 87 participants enrolled in two sections of a distance course on educational assessment.             Both
sections were taught the same way and used identical materials.         Students were required to post a minimum
of  two notes per   discussion,  and   one  student     also  had  to write  a note   summarizing     the discussion.

        There   were  three   discussions,  each  lasting    one  week.  The discussion topics were: (a) Should
students be graded on class participation, effort, and homework completion? (b) Should ability grouping be
used to teach reading? and (c) Should states be required to have accountability systems for evaluating
student performance?       For the   first discussion    (experimental     group),  we   developed  several   worked
examples on how to complete the AVDs, presented to students using Macromedia Captivate. Similar to live
lectures, Captivate provides a series of written instructions in real time and demonstrates filling in the form.
The examples were also presented in Webpages to which students could later refer.

        After  each   of the   first two   discussions,   the   instructor  (first author) reviewed   the   summary
notes/group AVDs, and gave each student short, written feedback. The purpose was to discourage "pseudo
integration" where students--in forming their final opinion--just picked the arguments they liked best and
ignored counterarguments.     Thus students  were typically encouraged to "think         deeper about the other side"
and "not to ignore any important counterargument when performing your integration."

        It also became     apparent,  after the   first discussion,   that students   needed  additional  criteria for
judging why arguments on one side might be stronger than the other.          For the second and third discussions,
we  added a series of additional questions at the bottom      of the AVD   but before the integration  section.    The
questions simplified the integration process by having students identify the two most important arguments
on each side, judge the extensiveness of any advantages/disadvantages, weigh the values involved, and then
evaluate whether the other arguments might change their final opinion, if at all.        One question also asked if
"there was a way of designing a solution so that opposing values could be realized?"

        We coded notes and AVDs on: (a) number of arguments/counterarguments raised, (b) mention of
the  most  important  arguments/counterarguments         in   an   organized   way    (Coverage/Organization),     (c)
development of "it depends" final opinions that took into account both sides (Compromises), (d) generation
of creative solutions that realized advantages    while minimizing disadvantage (Creative       Solutions). We also
examined whether students changed their opinion at some point during the procedure (Change).                       We
randomly selected 22 discussions to double score reliabilities were satisfactory (r = .87 and up).

        We   used   the  group  as   our   level of analysis,    because   individual scores  in a group    were   not
statistically independent.  Except for the first outcome variable, the variables were nominal.            There were
two sets of scores: one for the discussion notes, and one for      the group AVDs in the experimental group.       At
the end of the study, students completed a confidential survey on the usefulness of AVDs.

Results
        Overall, the AVDs significantly improved the richness of students' discussion, as measured by the
number  of different  arguments/counterargument         raised.   The mean in the experimental group was 8.61
arguments  and  8.89    counterarguments     per  group     discussion,  compared     to 2.11   arguments   and  2.09
counterarguments for the control group (t(23) = 6.07, p < .001).

        In  addition,   the   discussion   notes   of   the  experimental   group    contained   significantly  more
compromises (t(24) = 4.81, p < .001).      About twothirds of the groups in the experimental group engaged in
compromises (M = 0.67), almost none in the control group did so (M = .06).               There was not, however, a
significant difference in regards to creative solution (t(34) = 1.28, p = .21).        Importantly, there was more
opinion change in the experimental group (M = .39, t(17) = 3.29, p < .01, M = 0 for control).

        There was not a significant difference in regards to coverage (t(33) = 1.76, p = .087).            However,
when the final group AVD's were examined, there was steady improvement in coverage (see Table 1).
This finding  suggests   that  the discussion    stage  did   not  contain a comprehensive      coverage   of all  the
important arguments, but enough arguments and counterarguments were nevertheless considered to induce
compromising.    The    group  AVD's     may     have   added   an additional  element    of coverage  because     the
composer and elaborator were directed to include all important arguments and counterarguments.

                                                          552                                                   CSCL 2007
Table 1: Experimental group means over time.

Time                         Coverage                    Compromise                   Opinion change
1                            1.00                        0.67                         0.17
2                            1.40                        1.20                         0.80
3                            1.75                        1.00                         0.50

         Table 1 also shows a jump from Time 1 to Time 2 for compromises and opinion change.               These
differences could be due to topic or   to the introduction of the additional AVD prompts at Time 2.     Student
survey  comments    indicated  that   the  prompts helped   them   focus   on  counterarguments    and compare
arguments,  resulting  in  more    compromises  and, in turn, opinion   changes.    (Using  logistic regression,
compromises did predict opinion change, odds ratio 4.16, p < .05.)      Instructor feedback about not ignoring
any important counterarguments and providing a balanced view could also account for the jumps.

         In regards to the student survey (N = 19), comments were substantially positive.       Students noted
that the AVDs helped them focus on and evaluate the other side of the issue, and that the group AVDs
helped them organize and synthesize various points.        Of the 19 respondents, 13 (68%) made uniformly
positive comments, and 5 (26%) made partially positive comments.        Of these five, the greatest reservations
related to the individual    AVDs.     A  few  students did  not possess   enough   knowledge   to   think about
counterarguments.       Most  students    found  the  individual   AVDs    a   useful  brainstorming    activity.

Discussion
         With  AVDs,      students made   more  arguments/counterarguments,     and synthesized  them   through
suggesting   compromises.         The   process  also   resulted   in   more   opinion  change.        However,
argument/counterargument integration was weak the first time students used AVDs.             Students must be
discouraged from engaging in pseudointegration, where--in filling out the integration box--they just pick
the argument that they think is strongest but counterarguments are ignored.        We dealt with this problem
through feedback and by including additional prompts.       One surprising finding was that AVDs had little
effect on generating creative solutions, which is at odds with the results from Nussbaum's (2006) essay
study perhaps the additional prompts that we added to the online version did not focus strongly enough on
creative solutions. Future research should examine how to modify and streamline the additional prompts.
Overall, however, AVDs show great promise for enhancing students' critical thinking and discussion skills.

References
Baker,  M.  (2003).    Computermediated     argumentative   interactions   for the coelaboration   of  scientific
         notions.   In J.  Andriessen,  M.  Baker,   &  D.  Suthers   (Eds.).  Arguing  to  learn: Confronting
         cognitions    in computersupported     collaborative learning     environments (pp.  4778).    Boston:
         Kluwer.
Koschmann,   T.   (2003).  CSCL,   argumentation,  and  Deweyan    inquiry:   Argumentation  is learning.   In J.
         Andriessen,   M.   Baker,  &   D. Suthers  (Eds.).   Arguing   to Learn:   Confronting  cognitions    in
         computersupported collaborative learning environments (pp. 261269). Boston: Kluwer.
Nussbaum, E. M. (2006).      Argumentation Vee Diagrams enhance argument/counterargument integration in
         students'  writing. Unpublished manuscript, University of Nevada, Las Vegas.
Nussbaum, E. M., & Schraw, G. (in press).       Promoting argument/counterargument integration in students'
         writing.  Journal of Experimental Education.
Schwarz, B. B., & Glassner, A. (2003).     The blind and the paralytic: Supporting argumentation in everyday
         and scientific   issues.   In J. Andriessen,   M.  Baker, &    D. Suthers  (Eds.), Arguing    to  learn:
         Confronting cognitions in computersupported collaborative learning environments (pp. 227 ­
         260). Norwell, MA:     Kluwer.
Walton, D. N. (1996).     Argument schemes for presumptive   reasoning.    Mahwah,  NJ: Erlbaum.
Webb, N. M., & Palincsar, A. S. (1996).       Group processes in the classroom.     In D. C. Berliner & R. C.
         Calfee (Eds.), Handbook of educational psychology (pp. 841873). NY: Simon & Schuster.

                                                       553                                                  CSCL 2007
