              Redefining learning goals of very long-term learning
                           across many different fields of activity

               Naomi Miyake, Chukyo University, Toyota, JAPAN, nmiyake@sist.chukyo-u.ac.jp
                      Roy Pea, Stanford University, Stanford, Ca. USA., roypea@stanford.edu
                                                        With
                               Brigid Barron, Stanford University, Stanford, Ca. USA.
                    Daniel L. Schwartz and Lee Martin, Stanford University, Stanford, Ca. USA.
         Rogers Hall, Ken Wright, and Ka:ren       Wieckert    Vanderbilt University, Nashville, Tn. USA.

        Abstract:    There  is a  hidden  agenda   in our  modern    conception   of learning--especially   as
        embodied    in  education--that  the learning  experiences   gained  in one  "learning  situation" are
        naturally built-upon, expanded, and integrated with experiences from other learning situations. But
        we   believe this  implicit learning assumption   has  not yet  been  as  substantially researched  or
        discussed as is warranted by its importance. Furthermore, little support has been implemented.      In
        this symposium,    in  accordance   with  the conference   theme   which  encourages    us to explore
        interrelations among individual and social cognition with technology, we would help illuminate
        this hidden agenda.    We   would  take  some  closer  looks at cutting-edge  research  on knowledge
        integration  of learning  outcomes   from  different  classes, across formal  and informal    learning
        settings, and  for longer   time periods than usually  taken   up by learning science   research.  We
        would then propose to define a new set of learning goals as assuring the portability, dependability,
        and sustainability of learning outcomes.

        As the newest "transfer strand" issue of the Journal of the Learning Sciences suggests, the field is
expressing a growing concern about how far into the future learning science research should look to
appraise  the  qualities   of   learning   activities  and    outcomes.     Short-term  assessments       of   learning
performances may not be as predictive as we would hope of cross-situational uses of concepts, skills and
other achievements in the realism of longer time frames. This concern is clearly related to how outcomes
from different settings of learning are and should be portable to other situations, be dependable when the
need arises to use them in different situations, and prove sustainable in terms of providing preparation for
further learning.   Examination     of   these issues  could   open    additional dialogues     about redefining  the
"transfer of learning" theoretical construct, and related concepts such as "generative learning."              In this
symposium, based on some cutting-edge research on knowledge integration of learning outcomes from
different classes, across formal and informal learning settings, and for longer time periods than usually
taken up by learning science research, we would like to propose to define a new set of learning goals as
assuring the portability, dependability, and sustainability of learning outcomes.
        Naomi Miyake and Roy Pea will open this symposium by proposing a new perspective of long-
term, wide-ranged learning, and by proposing a new set of learning goals.                 While    people  gain many
different learning outcomes from various "learning situations," their integration and maintenance has not
been much focused on in research.         By taking a closer look at how learning outcomes from different
classes at school are naturally integrated (or not integrated) in an individual, we could begin to understand
an underspecified aspect of knowledge integration ranging for longer time learning, across many different
learning situations. We need to better understand how learning outside of school relates to learning within
schools and other designed environments, and how learning in school can spur related learning outside
formal designed environments.       This new look would reveal not only the complex interaction of             formal
and informal learning, and their different and sometimes conflicting properties (e.g., locus of control;
emergence), but also the lack of supports to enable people to take full advantage of the complexity of
these interrelationships.
        Brigid Barron will present her newest work on the fascinating nature of middle school learners'
developing technological fluencies, across different learning ecologies, and commonly with peers and
distributed  resources.   She  will  describe  a  learning    ecologies   framework   and an    associated   empirical

                                                           26                                                 CSCL 2007
research agenda to deal with how adolescents often pursue learning opportunities both in and outside of
school once they become interested in a topic.
       Dan Schwartz and Lee Martin will describe a new type of transfer measure, called "Preparation
for Future Learning." Ideally, experiences in school can prepare people to learn and adapt once they leave
school. They will present several lines of empirical results that show its value for detecting people's
readiness to learn and adapt to new situations.       They will also hypothesize about ways that the PFL
assessments could be extended to help indicate which school-based experiences can prepare people for
lifelong adaptation.
       Naomi     Miyake   will  report on  her  team's   research  on  explicitly supporting  the college   level
learning by paying closer attention to the acquisition of the portability, sustainability and dependability of
what they have learned, what they are learning, as well as of what they are going to learn after graduation.
Her team focuses on the acquisition of `schematic' knowledge, a form of expertise expected to allow the
learners to apply it to solve the wider scope of similar problems, as well as to create new problems and
solutions. Her team has been developing and testing college level learning environments in the domain         of
cognitive science, emphasizing the acquisition of some explicit metacognitive schemata on how people
learn, and how they could take advantage of such knowledge.           In the two-year course, the students are
first introduced to the notion of schematic learning by experiencing their own formation of schemata, and
then are guided to reflect upon the process, through carefully designed collaborative activities, supported
by technology.   They are also constantly encouraged to form a schema from their learning experiences of
different  classes, as well  as to integrate   their learning   experiences with   scientific literature through
collaborative discussion. She will describe on the theoretical bases of the practice, concrete learning
activities, technological supports, and some results of the evaluative analyses of the learning processes
and the outcomes.
       Roy   Pea     will present  findings    from  the    Family  Math  project,  involving   interviews   and
observations of 20 diverse families to understand when, how and under which conditions mathematical
practices arise in everyday problem solving and interaction. When do daily contexts generate common or
distinctive problems that are solved with mathematical concepts and tools (and of what kinds), what
resources do family members use for solving problems together, how are activities structured socially,
and in what   ways     does such   mathematical  activity    leverage --but  also   differ significantly   from--
knowledge acquired in formal settings?     Unlike many school-based mathematical problems, those arising
in family life do not come prepackaged with well-defined goals, pre-established problem-solving methods
and normative solution paths. As problems emerge, family members must decide whether and how to deal
with them.  Playing central roles in when and how math-relevant activities are approached and engaged
are interacting value systems (e.g., time-efficiency, cost-efficiency, different kinds of costs to error, social
accommodation to power relations inside and outside of the family, aesthetics, and for some families, the
symbolic   value placed   on 'school   math'). The   types  and dominant    family  mathematical  activities  for
roughly four hundred reported and observed math events illustrate the complexity of the math that is
engaged.   The content put to use in families is wide ranging and often more than one type of math is
brought to bear, including fractions, decimals and percents; ratios and proportions (direct and indirect);
measurement and conversion; probability and odds; basic geometry; charts and graphs; statistics (such as
averages), and statistical comparisons.
       Rogers Hall, Ken Wright, and Ka:ren Wieckert will report ethnographic and cognitive studies of
learning,  teaching, and  generalizing  statistical  concepts   as statisticians advise clients across   different
research domains (e.g., the epidemiology of infectious disease, laboratory research on human metabolic
processes,  the  community      ecology of   social  insects,   and   large-scale  conservation  planning).   By
comparing   consulting    sessions  across  consultants     and client  domains,    his group   seeks    a better
understanding of how the same concepts (e.g., statistical independence) are made generally applicable in
different research contexts. Their approach treats complementary expertise between statistical consultants
and their clients as a critical context for cognitive and interactional processes of teaching, learning, and
generalizing statistical concepts.
       More detailed papers by Barron, Schwartz & Martin, and Hall, Wright & Wiechert follow.

                                                         27                                                CSCL 2007
                A multiple case study on middle school learners'
          technological fluencies across different learning ecologies
              Brigid Barron, Stanford University, Stanford, Ca. USA., barronbj@stanford.edu

         In this presentation I will report a study that was designed to better understand the conditions that
support children's persistent engagement in technologically mediated activities that are likely to build
knowledge, confidence, and interest in a broad range of subject domains including digital arts, computer
science,  and   human   computer     interaction. This      works  builds   on ecological  and    developmental
perspectives, and is designed to contribute to a larger research agenda that seeks to better articulate the
interdependencies between child level and environmental variables in development and acknowledge the
tight intertwining of person and context in producing developmental change (Bronfenbrenner, 1979; Cole,
2000; Lerner, 1991; Lewin, 1951; Rogoff, 2003). One focus within this broad agenda involves further
specification of types of roles people play in a learner's knowledge network and how these support
learning interactions, description of the nature of activities that propel learning and the ways that activities
evolve over   time or with   age, and  the role   of distributed    resources  such  a books  or  Internet based
communities (Barron, 2004; 2006, Barron et al, 2007).
         In this study eight middle school students, their parents, one of their teachers, and any learning
partners they nominated were interviewed. A two-stage process was used to identify these case study
participants. First we administered a survey focused on use of computers to approximately 50 students at
a public  middle school   located in  the Silicon  Valley    region  who    were currently enrolled  in  either a
programming or a web design class. Second we interviewed them about their activities that they sustained
after school. Our multi-informant interview methods yield reports on learners' histories in the form of
conversations between the interviewers, the learners, and their parents. Responses to questions posed by
the interviewer include rich information about children's activities, their learning resources, the ways
their parents and peers support their learning, as well as their future goals, attitudes, and interests.   These
interviews are summarized to create portraits of learning about technology in a genre that has been called
"technobiography" in recent work (Henwood, Kennedy, & Miller, 2001). A life narrative approach allows
us to chart a learning history in terms that go beyond metrics such as numbers of courses taken to include
the meaning and attribution behind decision making and narratives of how the learning activities unfolded
across time, resources, and historical context (Bruner, 1994; Elder, 1994; Linde, 1993). In addition,
interviews can reveal processes that are missed through other methods and provide us with portraits that
go some distance toward "recovering the person" in our theorizing about human development (Mishler,
1996).
         Beyond these informant accounts of learning, the interviews offer a sample of language that can
be analyzed   with respect to vocabulary,   means    of expression,    and   syntax. In order  to maximize   the
potential for developing new insights from these records, Barron's research team has created a number of
intermediate representations that summarize the raw interview data. Each representation highlights unique
information   contained within the   records.     These     representations include  narrative texts  that tell a
learners' story along a   number  of  set dimensions;       excel spreadsheets  that tabulate  types of learning
resources and   allow us  to code    and quantify  variables   such  as  the  number   of people  in the   child's
knowledge network or the number of structured learning contexts a child has participated in;          lists of the
technical terms a learner used while recounting their history or describing a project they created during
the Artifact Based Interview; formal codes for parent roles that are applied to turns; graphs and tables
that present  descriptive statistics for  each code;    and   finally, visual  representations  in the  form    of
developmental timelines that locate fluency building activities across setting and age, depict relations
between activities, show the involvement of peers or adults in the activity, and note the types of material
resources used for learning. Developmental timelines.       This visual representation easily lets us see where
activities are clustered, when they began, who was involved.           Comparing the timelines of individual
learners highlights differences in developmental history (see figure 1).
         These portraits, as well as our others, have revealed the critical role that parents, peers, and other
mentors play in supporting the engagement of these highly engaged learners. The participation of peers or

                                                         28                                                CSCL 2007
adults in activities was sometimes recruited by the learner, and other times parents or others recruited the
child's attention and led the learning. In other cases the forming of a teaching/learning partnership was a
highly   reciprocal      and  interdependent  process.          Though        socio-cultural
perspectives have   emphasized     social learning processes             generally, and  the
importance of guided participation specifically (Rogoff, 2003), the variety of
roles played by others in our cases is striking and suggests the value of further
specifying types and     patterns of participation as        an important     direction   for
future research. The      number  and  diversity of   learning            partnerships, their
duration, and their content, are all variables that could be productively defined
and perhaps quantified. To that end we have begun to develop coding schemes
that can help us better specify social learning networks and chart how they
differ for individual learners. Parent roles in learning were developed based on
a review of the transcripts for the learning ecologies and parent interviews of
all eight cases. We believe that they will help account for important individual
differences in engagement and conceptual development and have implications
for how we seed informal learning networks. In this presentation, individual
portraits and the analysis of parent roles in learning will be presented

               Figure 1A & 1B. Example of a learning history visualization and key

                                                 References
Barron, B. (2004). Learning ecologies for technological fluency: Gender and experience differences. J. of Educational Computing
  Research, 31(1), 1-36.
Barron. B. (2006). Interest and self-sustained learning as catalysts of development: A learning ecologies perspective. Human
  Development, 49, 193-224.
Barron, B. Martin, C.K. & Roberts, E. (2007). Sparking self-sustained learning: Report on a design experiment to build technological
  fluency and bridge divides. International Journal of Technology and Design Education, 17(1), 75-105.
Bronfenbrenner, U. (1979). The ecology of human development: Experiments by nature and design. Cambridge: Harvard University
  Press.
Bruner, J. S. (1994). The remembered self. In U. Neisser & R. Fivush (Eds.), The remembering self: Construction and accuracy in the
  self-narrative. Cambridge, UK: Cambridge University Press.
Cole, M. (2000). Struggling with complexity: The handbook of child psychology at the millennium. Human Development, 43, 369-
  375.
Elder, G. (1994). Time, human agency, and social change: Perspectives on the life course. Social Psychology Quarterly, 57, 4-15.
Henwood, F., Kennedy, H., & Miller, N. (2001). Cyborg lives?: Women's technobiographies. York, UK: Raw Nerve Books.
Lerner, R.M. (1991). Changing organism-context relations as the basic process of development. Developmental Psychology, 27, 27-32.
Lewin, K. (1951). Field theory in social science: Selected theoretical papers. (D. Cartwright, Ed.) New York: Harper & Row.
Linde, C. (1993). Life stories. New York, NY: Oxford University Press.
Mishler, E. (1996). Missing persons: Recovering developmental stories/histories. In A. Colby & R.A. Shweder (Eds.), Ethnography
  and Human Development: Context and Meaning in Social Inquiry (pp. 73-100). Chicago, IL: University of Chicago Press.
Rogoff, B. (2003). The cultural nature of human development. New York, NY: Oxford University Press.

                                                             29                                                      CSCL 2007
       INSTRUCTION AND ASSESSMENT FOR FUTURE LEARNING
            Daniel L. Schwartz, Stanford University, Stanford, Ca. USA., danls@stanford.edu
               Lee Martin, Stanford University, Stanford, Ca. USA., lmmartin@stanford.edu

        The   learning  measures    used  in many    instructional   studies are  retrospective; they ask   what
students  have learned. However, if   one's interest is whether instruction will help people continue to learn
once they leave school, then it may be more appropriate to use prospective measures.          Over the past few
years we have been working on developing and evaluating prospective measures of learning.                We first
describe the characteristics of retrospective and prospective measures.        We then describe how we have
used these measures to differentiate instruction that prepares people to learn.         These    studies have  all
occurred on a short-time scale within schools.       Therefore, we also present the results of a study that
examined the long term effects of sustained education on people's preparation to adapt and learn from
new situations.
        Retrospective   measures    take  a  common     form    called  Sequestered   Problem    Solving    (SPS)
(Bransford  & Schwartz, 1999).   Students receive   a problem    or series of problems, and like a jury, they  are
sequestered from any resources that might help them learn during the test (and contaminate the results).
SPS measures    are  excellent for  determining  the  efficiency   with which    students can apply   their prior
knowledge   to solve   problems.    A limitation of SPS measures is they do not directly measure student
abilities to adapt to new situations and learn from them.      SPS measures do not include any resources for
learning. Students may flexibly use what they know to solve a tricky problem, but they cannot adapt their
understanding in response to new information in the environment, because there is no new information.
        Prospective measures differ from SPS measures because they include resources for learning at the
time of test.  These resources can include feedback, verbal materials, examples, and even other people.
The question is whether students have been prepared to take advantage of these learning materials to help
themselves    learn how  to   solve a novel   problem.      Such prospective   assessments  measure      students'
Preparation for Future Learning (PFL).       It is fair to say that PFL assessments are transfer measures,
because students need to transfer learning from prior experiences into a novel experience or problem,
which  differs  significantly  from  problems  that  they   have already   solved.   Yet  PFL    assessments   are
different than most transfer measures; PFL assessments examine whether people can transfer to adapt and
learn, whereas most transfer measures examine whether people can recognize that they have already
solved a  given problem    type.   The emphasis on learning and adaptation makes PFL measures highly
relevant to issues of whether and how school experiences can prepare people to be life-long learners.
Over the past few years, we have been conducting studies that show that PFL measures capture something
different from SPS measures when it comes to readiness for future learning (see Schwartz, Bransford, &
Sears, 2005   for   examples).   A  primary  goal of  these   studies  has   been to show   that some    types of
instructional  experiences  lead  to  learning gains  on     PFL measures,    even   though these  instructional
experiences may not yield any appreciable differences on      SPS measures.    This  has been useful in showing
the hidden value of pedagogies that engage students in creating knowledge rather than only receiving and
practicing.
        For   example,  in a  study  with college students,    we    compared  (a) students who   analyzed    and
looked for patterns in simplified data sets from classic psychology experiments; and (b) students who
wrote a summary of a chapter on the same psychology experiments (Schwartz & Bransford, 1998).              On an
SPS true-false    test immediately    following   these     learning experiences,   the  summarizing     students
performed much better, presumably because they had read tidy summaries of the studies.             However, an
additional, PFL measure revealed what the SPS measure could not: the analyzing students were better
prepared to learn new material.     Students from both conditions heard the same lecture that explained the
psychological experiments, their results, and their implications for broader human behavior.       To see if the
two groups were equally prepared to learn from this shared learning opportunity, we had them predict the
results of a novel experiment which was highly relevant to what they had learned, but had very different
surface features.   On this transfer test, the students who had analyzed the data did much better than the
students who had summarized the chapter.      It was not simply that data analysis taught them more, because

                                                         30                                                CSCL 2007
a comparison group who analyzed data but never heard the lecture performed very poorly on the transfer
test.  Instead, students in the data analysis condition were more prepared to learn from the lecture and then
transfer this learning to make predictions about the novel experiment.              Had    we  not  included  a  PFL
assessment, the data analysis activity would have seemed like a waste of time, because the students did so
poorly on the SPS test relative to students who summarized the chapter.            Notably, after the data analysis
students  had   heard   the   lecture, they  did  extremely    well  on   the SPS  measure.    Knowledge-creation
opportunities     need  not  look    bad  by retrospective     measures   of  learning, if those   opportunities are
complemented by formal treatments that help students organize what they have learned.
         As   a second     example,  we   describe a study     with hundreds   of 9th-grade  students in  which  we
compared two methods of teaching statistical concepts and procedures associated with variance (Schwartz
& Martin, 2005).       In one condition, students received standard tell-and-practice lessons.        In the second
condition, students had to invent their own formulas for solving a set of problems.             After attempting to
invent their own formulas, the students were shown how experts solve these types of problems.              Students
in both conditions had the same time on task.       After several weeks of instruction, students received a long
posttest, which contained a target transfer     problem.  It was a very far transfer problem, because it included
novel content and a novel type of problem (i.e., finding and using standardized scores to compare athletes
across history).     Because we did not expect many students to be able to solve this problem in SPS form,
we included a learning resource within the test.     The students received a worked example in the middle of
the test showing how to solve a problem, and then they had to copy the steps using a new set of numbers.
For these students, following the worked example was quite easy, and nearly all of them did it perfectly
on the posttest.     The question was whether they would learn from the worked example, which held the
key   to solving   the  target  transfer  problem  later in    the test.  To  make sure    any differences between
conditions were due to learning from the worked example, we constructed two forms of the test.             For half
of the students in each condition, their test included the worked example.               For   the other half of the
students in each condition, we omitted the worked example.               Including the worked example made the
transfer problem a PFL measure, and excluding the worked example made the transfer problem an SPS
measure.     The figure shows the combined results of the original study and a replication study.         We coded
answers to the transfer problem whether they were correct quantitatively or correct qualitatively (for
example, a student made a graph instead of computing).              The results showed that the PFL version (that
included    the worked     example   to   learn
from)    was    more       sensitive   to  the
differences between conditions than the
SPS version (no worked example in the
test).   The results also showed that one
of  the  benefits    of asking   students    to
create   knowledge      is that  it  prepares
students  to    learn  subsequently    and   to
spontaneously apply that learning later.
         If   we     extrapolate    from   the
preceding studies, it would appear that a
steady   diet  of  tell-and-copy   instruction
may not prepare students to learn once
they     leave    school.       In   contrast,
opportunities     to  create   knowledge     in
school may prepare students to learn and
create knowledge once they leave school.
Of course, this is a speculation.      We did
find   that,  a year    later, the   9th-grade
students  in   the statistics  study   showed
excellent memory for the statistics they

                                                            31                                                CSCL 2007
had learned, but we did not test whether they were learning better in their other classes, let alone outside
of school.
        In more recent work, we have been examining whether sustained school experiences can have a
lasting influence  in  how    people adapt and  learn   from   new    situations.   In  one study, we   provided
participants with a medical diagnosis task.    They received a set of reference cases, which included test
results and disease diagnoses for several patients.    Participants had to diagnose new patients by ordering
tests and considering how the results compared to those in the reference cases.        One goal of the study was
to determine whether people develop representational adaptive expertise ­ do people learn to make visual
representations to help organize complex and novel information? The critical question was whether the
participants would make visual representations to help them organize information in the reference cases
and thus help them optimize their ordering of tests and diagnoses.            To  examine   the effect of  school
experiences, we compared undergraduates with       graduate students.    The graduate   students were  selected to
only include   students    who   worked   in  data rich     fields (e.g., biology,   computer   science).    The
undergraduates and graduate students completed the task with the reference cases always available.           This
made it possible for them to solve the problem without creating a visual representation; they could work
by shuffling through the references cases.    Both conditions were successful at diagnosing the new cases.
However, the results indicated that all of the graduate students created visual representations to help solve
the diagnosis problems, whereas very few of the undergraduates made any sort of explicit representation.
Creating the visual representations slowed down the     graduate students    relative to the undergraduates. But,
in the long run, creating the visual representations paid off.     The graduate students were more optimal in
their ordering of tests, and they were able to diagnose the new cases just as quickly.        In addition, there
was a second phase of the study, where both groups received a new set of reference cases about several
new diseases.  The graduate students were able to outperform the undergraduates in search optimality and
time per   diagnosis.   It  was  not  the  case  that   undergraduates      did not  know   how    to use  visual
representations.   In a third condition, another group of undergraduates completed the same task, but we
removed the reference cases each time they received a new patient (they were allowed to consult the
reference cases between patients).    In this case, the undergraduates did make visual representations to
help alleviate the memory burden.     All told, the results indicate that extended experiences with managing
complex    information (i.e., as a   graduate student)  transferred   to  a  new  task.  The  graduate  students
spontaneously created visual representations, even though they could have solved the problems without
them and the task of creating the representations led to a temporary inefficiency.        They were exhibiting
adaptive behavior, because they did not just plow into the problems, but rather, they took the time to
create some organization that would help them work and learn more effectively in the long run.
        In summary, we have been looking at ways of measuring people's abilities to adapt and learn in
new situations.    This is relevant to life long learning, because in contemporary society people need to
adapt to new jobs, technological innovations, and   so  forth.  With  the  help of these new  PFL  measures,  we
have begun to illuminate the experiences that prepare people to continue learning, and we have been able
to document    the effects of  sustained experiences    on   people's readiness   to adapt  and  learn  in a new
situation.

                                                 References
Bransford,  J. D.,  &  Schwartz,   D. L.  (1999).  Rethinking      transfer: A  simple  proposal   with multiple
        implications.  In A. Iran-Nejad & P. D. Pearson (Eds.), Review of Research in Education, 24, 61-
        101.   Washington DC: American Educational Research Association.
Schwartz, D. L., Bransford, J. D., Sears, D.  L. (2005).    Efficiency and innovation in transfer. In   J. Mestre
        (Ed.), Transfer of learning from a modern multidisciplinary perspective. CT: Information Age
        Publishing. pp.1-51.
Schwartz, D. L. & Bransford, J. D. (1998).    A time for telling.   Cognition & Instruction, 16, 475-522,
Schwartz, D. L., & Martin, T. (2004). Inventing to prepare for learning: The hidden efficiency of original
        student production in  statistics instruction. Cognition & Instruction, 22, 129-184.

                                                         32                                                CSCL 2007
          Learning in Activities that Cross Disciplinary Boundaries
          Rogers Hall, Vanderbilt University, Nashville, TN. USA., rogers.hall@vanderbilt.edu
                    Ken Wright, Vanderbilt University, kenneth.a.wright@vanderbilt.edu
           Ka:ren Wieckert, Belmont University, Nashville TN. USA., kwieckert@yahoo.com

      We report ethnographic and cognitive studies of learning, teaching, and generalizing statistical
concepts  as   statisticians advise  clients across    different  research domains    (e.g., the   epidemiology  of
infectious disease, laboratory research on human metabolic processes, the community ecology of social
insects, and large-scale conservation planning). By comparing consulting sessions across consultants and
client domains, we seek a better understanding of how the same concepts (e.g., statistical independence)
are made generally applicable in different research contexts. Learning, from this perspective, occurs both
at individual and collective levels of analysis, involves not only people but also a dynamically distributed
technical culture of things (algorithms, code fragments, graphical displays, and argument structures), and
extends in temporal scale from moments to years. This approach treats complementary expertise between
statistical consultants and their clients as a critical context for cognitive and interactional processes of
teaching,  learning, and     generalizing  statistical concepts.  Consultants   and clients  each    know   different
things, and a successful outcome--a set of findings based on a defensible model for a client's research
problem--requires    that    these differences  are    turned  into complementary     strengths  in  the consulting
relation. Field data include audio and video recordings of consulting meetings, semi-structured interviews
about material selected from these recordings, historical and ethnographic analysis of changes in client
work practice, and working documents produced and used in consulting sessions.
      Within consulting meetings, three recurring processes appear to drive learning and teaching, with
far-reaching   consequences    for  client work   practices    and  for  the career   trajectories of participating
statisticians.
         (1)   Consulting    narratives    (stories)   assemble   future   work.  Consulting     meetings    involve
purposeful efforts to displace some aspect of the client's existing infrastructure for representation and
modeling with another way of working. In this sense, consultations are a disruption in the client's project
timeline, and within the meeting, different ways of assembling the client's future work are created and
compared in conversation. These are produced as narrative structures that involve basic processes of
animation, gesture, and inscription to assemble new ways of working. Each such narrative assembly
orders objects in the client's work (e.g., specimens, machines, and systems of classification), people on
the project as human labor and spokespersons for objects, and statistical techniques or concepts.
      For example (Hall, Wright & Wieckert, 2007), in a consultation between a biostatistician and
entomologists   considering   the   use of cluster   analysis   (CA)  to identify new  termite     species, a senior
research client proposed using CA to confirm insect groups they observed in the field. The consulting
biostatistician pointed  out   that CA    finds clusters,   regardless  of their  meaning,   and   a second   senior
researcher proposed,    instead,   that they use     CA  to    discover insect groups  that  are   confirmed   using
independent field and laboratory data. This seemingly simple, narrative repair in how CA should be used
in the client's work avoided a logical error and, over time, became a standard method for identifying
group structures as species candidates.
         (2) Parables position clients' statistical decisions. Statisticians (exclusively, in our case studies)
tell parables that offer clients alternative subject positions in stories about statistical inference and data
modeling. These stories have highly evaluative outcomes, depending on which position a client takes. For
example,  in   the case of   entomologists   using     cluster analysis (above),  the statistician  compared   their
situation to blood type shown on a California driver's license. The lead entomologist initially responded
from the position of a harried Type O blood donor, but later realized that in the completed parable, he
would grant licenses on the basis of blood type (i.e., blood type is a real structure, but it has nothing to do
with obtaining a driving license). In another example concerning whether to cut a continuous variable
around high/low risk values for diagnostic use, a senior biostatistician told a story in which a doctor
following "evidence-based medicine" mis-used a blood cholesterol test:

                                                           33                                                CSCL 2007
        I mean   I  knew   an eighty-four-year   old woman     with   leukemia   who    grew up  in  New
        Orleans and loved French cooking, whose doctor told her to quit eating French food,
        `cause her cholesterol was high. Um, the doctor should have been shot, or sentenced to
        McDonald's for a year.
In both examples, subject positions offered to clients (in some cases to other statisticians) are meant as
cautions or criticisms, pointing to common mistakes they should avoid when using statistical concepts or
techniques.
         (3) Analogical reasoning builds project infrastructure. A third and centrally important process of
learning and teaching in statistical consulting is the use of analogy to borrow and modify statistical
methods or approaches to modeling appearing in prior publications, sometimes out of field for research
clients. SCADS findings here are similar Dunbar's (1995) studies of scientific research groups, but in our
cases, consulting   statisticians work as brokers    to map    and  evaluate   analogies  that  are  brought  into
consulting meetings by research clients.
        For example (Hall, Wieckert & Wright, 2006), in a case where research epidemiologists were
seeking to estimate the number of young children hospitalized with influenza (these could not be counted
completely), the lead researcher borrowed a capture-recapture estimate (CRE) from prior publications in
epidemiology, but made an overly narrow assumption about matching hospital days for two screening
procedures. The consulting statistician advised that matching days were not required, yet the client was
not convinced,   posing  an   extreme  case in which    a   1  day  screen    would be  incorrectly  (he thought)
combined with a 7 day screen. After further discussion and a concrete demonstration, the statistician was
able to convince the client to use all screening days, and the resulting estimate of children with influenza
(now in print) was more robust. In the same consultation, the statistician convinced epidemiologists at a
national public health agency that screens with quite different coverage could be combined, as long as
there were no dependencies (temporal or otherwise) among them. As a result, new studies and a national
influenza monitoring program for adults are underway, using the client's extreme negative case (1 versus
7 screening days) as a feature of the new health surveillance system.
        Looking across SCADS cases and ongoing analyses, we find a multi-lineal process of learning,
teaching  and  development    summarized    in Figure   1.   Client research   projects  have   ongoing  histories
(shown as dashed lines) that are intentionally disrupted (Hall, Stevens & Torralba, 2002; Engestrom,
Brown, Christopher & Gregory, 1997) in consulting meetings with statisticians. In these meetings (shown
as  shaded  regions)   different  ways of assembling     the   client's research    and statistical modeling   are
proposed and compared (i.e., narrative assembly, evaluative use of parables, and analogical reasoning),
and new   uses   of models  circulate  back  into the   published   literature,  where  they  are   borrowed  and
extended  by  other   investigators. The  capacity   of client  research   groups   is  expanded,   and  statistical
consultants  act  as   "boundary   spanners"   or brokers      (heavy   line) by  moving   across    projects and
accumulating   a  consulting  portfolio. Within   particular   research  fields  these  multi-lineal  patterns  of
circulation yield   a kind of horizontal  development,      as clients' research  methods    and  group  capacity
become    more powerful.    By    moving  across  different    research projects    and fields, statisticians find
opportunities for vertical development of new and more powerful (or more useful) statistical methods.

                                                         34                                                CSCL 2007
        Figure 1. Statistical consulting as an intentional disruption to research clients' work practices.
        Consulting trajectories help put new and more powerful methods into circulation within research
        fields (horizontal development), while providing statisticians with opportunities to create new
        statistical methods (vertical development).
        Our analyses and findings support a view of statistical consulting as a set of boundary encounters,
places where  clients  and  statisticians bring complementary       expertise to bear  on particular research
problems, craft "do-able problems" (Fujimura, 1987) that enable clients to answer questions in ways that
are appropriate and more powerful than they might manage on their own. These boundary encounters
occur in organizational environments already dense with resources for modeling, statistical description
and inference  (i.e., prior publications, statistical software    and user-extensible code, consultants with
identified expertise, and diverse capacity within research groups). As a result, statistical concepts are used
more   widely across   research projects  and fields,  this   use involves changes  in client work   practices
(including what researchers "know" and the nature of arguments they make), and the statistical concepts,
themselves, take on new meanings and potential as research tools. In this sense, statistical consultations
feed back into a larger, distributed system of resources for conducting research, a boundary infrastructure
that we have analyzed simultaneously at interactional and historical levels.

                                                References
Dunbar, K. (1995). How scientists really reason: Scientific reasoning in real-world    laboratories. In R.J.
        Sternberg, & J. Davidson (Eds.). Mechanisms of insight (pp.        365-395). Cambridge MA: MIT
        Press.
Fujimura, J. (1987). Constructing 'doable' problems in cancer research: Articulating    alignment. Social
        Studies of Science, 17, 257-293.
Hall, R., Wieckert, K. & Wright, K. (2006). Learning, teaching and generalizing statistical concepts as
        statisticians consult across client domains. Paper presented at the annual meetings of the
        American Educational Research Association, San Francisco, California.
Hall, R., Wright, K. & Wieckert, K. (2007). Interactive and historical processes of distributing statistical
        concepts through work organization. Mind, Culture, and Activity, 14(1&2).
Hall, R., Stevens, R., & Torralba, A. (2002). Disrupting representational infrastructure in conversations
        across disciplines. Mind, Culture, and Activity, 9(3), 179-210.

                                                         35                                                CSCL 2007
