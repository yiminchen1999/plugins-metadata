Tools for Concurrent, Embedded, and Transformative Assessment of
                        Knowledge Building Processes and Progress

         Chris Teplovs, Institute for Knowledge Innovation and Technology, Ontario Institute for Studies in
                                Education/University of Toronto, chris.teplovs@utoronto.ca
       Zoe Donoahue, Institute of Child Study, Ontario Institute for Studies in Education/University of Toronto,
                                               zdonoahue@oise.utoronto.ca
     Marlene Scardamalia, Institute for Knowledge Innovation and Technology, Ontario Institute for Studies in
                          Education/University of Toronto, mscardamalia@kf.oise.utoronto.ca
         Donald Philip, Institute for Knowledge Innovation and Technology, Ontario Institute for Studies in
                                Education/University of Toronto, dphilip@oise.utoronto.ca

         Abstract: In this paper we introduce a suite of analytic tools to enable users of Knowledge Forum
         to monitor various participation and collaboration patterns, with almost instantaneous feedback to
         ongoing     processes.   Tools   for semantic    analysis  of   content   similarly  provide   just-in-time
         assessment     (e.g., vocabulary   overlap  for  different documents    or   Knowledge     Forum   database
         segments). Early results suggest a number of ways in which concurrent and embedded assessment
         enhances knowledge building in classrooms.

Background
         Knowledge      building  systems,  with  formative  assessment,   can  be   conceptualized  as a  cybernetic system
with   feedback  loops   serving   to drive   the system  in new    directions  (Roos    & Hamilton,    2005).   To  optimize
performance     feedback must   be  relevant  and timely. Analysis   of  discourse   from computer-supported     collaborative
learning environments is common but, as Lee, Chan & van Aalst (2006) note, relatively little attention has been paid
to the "formative, embedded, and transformative aspects of assessment in collaborative inquiry".            In this paper we
introduce a suite of tools that are embedded in Knowledge Forum® version 4.6 as a series of Java applets.             Results
can be made available to any user (teacher, student, manager, at the teacher/manager discretion). Designs also aim to
empower users rather than engage them in competitive analysis, with much of the focus on community dynamics
and  knowledge     advancement.   With   appropriate   safeguards   and  attention to issues  of security,  data can  be read
directly from   the  Knowledge    Forum   database,  and  integrated  back into  it, thereby  transforming  the  dynamics   of
knowledge building (Scardamalia, 2002).

Participation and Collaboration Tools
         A previous Analytic Tool Kit for Knowledge Forum (Burtis, 1998) included participation and collaboration
tools. The Contribution Tool      (Figure 1) provides information about the number and nature of artifacts created by
participants at  the individual   and   group level. The  tool provides   measures    of  the number    of notes  created, the
number of views in which participants worked, and other measures of individual and group performance, but it does
not provide  information    about   the  relationships between    individuals.  That  is  the realm  of the  Social  Network
Analysis Tool (Figure 2), which displays the social relationships among participants based on patterns of behavior
recorded in Knowledge Forum (e.g., who read/referenced/built on whose note).

Writing Analysis Tools
         One    of  the advantages    of CSCL     environments is   that they  provide   access  to digitized records of   the
contributions of the participants.    Thus, all utterances are recorded and are available for analysis. Various studies
now    indicate that advances    in textual  and  graphical  literacy are  important   by-products   of work   in knowledge
building environments (Sun et al., 2006; Gan, 2006).      In an effort to better identify such growth we have developed
several  writing   analysis tools.    These   tools parse and  quantify    the  contributions   of  participants in terms   of
vocabulary growth (Figure 3) and basic writing measures (e.g. total and unique words, mean sentence length).

Semantic Analysis Tools
         The Participation, Collaboration and Writing Analysis tools focus on surface features of contributions.           The
Semantic Analysis Tools deal with the meaning of the discourse.          The Semantic Overlap Tool extracts key words or
phrases from a user-selected subset of the discourse and reports the extent to which that subset overlaps with another
user-selected subset of the discourse.    One application of this tool is to examine the overlap between a participant's

                                                              720                                                   CSCL 2007
discourse and discourse generated by experts in a discipline or in curriculum guidelines.       Other applications include
the examination of overlap between two or more participants.         The Semantic Field Visualization Tool (Figure 4)
provides graphical displays of the overlap of the semantic fields of subsets of the discourse by employing techniques
from Latent Semantic Analysis (Deerwester et al., 1990; Landauer et al. 1998).

Transformative Assessment to Support Knowledge Building
           In the past, teachers using Knowledge Forum software assessed student performance through observation
of classroom interactions and reading students' notes.      While detailed information was available from the Analytic
Tool Kit, the tools were used by researchers, not users, and for summative evaluation rather than input to ongoing
practice. The just-in-time nature of the new tools is changing that.

           The teacher  can  use the Contribution    Tool during  or immediately    after each  session to determine  how
productive each student has been.(e.g, how many notes were read, created or modified).          Such information helps the
teacher direct  attention to  students  who  may   need more   support or  instruction, and  helps  them identify barriers
preventing students from participating fully in the knowledge building community.

           The Social Network Analysis Tool can help teachers to better understand who the central participants are in
the knowledge building discourse and to see if existing social relationships are limiting or impacting positively on
the community's work. The tool draws the teacher's attention to children who are on the periphery and makes it
more likely that these children will receive the direct support they may need to be more integral to the work of the
class.

           Looking at the growth of vocabulary relative to outside measures or benchmarks gives the teacher a good
indication  of whether    the  students are learning  and   using concepts in   the discipline,  at or above   grade level.
Information about the complexity and quality of children's notes can also give the teacher clear direction as to the
type of guidance or instruction the class may need.     All of the tools support the teacher in planning in a way that is
responsive to the students' evolving needs.

           The various dimensions of the analytic tools identified here, and additional aspects of their use can be seen
through the work of a teacher demonstrating how these tools are used to engage all students more productively in
knowledge building     (http://ikit.org/video/assessment/).

Future Work
           Because the use of the assessment tools is tracked in the same database in which the participant-generated
discourse is stored it is possible to examine the changes in discourse patterns that result from the use of the tools.
We are currently designing a series of experiments that will track the nature of changes to the discourse that occur as
a result of the use of the assessment tools.  For example, does knowledge about participation patterns enable
teachers to engage all students? Does information about semantic overlap with discourse generated by experts
support knowledge advancement?

References
Burtis, J.  (1998).  Analytic   Toolkit for Knowledge     Forum.  Centre  for  Applied    Cognitive Science, The  Ontario
           Institute for Studies in Education/University of Toronto.
Deerwester,    S., Dumais,  S.  T., Furnas,  G.  W., Landauer,    T. K., & Harshman,      R. (1990).   Indexing By   Latent
           Semantic Analysis.   Journal of the American Society For Information Science, 41, 391-407.
Gan,   Y.  (2006).  Making    thinking  visible: Towards  the  graphical literacy   growth   in Knowledge   Forum.   Paper
           presented at the Summer Institute of Knowledge Building, Ontario Institute for Studies in Education of the
           University of Toronto
Landauer,   T.  K.,  Foltz, P.  W.,  &  Laham,    D. (1998).     Introduction  to Latent   Semantic   Analysis. Discourse
           Processes, 25, 259-284.
Lee,   E., Chan,   C., &    van Aalst,  J. (2006).   Students assessing  their  own  collaborative   knowledge   building.
           International Journal of Computer-Supported Collaborative Learning, 1, 57-87.
Roos,   B.  &  Hamilton,    D.  (2005). Formative    assessment:  a  cybernetic viewpoint.      Assessment  in  Education:
           Principles, Policy & Practice. 12(1), 7-20.

                                                             721                                                  CSCL 2007
Scardamalia, M. (2002). Collective cognitive responsibility for the advancement of knowledge. In B. Smith (Ed.),
         Liberal education in a knowledge society (pp. 67-98). Chicago: Open Court.
Sun, Y., Zhang, J., & Scardamalia,  M. (2006). Literacy as    a by-product of knowledge building: An analysis  of
         vocabulary growth. Paper presented at the Annual Meeting of American Educational Research Association,
         San Francisco, CA.

Acknowledgements
         The authors wish to acknowledge the generous support of the Social Sciences and Humanities Research
Council of Canada. We would also like to acknowledge the software engineering talents of Jud Burtis (Vocabulary
Tool), Paul Johnson (Contribution and Social Network Analysis Tools), and Ben Smith Lea (Writing Tool).

                                                        Figure 2. The Social Network Analysis Tool.

Figure 1. The Contribution Tool.

Figure 3. The Vocabulary Growth Tool.

                                                        Figure 4.   The Semantic Field Visualization Tool.

                                                         722                                               CSCL 2007
