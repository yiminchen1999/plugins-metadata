Orchestrating learning activities on the social and the cognitive level
                                                 to foster CSCL
 Armin Weinberger1, Douglas Clark2, Pierre Dillenbourg3, Dejana Diziol4, Victor Sampson2, Karsten Stegmann1,
        Nikol Rummel4, Fabrice Hong3, Hans Spada4, Bruce McLaren5, Taiga Brahm6, and Frank Fischer1
                            1Department of Psychology, University of Munich, Germany
           2College of Education, Payne 203F, Arizona State University, Tempe, AZ 85287-0911, USA
                           3CRAFT, Ecole Polytechnique Fédérale de Lausanne, Switzerland
                               4 Institute of Psychology, University of Freiburg, Germany
               5Human Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, USA
                                      6SCIL, University of St Gallen, Switzerland
           Email: 1{armin.weinberger, karsten.stegmann, frank.fischer}@psy.lmu.de, 2{douglas.b.clark,
victor.sampson}@asu.edu, 3{pierre.dillenbourg, fabrice.hong}@epfl.ch, 4{diziol, rummel, spada}@psychologie.uni-
    freiburg.de, 3{pierre.dillenbourg, fabrice.hong}@epfl.ch, 4bmclaren@cs.cmu.edu, taiga.brahm@unisg.ch

        Abstract: CSCL includes a wide range of scenarios that integrate individual and collaborative
        learning. Scripts have repeatedly proven useful for guiding learners to engage in specific roles and
        activities in CSCL environments. The effective mechanisms of scripts in stimulating cognitive and
        collaborative processes, however, are not yet well understood. Moreover, scripts have been shown
        to be somewhat inflexible to variations in needs across individual learners, specific groups, and
        classroom constellations. In this symposium, we present research on how scripts impact socio-
        cognitive   processes.   The symposium    additionally  focuses on   how  CSCL   environments      can be
        orchestrated through flexible scripts that adapt to meet the special requirements at the classroom,
        small group, and individual levels.

Orchestrating         learning    activities       on    the   social   and   the  cognitive        level   to    foster
CSCL
        CSCL covers a range of scenarios in which learners both interact with each other supported by technology
and engage in phases of individual learning activities, e.g., computer-mediated learners individually access specific
resources before communicating through an asynchronous discussion board with each other (Dillenbourg & Fischer,
2006). But learners seem to rarely draw on CSCL's potential to engage in specific learning activities both on the
cognitive and the social level. Hence, CSCL often benefits from socio-cognitive structuring, for example, in the
form of scripts that guide learners' interactions (Fischer, Kollar, Mandl, & Haake, 2007). While scripts generally
aim to facilitate specific socio-cognitive learning activities, scripts may have different foci and granularities leading
researchers to distinguish between macro- and micro-scripts (e.g., Dillenbourg & Jermann, 2007; Kobbe et al., in
press). Micro-scripts focus on specific activities of learners and may, for instance, prompt learners to build their
arguments in a specific way or instruct students how to collaborate effectively. Macro-scripts rather support the
teacher to implement   CSCL      scenarios within  the classroom   orchestrating individual  and   collaborative  learning
phases  (e.g., by suggesting   individual  preparation   before   entering discussion). There   is  some   need   to better
understand  how   micro-   and macro-scripts   can be  tuned   to orchestrate learning  activities on  the social and  the
cognitive  level to foster CSCL.   First,  to understand  how   and  when  CSCL   should   encompass   collaborative   and
individual learning  activities, the effects  of scripts on  processes  and   outcomes  of collaborative   and  individual
computer-supported learning need to be investigated. Second, to understand how scripts should orchestrate learning
activities on the social and the cognitive level, macro-scripts should be investigated that guide learners through the
different individual and collaborative learning activities.

Research Presented
        To    answer  these questions,  we    present  studies ranging  from  hypotheses   testing  to design   study  and
investigating  micro- and   macro-scripts.  This  symposium    first focuses  on how   scripts can  affect cognitive   and
collaborative processes in integrated learning environments (the studies by Weinberger et al. and Diziol et al.). The
Weinberger et al. study indicates that CSCL has additional benefits over individual learning scenarios only when the
collaborative learners are supported with a script that facilitates the construction of single arguments. The Diziol et
al. study examines the extent to which learners in an individual learning environment that incorporates an intelligent
tutoring system benefit from working collaboratively with a script that guides learners through different individual

                                                            36                                                   CSCL 2007
and collaborative phases. These phases include adaptive and meta-cognitive components. The second focus of this
symposium is on how scripts can guide learners through different social levels by assigning learners to discussion
groups based on differences in perspectives (the studies by Clark & Sampson and Dillenbourg et al.). The Clark &
Sampson study compares a script that assigns learners to discussion groups based on their individual positions in
comparison to a script that assigns learners to defend a specific perspective. The Dillenbourg et al. study presents a
computer tool that supports teachers as they design and adapt a script that assigns learners to discussion groups
based on  their individual  positions  (similar to  the Clark   & Sampson     study)  to   orchestrate learning activities  on
different social levels.

Scripting       argumentative            knowledge          construction:          Effects      on     individual        and
collaborative learning
Armin Weinberger, Karsten Stegmann, & Frank Fischer
Department of Psychology, University of Munich, Germany

          In argumentative knowledge construction (AKC), learners construct knowledge through the construction of
arguments  and  counterarguments      about  a complex   problem   (Andriessen     et al., 2003;   Weinberger   et  al., 2006;
Weinberger & Fischer, 2006). AKC research thus far has focused on both (1) the individual processes of learners
self-explaining the learning material when constructing arguments (Baker, 2003; Stegmann et al., 2006) as well as
(2) the inter-individual  aspects  of AKC    involving  the added  value   of confronting    learners  with  peers' diverging
conceptualizations of a problem (Leitão, 2000). Research in this area is challenging because social and cognitive
processes are highly intertwined. To date, few empirical studies have examined the nature, existence, and added
value of the inter-individual aspects of AKC. Exploring differences between individual and collaborative learning is
often considered    outdated  against  the  assumption   that  learning  in  groups   exceeds   individual   domain-specific
learning  depending   on  specific  conditions  that have   to be met   to  foster collaborative   learning  (Slavin,    1993).
Investigating  the social form   of learning,  however,  might  involve  more   specific   questions   on how   collaborative
learning can be supported to foster domain-specific as well as domain-general knowledge such as argumentative
knowledge.

          One  approach    to facilitate AKC    in   online learning   environments    involves    providing  learners     with
computer-supported scripts that specify, sequence, and assign roles and activities to learners. Scripts may effectively
structure different aspects   of learners'  interactions (e.g., formal  or   epistemic   aspects of    argumentation).   Some
scripts, for example, facilitate argumentative knowledge without reducing domain-specific knowledge acquisition
(Stegmann et al., 2006). It remains unclear, however, whether this beneficial script effect is due to a reduction of
process losses typically experienced by computer-supported collaborative learners, such as coordination problems
(e.g., Strijbos et al., 2004), or the support of meaningful learning activities by the individual learner, such as sound
argument construction (e.g., Stegmann et al., 2006).

          Research Question 1: To what extent does an argumentative script (with vs. without) and the social form of
learning  (individual vs.  collaborative)   affect the  formal  and  the   epistemic  quality   of arguments    that learners
construct within an online learning environment? Regarding RQ1, we hypothesize that the script would foster the
formal and the epistemic quality of arguments of individual and collaborative learners.

          Research Question 2: To what extent does an argumentative script (with vs. without) and the social form of
learning (individual vs. collaborative) affect individual learning outcomes? Regarding RQ2 we hypothesize that the
script would foster learning outcomes of collaborative learners beyond the level that unscripted collaborative and
individual learners would attain.

Methods
          In this 2×2-factorial design (n = 72), we investigate the effects of an argumentative script (with vs. without)
and the social form of learning (individual vs. collaborative) on learning processes and outcomes in the context of a
computer-supported    learning   environment    in higher   education.  Learners   analyzed   problem     cases focusing    on
attribution theory (Weiner, 1985) individually or in groups of three. The script was designed to support specific
formal aspects of argumentation, namely the construction of single arguments according to a simplified model of
argument construction by Toulmin (1958). The script guides learners to specify their claims, provide at least one
datum   with a  warrant  that supports   the claim,  and identify  at  least  one  qualifier of  the  claim. The    script was

                                                             37                                                     CSCL 2007
                                                                                                                             z- scores of
                                                                                                                                          know ledge tests
implemented into an asynchronous CSCL environment involving discussion boards with text windows for each of
the three single argument components: (1) claim, (2) datum, and (3) qualifier (see Figure 1).

         Based on the written analyses of the learners during the online learning session, we analyzed the formal
quality  of arguments  (i.e. the frequency  of warranted                                                 and                              qualified                   claims),            the        epistemic              quality         of arguments
within the learning environment (i.e. the frequency of arguments that contributed to solving the learning task by
applying specific theoretical concepts adequately to a problem case), individual learning outcomes with a pen and
paper test regarding domain-specific knowledge (i.e. the extent to which learners were individually able to apply
specific theoretical concepts  to a transfer problem     case                                                                   after                         participating              in the         online     learning                 session),             and
argumentative knowledge (i.e. the extent to which learners were individually able to recall argument components
such as claim, warrant, and qualifier and to construct warranted and qualified claims on another topic).

Results
         With regard to RQ1, the findings show clearly that the script increases formal quality and reduces epistemic
quality of arguments. Although this holds true for both individual and collaborative learners, a positive interaction
effect shows that the script particularly facilitates the formal quality of collaborative learners' arguments.                                                                                                                                 Regarding
learning    outcomes  (RQ2),     formerly   scripted  collaborative                                                                                              learners              acquired               more  domain-specific                               and
argumentative knowledge than any other experimental group (see Figure 2). We found a disordinal interaction of the
two factors (i.e. script and social form of learning), leading us to compare the effects of each factor controlled by the
other factor.

                                                                                                                                                                      Learning Outcom es

                                                                                                                   Dom ain- specific                        1,5
                                                                                                                   knowledge                                                                                                                              0.94
                                                                                                                   Argum entative                                                                                                                         (0.63
                                                                                                                   knowledge                                   1                                      0.360,50.19(1.04                         0.60(1.25
                                                                                                                                                                     (1.02

                                                                                                                                                               0

                                                                                                                                                           -0,5                                                      -0.29-0.51(0.71)-0.51
                                                                                                                                                             -1               -0.80          (0.64)(0.77)                       (0.64)

                                                                                                                                                           -1,5
                                                                                               So cia l form                 of learning                            individual learner      individual learner        group  of t hr ee         group  of t hr ee
                                                                                                 Argum entative script                                                without scr ip t          with scr ip t          without  scr ip t          with scr ip t

 Figure 1. Interface of the scripted discussion board                                                                                                             Figure 2. Z-scores of domain-specific and
                                                                                                                                                           argumentative knowledge tests: means and standard
                                                                                                                                                                     deviations for each experimental group.

         The  multivariate   ANOVA      demonstrates  no                                                effects                                            of    the social            form  of         learning            for          learners         without
support of the script. The multivariate comparisons between learners in groups with script and learners in groups
without script (F(2,15) = 16.26, p < .01; 2 = 0.68) as well as with individual learners without script (F(2,15) = 4.99,
p < .05; 2 = 0.40) show strong significant effects.

Discussion
         (RQ1) The argumentative script facilitates the formal construction of arguments, but has detrimental effects
on the epistemic quality of arguments. By focusing learners' efforts to construct formally adequate arguments, the
script may   have lead learners'  attention away  from                                                  building                                            arguments           of      high         epistemic              quality         (Dillenbourg,
2002). Learners seemed to somewhat lose sight of the theoretical concepts they were supposed to apply. This may
be particularly problematic for scripted individual learners who cannot compensate by drawing on sound arguments
from their learning partners (Leitão, 2000). For collaborative learners, on the contrary, the script seemed to reduce
process losses normally resulting from learning together online (see Strijbos et al., 2004).                                                                                                                                (RQ2) Collaborative
learning may   outperform    individual learning regarding                                                   learning                                            outcomes              when          it is     structured                by a  script.             Put
another way, individuals in unstructured groups did not learn better than individual learners, and CSCL unfolds its
potential only, when the degree of freedom is not too large (Kirschner et al., 2006). Scripted collaborative learners
acquired more domain-specific and more argumentative knowledge than any other experimental group.

                                                                                                          38                                                                                                                                           CSCL 2007
         Some   limitations  of the study  should   be considered,   however.    First, earlier  studies comparing   different
supports of AKC     for CSCL    groups    found that   argumentative   scripts have     positive effects  on   domain-general
knowledge   but  no   effects on   domain-specific     knowledge.   Studies  with   larger  samples      need  to clarify  the
circumstances   and the extent  to  which  argumentative    scripts also facilitate domain-specific      knowledge.  Second,
because the participants of the study were first semester students with little prior domain-specific knowledge and
little CSCL experience, the findings may not generalize to other, more experienced populations of learners. Future
research needs to consider how scripts interact with varying levels of prior knowledge (Kollar et al., 2006). Third,
although the problem cases could be regarded as complex (with the possibility of multiple solutions), the problem
cases cannot be regarded as genuine group tasks (where co-learners are required to solve the task). Investigating
scripts for genuine group tasks may clarify further how scripts need to be adapted to the needs of individual learners
and how groups of learners benefit from determining their own procedures (see Clark & Sampson, this symposium).

Promoting       Learning        in  Mathematics:           Script     Support       for   Collaborative           Problem
Solving with the Cognitive Tutor Algebra
Dejana Diziol, Nikol Rummel, Hans Spada, Bruce McLaren
Institute of Psychology, University of Freiburg, Germany
Human Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, USA

         We combined two different instructional methods both of which have been shown to improve students'
learning in mathematics:    Learning  with   intelligent  tutoring systems  (Koedinger     et   al., 1997) and   collaborative
problem solving (Berg, 1993). The problem-solving guidance provided by an intelligent tutoring system is effective,
but because it places emphasis on learning problem solving skills, a deep understanding of underlying mathematical
concepts is not  necessarily    achieved  (Anderson    et al., 1995).  Collaborative    activities   can yield elaboration of
learning content (Teasley, 1995) and thus increase the potential for the acquisition of deep knowledge, but students
are not always able to effectively meet the challenges of a collaborative setting and tap this potential (Rummel &
Spada,   2005). Collaboration     scripts that  prompt    fruitful interaction   have   proven     effectively in  supporting
collaborative learning (Kollar, et al., 2006). We believe that by combining intelligent tutoring and collaborative
learning we   could   foster  the  advantages   of  both   instructional methods    and    overcome      their disadvantages.
Collaborative   interaction  could  augment    the  effects of   an  intelligent tutoring   system     by  promoting    deeper
elaboration, and script support integrated in the tutoring environment could provide guidance to students as they
collaborate and thus improve the quality of their collaboration.

Script Design
         Our collaboration script was designed to guide students in collaborating while solving problems with the
Cognitive Tutor Algebra (Koedinger et al., 1997), a tutor for mathematics instruction at the high school level. Its
main features   are immediate   error feedback,  the   possibility to ask  for a  hint  when    encountering   impasses,  and
knowledge tracing, i.e. the Tutor creates and updates a model of the student's knowledge and selects new problems
tailored to the student's knowledge level. For the present study we focused on "systems of equations", content novel
to the participating students. The script consisted of three components. First, it had a fixed script component that
structured the problem solving process in two phases. During the individual problem solving phase, each student
solved a problem in the Cognitive Tutor that consisted of one equation. In the collaborative phase, the two students
joined on a single computer to solve a more complex system of equations problem that combined the two individual
equations. They  received   instructions  from  the enhanced    Tutor, e.g. prompting     them   to  use  collaborative skills.
Second, the script had an adaptive script component that reacted when students met impasses that resulted in Tutor
actions (e.g. hints). To encourage students to take advantage of these learning opportunities, the script asked the
dyad to  elaborate   on  the  help  received.   Third, the  script  had  a  metacognitive     component.     Following    each
collaborative phase, students evaluated their collaboration and set goals for how to improve it during the next joint
problem solving session. This component aimed at increasing students' ability to collaborate effectively even when
no longer receiving script support. This is particularly important due to the risk of overscripting collaboration, i.e.
motivation losses yielding reduced performance and learning, a phenomenon that has been discussed in conjunction
with scripting for longer periods of time (Rummel & Spada, 2005).

Script Evaluation
         We  conducted   a  classroom  study   with  a one-factorial  design,  comparing    scripted   collaboration with  an
unscripted collaboration condition in which students collaborated without support. This study was an initial, small

                                                             39                                                      CSCL 2007
scale study to establish basic effects and to test the procedure in a classroom setting. The study took place during
three periods over the course of a week at a vocational high school outside of Pittsburgh in the U.S. Due to the
disruptiveness  of students    in the same   class  using different  interventions,  we  used a  between-class    design. The
unscripted condition consisted of two classes (12 and 4 students), and the scripted condition consisted of one class
(13 students). All classes were taught by the same teacher.

           During day 1 and day 2 (learning phase), students learned how to solve system of equations problems.
Depending on their condition, they collaboratively solved problems either with or without script support. On day 3
(test phase) we assessed students' individual and collaborative learning gains with three tests administered within
the Cognitive   Tutor   and a  paper  and   pencil  test. The  Tutor  post-tests   assessed the script's effect  on  students'
problem solving skills. One post-test asked students to individually solve system of equations isomorphic to those
during instruction, thus testing the individual's retention of the learned skills. A second post-test asked students to
collaboratively  solve   system   of  equations    without  script  support   to assess  the  script's  effect on   improving
collaborative problem solving skills. Learning from the script should also enable students to capitalize on future
collaborations at the Tutor, i.e. it should accelerate their future collaborative learning. Hence, the third Cognitive
Tutor post-test confronted students with a novel problem type: inequality problems. The paper and pencil post-test
concentrated on assessing students' conceptual knowledge with two different problem sets. Problem set 1 tested for
students' understanding of the basic concepts y-intercept and slope: Multiple choice questions asked students to
make transformations between verbal, algebraic and graphical representations of those concepts, and open format
questions asked them to explain their answers. Problem set 2 assessed students' understanding of the main new
system of equations concept learned: the intersection point. Again, students had to answer two types of questions:
questions  with  discrete   answer    possibilities (correct  or  incorrect), and   open format    questions   that asked  for
explanations. Scores were summed for each problem set. For answers to the multiple choice questions of problem
set 1 (basic concepts), a maximum of 11 points could be reached; the possible maximum for explanations on basic
concepts   was 22  points.  For   problem  set  2 (intersection  point), the  maxima   were  six  points for discrete  answer
format and 12 for open format questions.

Results
           The analysis  was   restricted to   students   who  always   worked   collaboratively   when  present,   as we  are
interested in the script's effect on collaborative learning in particular. Due to student absenteeism, only 9 students in
the unscripted and 10 students in the scripted condition were included in our analysis. First results of a MANOVA
comparing   performance     of conditions   in  the paper  and   pencil  post-test  showed  significant  differences   between
conditions (Pillai-Spur, F(4, 14) = 7.35, p < .05). Means and standard deviations of the ANOVAs for each variable
are displayed in Table 1. Answers to the multiple choice questions on basic concepts did not show a significant
difference, F(1,17) = 2.26, ns. However, the scripted condition outperformed the unscripted condition on the discrete
answer questions about the system's concept, F(1,17) = 22.16, p < .01. Significant differences between conditions
was   also found for  the  open   format  questions  of   both problem   sets with   F(1,17) =  5.85,  p <  .05 for  the basic
concepts and F(1,17) = 17.01, p < .01 for the system's concept.

Table 1: Means and standard deviations of the paper and pencil post-test, assessing conceptual understanding

                                                Unscripted condition                   Scripted condition
                                                M                 SD                 M                   SD
  Basic concepts: multiple choice                   4.89              1.83               3.60                1.90
      Basic concepts: open format                    .22                 .44             1.20                1.14
System concept: discrete answers                     .89              1.45               4.50                1.84
      System concept: open format                    .44              1.33               5.70                3.59

Discussion and Outlook
           The script had a significant effect on the acquisition of the main new concept of the system of equations
unit, the  intersection point. Particularly  interesting   are the  substantial  differences that  were  found  for  the  open
format  questions    of both   problem    sets, demonstrating     a strong   effect of the  script on   students'   conceptual
knowledge:     After scripted   interaction  during   the  learning   phase,   students  were   better  at  articulating  their
mathematical thinking compared to their unscripted counterparts. It should be noted, however, that students in both
conditions had difficulties providing explanations and only reached low scores in the open format questions. The

                                                               40                                                    CSCL 2007
amount of wrong explanations and the number of students who did not even try to articulate their thinking was very
high. Thus, it might be promising to extend the learning phase in future studies to increase the script's effect. It
remains to be seen if the script's effect can also be found in the Cognitive Tutor tests. Currently, we are analyzing
the Tutor log files for variables such as number of errors per problem, time per problem, decrease of error rates over
the course of several problems etc. Contrasting this post-test data with corresponding data from the learning phase
will inform us on differences in students' learning progress. Results of the Tutor post-tests will be presented at the
conference.

Fostering Productive Argumentation in Online Environments: Strategies for
Grouping Students in Discussion Forums
Douglas Clark and Victor Sampson
College of Education, Arizona State University

         Our ongoing research (Clark & Sampson, 2006, 2007) focuses on fostering productive argumentation in
science classrooms through a process that involves (a) providing students with empirical data and scientific ideas
about a phenomenon, (b) scaffolding students in the creation of an explanation that articulates their ideas clearly and
focuses on the salient issues, (c) organizing discussions around alternative perspectives, and (d) facilitating equitable
and productive discourse among the students. This study examines the tradeoffs between organizing debates around
students' own proposed explanations versus assigning students to conceptually optimized pre-selected explanations.

         Our work adopts a view of argumentation as a process where "different perspectives are being examined
and the purpose is to reach agreement on acceptable claims or courses of action" (Driver et al., 2000, p. 291). Hence,
our efforts to support  and   promote  argumentation    in science   classrooms  have   focused on the  development     of a
CSCL environment where students generate competing explanations for a given phenomenon and then examine,
discuss,  and  evaluate these   explanations  based  on    available evidence.   We   have   developed  personally-seeded
discussions to support students in this discourse. These customized asynchronous discussion forums (a) scaffold
students as they synthesize an explanation to describe data that they have collected, (b) organize discussion groups
of students who have created different explanations, and (c) encourage students to critique each other's explanations
and work toward consensus based on evidence available to them. Research that we have conducted over the last four
years indicates   that  personally-seeded   discussions    are  an  effective   way  to foster  equitable   and   productive
argumentation between students; which we define in this context as a discussion that incorporates the voices of all
students, exposes students to new ideas, and creates a need for students to evaluate the legitimacy of alternative
viewpoints (Clark & Sampson, 2007).

         As   discussed above,   the  current study  investigates    the tradeoffs  between    organizing   debates around
students' own   proposed   explanations    versus assigning    students  to defend  conceptually  optimized     pre-selected
explanations.  In particular, we investigate  and   compare     the impacts   on student argumentation    of  two  different
strategies for organizing and scripting discussions around alternative perspectives. In both interventions, students
first create their own explanations to explain the phenomenon under investigation. The software then uses these
proposed  explanations  to  automatically   sort  students into  discussion   forums  with   students who   have  proposed
different explanations (and are therefore likely to have different perspectives on the phenomenon). The treatment
groups differ in terms of what happens after this sorting process.

    Personalized   Explanations    Treatment:    In the  personalized    treatment    group, the students'   proposed
    explanations  from  the   sorting step become   the  seed   comments    for the discussion. Because   students  are
    sorted into groups with students who proposed different explanations for the phenomenon, some range of
    explanations is represented, but that range is not necessarily controlled or optimized.

    Range of Explanations Treatment: In the range intervention, students are sorted into groups using the same
    procedures,   but  the seed  comments     for   the discussion   come    from   a predetermined    list of  sample
    explanations generated specifically to represent a range of the critical student misconceptions identified
    through   earlier research. In this approach,   students    are automatically   assigned to  defend one    of these
    specific explanations.

                                                             41                                                   CSCL 2007
          In both treatments, students are instructed to critique all of the explanations. Students are further instructed
to reply  to the comments   addressed    to them  and to  focus   on evidence.  Students  are  asked  to compare     their
explanations, take into account all of the arguments and evidence, and revise their final answers accordingly. The
goal of this scripting strategy is to encourage students to view explanations as objects of cognition (Kuhn, 1993) that
need to be critiqued and revised before they can be accepted. In sum, the personalized strategy focuses on engaging
students own ideas (while potentially not presenting as optimal a range of explanations to spark discussion) and the
range strategy presents an optimal range of explanations from a conceptual perspective but omits the personalization
of the discussion (i.e., the students are discussing generic explanations rather than one another's explanations as the
seed comments).

Data and Results
          To evaluate the relative impacts of the range and personalized strategies, we have been (and continue to)
randomly   assign  students within  classrooms   to one   of  the two    conditions within   a standard  WISE    project
investigating thermodynamics     (Thermodynamics:    Probing   Your  Surroundings,   http://wise.berkeley.edu).  In  this
project students investigate the concepts of thermal equilibrium, thermal conductivity, and the difference between
heat and  temperature   by  collecting real-time data and   interacting  with simulations  (see Figure   3) before   they
participate in the online asynchronous discussion forum. Data is logged on our servers as teachers naturally come to
the WISE website and run the project with their students.

 Figure 3. During the online project, Thermodynamics: Probing Your Surroundings, students collect real time data
                   (left) and interact with simulations (right) to learn about the thermodynamics.

          In this study, as discussed above, students in each class are sorted into discussion groups by the software so
that a range of different perspectives is represented in each group. At this point, the software randomly divides the
groups within each classroom between the two conditions. This approach allows us to collect data from a variety of
classrooms and schools without the intrusiveness of a formal intervention and provides a window into the overall
effectiveness of the two treatment groups in an authentic context. Also importantly, this approach maintains the
methodological advantages of random assignment within classroom rather than by classroom.

          The data collected by   the  servers includes:  (1) the initial explanations  that students  submit,   (2) full
transcripts of the discussions, and (3) the final explanations that students submit after leaving the discussions. We
therefore have a pre/post measure of students' proposed explanations as well as the actual discussion transcripts. The
initial data suggests that  (1) students engage  in higher   amounts  of  discourse  in the  personalized   condition as
measured by the number of comments made and the average length of comments and (2) students are more likely to
select the normatively "correct" explanation subsequent to the discussion in the personalized condition.

          These initial findings suggest that organizing discussions around students' own proposed explanations is
more valuable than organizing discussions around optimized sets of candidate explanations even though the latter
approach   guarantees a  more   thorough    presentation of key   ideas.  These findings  further suggest   the  relative
importance   of student ownership   and  motivation   in argumentation    environments  in  comparison   to  the careful
orchestration of the conceptual components within the argumentation environment. The full presentation of our data
will outline the details of these relationships and their implications for the design of learning environments at the
interface between technological and social supports.

                                                           42                                                  CSCL 2007
The Teacher's Side of CSCL Scripts
Pierre Dillenbourg, Fabrice Hong, & Taiga Brahm
CRAFT, Ecole Polytechnique Fédérale de Lausanne, Switzerland; SCIL, University of St Gallen, Switzerland

          Integrated learning scripts    (Dillenbourg & Jermann,   2007)   do no only  include group   activities  but also
integrate individual  activities and  class-wide  activities. These  activities  occur in the  classroom    space  and  are
orchestrated by the teacher. This contribution addresses the general issue of the teacher's role in CSCL activities in a
concrete  case:  how  the   ManyScripts    environment    enables teachers to   design a  script, prepare   a session  and
orchestrate the activities in real time.

Preparing a script instance
          This works stems from our European research team (1) on formalizing CSCL Scripts. Most macro-scripts
can be described from a small set of elements: a script is a sequence of phases, groups are structured with roles
associated to different resources and modes of interactions. The script description scheme (2) would support a top-
down   approach  to  script authoring,   focusing on  a language   able to model   a large variety  of scripts,  as it was
developed by the COLLAGE group in Valladolid or by the COLLIDE group in Duisburg (3). This approach raises
the various difficulties that authoring tools encountered over the previous decades: the tool is powerful but it is not
easy for a teacher to come up with an innovative scenario that can be expressed within such a constrained language.
Instead,  we implemented    a bottom-up    approach,   in which   teachers start from  an  existing script, modify   some
parameters and edit the content. The philosophy behind this is that the authoring tool is not pedagogically neutral but
conveys instead a specific pedagogical model.

          Currently, the environment, called ManyScripts, supports editing the script called 'ConceptGrid'. This script
is a sub-class of the class of script referred for many years as "JIGSAWS". The 'ConceptGrid' unfolds as follows: 1)
Groups of students have to distribute roles among themselves. Roles correspond to theoretical approaches of the
domain under study. In order to learn how to play their roles, students have to read n papers that describe the theory
underlying their role. 2) Each group receives a list of concepts to be defined and distributes these concepts among its
members. Students write a 5 lines definition of the concepts that were allocated to them. 3) Groups have to assemble
these concepts into a grid and to define the relationship between two concepts that are neighbours on the grid. The
key task is to write 5 lines that relate or discriminate two juxtaposed concepts: if Concept-A has been defined by
Student-A  and   Concept-B    by Student-B,   writing   the Concept-A/Concept-B     link  requires  Student-A   to  explain
Concept-A to Student-B and vice versa. 4) During the debriefing session, the teacher compares the grid produced by
different groups and asks them to justify divergences. To use a ConceptGrid script in her course, the teacher has to
decide about the group size (number of roles) and edit the contents of the script: she defines the roles, the papers to
be read for each role and the sets of concepts to be defined and assembled in a grid by the student groups. The result
is what we refer to as a script instance, e.g. "ConceptGridBiology2.1".

                                                                Figure 4b (above). Global look at group work

                                               Figure 4a (left). Coping with irregular groups

Preparing a script session
          The same script instance may be run several times, for instance if "ConceptGridBiology2.1" is used in two
different classes, respectively in winter and summer terms. Hence, the teacher has to prepare two sessions of the
script instance, the "ConceptGridBiology2.1.oct06"      and   "ConceptGridBiology2.1.march07".      Setting   up a  session
may sound trivial: the teacher has to provide student names, form groups (or let them do it) and set up the start/end
dates for each script phase. This simplicity does not match what happens in actual university classes: some students

                                                             43                                                  CSCL 2007
joint the course late, some drop out, ... A common bit tricky problem is when the number of students is not a
multiple of the group size. What does the teacher do if 11 students have to be distributed into groups of 2? The
ManyScripts environment offers two 'flexibility' options: to handle extraneous group members (groups of 3,4,4) or
to handle missing members (groups of 3,3,3,2) as in figure 4a. The system copes with these situations as follows. A
team with a missing member/role X may reuse definitions produces by the role-X members of any other team in the
class and session. If a team has an additional group member, he or she plays the role of a 'joker' allowed to off-load
the work of any other group member; the team is free to decide how to share the workload.

Orchestrating a session
         When the script is running, the teacher has the possibility to change some parameters such as the group
composition  or deadlines     up to a  certain  level. The ManyScripts   environment   enables the teacher to follow the
evolution of teamwork at a high level of aggregation as in figure 4b. More importantly, the 'teacher cockpit' enables
the teacher to explore the contents produced by group along different axis: per construct concepts grids, per group,
per concept or per relation between concepts. Teachers may use the cockpit for grading the groups' work and, more
importantly, for preparing the debriefing phase, i.e. when the teacher discusses the group productions with the whole
class. The debriefing can be prepared in different ways. The teacher may annotate with her own colour codes the
different productions (Figure 5a). Hence, when she uses the cockpit during the debriefing lecture, she may easily
find the definitions she     wants to  refer to in her  comments.   Alternatively, she may  simply  integrate the student
productions within her presentations as in figure 5b.

Figures 5a and 5b. Teacher reusing group productions by annotating them within the ManyScripts environment (left)
                         or by integrating them into her lecture presentation material (right).

Experiments
         This new release of the ConceptGrid is now being used in an EPFL course, through 4 successive iterations.
It is also used in a course for educational management at the University of St. Gallen. The different sessions will be
evaluated and   compared     using  content   analysis. In addition,  a questionnaire  will be used  to capture students'
reactions, and the teachers using the grid will be interviewed. Results will be reported at the conference.

Concluding Remarks
         The research  presented    in  this symposium     differs to a large  extend in terms of addressing  micro- and
macro-scripts and in terms of presenting hypotheses testing as well as design studies. As a whole, however, the
symposium    provides a      guideline of how   to implement      (scripted) CSCL  in the classroom, how   to orchestrate
individual and collaborative learning activities, and what effects on learning processes and outcomes to expect of it.
Overall, the presented research shows that CSCL may neither unfold its full potential when no structure is provided
to the individual and collaborative learning processes (see Fischer et al., 2007) nor when learners are confronted
with too much, badly timed or the wrong kind of "support" (see Dillenbourg, 2002). A major focus of future script
research therefore is to introduce flexible scripts that can be adapted and modified by both, teachers and learners.

Endnotes
(1) The European Research Team COSSICLE (http://www.iwm-kmrc.de/cossicle/fr_index.html?news)
(2) http://www.iwm-kmrc.de/cossicle/resources/D29-02-01-F.pdf
(3) http://www.collide.info/

                                                               44                                                 CSCL 2007
References
Anderson, J. R., Corbett, A. T., Koedinger, K. R., & Pelletier, R. (1995). Cognitive tutors: Lessons learned. Journal
        of the Learning Sciences, 4(2), 167-207.
Andriessen, J., Baker, M.,  &  Suthers, D. (Eds.). (2003).   Arguing to learn. Confronting    cognitions in  computer-
        supported collaborative learning environments. Dordrecht: Kluwer.
Baker, M. (2003). Computer-mediated argumentative interactions for the co-elaboration of scientific notions. In J.
        Andriessen, M. Baker & D. Suthers (Eds.), Arguing to learn: confronting cognitions in computer-supported
        collaborative learning environments (Vol. 1, pp. 1-25). Dordrecht: Kluwer.
Berg, K. F. (1993). Structured cooperative learning and achievement in a high school mathematics class. Paper
        presented at the Annual Meeting of the American Educational Research Association, Atlanta, GA.
Clark, D. B., & Sampson, V. (2006, April). Characteristics of Students' Argumentation Practices When Supported
        by  Online   Personally-Seeded   Discussions.  Paper    presented at the  annual    meeting  of  the  National
        Association of Research in Science Teaching, San Francisco, California.
Clark, D.  B.,  &  Sampson,   V. (2007). Personally-seeded    discussions to scaffold online    argumentation.   To be
        published in 2007 in the International Journal of Science Education.
Dillenbourg, P. (2002). Over-scripting CSCL: The risks of blending collaborative learning with instructional design.
        In  P.  A. Kirschner  (Ed.), Three worlds  of CSCL:   Can  we   support CSCL?      (pp. 61-91). Heerlen: Open
        Universiteit Nederland.
Dillenbourg, P., & Fischer, F. (2006). Computer-supported collaborative learning: The basics.
Dillenbourg, P., & Jermann, P. (2007). Designing integrative scripts. In F. Fischer, H. Mandl, J. Haake & I. Kollar
        (Eds.),   Scripting computer-supported   communication     of knowledge   -   cognitive,   computational  and
        educational perspectives (pp. 275-301). New York: Springer.
Driver, R., Newton, P., & Osborne, J. (2000). Establishing the norms of scientific argumentation in classrooms.
        Science Education, 84(3), 287-313.
Fischer, F., Kollar, I., Mandl, H., & Haake, J. (Eds.). (2007). Scripting computer-supported collaborative learning.
        New York: Springer.
Kirschner, P. A., Sweller, J., & Clark, R. E. (2006). Why minimal guidance during instruction does not work: An
        analysis of the failure of constructivist, discovery, problem-based, experiential, and inquiry-based teaching.
        Educational Psychologist, 41(2), 75-86.
Kobbe, L., Weinberger, A., Dillenbourg, P., Harrer, A., Hämäläinen, R., Häkkinen, P., et al. (in press). Specifying
        Computer-Supported     Collaboration Scripts. International  Journal of  Computer-Supported      Collaborative
        Learning.
Koedinger, K. R., Anderson, J. R., Hadley, W. H., & Mark, M. A. (1997). Intelligent tutoring goes to school in the
        big city. International Journal of Artificial Intelligence in Education, 8, 30-43.
Kollar, I., Fischer, F., & Hesse, F. W. (2006). Collaboration scripts - a conceptual analysis. Educational Psychology
        Review, 18(2), 159-185.
Kuhn, D. (1993). Science as argument: Implications for teaching and learning scientific thinking. Science Education,
        77(3), 319-337.
Leitão, S. (2000). The potential of argument in knowledge building. Human Development, 43, 332-360.
Rummel, N., & Spada, H. (2005). Learning to Collaborate: An Instructional Approach to Promoting Collaborative
        Problem Solving in Computer-Mediated Settings. Journal of the Learning Sciences, 14(2), 201-241.
Slavin, R. E. (1993). Synthesis of research on cooperative learning. In A. E. Woolfolk (Ed.), Readings & cases in
        educational psychology (pp. 170-178). Needham Heights: Allyn & Bacon.
Stegmann,  K.,  Wecker, C.,   Weinberger,  A., &   Fischer,  F. (2006). Collaborative argumentation      and cognitive
        processing - An empirical study in a computer-supported collaborative learning environment.
Strijbos, J. W., Martens, R. L., Jochems, W. M. G., & Broers, N. J. (2004). The effects of functional roles on group
        efficiency: Using multilevel modeling and content analysis to investigate computer-supported collaboration
        in small groups. Small Group Research, 35(2), 195-229.
Teasley, S. D. (1995). The role of talk in children's peer collaborations. Developmental Psychology, 31(2), 207-220.
Toulmin, S. (1958). The uses of argument. Cambridge: Cambridge University Press.
Weinberger, A., & Fischer, F. (2006). A framework to analyze argumentative knowledge construction in computer-
        supported collaborative learning. Computers & Education, 46, 71-95.
Weiner, B. (1985). An attributional theory of achievement motivation and emotion. Psychological Review, 92, 548-
        573.

                                                          45                                                  CSCL 2007
