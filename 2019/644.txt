The Effects of Online Peer Feedback Supported by Argumentation
 Instruction With Worked Example and Argumentative Scripts on
                                 Students' Learning Outcomes
                     Saeed Latifi, Tarbiat Modares University (Iran), s.latifi@modares.ac.ir
        Omid Noroozi, Wageningen University and Research (the Netherlands), omid.noroozi@wur.nl
                    Javad Hatami, Tarbiat Modares University (Iran), j.hatami@modares.ac.ir
    Harm J.A. Biemans, Wageningen University and Research (the Netherlands), harm.biemans@wur.nl

        Abstract:    This  study   investigates  the   effects  of  online   peer feedback    supported   by
        argumentation    instruction   with worked    example    and Argumentative    scripts on  students'
        argumentative essay writing, argumentative feedback quality and domain-specific knowledge
        acquisition  in  the field  of educational    sciences. Participants  were 52  students  who   were
        randomly divided over 26 dyads and randomly assigned to three conditions (unscripted peer
        feedback, Instruction with worked example, scripted peer feedback). To do so, an online peer
        feedback system was designed and developed. They were then asked to write and argumentative
        essay   (individually), to engage   in argumentative    peer feedback   with their learning partner
        (collaboratively),   and finally to    revise their  essays  based   on   feedback which   received
        (individually). The findings indicate that the online peer feedback supported by argumentative
        scripts  outperformed    other   two   conditions    in  terms of   argumentative   essay   writing,
        argumentative     feedback   quality   and    students'  learning.  Implications,  limitations  and
        suggestions for future research are discussed.

Introduction
Online peer feedback is one of the promising educational strategies to improve student's learning outcomes. For
example, researchers have shown that peer feedback can improve students' writing quality (Huisman et al., 2018;
Gielen & De Wever, 2012, 2015; Noroozi & Hatami, 2018;             Noroozi et al., 2016; Valero Haro et al., 2018),
students' feedback quality (Gielen & De Wever, 2015; Noroozi et al., 2016), domain-specific knowledge gain
(Noroozi & Mulder, 2017; Valero Haro et al., 2018), and students' attitudes toward the subject at hand (Noroozi
& Mulder, 2017). Although, these studies have confirmed the effectiveness of online peer feedback, there are
some main criticisms on the way in which the peer feedback is implemented. For example, there are concerns
about the quality of peer feedback because of students' limited knowledge, experience and language ability (Saito
& Fujita, 2004). Also, there are emotional and psychological issues with giving and receiving critical feedback
(Andriessen, 2006), such as perceiving critiques and counterarguments as personal attacks (Rourke & Kanuka,
2007). Therefore,   peer  feedback   should  be  supported    in the   online environments    to fully guarantee   its
effectiveness (Noroozi et al., 2016). Different instructional approaches have been proposed to support online peer
feedback. These   approaches    include sentence   starters, open   text-boxes, assigning  and   rotating roles, peer
interactions, input text fields and question   prompts  including   procedural, elaboration and   reflection prompts
(Noroozi et al., 2012). All of these approaches fall under the name "scripting". Although, studies have shown the
effectiveness of scripting approaches on improving students' academic writing, some researchers point out that
this approach can be challenging. For example, overly detailed scripts or "over-scripting" can impose cognitive
load (Dillenbourg, 2002) and impede learning (see Noroozi et al., 2013). To cope with this challenge, researchers
have proposed to use instructional strategies to reduce cognitive load such as instruction with worked example
(see Clark & Mayer, 2016). Valero Haro et al. (2018) showed the effectiveness of worked example on improving
students' argumentative essay writing quality. This study therefore compares the impacts of online peer feedback
supported by argumentation instruction with worked examples and argumentative scripts on students' learning
outcomes such as students' argumentative essay writing, argumentative feedback quality and domain-specific
knowledge acquisition in the field of educational sciences. This overall research focus was divided into three
research questions:
   1.   What are the eects of an online peer feedback supported by argumentation instruction with worked
        example and argumentative scripts on students' argumentative essays quality?
   2.   What are the eects of an online peer feedback supported by argumentation instruction with worked
        example and argumentative scripts on students' argumentative feedback quality?
   3.   What are the eects of an online peer feedback supported by argumentation instruction with worked
        example and argumentative scripts on students' domain-specific knowledge acquisition?

CSCL 2019 Proceedings                                    644                                                   © ISLS
Methods
The study took place at Kharazmi University, Tehran, Iran. The participants were 52 BSc students who enrolled
for the course "Applying Computer in Educational Sciences", and were randomly divided over 26 dyads and were
assigned to unscripted (9 dyads), instruction with worked example (9 dyads) and scripted (8 dyads) conditions.
Students in the unscripted condition were regarded as a control group without any support during the online peer
feedback.  Students   in the instruction   with   worked  condition   received  instruction  on  "how   to  provide  an
argumentative  peer   feedback".   Then,  they   were   provided with   a worked  example.   Students  in  the scripted
condition were supported by argumentative scripts in the form of a question prompts during their online peer
feedback. The mean age of the students were 20.21 (SD = 1.51) years. All participants were female. The topic for
discussion was Mobile Learning. Students were asked to write an argumentative essay on the following statement:
"The  use  of mobile    phones  and tablets   in the classroom   should   be  banned". They  were  provided    with the
description of the  case, summary      of the theoretical text regarding   the topic  and sets of links to  article and
webpages. They were provided with some additional links to websites to further study the concept of the "M-
Learning". The students were asked to take into account the various perspectives on the use ­ or lack thereof ­ of
using "Mobile   Learning    (such  as, Tablets   and Smartphones)   in    classroom".  Then, the  students  engaged  in
argumentative peer feedback, and finally they revised their essays based on feedback which received. A self-made
online learning environment (EduTech) was designed and used in this study. This online learning environment
had a series of steps (see Figure 1).

                                   Figure 1. The steps that students should take in EduTech

        All   these steps had   to be  completed   individually  except   for the peer feedback   step (all steps were
completed by student in double anonymous format). EduTech not only helped with regard to managing and
monitoring students' learning activities, but also it provided us with data gathering. EduTech provided students
with various forms of information presentation, such as texts, exercises, graphs, diagrams, and pictures with the
feedback features to stimulate interactions between members of a group in an active learning environment by
getting them thinking together about topics, media or material that is relevant to them. The feedback features in
EduTech (for scripted condition) was designed in such a way as to guide the interaction style for both synchronous
and asynchronous interactions ­ promoting reasoning, critical discussion, and justified arguments. The structure
of the guided peer feedback (i.e., argumentative peer feedback scripts) was designed on the basis of argumentation
literature (Toulmin, 1958; Andrews, 2010; Noroozi et al., 2016; Wingate, 2012; Schneer, 2014) and a high-quality
argumentative essay in the field of Educational Sciences; because, various disciplines have different features of
structure, discipline's  value, epistemology,    and  argumentation   (Andrews,   2010;   Wingate, 2012).   Therefore,
specific requirements of the essay and presentation of the arguments in the essays should be taught to students in
a given discipline by disciplinary experts (Wingate, 2012). To do so, a series of meetings were held with the
experts of the field (three professors in the field of Educational Sciences and first author of this article) to define
the elements  of a  high-quality   argumentative   essay  for  students in the field  of Educational Sciences.   These
meetings resulted in a list of items that should be included in argumentative essays of students. The panel of
experts concluded that a high-quality argumentative essay in the field of Educational Sciences should include: the
expression of a clear position on the topic at hand, expressing the context of topic (introduction), the arguments
and evidences (examples, facts, Expert opinion etc.) for and against the topic, integration of various pros and cons,
and the final conclusion on the first position. We then designed our argumentative peer feedback script as well as
Instruction with worked example on the basis of these items and embedded them in EduTech.
        Overall, implementation of the study took about 5:30 hours and consisted of five main phases (each
phase in one session in five consecutive weeks). 1) During the introduction and pretest phase, students received
introductory  textual   and  verbal explanations     in the online  learning   environment    and  completed    several
questionnaires on demographic variables, and their domain-specific knowledge (about 30 minutes). 2) In the study
and draft phase, students were asked to read theoretical text and articles on the topic at hand (M-learning), to
search the Internet based on keywords that were bolded in the theoretical text (40 minutes), and to write an

CSCL 2019 Proceedings                                      645                                                   © ISLS
argumentative essay on the following statement: "The use of mobile phones and tablets (Mobile Devices) in the
classroom should be banned" (80 minutes). 3) In the peer feedback phase, each student were asked to read the
draft argumentative essay of her learning partner and provide feedback on them (50 minutes). 4) During the
revision phase, students were asked to read the comments of their learning partners and then revise their draft
argumentative  essay   (60 minutes).   5) Finally, in the posttest  phase, students   were asked    to fill out several
questionnaires to assess their domain-specific knowledge on the topic at hand (15 minutes).

Measurements
The quality of student's written argumentative essays (in the draft and the revision phases), was measured using
the coding scheme developed by the authors. The scheme considers the features of a high-quality argumentative
essay in the field of Educational Sciences and was developed in conformity with the literature (Toulmin, 1958;
Andrews, 2010; Noroozi et al., 2016; Wingate, 2012; Schneer, 2014). The scheme included eight components. A
single score was   assigned  for each  of   these component.   Each   student was given   no    point for each  level 1
assessment (e.g. not mentioned), one point for each level 2 assessment (e.g. non-elaborated), and two points for
each level 3 assessment (e.g. elaborated). Thus, for each component, students could get a score of between zero
and two. Subsequently, all points assigned to each student were added together and served as the final score for
students' written argumentative essay quality. Two trained coders coded 10% of the data to evaluate reliability
index of inter-rater agreement. This resulted in identical scores in 80% of draft and 82% of the revision phases.
The same coding scheme was adjusted to assess the quality of students' feedback quality. Two trained coders
coded 10% of the data resulted in identical scores in 83% of the data. The pre- and post-test questionnaire, which
was completed     by  students before  draft phase  and after revision  phase  consisted  out   of 10  multiple-choice
questions to measure students' domain-specific knowledge. For these questionnaire, students needed to choose
one answer out of four options. Each correct answer was given one point and as a result each student could receive
10 points at maximum for both pre- and post-test.

Findings and discussions
Repeated measures ANOVA test showed that the written argumentative essays quality of students in all conditions
improved significantly from the draft phase to the revision phase, F (1, 49) = 70.28,           ,        58. Also, there
was a significant difference between the conditions in terms of argumentative essay quality, F (1, 49) = 40.82, p
< .001,        62. The post hoc Tukey HSD test showed that the mean score for the scripted condition was
significantly higher than unscripted condition, p < .001. In addition, this test showed that the mean score for the
instruction with worked example condition was significantly higher than unscripted condition, p < .001. Also,
students in the scripted condition scored higher than students in the instruction with worked example condition in
terms of argumentative essays quality, p < .001. This is in line with previous studies that emphasize the positive
effects of scripts on quality of students' written argumentative essays (Huisman et al., 2018; Gielen & De Wever,
2012, 2015; Noroozi et al., 2016). Giving and receiving a high-quality feedback allow students to consider these
features during the revision phase. Students in the scripted condition outperformed students in the Instruction with
worked example condition in terms of argumentative essay quality. The reason may be that, although students in
Instruction  with worked   example  learned   how  to write   argumentative   essay, they were   not   prompted  in the
feedback phase to provide a high-quality feedback. This matter should be considered in future research on the use
of scripts; i.e. when scripts and Instruction with worked example are used in combination.
        One-way ANOVA showed a significant difference between various conditions in terms of argumentative
feedback quality, F = 31.77, p < .001. The post hoc Tukey HSD test revealed that the mean score for the scripted
condition was  significantly   higher  than  unscripted condition,  p < .001.  In addition,  the   mean   score for the
instruction with worked example condition was significantly higher than unscripted condition, p < .001. Also,
students in the scripted condition scored higher than students in the instruction with worked example condition in
terms of argumentative feedback quality, p < .001. This is in line with previous studies that emphasize the positive
effects of scripts on quality of students' argumentative feedback (Gielen & De Wever, 2015; Noroozi et al., 2016).
Peer feedback scripts provided students with criteria that help them to assess partners' essays clearly. Therefore,
using  these scripts, students  assess their peers'  essays   based on  predesigned   criteria, not   on their personal
perspective. Also, EduTech was designed in such a way that the assessee and assessor were double anonymous.
Bostock (2000) proposed two ways for increasing the validity and reliability of peer feedback: the use of clear
criteria for assessment, and double anonymity of assessors and assessees.
        Repeated     measures   ANOVA     test showed    that the   domain-specific   knowledge     of students  in all
conditions improved significantly from the pretest to the posttes ,     ,             ,         ,              so, there
was a significant difference between the conditions in terms of the domain-specific knowledge, F (1, 49) = 4.43,
        ,         15. The post hoc Tukey HSD test revealed that the mean score for the scripted condition was

CSCL 2019 Proceedings                                     646                                                    © ISLS
significantly higher than unscripted condition, p < .001. In addition, the mean score for the instruction with worked
example  condition  was  significantly higher  than   unscripted   condition. However,     there was   no  significant
difference between the scripted and the instruction with worked example condition, p < .62.       This is in line with
previous studies that emphasize the positive effects of scripts on quality of students' domain-specific knowledge
(Noroozi & Mulder, 2017; Valero Haro et al., 2018). The peer feedback scripts in this study allow students to
engage in higher cognitive processing (such as, argumentation, evaluation, criticism, justification, clarification,
elaboration and analysing); as a result, students process learning material in deep manner.

Conclusions and implications
This study investigated the effects of online peer feedback supported by argumentation instruction with worked
examples and argumentative scripts on students' learning outcomes such as students' argumentative essay writing,
argumentative feedback quality and domain-specific knowledge acquisition in the field of educational sciences.
The online learning environment designed for this study led students to improve their domain specific knowledge
about the subject at hand. Also, peer feedback script allowed students to elaborate learning material included in
EduTech    and process them  in a higher level.   The peer feedback   script  provided    students with  high-quality
feedback on partners' essays by clarifying criteria of assessment and features of a high-quality feedback. Students
in the instruction with worked example condition outperformed students in the unscripted condition in terms of
quality of feedback  and  argumentative  essay  writing.  However,   they were    not as  successful as  the scripted
condition. Therefore, this matter should be considered in future research on the use of scripts; i.e. when scripts
and instruction with worked example are used together in combination.

References
Andrews, R. (2010). Argumentation in higher education. Improving practice through theory and research. New
         York, London: Routledge.
Andriessen, J. (2006). Arguing to learn. In R. K. Sawyer (Ed.), The Cambridge handbook of the learning sciences
         (pp. 443­460). New York: Cambridge University Press.
Bostock, S. (2000). Student peer assessment. Learning Technology, 5.
Clark, R. C., & Mayer, R. E. (2016). E-learning and the science of instruction: Proven guidelines for consumers
         and designers of multimedia learning. John Wiley & Sons.
Dillenbourg, P. (2002). Over-scripting CSCL: The risks of blending collaborative learning with instructional
         design.
Gielen, M., & De Wever, B. (2012). Peer assessment in a wiki: Product improvement, students' learning and
         perception regarding peer feedback. Procedia-Social and Behavioral Sciences, 69, 585-594.
Gielen, M., & De Wever, B. (2015). Scripting the role of assessor and assessee in peer assessment in a wiki
         environment: Impact on peer feedback quality and product improvement. Computers & Education, 88,
         370-386.
Huisman,   B., Saab, N.,  van Driel, J., &  van   den  Broek,  P.  (2018).   Peer feedback   on    academic  writing:
         undergraduate  students' peer   feedback   role, peer   feedback    perceptions   and   essay   performance.
         Assessment & Evaluation in Higher Education, 1-14.
Noroozi, O.,   & Hatami,  J. (2018). The  effects of  online peer   feedback   and epistemic     beliefs on students'
         argumentation-based learning. Innovations in Education and Teaching International, 1-10.
Noroozi, O., & Mulder, M. (2017). Design and evaluation of a digital module with guided peer feedback for
         student learning biotechnology   and   molecular   life   sciences,  attitudinal change,  and    satisfaction.
         Biochemistry and Molecular Biology Education, 45(1), 31-39.
Noroozi, O., Biemans, H., & Mulder, M. (2016). Relations between scripted online peer feedback processes and
         quality of written argumentative essay. The Internet and Higher Education, 31, 20-31.
Rourke,  L., &  Kanuka,  H.  (2007). Barriers  to online  critical discourse. International  Journal   of Computer-
         Supported Collaborative Learning, 2(1), 105­126.
Saito, H., & Fujita, T. (2004). Characteristics and user acceptance of peer rating in EFL writing classrooms,
         Language Teaching Research, 8(1), 31­54.
Schneer, D. (2014). Rethinking the argumentative essay. TESOL Journal, 5(4), 619-653.
Toulmin, S. (1958). The uses of argument. Cambridge: Cambridge University Press.
Valero Haro, A., Noroozi, O., Biemans, H. J., & Mulder, M. (2018). The effects of an online learning environment
         with worked examples and peer feedback on students' argumentative essay writing and domain-specific
         knowledge acquisition in the field of biotechnology. Journal of Biological Education, 1-9.
Wingate, U. (2012). `Argument!' helping students understand what essay writing is about. Journal of English for
         Academic Purposes, 11(2), 145-154.

CSCL 2019 Proceedings                                  647                                                      © ISLS
