       The Role of Asynchronous Digital Feedback in Youth Maker
                                                    Projects
                                 Erica Halverson, Amy Mueller, and Zhaohui Dai
                        erica.halverson@wisc.edu, awenger@wisc.edu, zdai39@wisc.edu
                                         University of Wisconsin-Madison

          Abstract: The aim of this work is to make engagement with ideation, iteration, and critique
          more accessible   to  learners and   to understand   the value of these   art-making  practices for
          learning (Clapp et al., 2016). While these terms may be unique to arts disciplines, giving and
          getting  feedback  are core    tasks across  almost  any   discipline.  Here we   are referring   to
          formative  feedback,  dialogic  interactions either  among   that focus  on  the whole  process   of
          creation (Bangert,   2004). In  this  paper, we    share results  from  a design  experiment    that
          included  the introduction  of  asynchronous,    digital feedback   into  a making   process.  This
          making process, a six-week project with a group of fifth graders is described in other work
          (Litts & Halverson, in press). Here, we ask the following research questions: What is the role
          of asynchronous, digital feedback in young people's maker projects? Specifically, what kind
          of feedback is offered and how does this feedback influence subsequent project iterations?

Build in Progress: The goldilocks model of e-leaning platforms
We partnered with three different platform designers over the course of a two-year period to find a tool that was
both non-disruptive to the making process and amenable to a range of makerspace contexts. We termed our
selection process  the  "Goldilocks"    model:  the first tool afforded  deep   engagement   between  makers    around
iteration and critique but was far too constrained to support the learning arrangements. The second tool was very
easy to use and could be dropped in to a range of settings but did not offer enough scaffolding to encourage
younger makers to engage in productive critique and iteration. The third tool, Build in Progress, an online, open-
source project sharing and development tool which includes over 2,000 shared projects became the platform of
choice for a range of design experiments. Build in Progress was "just right"; it proved easy to use, scaffolded to
encourage iteration and critique, and seemed to not disrupt the making process.
          Our  work  with  Build in Progress    involved   a six-week  design  experiment;  a  maker  experience   that
stretched across school and museum spaces. Three sessions were in the students' classroom and the other three
were in the makerspace of the nearby children's museum. All sessions were facilitated by the museum's lead
teaching artist, assisted by museum staff and researchers. At the end of the project, 11 teams of two and three
presented two-minute puppet shows that were recorded and shared at the museum space for younger students.
Build in Progress was used to document weekly progress, get feedback from researchers on the work, and to
share ideas   with one  another.   Each  week,    students documented    their  work   by  taking photos  and   writing
reflections in Build in Progress where they could get feedback from their peers and from adult maker mentors,
who   were researchers   working   on   the project with   expertise in  making.   Our data  analysis focused   on the
information entered in the Build in Progress application by the student participants and their maker mentors.

How mentors give feedback
At the beginning   of  the project  the  maker  mentors   were  given  specific  guidelines for how   to give  students
feedback  based   on the  Harvard   based   Project Zero   "Visible  Thinking"   core thinking  routine  of "I see... I
think...I wonder". We placed mentor feedback into one of three categories: actionable feedback, compliments,
and general questions. Actionable feedback was designated as specific actions that students could incorporate
into their puppet. For example, one maker mentor suggested, "Have you thought about adding more fabric to
conceal the battery pack?" Another type of feedback was general questions. These were less specific such as a
mentor who asked, "I wonder what type of personality your puppet has?" While these general questions offered
things for students to consider they did not offer a specific course of action to take next. Finally, mentors may
have offered compliments to students such as "great idea" or "I am so impressed...".

How learners engage with the feedback
After considering how mentors offer feedback and separating it into three distinct categories, we then analyzed
how   students engaged     with the mentor     feedback   through  the  Build  in  Progress app.   Students  primarily
responded to the actionable feedback (Figure 1) and general questions (Figure 2) within a common framework.

CSCL 2019 Proceedings                                      899                                                   © ISLS
 Figure 1. Student engagement paths with asynchronous               Figure 2. Student engagement paths with
               digital actionable feedback.                    asynchronous digital general questions feedback.

Table 1: Student overall engagement with the asynchronous digital feedback while working individually

                                        Actionable Feedback       General Question   Compliments

            Total Given                 25                        23                 2

            Total Incorporated          13                        5                  N/A

Table 2: Student engagement with the asynchronous digital feedback while working collaboratively

                                  Actionable Feedback       General Questions    Compliments

            Total Given           5                         1                    5

            Total Incorporated    4                         1                    N/A

Discussion
Our data indicate that when students are given actionable, specific feedback they tend to incorporate it into their
projects. Interestingly, the critique and iteration cycle is not as linear as we might typically see in a formal
classroom   setting; students' incorporation  of feedback   often happened  weeks  after the  feedback  was    first
offered. Additionally, students seem to incorporate feedback at a higher rate when they work collaboratively.
Students who did not incorporate feedback while working individually were more likely to incorporate it when
working in a group, indicating that there is something about working with others that promotes engaging with
feedback. We also find that the student engagement paths mirror the features of peer feedback and the indicators
of whether this feedback was taken up as described in Nelson & Schunn (2009). What we termed "actionable
feedback" shared many of their cognitive features, notably feedback specificity. Feedback seems to be most
useful when it refers to a particular design feature or artistic decision. General questions seemed less useful,
especially when those general questions did not ask students to reflect on how an audience or user might interact
with their design. "Compliments" looked a lot like the affective feedback Nelson and Schunn described. And
while  it may be true  that the students in  our  study agreed  with  these compliments,    their presence did  not
encourage students to make changes to their work.

References
Bangert, A. W. (2004). The seven principles of good practice: A framework for evaluating online teaching.
          Internet and Higher Education, 7(3), 217­232.
Clapp, E. P., et al. (2016). Maker-centered learning: Empowering young people to    shape    their   worlds.  John
          Wiley & Sons.
Litts, B. &  Halverson,  E. R.  (in press). Taking up multiliteracies in a  constructionist design  context. In N.
          Holbert, M. Berland, & Y. Kafai (Eds.), Constructionism in context. Cambridge, MA: MIT Press.
Nelson, M. M., & Schunn, C. D. (2009). The nature of feedback: How different types of peer feedback affect
          writing performance. Instructional Science, 37(4), 375­401.

CSCL 2019 Proceedings                                   900                                                  © ISLS
