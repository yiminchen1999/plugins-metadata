  A Qualitative Analysis of Joint Visual Attention and Collaboration
    with High- and Low-Achieving Groups in Computer-Mediated
                                            Learning
                            Tonya Bryant, Iulian Radu, and Bertrand Schneider
     tonya_bryant@gse.harvard.edu, iulian_radu@gse.harvard.edu, bertrand_schneider@g.harvard.edu
                              Harvard University Graduate School of Education

         Abstract: While interest in using dual eye tracking sensors in computer-supported collaborative
         learning research continues to grow, it remains a challenge to know how to interpret the data
         these tools generate. This qualitative analysis leverages dual eye tracking data to offer Joint
         Visual Attention (JVA) graphs as a novel approach to depicting gaze synchronization, and
         presents a case study to provoke discussion around the opportunities to improve JVA graphs.

Introduction
Measuring collaborative learning is a difficult task, as collaboration is a continuous and multi-dimensional process
(Meier, Spada, & Rummel, 2007). In situations of collaborative learning, however, Joint Visual Attention (JVA)­
­the tendency for social partners to focus on a common reference and to monitor one another's attention to an
outside entity (Tomasello et al., 2005)­­can act as a proxy for the quality of students' collaboration (Schneider et
al., 2018). Additionally, researchers can now leverage emerging technologies, such as mobile eye tracking devices,
to more rigorously measure students' levels of JVA. In this analysis, we leverage the massive datasets generated
by mobile eye trackers to offer JVA graphs as an objective depiction of synchrony in students' gaze behaviors.
We conclude by coupling two JVA graphs with observational data from a case study of two groups­­who are
similar based on their JVA levels, but differ in collaboration quality and learning gains­­to open opportunities to
improve JVA graphs.

Study design
This abstract focuses on the qualitative analysis of mobile eye tracking video footage collected from a subset of two
dyad pairs, Groups 6 and 35 (N=4 out of 84), who participated in a previous empirical study (Schneider, accepted).
Paired participants were asked to program a robot using a block-based programming language to navigate a series
of increasingly difficult mazes in 30 minutes. The groups were selected based on two criteria: similarity in JVA
levels and significant differences in learning gains scores compared to the whole study sample (n= 42 pairs).
Group 6 had a learning gain score of 2 points and Group 35 had a learning gain score of 48 points, both on a 100-
point scale.

Methods
Participants wore mobile eye trackers, and an automated system determined the location and proximity of participants'
gazes. JVA graphs were generated for each dyad pair to depict the geometric proximity of participant gazes during the
learning activity. Gaze proximity was counted as present whenever the distance between the two participants' gaze
points was below a certain threshold (Schneider, accepted). Rising JVA lines indicate gaze convergence and falling
JVA lines indicate the opposite (see Figure 1). We generated a qualitative codebook to categorize collaborative
learning processes associated with high and low levels      of JVA  depicted by the graph.     Two  researchers
independently coded a sample, and a Cohen's Kappa coefficient of 0.69 was reached indicating "good" agreement.
Codes referenced in the case study below are illustrated by observational data in Table 1.

Figure 1. JVA graphs of two dyads during the 30-minute programming activity with examples of high and low JVA
                                             circled in red.

CSCL 2019 Proceedings                                  923                                                 © ISLS
Case Study
In this section we    present a case study     to illustrate that high   and low JVA       levels are not always  predictive      of
collaboration quality, and to identify promising indicators of quality collaboration as it relates to JVA.

Table 1: Qualitative observations (left) and quotes (right) showing differences in collaborative processes at high JVA
(top row) and low JVA (bottom row) between Group 6 (low-achieving) and Group 35 (high-achieving)

 Group 6 (low learning gains)                             Group 35 (high learning gains)

 High JVA: Gaze Following / Unbalanced                    High JVA: Coordinated Gaze / Thinking Aloud
 Participation                                            <R thinks aloud, builds common ground>
 <L tries to solve a sensor value problem>                R: "It seems like the `else' is probably forward. And [every time]
 Then for about 40 seconds there is complete silence.     we turn we want to have this (points to block) repeat. I forgot about
 Though it seems as though she is struggling to find      that."
 an answer to the sensor value question, Left does not    <without prompt, L agrees with R's ideas>
 ask Right, nor does Right volunteer any suggestions.     L: "Yeah, to go straight again."

 Low JVA: Looking at Different Places / Unbalanced        Low JVA: Looking at Different Places / Thinking Aloud
 Participation                                            <Dyad decides to use sensors to make the robot run>
 The participant on the left picks up the cord to guide   R: "So we know now how to make it go straight and hit a wall. The
 the robot. Left stands up to run code on robot. Right    question is, `we need to know whether it goes right or left'. So,
 remains seated. It appears Right can neither see the     then, we might want to work with these sensors to determine what's
 robot, nor is trying to see the robot move.              on each side."
 Meanwhile, Left watches the robot as it moves, and       <R points to the sensors on the left and right sides of the robot>
 as she controls it.                                      L: "Okay..."

Analysis. Based      on Table   1, we  see     at  high   JVA    Group   6's  collaborative   learning    processes (CLP)         are
characterized by gaze following and unbalanced participation where one participant actively works with the robot
and the other is passive. Meanwhile, Group 35's CLP are characterized by thinking aloud and coordinated gaze
where students share gazes due to verbal communication that helps them maintain their approach to achieve a
shared  goal   and   build common    ground.      At   low JVA,   Group   6  looks at different     places during moments         of
unbalanced participation, while Group 35 engages in thinking aloud. This shows low JVA can also be an indicator
of high-quality collaboration. Additionally, Group 6 spends most of their time in silence, while Group 35 often
shows verbal activity. This observation suggests that thinking aloud is associated with a quality of collaboration
that leads to high learning gains, while a tendency to engage in unbalanced participation is associated with a
quality of collaboration that leads to low learning gains.

Conclusion
The JVA graph is an objective tool that provides a way for people to see different levels of synchronized gaze and
rigorously measure students' JVA. Key indicators of quality of collaboration highlighted in the case study present
an opportunity to discuss ways to improve JVA graphs, and even ideate new, compound visual representations
that include key indicators of quality of collaboration and learning gains such as verbal activity, movement, and
other multi-modal data streams.

References
Meier, A., Spada, H., & Rummel, N. (2007). A rating scheme for assessing the quality of computer-supported
         collaboration processes. International Journal of Computer-Supported Collaborative Learning, 2(1), 63­86.
Schneider, B., Sharma, K., Cuendet, S., (2018). Leveraging mobile eye-trackers to capture joint visual attention in co-
         located collaborative learning groups. International Journal of Computer-Supported Collaborative Learning,
         13: 241.
Schneider, B.(accepted).      Unpacking      Collaborative    Learning   Processes  during    Hands-on     Activities       using
         Mobile Eye-Tracking. In the 13th International Conference on Computer Supported Collaborative
         Learning.
Tomasello, M., Carpenter, M., Call, J., Behne, T., & Moll, H. (2005). Understanding and sharing intentions: The origins
         of cultural cognition. Behavioral and Brain Sciences, 28(05).

CSCL 2019 Proceedings                                            924                                                          © ISLS
