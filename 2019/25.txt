       Effects of the Need for Cognitive Closure and Guidance on
                     Contribution Quality in Wiki-Based Learning
                                         Sven Heimbuch and Daniel Bodemer
                                sven.heimbuch@uni-due.de, bodemer@uni-due.de
                                       University of Duisburg-Essen, Germany

          Abstract: Controversies based on opposing points of view and contradictory evidence can be
          fruitful to trigger individual elaboration processes. However, research showed that many wikis
          are not  necessarily  suited   to make   relevant  content  salient    and thus    users need   further
          guidance. In an experimental laboratory study on wikis, we investigated two guidance types in
          conjunction with the Need for Cognitive Closure: (1) visual markers to highlight controversy
          status (implicit guidance) and (2) a collaboration script that directs users towards discussions
          (explicit guidance). We analysed the quality of N = 724 wiki contributions, namely final edits
          to an article and corresponding discussion replies. The results show that both guidance types
          do  neither directly  affect the  user contributions   to the  wiki  nor   the learning  outcome.     In
          interaction with the individual Need for Cognitive Closure there was a meaningful effect on
          the quality   of  discussion   contributions,   matching    previous    research    findings   on    the
          quantitative learning outcomes.

Introduction and background
Working   and  learning  productively    and efficiently  in groups  is  becoming    increasingly   important   (Miller  &
Hadwin, 2015). Net-based communication can help by maintaining the benefits of offline communication, such
as mutual  knowledge    sharing  (McLoughlin,     2002),  while  reducing    disadvantages,   such  as   social inhibitions
(Murray, 2003). However, it is not only possible to use net-based environments for communication, but it can
also support users in their individual learning processes and (cooperative) knowledge construction (Cress &
Kimmerle,     2008).  A well-known     and   popular environment,     which      offers  the possibility    of  cooperative
knowledge construction, are wiki pages and the corresponding discussion pages. These allow participants to
participate in existing discussions, i.e. express themselves or even clean up a topic, initiate new discussions
about topics that are important to them, and finally make changes to the article, ideally based on the discussions
about  an article. Such    collaborative article writing  is one of  the    most common      group activities   (Schlichter,
Koch, & Bürger, 1998). In a wiki environment, it is not unusual or unintended for conflicts or constructive
controversies to occur (Johnson, Johnson, & Tjosvold, 2000) when the wiki information deviates from one's
personal  knowledge     (Cress  & Kimmerle,      2007).  This  makes     it necessary   to assimilate    or accommodate
internally from the user's perspective or externally from the wiki's perspective. This shows that precisely these
conflicts can  be  particularly helpful  for the  knowledge    construction   and  learning    success   of the individual
(Piaget, 1977). Furthermore, they can also lead to partners being more motivated and using their expertise more
effectively (Johnson, Johnson, & Smith, 2000).
          The Need for Cognitive Closure (NCC) is an important influence on people's behaviour in dealing with
controversies. It is the need that people want to find an obvious solution, although it does not always have to be
the right solution (Dijksterhuis, van Knippenberg, Kruglanski, & Schaper, 1996). People with a high NCC strive
to achieve a quick solution and show insecure aversive behaviour. However, people with a lower NCC tend to
prefer finding  the   best solution to   ambiguity  (Schumpe     et al., 2017;   Webster     & Kruglanski,     1997).  This
difference between high and low NCC persons can also be measured in the speed of decisions, as people with
high NCCs perceive ambiguity as unpleasant. Consequently, they tend to make decisions more quickly and use
less information and anchor heuristics for judgment formation (Schlink & Walther, 2007). In contrast to that,
people with a low NCC enjoy the uncertainty of ambiguous situations. Thus, they tend to postpone the decision
and prefer weighing and finding more information (Schlink & Walther, 2007). In wiki-based learning settings,
individuals with a low NCC are more likely to search purposefully for additional in-depth information about a
topic in an ambiguous situation, whereas high NCC persons will more likely process the simplest information at
hand. Although there are close ties between the NCC and inter-individual differences in learning and knowledge
construction, there are only few studies in technology-enhanced learning addressing this construct.
          With increasing complexity of digital learning environments with, it can become helpful that learners
are further supported in dealing with controversial and ambiguous information with the help of supplemental
Cognitive Group Awareness tools (Bodemer & Buder, 2006). Although minimal tacit guidance for learners has
been   questioned    by  others   (Kirschner,    Sweller,  &   Clark,    2006),   we    do   not   fully  agree    to  such

CSCL 2019 Proceedings                                      25                                                         © ISLS
floccinaucinihilipilification of implicit guidance. Cognitive group awareness tools that are focused on gathering
and  visualising knowledge-related      contextual cues   have   been   successfully implemented     as implicit  guidance
measures   to structure  collaborative  learning  processes   (Heimbuch    & Bodemer,      2017).  Another   line  of wiki-
related research has proposed additional measures of explicit guidance to incorporate in wiki-based learning
environments to improve the overall quality of knowledge artefacts and for better coordination processes of
students.  The implementation      of collaboration   scripts is one    possible  explicit guidance   measure  where      the
activities of writers and   editors   within a social  system    are coordinated   and  optimised.   A  script is  a  set of
instructions  that specifies   the    group   formation,   modes     of interaction    and   task management       between
collaboration partners (Dillenbourg, 2002). Positive effects have been found for scripts with a special focus on
article editing and revising that ultimately led to more coherent articles and fewer inaccurate articles (Wichmann
& Rummel, 2013). Furthermore, it has also been shown that a certain level of coercion in the implemented
collaboration  script is  recommended      to  produce  content   of  higher quality    (Papadopoulos,    Demetriadis,    &
Weinberger, 2013).
          In previous analyses of the underlying study data, we could show that test persons in the experimental
study  groups  (implicit  vs.  explicit or high  vs.  low  NCC)   showed   no    meaningful   differences in   the process
variables with the log data that we measured (e.g., topic selection, time to contribute, topic reply frequency), as
assumed in the hypotheses (Heimbuch & Bodemer, 2018). Likewise, there was no direct effect of the guidance
type on the performance in the knowledge test. The in-depth investigation of the interaction of guidance type
and  NCC    confirmed   the hypothesised     pattern. Evidence   suggested   that  subjects  with  a  low NCC     achieved
higher test scores with explicit guidance (collaboration script) and accordingly subjects with a relatively high
NCC achieved better scores with implicit guidance (controversy awareness highlights). These findings support
our claim that implicit guidance provides a quick, non-restrictive way to find a solution, which is preferred by
those persons with a high NCC. Explicit guidance can be beneficial to people with a low NCC, as it can support
them to find a better solution rather than just the quickest. To complete our previous analyses on the quantitative
part, we were left with the question if we can find promising effects on the quality of contributions when we
specifically  investigate implicit  and  explicit  guidance   in the  interplay   with the Need   for Cognitive    Closure.
Thus, we were interested in two main research questions:
          RQ 1: What kind of contributions would we find in either the implicit guidance or the explicit guidance
wiki group, and how can these be translated into a quality measure?
          RQ  2: Does   the   type of   guidance  directly or  indirectly influence    the quality  of  contributions  and
learning outcomes, and how does the NCC moderate potential effects?

Method

Participants and study design
The N = 181 participants were mostly undergraduate students at the University of Duisburg-Essen (Germany) in
their first semester. Students were recruited via the university's social media channels and on-site. Their age
range spanned from 17 to 33 years (M = 20.59, SD = 2.59). We have randomly assigned students to one of two
experimental learning environments about different forms of energy (e.g., nuclear power, fossil fuels, renewable
energy). This was either a wiki with added controversy awareness highlights for implicit guidance or a wiki
with  a collaboration   script for  explicit  guidance.  Thus,   this   variation of wikis   was  our   main independent
variable. Furthermore, we have assessed the Need for Cognitive Closure with the German short scale 16-NCCS
(Schlink & Walther, 2007) of each participant and used this as a second factor for analytical purposes. Our main
dependent variable was the article and discussion quality of each student's contribution. Moreover, we have also
measured numerous process variables through data logging and learning outcomes with knowledge tests.

Study procedure
We conducted the experiment in an individual setup with up to four participants at the same time, separated by
divider panels. Participants performed all the experiment's stages individually in their own wiki instance. After
participants were briefed with standardised written instructions on the computer screen and had given consent to
participate in the study, they were first asked a few basic socio-demographics as well as interest in and prior
knowledge of the study's subject matter (forms of energy). This was followed by a short mandatory introduction
to the  specific wiki environment.      We   asked the  participants  to click   through   a mock-up    environment   with
"lorem ipsum" texts to familiarize with the general wiki structure. In addition to the general orientation in a
wiki, this tutorial phase also served to familiarize with the specific additions we added to the experimental wikis
(controversy highlighting vs collaboration script) to ensure that participants have a common ground about their
wiki environment's mechanics (Figure 1).

CSCL 2019 Proceedings                                       26                                                       © ISLS
           Figure 1. In the floating upper left part of the figure, we illustrate the wiki's talk page table of contents
    with controversy status highlights for implicit guidance. On the right, we illustrate a collaboration script
                               representation as used for the explicit guidance wiki.

           Both groups had the same task of contributing to an initial Wikipedia-like base article about different
forms   of energy  and participating in  up to   three of the corresponding   discussions.   Participants received  the
information that the discussions contain enough arguments and evidence to enrich the original article, since we
did not  provide   any other additional  material   regarding  the  subject  matter  elsewhere. We    gave   no   further
instructions on how to start their wiki task (e.g., reading the article or any discussion first) or what kind of reply
they should make to a self-selected discussion. This was the experiment's main stage where participants had a
loose total time limit of 21 minutes for finishing all article edits and discussion replies. After the time for a
contribution phase was up, they the environment automatically prompted them to finish their contributions in
the wiki and proceed further. Followed by the wiki contribution stage, we provided them with the questionnaires
to determine  their individual   levels of their Need   for Cognitive   Closure (16-NCCS).     After  filling out these
questionnaires  participants had  to answer  a   multiple-choice  test about  the study's   contents. As  an  additional
manipulation check, we asked participants to sum up briefly in open text fields why they have selected certain
discussions to comment on and what led to the final decisions for the resulting article edits. Finally, to gain
insights about how participants evaluate the additions we made to the wikis we asked them to fill out the User
Experience Questionnaire (UEQ) by Laugwitz, Held, & Schrepp (2008).

Wiki contribution coding
In total, we had to analyse N = 181 article edits and N = 543 replies to the article's discussions. We decided to
start our content categorisation deductively with previously discussed categorisations of user types in wikis who
participate in the co-evolution of knowledge (Cress & Kimmerle, 2008). The first two categories for edits to the
article that we have derived where Accommodators and Assimilators. The former is mainly characterised as a
user whose contributions are mostly restructuring and synthesizing tasks, whereas the latter in the simplest form
is purely adding new content to the wiki and not caring much about purposeful integration (Majchrzak, Wagner,
&  Yates,  2006).  With  further inductively derived    categorisations  for article edits, we added    four  additional
categories: Reformulator, Reformulator-shortener, Shortener and No edit. Subsequently, we used these final six
article editing categorisations  for our   quality assignments    (Table 1). A  second  trained coder    was  asked  to
categorise and rate a random sample of 12 articles and resulted in a K = .79, which is an adequate level of
concordance (Mayring, 2015).
           As a second step of our quality analyses, we had to work through the discussion replies and assign
adequate categories to these contributions. We decided to work fully inductive with the material in multiple
iterations, because we had to expect a large diversity in reply content and quality. Finally, we ended up with
seven   discussion reply categories:    No statement,   Repetition, Addition,  Compromise,     Other    (related) topic,
Personal   criticism, Other. Furthermore,    we    arranged   the discussion  reply  categories in    a flat  hierarchy.
Therefore, we created two higher-level categories for participants' replies, namely test persons who contributed

CSCL 2019 Proceedings                                      27                                                     © ISLS
to the course  of the  discussion  with  their comments   and  those  who  replied to discussion  threads   without
advancing the discussion by any means (Figure 2).

Table 1: Assignment of categories to article quality ranks (with justifications)

Quality rank   Designation                       Description
6              Much accommodation                   -    Major revisions
                                                    -    More article structuring
5              Little accommodation                 -    Minor revisions
                                                    -    Minor article structuring
4              Much assimilation                    -    Added more content
3              Little assimilation                  -    Added some content
2              Reformulated and shortened           -    Combined reformulation and shortening of sections
1              Reformulated or shortened            -    Minor reformulation of sections
                                                    -    Minor shortening of sections
0              No edit                              -    No visible text changes
Note. Orange = lower quality, yellow = medium quality, green = higher quality

   Figure 2. Schematic representation of the hierarchy of the categories into two main categories and a total of
                                                seven subcategories.

          In contrast to the quality assignments for the final article edits, we assigned quality ranks to discussion
patterns. The order   in which   the categories  appeared in  the three discussions  that  each participant had  to
contribute was irrelevant. In order to obtain a quality score for a participant over the course of three discussion
contributions, in a next step, we further examined the patterns occurring in the discussion. As can be seen in
Table  2, we  assigned   the highest quality level (rank  9) to a  person  who   brought  three new arguments    as
Additions into the discussions. A second trained coder was asked to categorise and rate a random sample of 15
discussion contributions and resulted in a K = .74, which is again an acceptable level of concordance.

Table 2: Assignment of categories to quality ranks for discussion triads

Quality rank   Discussion triad (order irrelevant)
9                   -    Addition ­ Addition ­ Addition / Repetition / Compromise
8                   -    Addition ­ Addition ­ Other (related) topic / No contribution
7                   -    Compromise ­ Compromise ­ Compromise / Addition / Repetition
6                   -    Compromise ­ Compromise ­ Other (related) topic / No contribution
5                   -    Addition ­ Compromise ­ Repetition / No contribution
4                   -    Addition ­ Repetition ­ Other (related) topic / No contribution
3                   -    Repetition ­ Repetition ­ Repetition / Addition / Compromise
2                   -    Repetition ­ Repetition ­ Other (related) topic / No contribution
                    -    Other (related) topic - Other (related) topic ­ Addition / Compromise / Repetition
1                   -    Repetition ­ Other (related) topic ­ Compromise / No contribution
0                   -    No contribution ­ No contribution ­ Addition / Repetition
Note. Orange = lower quality, yellow = medium quality, green = higher quality

Path analysis
Since  this study had  a  serial process in  the action steps of  the test persons  (three separate iterations of
discussing and editing), a path analysis in form of a serial mediation offered itself for the investigation of the
effects (Hayes, 2018; Hayes, Montoya, & Rockwood, 2017). Thus, we investigated the path effects of the
quality assignments as serial mediators in a row on the effect of the independent variable (type of additional

CSCL 2019 Proceedings                                    28                                                  © ISLS
wiki guidance) on the knowledge test scores as learning outcome, which has been previously analysed in a
different context (Heimbuch & Bodemer, 2018).
         The score in the knowledge test achieved by the test persons served as the dependent variable. The
knowledge    test consisted of 18   multiple-choice questions   (up to three  distractors, at   least one attractor)
relating  to the  subject matter  of energy   sources as   presented in   the discussions  and   the   wiki  article.
Furthermore, in order to investigate potential influences of the Need for Cognitive Closure, we performed a
moderated    serial mediation  with  discussion quality as  first mediator    and article  edit quality   as second
mediator.  We    have chosen   this mediator  order after   investigating the log  files  and confirming     that all
participants started with a discussion before an article edit was performed.

Results and discussion
In order to provide a brief insight into the relationship between the quality allocations of the systems, Table 3
presents an excerpt of the results of both category systems side by side. two category systems side by side.
Even at first glance, a wide variety of combinations of quality ranks can be determined based on the colour
coding of the quality ranks. For example, there are similarities between the two quality assignments, as in the
case of test person 97, who contributed on a high-quality level in both cases (both green). A match of the
quality assignments can also be found with person 9 (both orange) or 96 (both yellow). But there are also
differences, as in the case of person 99, whose contributions to the discussion were classified as high quality
(green) but the discussion replies were classified as low quality (orange). Overall, in the whole coded dataset
we see a relatively even distribution of ranks and user type classifications across both types of guidance.

Table 3. Sample section of the quality assignments in both category systems side by side

Person        Guidance type           Rank of article quality               Rank of discussion quality
   1                 Implicit                   3                                     3
   2                 Implicit                   3                                     5
   3                 Implicit                   3                                     9
   4                 Implicit                   4                                     9
   5                 Implicit                   1                                     9
   6                 Implicit                   4                                     7
   7                 Implicit                   4                                     3
   8                 Implicit                   3                                     9
   9                 Implicit                   2                                     2
                                                        ...
   92                Explicit                   3                                     5
   93                Explicit                   5                                     9
   94                Explicit                   4                                     2
   95                Explicit                   3                                     4
   96                Explicit                   3                                     5
   97                Explicit                   4                                     7
   98                Explicit                   4                                     5
   99                Explicit                   4                                     3
                                                        ...

         The  assigned  user  categories showed    us that  the most   frequently  assigned   category   was  that  of
assimilators, which translated into a high frequency of medium quality contributions to the final article. We
assume that social inhibitions could also exist in such a web-based study setting and that the test person must get
used to the situation before he or she is "ready" for collaborative knowledge construction (Cole, 2009; Kump,
Moskaliuk, Dennerlein, & Ley, 2013). This may have had an influence on the procedure of the test persons to
the extent that they did not want to make any more far-reaching changes to the article. As outlined in Table 3,
there are no  major  quantitative differences between   the groups  with  implicit or explicit  support   in terms  of
corresponding quality distribution. This is further supported by the results of the path analysis in the following
subsection. The path effect of the guidance type on the article editing quality was very small and far from any
acceptable level of significance (cf. Figure 2, path d), which means that the guidance type had no meaningful
direct effect on the final article quality. It should be noted, of course, that since these results were based on a
qualitative content analysis, they depend very much on the underlying data. However, since similar categories

CSCL 2019 Proceedings                                    29                                                     © ISLS
have already  been   found          in other  studies  (e.g.,          Majchrzak          et al.,      2006), this indicates  that there is a  certain
generalisability.
         When     we  further          investigated   the  discussion             categorisations,            we   saw the  highest    frequencies of
discussion  replies  as          additions  and repetitions,             corresponding         to      higher  and  medium    quality   ranks  in  our
assignments.  On   the          one hand,   a high    number           of   persons       in the       repetition  category could  be   explained  by
superficial processing           that  would  require   a  rather           small        amount        of cognitive effort  (Vertzberger,   1990)  to
reiterate the arguments of the other participants and thus to write one's own statement. Therefore, if the subjects
had not been sufficiently motivated (Cole, 2009) or involved to engage in high cognitive (Newman, Webb, &
Cochrane, 1995), they might have relied on behaviour that required only low cognitive effort. On the other
hand, the high number of persons in the category additions could be explained by the fact that at least some of
our test persons   were           interested  and    motivated           to  engage        in  deeper,      more    complex   behaviour    and   could
therefore ultimately participate in higher quality discussions (Newman, Webb, & Cochrane, 1995). In addition,
they may have already had previous knowledge or a firm opinion on the subject in question and have written
their reply accordingly.

Path analysis
For analysing the potential moderating influences of the NCC on contribution quality and learning outcomes,
we  have calculated   a          moderated    serial  mediation             with both      discussion       quality  and  article  editing quality as
mediating variables. These serial mediations were calculated using Model 85 in PROCESS (v3.1) for SPSS
(Hayes,  2018).   Figure         3  shows   the results   of           the  paths in      this model       where    we show   that  only   one of  the
unmoderated paths has become significant, namely the path from the article editing quality to the knowledge
test score with a regression weight of c = .51, p =.007. From this it can be concluded that there is a meaningful
regression of the article editing quality on the knowledge test score, translating into a test score improvement of
approximately 0.5 for each raise in the quality rank. Furthermore, one of the paths moderated by the NCC in this
analysis was identified to be of further interest. We found a moderating effect of the NCC on the connection
between the guidance type and discussion quality, g = -.09, p = .023.

                                       Discussionquality                      b = -0.03p = .461        Article quality
                       a = -0.09                                                                                             c = 0.51*
                       p = .833                                                                                               p = .007

                                                                d = 0.08                      e = 0.10
                                                                p = .689                      p = .282
      Guidance                                                                 f = -0.16                                     Knowledge test
  (Implicit / Explicit)                    g = -0.09*        i = -0.04         p = .763                                             score
                                            p = .023         p = .447

                                                      NCC

                    Figure 3. Representation of the path analysis as moderated serial mediation.

         In addition to the above model, we further investigated the simple slopes of the moderations on the
paths a and d (Figure 4). Implicit guidance together with a high NCC and explicit guidance in conjunction with
a low NCC     can lead           to a  higher quality  of  discussion             contributions.           This   matches  to the  results  that were
previously presented in the quantitative analyses of the process variables and the learning outcomes (Heimbuch
& Bodemer, 2018). This finding can be explained by theories on the NCC and backed by empirical evidence,
where persons with a higher NCC want to find rather quick solutions and tend to prefer simpler signals and cue
heuristics, whereas low NCC persons enjoy to find better answers and solutions through information seeking
and more    elaborate  discussions          (Schlink   &  Walther,            2007;        Webster        &   Kruglanski,  1994,   1997).  The   same
pattern can also be seen for the article editing quality, although to a much weaker extent. It is reasonable to
assume   that the   effect          on this  article  editing            is less  obvious,             because  the NCC     refers  to  dealing   with
controversies and   decision-making             situations   (Dijksterhuis                et al.,      1996), which  were   not necessarily    present
during the article editing phase. That could be a valid reason why the NCC level had no meaningful moderating
effect on the article editing slope.

CSCL 2019 Proceedings                                                         30                                                               © ISLS
        Figure 4. Representations of the moderator effects of the NCC on both quality rank assignments.
                                            -1 = low NCC; 1 = high NCC.

Conclusions
Qualitative content analysis itself was often criticized because of the restriction to rather fixed categories and
that this  would take    the focus    from the  wholeness     of the  texts and   direct   it to paraphrases  in  the  text
(Ramsenthaler, 2013). This criticism, however, is debatable and has been refuted by others, since the categories
would  be  re-examined    and  re-evaluated   repeatedly  (Mayring,    2014). In  our   analysis,  we    categorised entire
articles and discussion contributions, which in turn ensured a more holistic view of the text. Thus, we think that
through   our  analytic  method,    we  were   able to   validly  categorise  and    assign   quality ranks   to the   wiki
contributions. Our  main     finding, that stands  in line  with  previously  reported     findings   on quantitative  data
(Heimbuch & Bodemer, 2018), is that a generally useful type of additional guidance for technology-enhanced
learning  may  not  be   enough.  Depending     on  the task, it  can  be necessary     to consider   adequate   individual
personality variables. In this case the Need for Cognitive Closure was valid research subject, since we were
explicitly interested in  the processing   of  ambiguous    information   and  if people      produce better  learning and
knowledge construction outcomes when guided either implicitly or explicitly. In future analyses, it might be
interesting to consider the constellations of both categorisation systems, as outlined in Table 3, and the type of
provided   guidance   in order to   take a closer   look at   possible correlations  between     these   two  variables. In
addition, the test persons in this study had the opportunity to leave comments about their contributions to the
discussion  and choice   of  topic. For  future analyses,  it may  be  interesting   to determine   how   the selection  of
topics was justified and whether there was a correlation between the justification and the contribution to the
discussion.

References
Bodemer, D., & Buder, J. (2006). Supporting collaborative learning with augmented group awareness tools. In
          R. Sun & N. Miyake (Eds.), Proceedings of the Twenty-Eighth Annual Conference of the Cognitive
          Science Society (pp. 77­82). Mahwah, NJ: Lawrence Erlbaum.
Cole, M. (2009). Using Wiki technology to support student engagement: Lessons from the trenches. Computers
          & Education, 52(1), 141­146.
Cress, U., & Kimmerle, J. (2007). A theoretical framework of collaborative knowledge building with wikis: A
          systemic and cognitive perspective. In Proceedings of the 8th Iternational Conference on Computer
          Supported Collaborative Learning (pp. 156­164). New Brunswick, NJ: International Society of the
          Learning Sciences.
Cress, U., & Kimmerle, J. (2008). A systemic and cognitive view on collaborative knowledge building with
          wikis. International Journal of Computer-Supported Collaborative Learning, 3(2), 105.
Dijksterhuis, A., van Knippenberg, A., Kruglanski, A. W., & Schaper, C. (1996). Motivated Social Cognition:
          Need  for Closure   Effects  on  Memory     and  Judgment.   Journal    of Experimental     Social  Psychology,
          32(3), 254­270.
Dillenbourg, P. (2002). Over-scripting CSCL: The risks of blending collaborative learning with instructional
          design. Three Worlds of CSCL. Can We Support CSCL?, 61­91.
Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: a regression-
          based approach (Second edition). New York: Guilford Press.

CSCL 2019 Proceedings                                      31                                                        © ISLS
Hayes, A. F., Montoya, A. K., & Rockwood, N. J. (2017). The analysis of mechanisms and their contingencies:
         PROCESS versus structural equation modeling. Australasian Marketing Journal (AMJ), 25(1), 76­81.
Heimbuch,   S., &  Bodemer,    D.   (2017). Controversy   awareness   on  evidence-led  discussions  as guidance   for
         students in wiki-based learning. The Internet and Higher Education, 33(2017), 1­14.
Heimbuch, S., & Bodemer, D. (2018). Interaction of guidance types and the Need for Cognitive Closure in wiki-
         based learning. PeerJ, 6, e5541.
Johnson, D.   W.,  Johnson, R.   T., &   Smith, K.   A. (2000). Constructive  controversy:  The  educative  power  of
         intellectual conflict. Change: The Magazine of Higher Learning, 32(1), 28­37.
Johnson, D. W., Johnson, R. T., & Tjosvold, D. (2000). Constructive controversy: The value of intellectual
         opposition. In M. Deutsch, P. T. Coleman, & E. C. Marcus (Eds.), The handbook of conflict resolution:
         Theory and practice (pp. 65­85). San Francisco, CA: Jossey-Bass.
Kirschner,  P. A., Sweller,  J., &   Clark, R.  E. (2006).   Why  Minimal  Guidance   During   Instruction  Does Not
         Work:    An Analysis    of  the Failure of  Constructivist,  Discovery, Problem-Based,    Experiential, and
         Inquiry-Based Teaching. Educational Psychologist, 41(2), 75­86.
Kump, B., Moskaliuk, J., Dennerlein, S., & Ley, T. (2013). Tracing knowledge co-evolution in a realistic course
         setting: A wiki-based field experiment. Computers & Education, 69, 60­70.
Laugwitz, B., Held, T., & Schrepp, M. (2008). Construction and Evaluation of a User Experience Questionnaire.
         In A.    Holzinger (Ed.),   HCI  and   Usability for   Education and  Work   (pp.  63­76).  Springer  Berlin
         Heidelberg.
Majchrzak, A., Wagner, C., & Yates, D. (2006). Corporate wiki users: results of a survey. In Proceedings of the
         2006 international symposium on Wikis - WikiSym '06 (p. 99). Odense, Denmark: ACM Press.
Mayring,   P.  (2014). Qualitative    content  analysis:  theoretical  foundation, basic  procedures    and software
         solution. Klagenfurt.
Mayring, P.    (2015). Qualitative   Content   Analysis:  Theoretical  Background   and  Procedures.  In A.  Bikner-
         Ahsbahs,   C. Knipping,     & N.  Presmeg   (Eds.),  Approaches  to  Qualitative Research   in Mathematics
         Education: Examples of Methodology and Methods (pp. 365­380). Dordrecht: Springer Netherlands.
McLoughlin,    C.  (2002).  Computer     supported teamwork:    An integrative approach    to evaluating cooperative
         learning in an online environment. Australasian Journal of Educational Technology, 18(2).
Miller, M., & Hadwin, A. (2015). Scripting and awareness tools for regulating collaborative learning: Changing
         the landscape of support in CSCL. Computers in Human Behavior.
Murray,  M.    H. (2003).  Managing      teamwork    online. In A  forum  for engaging,   designing, assessing,  and
         collaborating in online learning and teaching (pp. 75­82). Brisbane, Australia: Queensland University
         of Technology.
Papadopoulos, P. M., Demetriadis, S. N., & Weinberger, A. (2013). `Make it explicit!': Improving collaboration
         through increase of script coercion. Journal of Computer Assisted Learning, 29(4), 383­398.
Piaget, J. (1977). The development of thought: equilibration of cognitive structures. Viking Press.
Ramsenthaler,   C. (2013).  Was   ist  ,,Qualitative Inhaltsanalyse?". In M.  Schnell,  C. Schulz,  H.  Kolbe, &   C.
         Dunger (Eds.), Der Patient am Lebensende (pp. 23­42). Wiesbaden: Springer Fachmedien Wiesbaden.
Schlichter, J., Koch, M., & Bürger, M. (1998). Workspace awareness for distributed teams. In W. Conen & G.
         Neumann (Eds.), Coordination Technology for Collaborative Applications (Vol. 1364, pp. 199­218).
         Berlin, Heidelberg: Springer Berlin Heidelberg.
Schlink, S., & Walther, E. (2007). Kurz und gut: Eine deutsche Kurzskala zur Erfassung des Bedürfnisses nach
         kognitiver Geschlossenheit. Zeitschrift Für Sozialpsychologie, 38(3), 153­161.
Schumpe, B. M., Brizi, A., Giacomantonio, M., Panno, A., Kopetz, C., Kosta, M., & Mannetti, L. (2017). Need
         for Cognitive Closure decreases risk taking and motivates discounting of delayed rewards. Personality
         and Individual Differences, 107, 66­71. https://doi.org/10.1016/j.paid.2016.11.039
Vertzberger,   Y. Y. (1990).  The    world  in their minds:   Information processing,  cognition, and   perception in
         foreign policy decisionmaking.
Webster, D. M., & Kruglanski, A. W. (1994). Individual differences in need for cognitive closure. Journal of
         Personality and Social Psychology, 67(6), 1049­1062. https://doi.org/10.1037/0022-3514.67.6.1049
Webster, D. M., & Kruglanski, A. W. (1997). Cognitive and Social Consequences of the Need for Cognitive
         Closure. European Review of Social Psychology, 8(1), 133­173.
Wichmann,     A., &  Rummel,     N.  (2013).   Improving  revision in  wiki-based  writing:   Coordination  pays off.
         Computers & Education, 62, 262­270.

Acknowledgments
We would like to thank Manon-Lea Laudien, B.Sc. for preparing the data in the course of her Bachelors' thesis.

CSCL 2019 Proceedings                                      32                                                  © ISLS
