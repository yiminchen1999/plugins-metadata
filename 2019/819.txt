         Assessing Iterative Planning for Real-world Design Teams
                     Daniel G. Rees Lewis, Elizabeth M. Gerber, and Matthew W. Easterday
         daniel.rees.lewis@u.northwestern.edu, egerber@northwestern.edu, easterday@northwestern.edu
                                            Northwestern University

         Abstract: Design disciplines require iteratively defining the problem, and building and testing
         solutions--consequently  design    requires regularly   planning. However,       we do  not  have
         frameworks   to assess design  planning. We   propose   Team    Planning   Trajectories (TPT)--a
         technology assisted formative assessment framework for planning in design classrooms.

Introduction
Learning environments for real-world design help students learn to tackle highly ill-structured design problems
while  working   closely with  stakeholders to  create   solutions  to stakeholder  problems   (Jonassen,  2000)--
solutions such as products, services, or policy. For example, in our research in an instructional design class, one
team  worked    with multiple stakeholders  to create  a software   voting system   to generate   plans for how  a
university department could better support underserved students.
         One core and under-taught practice in real-world design is planning. Planning in real-world design is
vital because design problems are so highly ill-structured--design problems have no initially obvious solution,
and no clear steps for solving the problem (Jonassen, 2000). Consequently, design teams must continually plan
(Cross, 2011). Unlike experienced designers, student designers tend to plan in a way that reduces their chances
of meeting   stakeholder needs. Students struggle to  plan:  (a) in a  way that  is aligned  with the needs of  the
project, (b) in an efficient way that maximizes   learning  what    solutions might  work,   and (c) an appropriate
workload given their time and experience (Adams et al., 2003; Rees Lewis et al., 2018; Cross, 2011). Assessing
planning in real-world design is challenging because teachers do not know the right solution or solution path.
Despite the importance of planning, we have not developed formative assessments for design planning.

The Team Planning Trajectories Assessment Framework
We propose the Team Planning Trajectories (TPT; Figure 1) a technology supported assessment framework we
are developing to help teachers and researchers know the extent a learning environment is supporting student
team design planning. TPT is a conceptual assessment framework (Pellegrino, 2014)--an assessment blueprint
that defines (a) the student  performance  variables  to attend  to (student  model),  (b) the student  and teacher
activities, and tools used (task model), and (c) how evidence is collected and analyzed (evidence model).
         TPT involves organizing the class into iterative 1-2 weeks cycles. At the start of each cycle teams use a
project template and a plan template to create a written record of (a) the state of their project, (b) the risks that
can make the project fail, and (c) their plan to reduce these risks (Rees Lewis et al., 2018). First, student teams
define the current state of their design problem and proposed solution such as user needs, and problem causes.
Teams then identify risks--what aspects of their problem and proposed solution might stop them making an
effective solution (Carlson, Maliakal, Rees Lewis, Gorson, Gerber, & Easterday, 2018). For example, it is risky
if teams have limited evidence of their assumed user need. Teams then plan to reduce their most severe risks.
         We propose three variables for assessing student plans drawn from research on design practice and
student  struggles in  design  planning  (Adams   et  al., 2003;   Rees  Lewis   et  al., 2018;  Cross,  2011): (a)
Alignment--the extent a plan is aligned with the project. An aligned plan is logically consistent with what the
team understands about the problem and solution (e.g. user needs, why existing solutions fail), and most severe
risks (e.g. users are 60+ years old, so might not want proposed software solution). (b) Efficiency--the extent the
plan achieves the goals efficiently. If the team's goal is to understand if a solution is desirable, are they planning
to spend 3 hours building a prototype, or 3 weeks building a complete working software? (c) Appropriateness of
workload--the extent the plan outlines work that the team can achieve given their time and expertise.

   Figure 1. Team Planning Trajectories technology supported assessment framework involves student design
   teams planning iterative cycles of work and teachers or researchers creating a pre- and post-coaching rubric.

CSCL 2019 Proceedings                                  819                                                    © ISLS
        Each cycle, TPT involves the following student and teacher activities, tools, and technology (Figure 1):
(1) At the start of a cycle, the teams fill out a project and plan templates, which involves defining the state of the
project, risks, and planning to reduce those risks. The plan stipulates the goal(s) of the cycle and activities to
meet the goal. (2) The teacher then reviews the teams' templates, and uses an online rubric to create a pre-
coaching record of the plan's alignment, efficiency, and appropriateness of workload. (3) The teacher and team
then discuss any parts of the templates the teacher found unclear. (4) The teacher updates the online rubric based
on this discussion. (5) The teacher and students then engage in coaching, revising the templates. (6) The teacher
then creates a post-coaching record of the plan using the same online rubric. (7) The team then enacts the plan.
        We   created TPT   to collect and assess teams'  plans  within  and across cycles   for real-world  design
projects. Each cycle, the teacher or researcher captures rubric scores of the plans pre- and post-coaching. At its
most simple, the TPT captures yes/no/unclear for plan alignment, efficiency, and appropriateness of workload,
displayed on a dashboard (Table 1). TPT helps answer two questions: (1) how are teams producing design plans
outside of coaching?  This is measured   by  the change  in the quality of  the pre-coaching    plan scores across
cycles--that is, what is each team's pre-coaching score in cycle 1 compared to cycle 2 etc.; (2) How are teams
planning with coaching? This is measured by the difference between the pre- and post-coaching scores within
each cycle. A learning environment created to help student design team planning would aim to: increase the pre-
coaching scores over time (across cycles), increase in pre-coaching scores and post-coaching scores in the same
cycle, and decrease difference between the pre-coaching scores and the post-coaching scores over time.
        We now illustrate TPT in an ongoing design-based research initiative (data display Table 1). We focus
on a team  in cycle  3 of  an instructional design class working  with  their   client, a university department's
diversity committee. Their client experienced the challenge of drawing on diverse community perspectives to
create action plans for better supporting underserved students. The team had proposed a software voting system
to gather data that can generate action plans. The team noted a risk: they did not know what data the client
needed from the community to generate and justify action plans. The team planned to create a prototype of the
voting system using off-the-shelf technology, gather data from 20+ stakeholders, and then present the data to the
client to test if it met their needs. The teacher rated this pre-coaching plan as (a) aligned, as the activities sought
to reduce a risk by testing something with the goal of solving stakeholder problems, (b) not efficient, as the team
had already collected data from 30 stakeholders, and didn't need to collect new data, and (c) an inappropriate
workload, as the proposed workload is more than undergraduates can typically undertake in 2 weeks. During
coaching, the team and teacher refined the plan to be more efficient with a more an appropriate workload.

Table 1. A technology data display of the planning rubric scores of one team in a 10-week class

Conclusion
We presented TPT, a novel approach for teachers and researchers to regularly formatively assess design
planning. TPT allows us to (a) regularly track changes in performance, (b) assess both independent and coach
supported planning, and (c) avoid letting students flounder by only assessing planning without support. TPT
uses technology to allow us to better assess and create learning environments for students learning design.

References
Adams, R. S., Turns, J., & Atman, C. J. (2003). Educating effective engineering designers: The role of reflective
        practice. Design Studies, 24(3), 275­294.
Carlson, S.E., Maliakal, L.V., Rees Lewis, D.G., Gorson, J., Gerber, E.M., & Easterday, M.W., (2018).
        Defining and assessing risk analysis: The key to strategic iteration in real-world problem solving. In
        proceedings of the International Conference of the Learning Sciences (ICLS). London, UK: ICLS.
Cross, N. (2011). Design thinking: Understanding how designers think and work. London, UK: Bloomsbury.
Jonassen, D. H. (2000). Toward a design theory of problem solving. Educational Technology Research and
        Development, 48(4), 63­85.
Pellegrino, J. W. (2014). A learning sciences perspective on the design and use of assessment in education. In
        The Cambridge handbook of the learning sciences (pp. 233­252).
Rees Lewis, D.G., Gorson, J., Maliakal, L.V., Carlson, S.E., Riesbeck, C.K., Gerber, E.M., & Easterday, M.W.
        (2018). Planning to Iterate: Supporting iterative practices for real-world ill-structured problem-solving.
        In proceedings of the International Conference of the Learning Sciences (ICLS). London, UK: ICLS.

CSCL 2019 Proceedings                                  820                                                  © ISLS
