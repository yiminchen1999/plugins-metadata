                                      Integrative Visualization:
   Exploring Data Collected in Collaborative Learning Contexts
                   Ben Rydal Shapiro, Georgia Institute of Technology, ben@benrydal.com

         Abstract:  The   development     and  use of computational     approaches   to  make   sense of  data
         collected in collaborative learning contexts is expanding rapidly in the Computer-Supported
         Collaborative  Learning      (CSCL)   and   Learning    Sciences   (LS)    communities.    However,
         developing and   using  these   approaches in ways    that maintain   a commitment     to theory and
         situational context is a significant challenge. This paper proposes integrative visualization, a
         computationally   assisted,   human-centered      process  to  visually explore  data   collected  in
         collaborative learning contexts in a way that maintains a commitment to theory and situational
         context. To   do  so,   this paper   summarizes     how   integrative   visualization supported   the
         development and use of interaction geography, an approach to describing, representing, and
         interpreting collaborative interaction across the physical environment. This paper concludes by
         emphasizing   the need   to   further develop     integrative visualization  in the   CSCL   and  LS
         communities through stronger connections with the information visualization community.

Introduction
The development and use of computational approaches to make sense of data collected in collaborative learning
contexts is expanding  rapidly   in   in the Computer-Supported      Collaborative   Learning   (CSCL)   and  Learning
Sciences (LS) communities. In particular, computational approaches are providing ways to extend traditional data
analysis of phenomena such as language, gesture, or gaze important to studying collaborative learning (Rosé et
al., 2008; Schneider & Pea, 2014). Alternatively, these approaches offer resources to reason about larger data sets
and data scales including multimodal data collected across classroom settings (Knight et al., 2017). However,
developing and using these approaches in ways that maintain a commitment to theory and situational context is a
significant challenge (Wise & Schwarz, 2017; also see Law et al., 2018). This challenge also reflects broader
efforts in and outside of education to develop "orientations towards and frameworks for data science that are not
reducible to mere efficiency" (Zegura, DiSalvo & Meng, 2018; also see Kahn, 2017; Berland et al., 2017).
         This paper proposes integrative visualization, a computationally assisted, human-centered process to
visually explore data collected in collaborative learning contexts in a way that maintains a commitment to theory
and situational context. Integrative visualization extends visual methods of exploratory data analysis (Tukey,
1977) to iteratively transcribe data collected in context in order to organize data and develop codes, categories,
units of analysis, and questions that support the development of grounded theory (Glaser & Strauss, 1967) and
new computational tools. In particular, integrative visualization extends the practice of "integrative diagramming"
(Strauss, 1987) through techniques of exploratory data analysis and is summarized as follows:

     data context  transcription amplified by visualization  grounded theory & computational tools

         This paper  illustrates this  process  of integrative  visualization    by describing  how   it supported  the
development   and  use of  interaction    geography,  an    approach   to describing, representing,   and  interpreting
collaborative interaction across the physical environment (Shapiro, Hall & Owens, 2017; Shapiro & Hall, 2018).
This paper concludes by emphasizing the need to further develop integrative visualization in the CSCL and LS
communities through stronger connections with the information visualization community.

An example of integrative visualization

Data context
The example described in this paper draws from data collected during a three-year project in collaboration with a
nationally renowned   museum     located  in  the mid-South    region  of  the United   Sates. This  project sought to
understand how visitors to this museum cultivated interests in and learned about the diverse historical and cultural
heritage of American Roots music during and after their visit. Two initial research questions guided this work.
First, this work aimed to understand the organization of visitors' activity not only at single museum exhibits as
was typically the case in existing research but also as visitors moved across gallery spaces over their complete
museum visit. Second, this work sought to understand how visitors furthered their own interest-driven engagement
and learning through their activity across gallery spaces.

CSCL 2019 Proceedings                                      184                                                   © ISLS
        To answer these questions, a purposive sample of complete museum visits across 22 visitor group cases
(2­5 visitors per group) was collected over a period of six weeks. This sample was collected in close collaboration
with museum    partners,  many  generous   families and  visitors participating in this research,  and followed
institutional review board (IRB) protocols. Data from these 22 cases included continuous, multi-perspective video
and audio records (72 hrs total) of each visiting groups' movement, interaction, and social media use collected
through small, unobtrusive cameras that each visitor in a group wore as necklaces for the duration of their visit
with no researchers present (visits ranged from 30 min to 4 hrs). This data provided detailed records of visitors'
interaction (e.g., conversation, movement, use of cell phones and cameras).
        This data presented two novel research challenges. First, existing research was only beginning to make
sense of complex, multi-perspective audio and video data in ways necessary to answer the questions informing
this work (see Marin, 2013; Steier, 2014; Taylor & Hall, 2013 for early work). Second, apart from a few novel
and inspirational examples (see Fouse et al., 2011), computational tools to support this work did not exist. For
example, contemporary transcription software (e.g., InqScribe, NVivo) and video editors (e.g., Final Cut Pro,
Adobe Premier) were not designed to account for the spatial dimension of collaborative interaction as people
moved. Likewise, information visualization and visual analytics software used to study visitor activity in settings
such as museums did not operate at a fine enough grain size to answer the research questions informing this work
and also typically focused exclusively on visitors' movement ignoring their conversation.
        In summary, this particular cultural heritage museum along with these initial questions, goals, types of
data collected, and unique challenges framed the data context of this work. This data context included a theoretical
commitment to studying visitors' interest-driven engagement and learning as they moved across gallery spaces
through continuous, multi-perspective video records of visitor activity. The following section uses a set of figures
and analysis to illustrate an iterative process of transcribing this data amplified by visualization in a way that
maintains this theoretical commitment and is driven by this data context.

Transcription amplified by visualization
Figure 1 is a hand drawn sketch that represents a first attempt to make sense of this data and specifically, a five-
member family's activity within a particular museum gallery space. Namely, the sketch tries to make sense of the
family's experiences across a gallery space from watching five separate video records.

 Figure 1. Manual sketch of a family's activity in a museum gallery transcribed from multi-perspective video.

        Importantly, the sketch draws from a set of famous architectural drawings known as the "Manhattan
Transcripts" developed    by architect Bernard    Tschumi:  The   Manhattan  Transcripts  aimed   to expand  the
theorization and design  of  architecture beyond  space and form   to also include the  relations between space,
movement, and event or what happens in space (Tschumi, 1994). The sketch uses the Manhattan Transcripts to
organize aspects of this family's activity in this gallery space across dimensions of object/space, movement, and
event. For example, the 2nd column describes one family member's (named Adhir) activity at an exhibit. The first
row of this column describes the exhibit/object of focus (a musician named Hank Williams); the second row
characterizes Adhir's movement as frozen or not moving; the third row characterizes events/things Adhir does at
the exhibit  (stands in reverence, talks, takes a photograph). Altogether,  the figure  shows a   commitment to

CSCL 2019 Proceedings                                  185                                                 © ISLS
understanding visitor groups as a mobile unit (e.g., multiple participants are placed in columns across different
times of their visit) and questions concerning how and what happens as each family member moves.
         Figure 2 is a computationally generated sketch produced 4 months after the previous sketch. It illustrates
an early attempt to transcribe the same five-member family's conversation as they move across part of the museum
gallery space  described  previously. Put  differently,  this  sketch illustrates an  initial attempt to address a
fundamental problem regarding how to make sense of people's conversation as they move.

 Figure 2. Extending the space-time cube to transcribe a family's conversation across a museum gallery space.

         The sketch shows a floor plan of part of the gallery space (i.e., looking down on the space). This floor
plan is tilted in 3D isometric perspective. A set of images is shown on top of the floor plan. These images
correspond to six museum exhibits that line a semicircle drawn on the floor plan. A timeline in minutes and
seconds along with grid lines that separate 6 regions of the floor plan (corresponding with the 6 exhibits along the
semicircle) extend downward/below the floor plan. Turns of transcribed talk from each family member are placed
along this timeline and in regions of this gridded space (i.e., placed in time and space). Turns of talk are also
grouped into topically related conversations (typically spatially related conversations about exhibit content). Thus,
the position of turns of talk/conversations vertically on the timeline and horizontally across the floor plan indicate
when    (over approximately  5   minutes) and   where    (along   the semicircle   of six exhibits)   each turn  of
talk/conversation occurs. In addition, turns of talk in the first conversation (top of the timeline) are overlaid by
colored lines that indicate speaker (i.e., color indicates which family member speaks that conversation turn).
         Altogether, this sketch illustrates an initial effort to extend a geographical   perspective  called  time
geography and a visualization system known as the space-time cube (Hagerstrand, 1970) to begin to develop
codes and categories to explore this family's conversation over space and time in new ways. Doing so necessitated
categorizing and grouping conversation in ways that foregrounded the spatial and mobile dimensions of visitors'
conversation (i.e., reflective of the theoretical commitments and data context of this work).

CSCL 2019 Proceedings                                   186                                                   © ISLS
        Figure 3, produced approximately three months after the previous figure visualizes different aspects of
the same family's interaction over the total time they spent in the same part of the gallery space (approximately 8
minutes) in a small multiple format (Tufte, 1990). The top left visualization in the figure titled "overlayed talk"
shows the turns of talk from the family colored by speaker. The visualization below this titled "conversation
structures" isolates visual boxes that group turns of talk into topically related conversations while the visualization
adjacent titled "transcribed talk" shows all transcribed talk for the family. In comparison to Figure 2, this includes
about 3 more minutes of talk. The visualization above titled "mobility paths" shows the family's movement across
this space and over time as lines or paths (color again indicates family member). The four visualizations to the
right isolate each family member's individual movement and turns of talk: the mother named Mae is shown in
purple, her son and daughter named Jeans and Lily are shown together in green and yellow respectively as their
movement is nearly identical, their 6-year old brother named Blake is shown in blue, and Lily's fiancé Adhir is
shown in orange. By visualizing each family member's movement and conversation as layers over space and time
comparisons can be drawn across family members to simultaneously study who speaks, what is said, and where
each family member goes in this gallery space. For example, the figure supports asking new questions such as
how parents' conversation across gallery spaces structures and responds to children's movement and conversation.

 Figure 3. Small multiple of a family's movement and conversation over space and time in a museum gallery.

        Figure 4 presents a more refined computationally generated visualization produced four months later of
two  members   of this family in this gallery space, Blake  and Adhir   (shown once again in blue  and orange
respectively). On the left, the floor plan is now shown in 2D (looking directly down on the space) and depicts the
full gallery space. The semicircle set of six  exhibits is now  clearly shown  and one exhibit is marked with
"Williams" to indicate it features content about a famous musician named Hank Williams. Blake and Adhir's
movement is shown across the floor plan or in "floor plan view" indicating where they travel while visiting this
gallery space. A timeline extends to the right of the floor plan as opposed to below/under the floor plan. In
comparison to Figures 2 and 3, this subtle rotation of the timeline (suggested by a collaborator, Lara Heiberger,
in the context where this data was collected) aids in interpreting complex space-time visualizations. In this case,
similar to the previous figures but more clearly illustrated here, the "space-time view" (Hagerstrand, 1970) extends

CSCL 2019 Proceedings                                  187                                                 © ISLS
Blake and Adhir's movement on the floor plan horizontally over time. This view shows how they interact with
exhibits and one another over time. For example, the space-time view shows that after entering the gallery space
(top left of the floor plan view and beginning of the space-time view), Adhir and Blake walk together toward the
Hank Williams    exhibit. Subsequently, Adhir   stands  for almost 5  minutes   at the Hank   Williams  exhibit,  as
indicated by his horizontal orange path in the space-time view that extends from approximately minutes 0­5 and
corresponds to the vertical position of the Hank Williams exhibit in the floor plan view. In the meantime, while
Adhir is standing, Blake is moving quickly (apparently running) back and forth across the gallery space (i.e.,
across the semi-circle of exhibits on the floor plan) in multiple attempts to draw Adhir away from the Hank
Williams exhibit. After four failed attempts, Blake finally succeeds in leading Adhir on what is described as a
tour of other exhibits in the gallery, indicated by their intertwined paths from approximately minutes 5-6. The
change in line pattern in Blake's path distinguishes between three different horizontal areas of space on the floor
plan providing some description of horizontal movement on the floor plan in the space-time view.
          In comparison   to previous figures, this figure  begins to   provide more   detailed  ways  to interpret
collaborative interaction across a physical environment (i.e., reflective of the original commitments of this work).
For instance, the figure characterizes new, path-based units of collaborative interaction such as Blake's tour that
support asking  and answering   new   types of questions including how    young    children use their movement    to
manage their families as resources for their own interest-driven engagement and learning.

   Figure 4. Adhir (orange) and Blake's (blue) movement over space and space-time in a museum gallery.

Grounded theory and computational tools
Figure  5 was  produced   over a year  after Figure  4  and  represents a significant  amount   of   theoretical and
computational development. The figure is a screenshot from a dynamic visualization tool called the Interaction
Geography Slicer (IGS), which allows for new forms of interaction and multimodal analysis. The figure also
illustrates a refined method to transcribe movement and conversation, in this case, of all five members of the
previous  family (including  Blake and  Adhir)  in  the previously described  gallery  space.   This method called
Mondrian Transcription draws inspiration from the Manhattan Transcripts and the Modernist artist, Piet Mondrian
(1872­1944), particularly his use of lines in relation to forms, which resemble how movement and conversation
are represented, coded, and categorized in Mondrian Transcription. The top half of the figure shows the family's
movement and the bottom half shows their conversation in relation to their movement (i.e., the family's movement
is shown in gray beneath their conversation to link the two halves of the figure). Conversation is transcribed and
organized in ways introduced previously. First, each turn at talk is shown as a colored line to indicate which family

CSCL 2019 Proceedings                                   188                                                  © ISLS
member speaks that conversation turn (indentations indicate overlapping speech). Second, colored lines of talk
are gathered into boxes that group topically related sequences of conversation turns and movement (e.g., usually
related to artifacts/musicians in this setting). In the space-time view, each box marks the start, duration, and end
of a sequence. In the floor plan view, conversation turns and separate (in time) sequences accumulate within
regions of gridded space--the box thickness in the floor plan view increases with each repeated sequence within
a region of space (resembling a "heat map" of talk in place). For example, the region of space around the Hank
Williams exhibit has the largest number of conversation turns (indicated by the many colored lines of talk) and is
enclosed by a dense box that reflects five separate (in time) sequences occurring at the Hank Williams exhibit.

  Figure 5. Screenshot from the Interaction Geography Slicer (IGS) of family's movement and conversation.

       In the figure, the highlighted sequence (i.e., readable conversation) in the space-time view expands the
conversation turns of one particular sequence. In other words, the highlighted sequence illustrates an analytic
"operation" possible within the IGS on data collected in this work. As the figure shows, one can use the IGS to
select, magnify, visualize, and read conversation turns. Not shown is the additional ability to use the IGS to watch
and listen to video/audio from the perspective of each family member gathered as part of this work. The IGS syncs

CSCL 2019 Proceedings                                 189                                                 © ISLS
multi-perspective audio and video to visualizations such as Figure 5. As a result, anywhere a user clicks on the
visualization activates audio or video from the perspective of an individual.
       The figure shows how these refined tools/methods provide ways to engage in exploratory data analysis
(Tukey, 1977) that pays careful, contextual attention to how people engage and learn across museum gallery
spaces. For example, the highlighted conversation or sequence in the figure from approximately minutes 4­5 in
the space-time view encompasses a complex mesh of activity around the Hank Williams exhibit. Reading this
sequence of activity in relation to the rest of the figure shows how: 1) Lily (yellow) soothes the emotions of Adhir
(her fiancé) by hugging and consoling him as he compares the Hank Williams exhibit to a "grave" (in line 8); 2)
Jeans (green) gives Lily and Adhir privacy by leading a frustrated Blake away from the Hank Williams exhibit
(the extension of their movement paths upwards in the floor plan and space-time views indicating their movement
away from the exhibit); 3) Blake and Jeans rejoin Lily and Adhir as Adhir continues to share his own account of
Hank William's painful life; 4) Mae (Mom in purple), who has been standing near Adhir and Lily and observing
her family's interaction, helps Blake lead Adhir on a tour of other exhibits by saying to Adhir, "but you gotta..
you gotta go see Bill Monroe's mandolin" (in lines 22­23); and 5) Evidently fully aware of Blake's ongoing
project to lead a tour, Adhir whispers to Blake, "ok let's go" and they move forward together to the next exhibit
along the semicircle of exhibits (at the end of the highlighted conversation; see Shapiro, Hall & Owens, 2017).
       Altogether, the ability to read this sequence of activity in relation to the rest of the figure by exploring
data within the IGS reveal phenomena and relations between phenomena such as Blake's tour, Adhir's persistent
engagement    with the Hank Williams    exhibit, a mother's efforts to support   her children's engagement,         and
particularly important units of engagement or "peak engagement contours" such as the previously described
sequence of activity during this family's visit to this gallery space. In other words, the figure communicates
concepts and methods of interaction geography, a new approach to describing, representing, and interpreting
people's collaborative interaction as they move across the physical environment, and how to use interaction
geography to study visitors' interest-driven engagement and learning across a museum gallery space.

Discussion and conclusion
In summary, the development and use of interaction geography was interleaved with and furthered a line of
exploratory data analysis that led to new questions, units of analysis, and computational tools to describe how
visitors pursued their own interest-driven engagement and learning in a museum. Put differently, the example
characterizes integrative visualization, a computationally assisted, human-centered process to visually explore
data in a way that maintains a commitment to theory and situational context.
       Though illustrated through a single example in this paper, integrative visualization is proposed as a
generalizable process researchers or practitioners can leverage to make sense of data collected in collaborative
learning contexts. Integrative visualization begins with a data context, understood as an initial set of questions,
goals, challenges, and particular types of data collected in a specific context. In the example, this data context
included continuous, multi-perspective audio/video data collected in a cultural heritage museum and a theoretical
commitment to understanding visitors' interest-driven engagement and learning as they moved across gallery
spaces. Subsequently, integrative visualization extends visual methods of exploratory data analysis to iteratively
transcribe data. Like any process of transcription, transcription of data amplified by visualization is theory laden
and selective because it aims to organize data and develop codes, categories, questions, and units of analysis
central to the data context (see Ochs, 1979; Hall, 2000). For instance, the example illustrated the use of the space-
time cube to categorize conversation over space and time in ways that foregrounded mobility. Finally, integrative
visualization supports the development   of grounded  theory  and   new computational   tools.  On one        hand,   the
example characterized concepts and methods of interaction geography, units of analysis, and questions about
visitors' interest driven engagement and learning as potentially generalizable to other types of settings where
people move to engage and learn (e.g., other museums, natural or urban environments). On the other hand, the
example demonstrated how integrative visualization produced computational tools that support new forms of
interaction and multimodal analysis. Importantly, developing these tools required (and requires) shifting from
using traditional transcription tools (e.g., ranging from Microsoft Word to InqScribe to NVivo) to composing in
more dynamic    graphical  layout tools (e.g., Adobe  products) to  developing   visualizations and          software in
programming languages used in exploratory data analysis such as Processing and p5.js (see Fry, 2004). Though
fully describing this shift is beyond the scope of this paper, it is critical to integrative visualization.
       Integrative visualization may be particularly well suited to addressing some of the unique challenges of
making sense of unstructured data (e.g., audio and video) about people's interaction collected in and important to
studying collaborative learning contexts. However, such work entails stronger connections between the CSCL
and LS communities and the information visualization community. These connections are challenging to develop
but essential to integrating technical skills of parsing, mining, representing, and interacting with data (see Stasko

CSCL 2019 Proceedings                                  190                                                         © ISLS
et al., 2008; Fry, 2004) with non-technical ways of working with data that foreground theoretical and contextual
dimensions (see Wise & Schwarz, 2017; Kahn, 2017; Zegura, DiSalvo & Meng, 2018; DiSalvo, 2016).

References
Berland, M., Halverson, E., Polman, J. & Wilkerson, M. (2017). Expressive construction: Enabling learners to
         represent  powerful   ideas.  In J. Roschelle,  W.   Martin, J. Ahn, &   P. Schank   (Eds.), Cyberlearning
         Community Report: The State of Cyberlearning and the Future of Learning with Technology.
DiSalvo. B.   2016. Participatory  Design    through  a Learning Science    Lens. In Proceedings  of  the  2016 CHI
         Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, 4459-4463.
Fouse, A., Weibel, N., Hutchins, E., and Hollan, J.D. (2011). ChronoViz: a system for supporting navigation of
         time-coded data. In CHI '11 Extended Abstracts on Human Factors in Computing Systems (CHI EA '11).
         ACM, New York, NY, USA, 299-304.
Fry, B. J. (2004). Computational information design. Ph.D. Dissertation. Cambridge: MIT.
Glaser, B.G.  &    Straus, A.L. (1967).   The discovery  of   grounded   theory: Strategies for qualitative research.
         Chicago, IL: Aldine.
Hagerstrand, T. (1970). What about people in regional science? Papers in regional science, 24(1), 7-24.
Hall, R. (2000). Video recording as theory. In D. Lesh & A. Kelley (Eds.) Handbook of Research Design in
         Mathematics and Science Education (pp. 647-664). Mahweh, NJ: Lawrence Erlbaum.
Kahn, J. B. (2017). At the intersection of self and society: Learning, storytelling, and modeling with big data.
         Ph.D. Dissertation. Vanderbilt University.
Knight, S., Wise, A., Ochoa, X. & Hershkovitz, A. (2017). Learning analytics: Looking to the future. Journal of
         Learning Analytics, 4(2), 1­5.
Law, N.,     Rose, C.P.,   Cress, U.   and   Ludvigsen,  S.   (2018). Different   technologies, methodologies   and
         epistemologies--is CSCL a community or communities? International Journal of Computer-Supported
         Collaborative Learning, 13(2), 131­136.
Marin, Ananda M. (2013) Learning to Attend and Observe: Parent-child Meaning Making in the Natural World.
         Ph.D. Dissertation. Northwestern University.
Ochs, E. (1979). Transcription as theory. In E. Ochs & B. Schieffelin (Eds.), Developmental pragmatics (pp. 43-
         72). New York: Academic Press.
Rosé, C., et al. (2008). Analyzing collaborative learning processes automatically: Exploiting the advances of
         computational     linguistics in computer-supported    collaborative    learning. International  Journal of
         Computer-Supported Collaborative Learning, 3(3), 237­271.
Schneider, B., & Pea, R. (2014). Toward collaboration sensing. International Journal of Computer-Supported
         Collaborative Learning, 9(4), 371­395.
Shapiro, B.R.,  Hall, R.   &  Owens,    D.   (2017). Developing  &    Using Interaction    Geography  in a  Museum.
         International Journal of Computer-Supported Collaborative Learning, 12(4), 377-399.
Shapiro, B.R. and Hall, R. (2018). Personal Curation in a Museum. In Proceedings of the ACM in Human-
         Computer Interaction, Vol. 2, CSCW, Article 158 (November 2018). ACM, New York, NY.
Stasko,  J., Görg,  C.,    & Liu,  Z.   (2008). Jigsaw:  Supporting    Investigative Analysis   through   Interactive
         Visualization. Information Visualization, 7(2), 118­132.
Steier, R. (2014). Posing the question: Visitor posing as embodied interpretation in an art museum. Mind, Culture,
         and Activity, 21(2), 148-170.
Straus, A.L. (1987). Integrative diagrams and integrative sessions. In A.L. Strauss, (Ed.), Qualitative Analysis for
         Social Scientists (pp. 170­182). Cambridge University Press.
Taylor, K. H., & Hall, R. (2013). Counter-mapping the neighborhood on bicycles: Mobilizing youth to reimagine
         the city. Technology, Knowledge and Learning, 18(1­2), 65­93.
Tschumi, B. (1994). The Manhattan Transcripts. Wiley.
Tukey, John W (1977). Exploratory Data Analysis. Addison-Wesley.
Tufte, E. R. (1990). Envisioning Information. Chesire, Connecticut: Graphic Press.
Wise, A., & Schwarz, B. (2017). Visions of CSCL: Eight provocations for the future of the field. International
         Journal of Computer-Supported Collaborative Learning, 12, 423­467.
Zegura. E., C. DiSalvo, & A. Meng. (2018). Care and the Practice of Data Science for Social Good. In Proceedings
         of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies. ACM, New York, NY.

Acknowledgements
Amanda Meng, Jennifer Kahn, and Rogers Hall provided critically important feedback that contributed to the
development of ideas in this paper. Figures copyright  Ben Rydal Shapiro. Reprinted with Permission.

CSCL 2019 Proceedings                                     191                                                  © ISLS
