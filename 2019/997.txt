     ElectroVR: An Electrostatic Playground for Collaborative,
   Simulation-Based Exploratory Learning in Immersive Virtual
                                                  Reality
              Scott W. Greenwald, Wiley Corning, Gavin McDowell, Pattie Maes, and John Belcher
   scottgwald@media.mit.edu, wjlc@mit.edu, gavinmcd@mit.edu, pattie@media.mit.edu, jbelcher@mit.edu
                                        Massachusetts Institute of Technology

         Abstract: The ElectroVR interactive demonstration allows two participants to occupy a single
         physical and immersive virtual space with one another, in which they can learn through spatial
         interaction with an electrostatics simulation sandbox. Narrative sequences optionally offer
         exposition of key principles and suggestions of exploratory activities. The demo shows three
         key approaches operating in tandem: collocated, multi-user, positionally tracked Virtual Reality
         (VR); a spatial simulation-based exploratory learning environment; and a playback system that
         presents narrative sequences prepared by instructors in the virtual environment. As such, it
          offers a novel and powerful embodiment of the "4E learning" paradigm that is the theme of this
          conference.

Introduction
We explore a promising design space for constructivist learning at the intersection of three well-established
approaches: (1) embodied learning in immersive six-degree-of-freedom
(6DoF)    VR,  (2)  simulation-based     exploratory  learning,   and  (3)
collaborative learning. These have not been combined previously to our
knowledge.   This  demo  brings  together  all three of  these in a novel
learning experience in the domain of electricity and magnetism. This
domain was chosen because it is known to be both challenging and highly
spatial, and  hence likely to   benefit from the use  of stereoscopic  3D
presentation,  6DoF    head     movement,    and  hand-based    embodied
interaction.
         One further key idea put forth in the demo is that of recording
and playback. The demo makes most prominent use of this in a series
of narrative  sequences    that are recorded   in the   environment   by      Figure 1. Collocated use of positionally
instructors. Learners hear instructors'   explanations, accompanied   by                tracked VR.
minimal avatars which move realistically, replicating the instructors'
real movements from the time of recording. This creates a strong sense of copresence ­ that is, the learner feels
they are sharing a space with a human (Greenwald et al., 2017b). In addition, these avatars interact with the same
interactive affordances (objects and tools) that are available to learner. Whatever is demonstrated by the instructor
can be directly accessed by the learner as well. This sets the stage for engaging exploratory activities that follow
the narrative sequences.
         Not only is the playback of recorded narrative sequences powerful pedagogically, it is also a key strategy
that can make the production of substantial quantities of content (from tens of minutes to hours) tractable for a
small team. Using typical approaches, where experiences make significant use of animated sequences that are
produced using digital art and graphic design tools, authoring 20 to 30 minutes of VR content is a highly resource-
and time-intensive process. Our approach is analogous to bringing a video camera into a physics lab in order to
create content ­ the lab equipment can be used in many different ways to illustrate a variety of ideas and principles.
It is the instructor that creates a narrative and guided activity to address a given topic area, and the content is
produced in real-time (of course, subject to repeat takes and manual preparation time in the virtual environment).

Background and prior work
In the past five years, consumer VR devices have burst onto the market, and created new opportunities for the
application of VR at scale. Although learning is thought to be one of the most promising areas, few attempts have
been made at implementing it in formal learning settings. Among these, the most common approaches have been
to expose learners to (1) the content that is available in online marketplaces in a very broad, nonpedagogical
fashion, and (2) the process of making VR content using today's tools. In contrast, this demo represents an attempt
to convey a specific set of ideas in electricity and magnetism (Coulomb's Law and Gauss' Law), which are

CSCL 2019 Proceedings                                    997                                                 © ISLS
challenging, and can benefit from an intuition-building approach that is complementary to algebraic approaches
that are the usual focus of the corresponding coursework.
         We briefly review prior work in the areas of (i) collocated 6DoF VR, (ii) science learning in VR, and (iii)
non-VR collaborative science learning.
         Several projects have implemented systems to explore collocated, 6DoF VR. One system for group-
togroup telepresence created a shared immersive virtual reality for local and remote groups of participants, using
projection-based multi-user 3D displays (Beck et al., 2013). The "Holojam" system used head-mounted displays
to allow many users to share a physical and virtual space. Use cases in data visualization and creative expression
were demonstrated (Royston et al., 2016; Masson et al., 2017). "CocoVerse" is a shared collocated immersive
virtual environment utilizing multiple head-mounted displays (HMD's), and including several different multiuser
co-creation interactions through hand-bound tools, including 2D and 3D painting, import and placement of
arbitrary 2D images and 3D models, and a virtual camera tool (Greenwald et al., 2017a). A later version of this
environment also included a software framework for recording and replaying users' actions and their effects on
the virtual environment. Users are represented using minimal avatars. In subsequent work building on this system,
the authors explore the quality of non-verbal communication afforded by this form of avatar representation. Using
subjective and objective measures, they find that the movement realism of embodied minimal avatars yields a
strong sense social presence and an effective medium for gestural communication (Greenwald et al., 2017b). In
our demo, we build on the same technology and avatar representation as CocoVerse, with the goal of leveraging
the demonstrated communicative benefits into an environment containing rich science-oriented content.
         In the area of spatial learning, ScienceSpace (Dede et al., 1996) was a pioneering work, implementing
science-oriented  educational content in 6DoF    VR,   including MaxwellWorld   focused  on  electrostatics using
interactive visualizations of charge, electric  field, and  electric flux. A  refined  model was  developed   for
understanding the impact of the various affordances of immersive virtual reality on conceptual learning (Salzman
et al., 1999). The much newer, more performant VR technology we use improves significantly on the user
experience of ScienceSpace. A recent paper makes a direct comparison between learning on a 2D screen and
learning in VR using electrostatics activities. Learners reported deeper spatial insights when using the VR version
(Greenwald et al., 2018). Both of these prior works indicate that science-oriented spatial learning in VR is highly
promising. Our demo goes further than both by incorporating collaboration, recorded in-world instruction, and an
extensive set of affordances for exploration.
         Finally, some notable  prior works   explored  the area of    non-immersive, simulation-based   computer
supported collaborative learning (CSCL). One of these used a system for co-located collaborative learning,
particularly of topics in physics, through a 2D (traditional screen) web interface, leveraging spatial arrangement
of information, interactions such as drawing, graphing, and text input (Coopey et al., 2013). This system enabled
classroom-scale collaboration leveraging 2D representations. Our demo does not support a large number of users
in this fashion, and it is oriented towards deep spatial insight, rather than algebraic and quantitative analytical
skills. Other authors explore the use of 3D virtual environments using non-immersive technology in collaborative
learning, through the design of a problem-based physics learning activity in Second Life, finding that such a
virtual collaborative learning activity can be engaging and effective (Vrellis et al., 2010). In contrast, the direct
spatial manipulation affordance  of 6DoF   immersive    VR   offers  a more learnable, natural interface than the
keyboard and mouse, in addition to the forms of non-verbal communication mentioned above.
         This brief survey of prior work has shown how each of the approaches we leverage in our demo has been
explored to some extent, but they have not been brought together in one system before.

User experience
The interactive content in the demo targets learning goals related to Coulomb's Law and Gauss's Law at the
undergraduate level. Participants enter VR together, and are given the option to either explore the affordances of
the toolbox, or view immersive narrative sequences, in which recorded avatars operate the various tools and
explain principles of physics (Figure 2). In the case that they view narrative sequences, they are at first somewhat
passive, gradually learning to interact with the simulation system as they see demonstrations from the recorded
instructors. In the case that they opt to explore using the toolbox, they use the graphical and text elements to infer
what is possible, and proceed to experiment. They can opt at any time to switch between the exploratory toolbox-
oriented mode and the explanatory narrative-sequence-oriented mode of interaction.
         The toolbox contains three kinds of items: charge distributions, visualization objects, and hand-based
tools. Charge distributions create the electric field that permeates the 3D space (Figure 3). Visualization objects
allow participants to visualize the field in different ways that are spatially local, and they can choose to place or
move these objects (Figure 4). Hand-based tools determine the functions of the handheld controllers (Figure 5).
Considering each of these from the perspective of collaboration: when one participant spawns a new charge

CSCL 2019 Proceedings                                   998                                                 © ISLS
distribution, it affects the field everywhere in space. This means that each participant can drastically affect the
visual and interactive experience of the other participant, regardless where they are standing or whether they are
attending to one another. Visualization objects, on the other hand, are local and will only be observed by the other
participant if they look in the relevant direction ­ choosing to explore visually and perhaps interact with the other
participant. Finally, the hand-based tools are  controlled  exclusively by    one user, as they  are bound   to   the
controllers. Each can be independently assigned­ there is no mutual exclusion when instantiating handheld tools.

System
ElectroVR creates a shared physical and virtual space among multiple users with HMD's and handheld controllers.
This section describes three aspects of the system: the physical and network architecture; the simulation engine;
and the recording and playback system.
        Each user requires a dedicated computer to run their HMD (our system uses the HTC Vive). Each
computer runs an instance of the interactive environment, and the instances are synchronized across the network.
This is accomplished through a client-server architecture, in which one of the connected machines acts as both a
client and as the authoritative server. Each client represents its user with an avatar, which shows the user's headset
and controllers on all connected machines. Each client instances also runs its own copy of the simulation. Because
some aspects of the input to the simulation are non-deterministic, some simulated elements such as the positions
of point charges are periodically synchronized with the server.
        The   simulation  engine computes   the   electric field analytically using superposition    of the charge
distribution primitives. The field due to each of these primitives is given by a simple expression ­ for example for
point charges, the contribution to the field is inversely proportional to the inverse square of the distance from a
given point to the location of the point charge. The dynamics of the system of point charges is computed with a
fourth-order Runge-Kutta algorithm.
        The recording and playback system allows for the capture and reproduction of the actions of users in the
environment. During recording, ElectroVR captures users' microphone audio, the movement of their avatars, and
the evolving state of the virtual environment. In particular, the system logs each state change and high-level
command that is executed on the server, along with an associated time stamp.

Project history and outlook
Begun in the summer of 2016, this project has proceeded through an iterative design process involving exploratory
prototyping, a focus group of physics instructors, co-design with physics instructors, and piloting with students
and instructors. In the spring of 2018, it was piloted with roughly 50 students, who each spent between 45 minutes
and two hours, either solo or together with one or more partners, immersed and interacting with the system. The
system successfully   achieved its design  goals, with very   positive feedback   from  students. An    analysis   of
collaborative behavior during the said pilots is ongoing work, and future applications of this system will enable
the effectiveness of collaborative learning in VR to be rigorously tested and characterized.

                 Figure 2. Toolbox (left) and narrative sequence with instructor avator (right).

   Figure 3. Example charge distributions (left to right): point charges, infinite slabs, and infinite cylinders.

CSCL 2019 Proceedings                                   999                                                  © ISLS
          Figure 4. Visualization objects (left to right): 2D field line plane, flux plane, flux cylinder.

                Figure 5. Hand-based tools (left to right): field line generator, simulator, camera.

References
Beck, S., Kunert,  A., Kulik,  A., and Froehlich,  B. (2013).   Immersive  group-to-group telepresence.        IEEE
         Transactions on Visualization and Computer Graphics, 19(4):616­625.
Coopey, E., Danahy, E., and Schneider, L. (2013). Interlace: Interactive learning and collaboration environment.
         In Proceedings of the 2013 Conference on Computer Supported Cooperative Work Companion, CSCW
         '13, pages 11­14, New York, NY, USA. ACM.
Dede, C., Salzman, M. C., and Bowen Loftin, R. (1996). Sciencespace: virtual realities for learning complex and
         abstract scientific concepts. In Proceedings of the IEEE 1996 Virtual Reality Annual International
         Symposium, pages 246­252.
Greenwald, S. W., Corning, W., Funk, M., and Maes, P. (2018). Comparing learning in virtual reality with learning
         on a 2d screen using electrostatics activities. Journal of Universal Computer Science, 24(2):220­ 245.
Greenwald, S. W., Corning, W., and Maes, P. (2017a). Multi-user framework for collaboration and co-creation in
         virtual reality. In Making a Difference: Prioritizing Equity and Access in CSCL/Proceedings of the 12th
         International Conference on Computer Supported Collaborative Learning, volume 2 of CSCL'17, pages
         879­880. Internation Society of the Learning Sciences.
Greenwald, S. W., Wang, Z., Funk, M., and Maes, P. (2017b). Investigating social presence and communication
         with embodied avatars in room-scale virtual reality. In Beck, D., Allison, C., Morgado, L., Pirker, J.,
         Khosmood, F., Richter, J., and Gütl, C., editors, Immersive Learning Research Network, pages 75­90,
         Cham. Springer International Publishing.
Masson, T., Daffy, and Perlin, K. (2017). Holo-doodle: An adaptation and expansion of collaborative holojam
         virtual reality. In ACM SIGGRAPH 2017 VR Village, SIGGRAPH '17, pages 9:1­9:2, NY, NY,. ACM.
Royston,  S., DeFanti, C., and Perlin, K. (2016).  A  collaborative untethered virtual reality environment       for
         interactive social network visualization. CoRR, abs/1604.08239.
Salzman, M. C., Dede, C., Loftin, R. B., and Chen, J. (1999). A model for understanding how virtual reality aids
           complex conceptual learning. Presence: Teleoperators and Virtual Environments, 8(3):293­316.
Vrellis, I., Papachristos, N. M., Bellou, J., Avouris, N., and Mikropoulos, T. A. (2010). Designing a collaborative
         learning activity in second life - an exploratory study in physics. In 2010 10th IEEE International
         Conference on Advanced Learning Technologies, pages 210­214.

CSCL 2019 Proceedings                                 1000                                                     © ISLS
