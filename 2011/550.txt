CSCL 2011 Proceedings                                                                                      Volume I: Long Papers

                                 A Portrait of CSCL Methodologies
                Heisawn Jeong, Hallym University, Chuncheon, Korea (South), heis@hallym.ac.kr
     Cindy E. Hmelo-Silver, Rutgers University, New Brunswick, US, cindy.hmelo-silver@gse.rutgers.edu

         Abstract: This study analyzed the methodologies of empirical CSCL research published in
         seven    leading   journals   of the  field  during   2005-2008     along  four dimensions     of  research
         methods, that is, research design, research setting, data, and analyses. In addition, this study
         examined       research  methodologies      in relation  to    theoretical frameworks.     Through    these
         analyses, this study provides a detailed picture of CSCL methodologies currently practiced in
         the field. In addition, the study also revealed a strong influence of theoretical frameworks on
         all aspects of research methodology.

Introduction
Computer-Supported Collaborative Learning (CSCL) is an interdisciplinary research field concerned with how
people can learn together with the help of computers (Stahl, Koschmann, & Suthers, 2006). Since its inception,
researchers have brought diverse theoretical perspectives and methodological approaches to the study of CSCL.
As a result, the field included an uncommon range of theoretical and methodological perspectives. Traditional
information    processing    perspectives    co-exist   with socio-cultural    perspectives   such   as activity   theory  and
situated cognition    in CSCL.     The  infusion   of   different theoretical  perspectives    has created   a  great deal  of
excitement and numerous efforts to bridge differences in disjointed and/or seemingly incompatible theoretical
traditions (Anderson, 1997; Anderson, Reder, & Simon, 1996; Greeno, 1997; Greeno & Sande, 2007; Paavola,
Lipponen, & Hakkarainen, 2004). The same is true for research methodology. In much CSCL research, the goal
is no longer merely to understand the phenomena but also to transform the current practices. When working in
the "blooming, buzzing confusion" of classrooms, researchers often no longer have the luxury to isolate and
manipulate variables as they would in the laboratories (Brown, 1992). The environment is complex with many
tightly interconnected components. Controlling variables is all but impossible in such environments. As a result,
working   in  such    settings   often meant   abandoning      scientific rigor  and   theoretical   relevance    in the  past.
Borrowing from design sciences such as engineering and artificial intelligence, however, the introduction of a
research strategy     called "Design-based     research"     has  allowed    researchers to   design  changes   in   classroom
practices while working toward the goal of developing theoretical models of learning and instruction. Design-
based  research   became     a tool not   only to  test  and  refine  educational   designs    but also a  tool  to  carry out
formative research about learning theories (Brown, 1992; Collins, Joseph, & Bielaczyc, 2004).
         Distinctions    between    quantitative   and  qualitative   methodologies    have   long  existed  in many   fields.
Quantitative research refers to the empirical investigation of numerical properties of variables and relationships
among    these variables    (Shadish,   Cook,  &   Campbell,     2002).   Heavily   influenced  by   logical positivism    and
statistical theories, the objective of quantitative research is often to test hypothesis that are true to the population
at large. It was typically associated with experimental and survey studies where numerical data are collected
with   active manipulation     of variables.  In such   studies,  large sample   sizes   are important  to  ensure   statistical
significance.  Quantitative    research   is often contrasted    with qualitative   research  that aims  to  construct an  in-
depth understanding of human behaviors. Qualitative research is associated with descriptive methods such as
case or ethnographic studies where rich data such as videotapes, verbal transcripts, and artifacts are collected
and  analyzed     qualitatively.  Analysis   typically  deals  with   a small   set of   data  and is  aimed   at  uncovering
meaningful    patterns   that  may     be  context-specific.     Statistical and    numeric   analyses   are sparsely    used.
Quantitative research with its longer history has been the dominant methodology in many fields of research
(Hunter & Leahey, 2008; Morrow & Brown, 1994). However, this picture is changing. Qualitative research,
although  initially   a methodology     practiced    in a few    fields such  as anthropology      and  sociology,   has  been
establishing   itself as  a  major   research    methodology      in many    fields including   education    and   CSCL.   As
qualitative methods become more popular, more attempts are made to triangulate data collection and analyses,
and  mixed-    or  multi-method      research    has  become     increasingly   used   (Hmelo-Silver,    2003;    Johnson   &
Onwuegbuzie, 2004).      Nonetheless, there are also cautionary voices regarding mixed-method approaches and/or
methodological eclecticism on the grounds that they fail to consider theoretical backgrounds and conceptual
framework     for research   (Maxwell,    2004;  Morrow      &   Brown,   1994;  Yanchar     & Williams,   2006).    What  this
means is that traditional descriptions of qualitative or quantitative research no longer adequately describe some
of the research being carried out in the field. There is a need to develop a more sophisticated understanding of
the kinds of research methodology currently practiced in CSCL investigations and ways to better align them
with diverse theoretical backgrounds.
         This study aimed at examining recent trends in CSCL research methodology. Our analyses examined
the following dimensions of CSCL research methodology: (1) Research designs, (2) Research settings, (3) Data,
and (4) Analyses. These methodological dimensions were then examined in relation to theoretical backgrounds

© ISLS                                                                                                                      550
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

of the investigations. We analyzed empirical CSCL research papers published in seven leading journals of the
field during 2005-2008. This study is an extension of Jeong and Hmelo-Silver (2010), which reported on some
of the  preliminary   findings  for  subset  of papers  published   during 2005-2007.     We added    additional studies
published in 2008 as well as an additional coding category.

Methods

Journal Selection
Seven journals were selected for this study: (1) International Journal of Computer Supported Collaborative
Learning   (ijCSCL)    (2) Journal  of   the Learning  Sciences, (3)  Learning  and   Instruction, (4)  Computers     and
Education, (5) Journal of Computer Assisted Learning, (6) International Journal of Artificial Intelligence in
Education (ijAIinEd), and (7) Computers in Human Behavior. The journals were selected based on a survey of
16 CSCL    community      leaders (e.g., CSCL     committee of  ICLS  and  the  editorial board  members    of ijCSCL).
These  are all peer-reviewed     journals   published by  well-known    publishers with   international authorship    and
readership. Articles published in the seven journals during 2005-2008 period, that is, four years of publication
and three years of publication in the case of ijCSCL were examined for the study.

Paper Selection
Excluding non-research articles (e.g., editorials, book reviews, or obituaries), 1,423 articles were published in
the seven journals during the 2005-2008 period. We screened them to identify empirical CSCL research papers.
Empirical  research    was  determined      based on  whether   the study  examined   primary    data.  Secondary   data
analysis, simulated    results, theoretical  papers,  and  meta-analyses   were excluded.    The data   may  have  been
collected as part of a larger project, but the analyses and findings had to be new. CSCL research was determined
in terms   of  whether     learners learned   collaboratively   using technological   tools. Learning   needed     to be
collaborative, but as long as parts of the learning process involve interaction (e.g., collaborative discussion after
individual study), it was considered as collaborative learning. The focus was on small group peer collaboration,
so that student-teacher interactions or whole class discussions were excluded unless they also included small
group peer collaboration. The applied technologies needed to be specific (studies examining general IT usage
were not included), but did not necessarily have to be so-called collaboration technology such as e-mails or
discussion boards. Interaction with computerized agents or intelligent systems were included if they involved
learning. Studies that examined social and technical issues were included if they were studied in relation to
CSCL.   In addition    to  empirical    CSCL  papers,  we  included   methodological   papers  that addressed    various
methodological issues related to CSCL (e.g., introduction of new methods such as Social Network Analysis,
development of specific rating schemes). Studies with special population students (e.g., ADHD, autism) were
excluded.
          The selection process proceeded in two stages. First, initial selection of empirical CSCL papers was
conducted based on the title and abstract of the paper. At this stage, we tried to be as inclusive as possible so as
not to miss any potential CSCL papers and included papers if their title and abstract suggested empirical CSCL
investigations. This initial screening was verified at the coding stage so that final judgment about the eligibility
was made based on a more comprehensive examination of the papers. Currently, the number of the papers in the
coding pool is 315, which is roughly about 22% of the papers published in the journals during 2005-2008.

Content Analyses
In order  to  examine   research  methodologies,    we  examined    the studies along  the  following   dimensions:   (1)
Research design, (2) Study setting, (3) Data, and (4) Analysis. We then examined these features of research
methodology in relation to (5) Theoretical frameworks of the study. Coding categories were developed based on
a  combination  of    inductive and  deductive    approaches.  They   were initially generated   top-down   (e.g., using
categories drawn from the submission descriptors of the 2005 CSCL conference) and later refined through a
bottom-up process of multiple coding iterations. We describe coding schemes for each category of codes below.

Research Designs
Research   designs    were coded    as: (1)  Experimental, (2)  Descriptive, or (3)  Design-based   research   methods.
Experimental designs refer to studies where some interventions were applied and was further divided into (a)
randomized, (b) quasi-experimental, and (c) pre-post design. Descriptive studies referred to studies that aimed at
describing a phenomena or case. These included case studies, surveys, and ethnographic investigations. Design-
based method referred to the research strategy in which CSCL designs and interventions were investigated in
theoretically-driven ways and refined progressively over several iterations. In order to be coded as design-based
method, the study not only needed to design CSCL systems or environments, but also the design needed to be
theoretically grounded,    instantiated  in  specific contexts, studied  and refined  iteratively  as  part of a   bigger
design-based research (Barab & Squire, 2004; Brown, 1992; Collins, Joseph, & Bielaczyc, 2004). Note that

© ISLS                                                                                                                551
CSCL 2011 Proceedings                                                                                    Volume I: Long Papers

design-based research refers to an approach or framework of research that can transcend the design of individual
iterations that may    have  been  either  experimental    or descriptive.   Once   a study   was  coded    as design-based
method, the design of individual iterations was not coded separately.

Research Settings
Research   settings   were defined  as the  contexts   in which    the research  was   conducted   and  was    coded as: (1)
Laboratory, (2) Classroom, or (3) Other settings. Laboratory referred to lab-like controlled settings where data
collection was carried out outside the context of classrooms or other authentic learning situations. Classroom
setting referred to more or less formal learning situations that were guided by teachers both within and outside
of physical classroom (e.g., field trips). Other settings meant settings outside laboratories or classrooms such as
workplace or informal learning environments (e.g., teacher workshop or professional conference).

Data
Data were coded as: (1) Process, (2) Outcome, and (3) Miscellaneous. Process data were further divided into (a)
text-asynchronous, (b) text-synchronous, (c) video/audio, (d) log data, and (e) other. Outcome data referred to
data collected to get static snapshots at the learners' cognitive and other states and could be collected at the
beginning of a study (e.g., pre-test) as well as at the end. Sub-categories were: (a) multiple-choice questions, (b)
open-ended questions, (c) artifacts (e.g., contents of multi-media whiteboard), and (d) other (e.g., expert ratings,
final course grades). Miscellaneous data included (a) self-reports/questionnaires (e.g., demographic information,
affective measures, perceived acceptance, etc.), (b) interview or focus groups, (c) field notes or observations,
and (d) other (e.g., IQ, learning styles).

Analysis Methods
Analysis methods refer to the kinds of analyses carried out on the data and consisted of two general categories:
(1) Quantitative and (2) Qualitative. Quantitative analyses were further coded as: (a) simple descriptive (e.g.,
frequencies or means, quantitative analysis of qualitative data such as coding numbers of words in messages or
scoring an open-ended answers), (b) code and count, (c) inferential statistics (e.g., t-test, analysis of variance,
regression), (d) modeling (e.g., log-linear analysis, structural equation modeling), (e) Social Network Analysis
(SNA), and (f) other miscellaneous quantitative analysis (e.g., comparison with simulated data). Among simple
descriptive, inferential, and modeling statistics, we coded the more sophisticated form of analysis since the use
of inferential statics and modeling assumes descriptive statistics and inferential statistics, respectively. If a study
did a  code  and  count    and then   ran  inferential statistics, they    were coded   separately,   however.  Qualitative
analyses   were   further  coded  as:  (a) (qualitative)  content   analysis,   (b) Conversational     Analysis   (CA)   and
Discourse Analysis (DA), (c) grounded theory, (d) Interaction Analysis (IA), (e) other (e.g. narrative analysis or
phenomenography), and (f) loosely defined where data was qualitatively described with some examples.

Theoretical Frameworks
Theoretical frameworks were coded as: (1) Information processing, (2) Socio-cognitive, (3) Constructivism, (4)
Socio-cultural  (e.g., distributed   cognition, activity   theory),    (5) Communication,     (6)  Social   psychology,  (7)
Motivation,  (8)  Atheoretical,    and (9)  Other.  Information     processing     theory  refers  to traditional cognitive
theories with   a strong   emphasis   on  individualistic  cognitive   processes   such   as encoding   and  retrieval from
memory (Klahr & Kotovsky, 1989; Newell & Simon, 1972). Socio-cognitive theory refer to theories related to
Piagetian notion of cognitive conflicts and conceptual change (De Lisi & Golbeck, 1999; Doise, Mugny, &
Perret-Clermont, 1975). Constructivism refers to a broad range of theoretical approaches that emphasize active
learner processing and knowledge construction either in individualistic and collaborative settings (Chi, 2009;
von Glaserfeld,   1987).   Socio-cultural  theory  refers  a  diverse   range   of theories  such  as  generic  Vygotskian
approach, distributed cognition, or activity theory (Engeström, 2001; Hutchins, 1995). Communication theory
refers to theories addressing linguistic and communicative aspects of collaboration (Krauss & Fussell, 1990).
Social psychology theory refers to theories that focus on social aspects of collaboration such as status difference,
gender, or group dynamics (Levine & Thompson, 1996). Motivation theory refers to theories with a focus on
motivational  aspects     of learning  addressing   issues    such  as  self-regulation    (Pintrich,  1999).   Atheoretical
framework refers to investigations that are more or less guided by practical concerns. Other theory category
refers to theories that did not fit into any of the categories that we have described.
         Coding was conducted based on researchers' description of studies. If researchers described their study
as  "experimental"    and/or  "interaction  analysis,"  then  we   coded    them   as such.  In  a few  cases   where  their
description  was    controversial, we     followed a   more   conventional      definition   so that  "near    synchronous"
interaction was coded as asynchronous interaction and that an "experiment" without any control condition was
coded  as  a descriptive   study. In  unclear cases    in which    the authors  did   not explicitly  state the information
relevant to the coding categories (e.g., no mention of whether the study was carried out in lab or in classrooms),
we relied on the contextual information presented in the paper. For example, when a study did not specify data

© ISLS                                                                                                                   552
CSCL 2011 Proceedings                                                                               Volume I: Long Papers

and   only stated  that   the number   of   words    in asynchronous   notes  was   analyzed, it  was  assumed    that
asynchronous text messages were collected as data (e.g., Hewitt & Brett, 2007). Multiple coding was possible
depending on the features of the study. For example, when the study collected more than one type of data such
as asynchronous text messages and interview data, all of them were coded. Two coders independently coded a
subset (20%) of papers from the 2005-2007 set and discussed disagreements. Cohen's kappa was above .75 for
all codes (Jeong & Hmelo-Silver, 2010). The coders divided the rest of the papers and are in the process of
coding them independently while discussing unclear cases.

Results

Portraits of CSCL Methodologies
About 8% of the papers in the paper pool were methodology papers. Note that methodology papers may not
have reported on actual data as some discussed approaches or issues in analyses (Strijbos, Martens, Prins, &
Jochems, 2006; Weinberger, Stegmann, & Fischer, 2007). Because research design or settings were not always
identifiable in methodology papers, the results reported in this section are based on a random sample of the
papers that contained actual data, excluding methodology papers (N=265).

Research Designs
The most prevalent CSCL research design were descriptive designs (54%), followed by experimental research
(37%),  and   design-based    research (9%).  Of   the  studies  with  experimental design, about   half (54%)    were
randomized experiments, followed by quasi-experimental (31%) and pre-post designs (15%).

Research Settings
Most   often, CSCL     research  was conducted    in classrooms   (73%),  followed  by   laboratory  (21%) and    other
settings (9%). A small proportion of studies (3%) was conducted in multiple settings, so that an experiment was
first carried out in the laboratory and then in classrooms (de Jong, Kolloffel, van der Meijden, Staarman, &
Janssen, 2005). Laboratory studies have been typically associated with experimental design, whereas classroom
studies have been typically associated with descriptive design in the past. Although this was generally true,
there  were   many    exceptions. Of   the laboratory   studies, 36%   were  descriptive studies, whereas  a   similar
proportion of classroom studies (31%) were experiments (Figure 1).

                                   Figure 1. CSCL Research Settings by Design.

Data
Researchers collected diverse types of data in CSCL investigations. The most frequently collected process data
were   asynchronous    text messages   (29%), followed    by log  data (28%), video/audio   (26%),   synchronous  text
messages   (15%),     and other  (2%). For  outcomes,    the most  frequently collected  data were   artifacts (24%),
followed   by  open-ended     questions    (17%),    multiple-choice   questions (16%),   and  other   (15%).      For
miscellaneous   data,  most   frequently   collected data  types  were  self-report (54%),  interviews   (30%),   field
notes/observations (16%), and other (8%). Overall, CSCL research collected process data in 68% of the studies,
outcome data in 54% of the studies, and miscellaneous data in 72% of the studies.
         Multiple data types were collected in typical CSCL investigations with the average number of data
types  being  2.82    per study.  Interestingly, research design   seemed to  have  influenced   the amount    of data
collected. Design-based research collected the most types of data (M=3.52), followed by experimental (M=2.78)
and descriptive (M=2.72) studies (Figure 2).

Analysis Methods
CSCL research used a variety of analysis methods. Overall, 86% of the studies carried out quantitative analyses
and 52% of the studies carried out qualitative analyses. Percentages exceeded 100%, because 38% of the studies

© ISLS                                                                                                             553
CSCL 2011 Proceedings                                                                             Volume I: Long Papers

included both quantitative and qualitative analyses. Studies with quantitative analyses replied on descriptive
statistics (20%), code and count (48%), inferential statistics (66%), modeling such as multi-level modeling (6%),
SNA    (1%), and  other  (1%).  Qualitative analyses  used qualitative  content analysis   (3%), CA   or DA   (9%),
grounded theory (8%), and IA (2%), and other methods (10%), and loosely defined (66%).

Figure 2. Data Collected in CSCL Research by Research Design (Data Types with Low Frequencies Omitted).

          When researchers used quantitative analysis, they generally used inferential statistics. This was true
even for studies that used code and count. The results of coding were subjected to inferential statics in 69% of
the cases. At the same time, there were also a sizable amount of studies that relied on descriptive statistics only.
This occurred when researchers reported some descriptive statistics in the contexts of qualitative analyses (43%)
or code and count (22%), but there were many studies whose analysis was solely descriptive. In the case of
qualitative analyses, the use of established techniques such as CA or DA was less common and accounted for
32%    of qualitative  analyses conducted.   The remaining    qualitative  analyses  were    loosely defined where
descriptions of data were provided with examples. Loosely defined analyses were usually carried out after some
initial quantitative analyses were conducted. For example, qualitative, in-depth descriptions of a subset of data
were provided after quantitative analyses of the whole data set. However, about 15% of qualitative analyses
were solely in the loosely defined category.
          Analysis methods were strongly influenced by research design (see Figure 3). While experimental and
descriptive studies relied more heavily on quantitative analysis (100% and 79%, each) than qualitative analyses
(28%   and   57%  each),  design-based studies   relied  more   heavily  on   qualitative analyses   (84%) than  on
quantitative analyses (68%). Use of multiple analysis methods was most common in design-based research with
about half (52%) using both quantitative and qualitative analyses. Note, however, that this could have occurred
because   design-based  studies collected more data   than other  studies and, as  a result, had to  use a range of
methods to analyze the data.

                             Figure 3. CSCL Research Design by Analysis Methods.

Theoretical Frameworks and Research Methodologies
CSCL    research was   guided by various  theoretical  frameworks   with  the most  common    being   constructivism
(32%), followed by socio-cultural theories (19%), social psychology (16%), other (14%), atheoretical (11%),
information  processing   (10%), and  socio-cognitive   theories (4%).  Note  that  there  were quite  a number  of
atheoretical investigations motivated  by   practical concerns.  At the same  time,  a small  portion of the papers
(14%) drew from multiple theoretical frameworks, reflecting the diverse theoretical heritage of CSCL.

© ISLS                                                                                                           554
CSCL 2011 Proceedings                                                                               Volume I: Long Papers

          Theoretical frameworks had a strong influence on all aspects of the investigations. It first influenced
research   design (see  Figure   4). Experimental   studies   were  strongly   guided by  constructivism  and  social
psychology theories, whereas descriptive and design-based studies were strongly guided by constructivism and
socio-cultural theories. Theoretical frameworks similarly influenced research settings so that laboratory studies
were most strongly associated with constructivism and social psychology framework, while classroom studies
were strongly associated with constructivism and socio-cultural theories.

                           Figure 4. CSCL Research Designs by Theoretical Frameworks.

          Theoretical frameworks also influenced kinds of data collected. Video/audio data and artifacts were
most likely to be collected in studies with a socio-cultural framework (44% and 32% each), whereas self-report
data   were most  likely   to be   collected in studies with   a social psychology    framework   (79%).  Theoretical
frameworks also influenced analysis methods (Figure 5). Although quantitative analysis was less common in
studies with  socio-cultural   frameworks    (64%), quantitative  analyses were    actively  used in studies  with all
theoretical frameworks. Theoretical frameworks influenced use of qualitative analysis methods more heavily.
Studies from information processing and social psychology framework were least likely to carry out qualitative
analyses (15% and 21% each), whereas studies from socio-cultural framework were most likely to carry out
qualitative analyses (82%).

   Figure 5. Theoretical Frameworks by Analysis Methods (IP: Information Processing; SC: Socio-Cognitive;
Const.: Constructivism; S-cultural: Socio-cultural; Comm: Communication; Social P: Social Psychology; Mot:
                                          Motivation; Atheo: Atheoretical).

Discussion
In this paper, we     conducted  a detailed  examination   of empirical CSCL    research published   in seven leading
journals of the field during 2005-2008. The analyses showed that the typical methodology adopted in empirical
CSCL    investigations  is a  descriptive design   with quantitative   analyses of self-report/questionnaire  data in
classroom settings. Although these may characterize the most typical CSCL empirical investigations, CSCL
methodology is far from monolithic. Design-based research, although still comprising a minority of studies, has
gained  a  respectable  footing  in  CSCL    research. Researchers  are  also  actively experimenting   with  existing
methodologies as they carry out experiments in classroom settings, collect many kinds of data, and increasingly
analyze them both quantitatively and qualitatively. In the past, characterization of research methodology often
relied  on  simplistic  distinctions such    as quantitative  and qualitative  and/or experimental   and  descriptive
distinctions (Hew,    Kale,   &  Kim,  2007;    Hrastinski &   Keller,  2007). Rather   than relying such  a  general

© ISLS                                                                                                             555
CSCL 2011 Proceedings                                                                                   Volume I: Long Papers

characterization, this study examined research methodology in more detail along four dimensions of research
methodology: design, setting, data, and analyses and identified some of the recent trends in CSCL research.
Through these analyses, this study was able to provide a more detailed picture of CSCL methodologies currently
practiced    in the   field.  Reflecting   its multi-disciplinary   mission,  CSCL       is characterized    by  multiple
methodological approaches. The complexity of the research methodology currently practiced in CSCL suggests
a need to develop more sophisticated understanding of research methodologies beyond the exiting dichotomies
of quantitative   and  qualitative methods.    In addition, this study  showed    that theoretical   framework   strongly
influenced all aspects of research methodologies, suggesting that researchers need to be more mindful of the
influences and biases of one's theoretical frameworks when they plan and carry out research.
          Despite the recent methodological developments in the field, there are a number of areas where more
sophisticated   methodological     understanding   and  practices   are needed.   First, the  field    needs to  be  more
principled in its applications of design-based research. Researchers often did not distinguish design as a research
goal from design as a research methodology. In addition, even when design research was used to refer to the
research method or strategies, its application was often name in only (Jeong & Hmelo-Silver, 2010). Second,
unprecedented     amounts    of  "content"  data  are  being  generated    online in   the   form   of  synchronous   and
asynchronous messages and various online artifacts. The advancement of the field greatly depends on how well
these rich sources of data can be utilized, and much of the field's current analytic efforts is directed toward
honing analytic methodologies related to analyzing these types of data, as can be seen in the topics of recent
methodology     papers  (Baker,  Andriessen,    Lund,  van  Amelsvoort,    &  Quignard,     2007;   de  Wever,  Schellens,
Valcke, & van Keer, 2006). So far, analyses of these content data have been mostly conducted through coding
and  counting   or  qualitative  analyses. Such   methods   are  time-consuming   and    not  well  suited to  large-scale
analyses, however.    Automating    the   process of code  and  count   is being explored    (Rosé,  2008),  but the field
needs to explore additional ways to analyze these data efficiently as well as meaningfully. The yearning for
meaning research outcomes that goes beyond "merely significant" results is reflected in the increasing role of
qualitative methodology. However, qualitative analyses often present barriers for many researchers who are new
to them. It is often unclear which qualitative methods to choose among the diverse qualitative research methods
such as discourse analysis and conversational analysis. The analytic techniques are not always transparent either.
These factors contribute to shallow applications of qualitative methodology. Qualitative research methods need
to be better communicated to the community in order to ensure more fluent and appropriate practices. Third, the
mixed-method     approach    is becoming   increasingly prevalent   in  CSCL   research.    There   are concerns that the
epistemological commitments of some of these methodologies are too disparate for true multi-method analyses
to be possible. Epistemological issues are not necessarily present in all forms of mixed-method research. Still,
researchers need to be aware of the differences in epistemological and theoretical frameworks and find ways to
achieve productive multi-vocality (Suthers, et al., 2011). Fourth, in this paper, we attempted to contextualize
research methodology within theoretical frameworks and captured some of its influences. In a similar fashion,
we need to understand what may be the influence of research methodologies (as well as theoretical framework)
on research findings. We need to understand whether and how adoption of certain methodology obscures certain
aspects of the phenomena while increasing sensitivity to others. The results of this study should help researchers
enhance their understanding of current practices of CSCL research methodologies as well as develop common
conceptual frameworks for discussing different methodologies and bridging diverse research traditions.

References
Anderson,    J.  R.   (1997).   Situative versus  cognitive  perspectives:     Form    versus    substance.  Educational
          Researcher, 26(1), 18-21.
Anderson, J. R., Reder, L. M., & Simon, H. A. (1996). Situated learning and education. Educational Researcher,
          25(4), 5-11.
Baker, M., Andriessen, J., Lund, K., van Amelsvoort, M., & Quignard, M. (2007). Rainbow: A framework for
          analyzing   computer-mediated     pedagogical    debates.  International  Journal      of Computer-Supported
          Collaborative Learning, 2, 315-357.
Brown,    A. L.  (1992).  Design   experiments:   Theoretical   and methodological     challenges   in  creating complex
          interventions in classroom settings. The Journal of The Learning Science, 2(2), 141-178.
Chi,   M. T. H.   (2009). Active-constructive-interactive:    A  conceptual   framework      for differentiating learning
          activities. Topics in Cognitive Science, 1, 73-105.
Collins, A., Joseph, D., & Bielaczyc, K. (2004). Design research: theoretical and methodological issues. Journal
          of the Learning Sciences, 13(1), 15-42.
de Jong, F., Kolloffel, B., van der Meijden, H., Staarman, J. K., & Janssen, J. (2005). Regulative processes in
          individual, 3D, and computer supported cooperative learning contexts. Computers in Human Behavior,
          21, 645-670.
De Lisi, R., & Golbeck, S. L. (1999). Implications of Piagetian theory for peer learning. In A. M. O'Donnell &
          A. King (Eds.), Cognitive perspectives on peer learning. Mahwah: Erlbaum.

© ISLS                                                                                                                 556
CSCL 2011 Proceedings                                                                                   Volume I: Long Papers

de Wever, B., Schellens, T., Valcke, M., & van Keer, H. (2006). Content analysis schemes to analyze transcripts
         of online asynchronous discussion groups: A review. Computers and Education, 46, 6-28.
Doise,  W.,  Mugny,    G.,  &   Perret-Clermont,   A.   (1975). Social interaction and     the development   of  cognitive
         operations. European Journal of Social Psychology, 5(3), 367-383.
Engeström, R. (2001). Expansive learning at work: toward an activity theoretical reconceptualization. Journal of
         Education and Work, 14(1), 133-156.
Greeno,  J.  G.   (1997).   Response:    On  claims    that answers   the wrong   questions.    Educational   researcher,
         January/February, 5-17.
Greeno,  J.  G.,  &   Sande,    C.  (2007). Perspectival    understanding  of conceptions      and conceptual   growth in
         interaction. Eduational Psychologist, 42(1), 9-23.
Hew, K. F., Kale, U., & Kim, N. (2007). Past research in instructional technology: Results of a content analysis
         of empirical studies published in three prominent instructional technology journals from the year 2000
         through 2004. Journal of Educational Computing Research, 36(3), 269-300.
Hmelo-Silver, C. E. (2003). Analyzing collaborative knowledge construction: Multiple methods for integrated
         understanding. Computers and Education, 41, 397-420.
Hrastinski, S., & Keller, C. (2007). An examination of research approaches that underlie research on educational
         technology: A review from 2000 to 2004. Journal of Educational Computing Research, 36(2), 175-190.
Hunter,  L.,  &  Leahey,    E.  (2008).  Collaborative    Research  in Sociology:  Trends      and Contributing   Factors.
         American Sociologist., 39(4), 290-306.
Hutchins, E. (1995). Cognition in the wild. Cambridge, MA: The MIT Press.
Johnson, R. B., & Onwuegbuzie, A. J. (2004). Mixed method research: A research paradigm whose time has
         come. Educational Researcher, 33(7), 14-26.
Klahr,  D., &   Kotovsky,   K.   (Eds.). (1989).  Complex    information  processing:  The     impact of Herbert   Simon.
         Hillsdale, NJ: LEA.
Krauss, R. M., & Fussell, S. R. (1990). Mutual knowledge and communicative effectiveness. In J. Galegher, R.
         E.   Kraut   &   C.    Edigo   (Eds.), Intellectual  teamwork:    Social  and     technological foundations   of
         cooperative work. Hillsdale, NJ: Erlbaum.
Levine, J. M., & Thompson, L. (1996). Conflict in groups. In E. T. Higgins & A. Kruglanski (Eds.), Social
         psychology: Handbook of basic principles.
Maxwell, J. A. (2004). Causal explanation, qualitative research, and scientific inquiry in education. Educational
         Researcher, March 3, 3-11.
Morrow, R. A., & Brown, D. B. (1994). Deconstructing the conventional discourse of methodology Critical
         Theory and Methodology Thousand Oaks, CA: Sage Publication.
Newell, A., & Simon, H. A. (1972). Human problem solving. Englewood Cliffs, NJ: Pretice-Hall.
Paavola, S., Lipponen, L., & Hakkarainen, K. (2004). Models of innovative knowledge communities and three
         metaphors of learning. Review of Educational Research, 74(4), 557-576.
Pintrich, P. R. (1999). The role of motivation in prompting and sustaining self-regulated learning. International
         Journal of Educational Research, 31, 459-470.
Rosé,   C.  (2008).   Analyzing     collaborative  learning   processes   automatically:   Exploiting  the   advances  of
         computational      linguistics  in computer-supported      collaborative  learning.   International  Journal  of
         Computer-Supported Collaborative Learning, 3, 237-271.
Shadish,   W. R., Cook,     T.  D., &   Campbell,  D.   T.  (2002). Experimental   and quasi-experimental     designs  for
         generalized causal inference. New York: Houghton Mifflin Company.
Stahl, G., Koschmann, T., & Suthers, D. D. (2006). Computer-supported collaborative learning: A historical
         perspective.    In R.  K.   Sawyer     (Ed.), Cambridge    handbook  oh   the learning    sciences. New    York:
         Cambridge University Press.
Strijbos, J., Martens, R. L., Prins, F. J., & Jochems, W. M. G. (2006). Content analysis: What are they talking
         about? Computers and Education, 46, 29-48.
Suthers, D.   D., Lund,     K., Law,   N.,  Rose,  C.,  Teplovs,  C.,  Chen,  W.,  et  al. (2011).  Towards   Productive
         Multivocality in the Analysis of Collaborative Learning. Paper to be presented at the CSCL 2011.
von Glaserfeld, E. (1987). Learning as a constructive activity. In C. Janvier (Ed.), Problems of representation in
         the teaching and learning of mathematics (pp. 3-38). Hillsdale, NJ: Erlbaum.
Weinberger,   A.,  Stegmann,       K., &  Fischer, F.   (2007).  Knowledge    convergence      in  collaborative learning:
         concepts and assessment. Learning and Instruction, 17, 416-426.
Yanchar, S. C., & Williams, D. D. (2006). Reconsidering the compatibility thesis and electicism: Five proposed
         guidelines for method use. Educational Researcher, 35(9), 3-12.

Acknowledgments
This   research was   in part   funded   by the  National   Research  Foundation   of  Korea   (NRF)  (Grant  No.   2009-
0068919) awarded to the first author and a Rutgers Faculty Research Council grant to the second author.

© ISLS                                                                                                                 557
