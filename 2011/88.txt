CSCL 2011 Proceedings                                                                                     Volume I: Long Papers

 Towards an Understanding of "Listening" in Online Discussions:
              A Cluster Analysis of Learners' Interaction Patterns
 Alyssa Friend Wise, Farshid Marbouti, Jennifer Speer, Ying-Ting Hsiao, Simon Fraser University, 250-13450
                                      102 Avenue, Surrey BC, Canada, V3T 0A3
                       Email: afw3@sfu.ca, fmarbout@sfu.ca, jspeer@sfu.ca, yha73@sfu.ca

          Abstract: Conducting learning conversations through online discussion forums differs from
          face-to-face   conversations  as   learners  can be   selective  in  what comments      they choose    to
          "listen" to, when   they   chose   to do so, and  how   long   they  spend attending    to them.  Using
          cluster  analysis of  learners'  click-stream   data  from  an   online  discussion  forum,  this study
          identified three patterns of behaviors that differentiate between learners: Superficial Listeners,
          Intermittent   Talkers;  Concentrated      Listeners,  Integrated    Talkers;  and   Broad   Listeners,
          Reflective Talkers. Clusters differed in the amount of time spent listening, number of posts
          attended to, number and length of their sessions, and number of own posts contributed and
          reviewed. Clusters did not differ in percentage of posts scanned (vs. read), time to compose
          posts, length of posts made, or final course grades. Results are compared to interaction styles
          found for other online tools and implications for practice and future research are discussed.

Introduction
Conversation conducted through online discussion forums continues to gain interest as a vehicle for learning
(e.g. Barab, Kling & Gray, 2004; Luppicini, 2007). Theoretically, discussion forums can support students in
actively engaging with others to build understanding as they externalize their thoughts, hear alternative points of
view   and   work  collectively to   negotiate  meaning    (Boulos    & Wheeler,   2007).  Such   conversations     can  thus
support knowledge construction both from the perspective of a group collectively improving ideas and from the
perspective   of the  individuals  in the  group   deepening    their personal   understanding    (Stahl, 2003). However,
online discussions don't always live up to this promise; in practice it is common to find fractured and incoherent
conversations (Herring, 1999) with low levels of interactivity between students (Thomas, 2002).

Theoretical Framework - Speaking and Listening as Core Elements of Conversation
In the model above, knowledge construction occurs as learners share the ideas and work with the ideas of others.
Similar   to face-to-face   conversation   this  can  be  thought  of   as "speaking"   (externalizing    one's  ideas)  and
"listening"  (taking  in the externalizations    of  others). But  compared     to face-to-face   conversations, in  online
discussions learners have greater control of what comments they choose to attend to, when they chose to do so,
and how long they spend "listening" to them. The majority of research on collaboration in online discussions
has focused on the "speaking" aspects of conversation ­ studying the messages learners contribute and how they
interact to produce group meaning-making (e.g. Arvaja, 2007; De Wever et al., 2006). Much less attention has
been paid to the interactions learners have with existing messages and the often extended sequences of listening
behaviors they engage in during the processes leading up to making a contribution (e.g. how learners navigate
the existing discussion; how many and which messages they choose to open; how they interact with this content
once   opened;   how   they compose    their    own  contributions).  These    "online  listening behaviors"    are core  to
interactivity in  online discussions  and    are an  important   part of   the knowledge  construction    process   that can
influence both the contributions made and the uptake of ideas between learners (Suthers, 2006).
          Initial work suggests that for many learners, their interactions with previous messages are brief and
superficial. Thomas (2002) found that on average students read a low number of messages compared to the
number they posted, and a substantial portion of messages did not meaningfully refer to previous ones. Hewitt
(2003; 2005) found that while most students did read at least one message before composing their own, they
took   a single-pass  strategy  that  focused   almost exclusively    on   the most  recently  posted  messages.    Learner
listening  behaviors   appear   to be  sub-optimal    for  learning   (Thomas,    2002)  and   heavily influenced    by  the
interface in which they take place (Kear, 2001). While past studies provide a broad outline of the situation, they
do not give detailed information about how particular students interact with the discussions. Nor do they help us
identify productive interaction strategies which might be encouraged in other students. Further research on how
learners listen in online spaces and their motivations for doing so is needed to build a more complete picture of
the  process   of  learning  through   online    conversation    and   create  a   theoretical foundation   for  designing
interventions to support more effective listening behaviors.

The Current Study
This   work   builds  on previous    efforts by  examining    in fine-grained    detail what   online  listening behaviors
particular learners engage in. Specifically, the goal of this study was to identify and group particular sets of

© ISLS                                                                                                                    88
CSCL 2011 Proceedings                                                                                   Volume I: Long Papers

behaviors  that  characterize   different  interaction patterns learners    use to  interact with  the  existing  posts  in
discussion forums. In future work, these styles can be classified as more or less productive and used to help
design interventions to support more effective listening behaviors in all students.

Cluster Analysis
Cluster analysis is a technique used to identify naturally occurring groups that has productively been used to
better understand learner behaviors in a variety of digital spaces. For example, in Barab, Bowdish, and Lawless'
(1997)  work  looking    at the use of   a hypermedia   computer     kiosk, four   types of  user  activity patterns  were
identified: model users (motivated to solve problems, least number of navigation choices, few deviations from
task path), disenchanted volunteers (explored very little, low number of choice, time spent on screens), feature
explorers (feature oriented, many navigation choices, used help screens), and cyber cartographers (goal-directed,
fewer navigation choices but longest time spent on each screen). In their work looking at activity in a learner-
centered  online  distance   education    environment,  del   Valle  &   Duffy    (2007) found    that learners   could  be
characterized as mastery-oriented (high number of sessions, activities and resource use), task-focused (shorter
more concentrated work time but similar amount of activities and resource use), or minimalists (few sessions,
activities and resources spread over a long time). In the current study, cluster analysis is used to look for patterns
in online listening behaviors that constitute different styles of interaction.

Research Questions
     1.  What    are    the  distinctive  approaches   learners   take   in  interacting   with existing    comments     in
         asynchronous online discussion forums?
     2.  What are the characteristics of these approaches with respect to "listening" and "speaking" in online
         discussions?

Methods

Participants
Ninety-six of 113 students enrolled in a blended (face-to-face and online) undergraduate business course on
organizational behavior at a mid-sized Canadian university agreed to participate in this study. Participants were
evenly divided on gender (51% female) with the majority in the first two years of their study (85%) and 22 years
old or younger (94%). Less than a third of participants were native English speakers (28%), which may not be
representative of a typical western university classroom. Final grade distribution for the class was typical for the
university with a mean in the B range.

Learning Environment and Discussion Task
The face-to-face component of the course consisted of a two-hour weekly whole class lecture and one of five
one-hour  weekly    tutorial sessions    conducted in  groups   of 20-23    students.  For the  online  component,    each
tutorial was split into two sub-groups to participate in three asynchronous discussions worth 9% of their grade.
Discussions   were    a week  long  and  ran Saturday  to Friday.   In the  first  week, all sub-groups  took    part in an
ungraded "Introductions" discussion. For the next six weeks, the two sub-groups alternated discussion weeks
(one   sub-group participated   in  discussions one,   three, and  five, the other   in  discussions   two, four, and  six)
though all discussions were available to both sub-groups throughout the six week period. Discussions took place
in Phorum,    a basic    asynchronous    threaded  discussion  forum.    In each   discussion,  students    were  asked  to
collectively  solve   an  authentic organizational   behaviour    challenge.  Students   were   required    to be actively
involved in the discussions: contribute more than once and make comments to progress the group's discussion.
One student was chosen in tutorial at the end of each assignment to summarize the challenge and solution orally.

Data Extraction and Processing
Participants' click   stream  data  was  collected based  on   their activity   in the  discussion forum.   Every  time   a
student clicked to read, create, or edit a post in the discussion forum, a data entry was created logging the action
taken, the identity and length of the post, and a time stamp. Data was collected from the all the organizational
behavior challenge discussions; data was collected for the Introductions forum only if it was generated after the
challenges were in progress. Extracted data was filtered by participants' user ID. Actions were coded as either
"views" (opening others' posts), "posts" (creating posts), "reviews" (revisiting one's own posts later), or "edits"
(making  changes    to  one's previously   submitted   posts). Time    between    subsequent  actions  was   subtracted  to
calculate the action duration. Views were then further categorized as either scans or reads based on the speed
with which the post was viewed. A threshold of 6.5 words per second (wps, calculated as the ratio of the time
spent viewing a post to the word length of the post viewed), was used based on a maximum reading speed of
6.39 wps for online messages found by Hewitt, Brett, and Peters (2007). Only views that fell below this speed
were categorized as reads, other views were categorized as scans.

© ISLS                                                                                                                   89
CSCL 2011 Proceedings                                                                              Volume I: Long Papers

         Because users did not have to formally log-out of the system, action length needed to be manually
divided into sessions of use (e.g. if a learner reads a post today and then another one tomorrow, the length of the
first read action would be calculated as over 12 hours).    Following the precedent set by del Valle and Duffy
(2007), we determined a maximum threshold of allowed action length. Frequency tables showed that 88.8% of
all actions and 96.9% of post actions (typically longer and less likely to be abandoned in progress) took 60
minutes or less, with a sharp drop in frequency after this point. Thus 60 minutes was taken to be the maximum
allowed action length. Actions exceeding this were determined to be the end of a session and their calculated
duration was replaced with an average for the action, taking into account the length of the post read or created
and the mean reading or posting speed for that learner.

Variables
Seven variables were judged as best representing the different facets of students' interactions in the discussions.
These  variables reflect  how   students chose to visit the discussions,  the breadth    and depth of  listening they
engaged in while there, their level of speaking in the discussion and the degree of integration with their listening
behaviors, and finally the degree to which they attended to their own voice in the forum. In addition to the
variables used in the cluster analysis, six other variables were used to further investigate the behavior of cluster
members and characterize the differences (and similarities) between clusters.

Cluster Analysis Variables
Average Length of Session served as a measure of the degree to which students spent continuous periods of
time in the discussion. It was calculated as the total time (in minutes) the student spent in the system divided by
the number of sessions in which the student used the tool.
         Percent  of   Posts Viewed   at  Least  Once   served as  a measure   of the breadth  with which   learners
listened to others in the discussion. It was calculated as the number of unique posts (made by others) that a
student opened divided by the total number of posts made by their classmates to the discussion forum.
         Percent of Total Views that were Reads (Not Scans) served as an initial measure of the depth with
which learners listened to others in the discussion. It was calculated as the number of views of others' posts that
were read at a rate higher than 6.5 words per second divided by the total number of views made.
         Average Length of Time Reading a Post served as a further measure of the depth with which learners
listened to others in the discussion. It was calculated based on posts read (not scanned) as the total time others'
posts were open in minutes, divided by the number of reads.
         Average      Number  of Posts   Contributed  per   Assignment    served  as a   measure of the  quantity  of
student's speaking. It was calculated as the total number of posts made divided by the number of assignments.
         Percent  of   Sessions  with Posting   Actions  served   as a measure    of the  degree to which   students
integrated their listening and speaking behaviors. It was calculated as the number of sessions in which a post
was made divided by the total number of sessions a student had.
         Average Number of Reviews per Assignment served as a measure of the degree to which learners
listened to their own speaking. It was calculated as the total number of times a learner opened their own posts
(not immediately following their creation) divided by the number of assignments.

Additional Comparison Variables
Average   Number       of Sessions per   Assignment     served as  a   measure of    the degree  to which   learners
concentrated or distributed their visits to the discussion forums. It was calculated as the total number of sessions
divided by the number of assignments.
         Average      Number  of Views   per Assignment     served as  an additional  measure   of the breadth   with
which learners listened to others in the discussion. Calculated as total number of posts (written by others) that
were opened divided by the number of assignments.
         Average      Number  of Reads    before  Contributing  a  Post   served  as an  additional measure  of   the
integration of listening and speaking behaviors. It was calculated as the total number of others' posts read before
making a post in a given session divided by the number of posts made.
         Average Number of Words per Post served as a measure of the quantity of speaking a student did in
a discussion. It was calculated as the total number of words posted divided by the total number of posts created.
         Average      Length of Time  Creating   a Post  served as   a measure  of   the care learners put into  their
speaking within the discussion forum. It was calculated as the total time the Creating a New Post window was
open in minutes divided by the total number of posts created.
         Final Grade served as a measure of the overall level of performance in the course. It was calculated by
the instructor based on the discussion assignment, in-class quizzes, and a midterm and final exam.

© ISLS                                                                                                             90
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

Cluster Analysis
There are no rules-of-thumb about the sample size necessary for cluster analysis, since this depends on how
participants are distributed across the variable space. In linear regression, a standard guideline is a ratio of 10-20
cases per variable; however, cluster analyses have been successful with ratios as low as 7.4 (del Valle & Duffy,
2007).  One of the 96 cases was removed from analysis because it appeared as an outlier on multiple measures.
Thus, in this study, cluster analysis was used to group 95 learners based on seven variables, producing a ratio of
13.6 cases per variable, well within acceptable limits.
          To examine within-subject activity profiles, Ward's (1963) hierarchical clustering technique and the
square Euclidean distance model were used to determine the distance between clusters. All scores in the cluster
analysis  were  standardized   to account for  the  differing  scales or measurement.   Following    the procedures    of
Barab et al. (1997), a scree plot was created to evaluate the between-cluster differences. Visual examination was
used to determine the point at which the plot leveled off, indicating that a clustering solution after this point
would   not   have meaningful     differences between   the   additional groups.  A    series of ANOVAs      examining
between-group    differences  were  conducted   to  confirm   that a  quality solution was    obtained. Tukey   post-hoc
comparisons with a Bonferroni correction of the alpha level were used to detect significant differences between
the clusters. ANOVA and post-hoc analyses were also performed on the additional six variables of interest.

Results

Descriptive Statistics
In total the 95 participants performed 17,695 actions in the system with an average of 186 (SD=127) actions per
learner. Each learner engaged with the discussion on average 22 (SD=16) times (sessions) or about eight times
for each discussion. For each discussion, learners viewed an average of 53 (SD=37) posts and created 2.2 of
their own (SD=.95). Posts averaged 192 words (SD=74) and overall 51% of viewed posts were actually read
(not   scanned) (SD=13%).     Of  the  almost  three  hours   (171   minutes,  SD=136)   that  learners  spent   in   each
discussion, on average, 73% (125 minutes, SD=113) were spent in listening activities. Of the remaining time,
18% (30 minutes; SD=21) was spent creating posts and 6% (10 minutes; SD=20) was spent on reviewing their
own    posts. The  remaining   3%   was   attributed to automatic     system-generated   actions.   The  high   standard
deviations indicate great variety in the degree to which individuals interacted with the discussion forum further
indicating the need for the more fine-grained analysis of individual behavior that follows.

Cluster Analysis
The scree plot for the data showed leveling between clusters 3 and 4 (see Figure 1), suggesting that a three
cluster solution is the best fit for this data. Data was resorted and analysis repeated to test the robustness of the
solution;  cluster membership     did not change.   ANOVAs      examining     showed   significant  differences between
clusters on six of the seven grouping variables, confirming a quality solution. There was no discernible pattern
of  alignment  between   clusters and  discussion   groups, all discussion    groups had members     from  at   least two
different clusters and eight of the ten discussion groups had members from all three clusters. The characteristics
of each of the three clusters are described in detail below and summarized in Table 1. Clusters whose levels of a
variable could not be distinguished from each other in the post-hoc tests share one or more subsets in common;
clusters which had significantly different levels for a variable have no subsets in common.

                                    Figure 1. Scree Plot for the Cluster Analysis.

Cluster 1: Superficial Listeners, Intermittent Talkers
The first cluster accounted for 31% of the participants (n=29). In contrast to the other clusters, these learners had
a short average session length (14 min), viewed only a moderate amount of their classmates' posts (on average
65%), read (as opposed to scanned) less than 50% of these, and spent an average of just 3 minutes per post on
the  posts they did   read. Looking   at the  short length  of both   sessions and post  reads,  these  learners can   be
characterized   as Superficial Listeners.  Learners  in Cluster    1  created an average  of   less than two    posts per

© ISLS                                                                                                                  91
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

assignment   and  performed    infrequent reviews     of these. While    both the number   of  posts made    and  reviews
conducted were significantly less than Cluster 3, the percent of sessions in which they made posts did not differ
significantly. Thus   a  large percentage    of Cluster  1 members'    sessions   (almost  80%)  were  "listening   only"
sessions. This repeated listening only behaviour, in combination with the low number of posts made, suggests
that the members of this cluster can be characterized as Intermittent Talkers.

Table 1: Results of cluster analysis and between cluster comparisons.

                                                      Cluster 1            Cluster 2            Cluster 3           F
                                                   Superficial         Concentrated             Broad             (2,92)
                                                   Listeners,              Listeners,          Listeners,
                                                  Intermittent           Integrated            Reflective
                                                      Talkers              Talkers              Talkers
                                                      n = 29                n = 47              n = 19
Average Length Of Session           Subset 1Subset 213.92 (5.37)         30.02 (9.13)         26.94 (8.48)       37.15*
Percent  of  Posts    Viewed   at   Subset 1Least OnceSubset 20.65 (0.20)0.52 (0.20)          0.96 (0.06)        39.82*
Percent of Total Views thatwere Reads (not Scans)  0.45 (0.14)           0.54 (0.13)          0.51 (0.08)         4.67
Average     Length    of   Time     Subset 1Reading a PostSubset 23.15 (1.38)5.18 (2.26)      4.63 (1.77)4.63 (1.77)9.98*
Average     Number     of  Posts    Subset 1Contributed per AssignmentSubset 21.69 (0.65)2.18 (0.98)3.04 (0.68)  14.88*
Percent   of   Sessions     with    Subset 1Posting ActionsSubset 20.23 (0.11)0.40 (0.16)     0.18 (0.06)        25.84*
Average Number of Reviews           Subset 1per AssignmentSubset 22.09 (1.64)2.09 (1.95)      10.16 (7.22)       38.29*
* p < .0038 (.05/13)

Cluster 2: Concentrated Listeners, Integrated Talkers
The second cluster consisted of the largest number of learners, 49% of all participants (n=47). Learners in this
cluster were Concentrated Listeners; they attended to a smaller percentage of their classmate's posts (52%) than
members of Cluster 3 (Broad Listeners), but for the posts they did read they spent significantly longer (5.18 min
on average) than members of Cluster 1 (Superficial Listeners). In addition, their average session length was 30
min,   equivalent to  that of  Cluster 3 (Broad   Listeners)  and  significantly  greater than  the 14 min   average   for
Cluster 1 (Superficial Listeners). Cluster 2 members were also distinct in the significantly higher proportion of
sessions in which they contributed to the discussion (40%). This implies that more of their listening activities
occurred in sessions in which they also posted and that they had fewer "listening only" sessions. In this sense
they   were  Integrated  Talkers,  integrating  their posting   with their listening  more than  members     of the other
clusters. While integrated in their talking, Cluster 2 learners were not prolific, contributing an average of just
over two posts per assignment, equivalent to the contribution rate for the Cluster 1 (Intermittent Talkers) and
significantly less than the rate for Cluster 3 (Reflective Talkers).

Cluster 3: Broad Listeners, Reflective Talkers
The final cluster consisted of a small group of learners, making up 20% of the total study sample (n=19). The
most striking characteristic of this cluster is the extremely large proportion of the discussion that they listened to
in some way. On average members of this cluster viewed 96% of all the posts contributed by their groupmates at
least  once. This is  substantially more  than   the  52-65%    of unique  posts  viewed  by  learners in  the  other two
clusters. Cluster 3 learners enacted their participation in sessions that lasted almost a half hour; this is similar to
learners in  Cluster  2   (Concentrated  Listeners),   but almost    double that  of  Cluster 1 (Superficial   Listeners).
Additionally,  a  large  percentage  of  their  sessions (over  80%)   were   "listening  only" sessions  in which    they
viewed   classmates'   posts,  but  did  not contribute   any   of their own.  Thus,   learners in   this cluster can   be
characterizes as Broad Listeners who seemed to put considerable emphasis on listening and interacted in some
way with a high proportion of the discussion comments contributed. Interestingly, these learners did not differ
from the other clusters in how they interacted with the posts once they were open; 51% of the posts that they
viewed were only scanned, and for the posts they did read, the average length of time spent on a post (4.63
minutes) did not differ significantly from either other cluster. Learners in Cluster 3 were also prolific talkers,
contributing a significantly higher number of posts for each assignment than the other clusters. Interestingly,
they also focused considerably on listening to their own voice--on average Cluster 3 learners revisited their

© ISLS                                                                                                                   92
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

own    contributions  ten times  per  assignment,   an average   of  over  three  visits for   each post  made.   This is
significantly greater than the number of reviews by learners in the other clusters and suggests that these learners
may be engaging in some reflective activities. Thus we characterize Cluster 3 members as Reflective Talkers.

Additional Comparisons
Cluster 3 (Broad Listeners) showed significantly higher levels of participation than both other clusters on two of
the six additional variables examined: Average Number of Sessions per Assignment and Average Number of
Views per Assignment (see Table 2). Broad Listeners had almost twice as many sessions as members of Cluster
1  (Superficial Listeners)   and  almost  three  times as many    sessions as  members      of Cluster  2 (Concentrated
Listeners). This indicates that they achieved their increased listening not only through extended sessions (see
earlier results) but also through engaging in a larger number of sessions.        Broad Listeners also had two and a
half times  as  many   total views   as members    of the other  two clusters; this  is  an even  higher  ratio than  the
difference in the percentage of posts they viewed at least once, indicating that another difference between the
clusters is the frequency with which they re-viewed posts.
         The three clusters did not differ significantly on the other four additional variables examined: Average
Number   of  Reads    Before  Creating  a Post,  Average   Number    of  Words   per Post,   Average    Length  of Time
Creating a Post, and Final Grade. The finding that learners in all three clusters read around the same number of
posts (three to seven) before making their own suggests that member of Cluster 3 (Broad Listeners) did not
achieve their additional listening through more extended listen-then-speak chains, but rather through additional
cycles of listen-then-speak and listening-only sessions. As well, the similarity in the average length of posts
(175 ­ 210 words) and time spent creating them (12-16 min) indicates that members of Cluster 3 achieved their
additional speaking through supplemental posts, not through longer or more thought-out ones. Finally, the lack
of significant difference between the clusters for the final course grade indicates that learners with all three
styles performed equally well in the course overall.

Table 2: Results of additional between cluster comparisons.

                                                      Cluster 1           Cluster 2             Cluster 3           F
                                                    Superficial         Concentrated              Broad           (2,92)
                                                      Listeners,          Listeners,            Listeners,
                                                    Intermittent          Integrated            Reflective
                                                       Talkers             Talkers                Talkers
                                                       n = 29              n = 47                 n = 19
Average   Number      of Sessions    Subset 1per AssignmentSubset 27.49 (3.42)4.77 (4.37)      13.56 (5.48)       27.55*
Average Number of Views per          Subset 1AssignmentSubset 244.10 (20.53)35.44 (22.34)      109.19 (29.44)     70.15*
Average     Number     of  Readsbefore Contributing a Post3.60 (2.38)    5.16 (4.48)            7.03 (2.61)        5.17
Average     Number    of   Wordsper Post           207.91 (72.00)     186.99 (83.61)           178.79 (47.66)      1.07
Average     Length     of    TimeCreating a Post   12.61 (8.23)          13.16 (7.33)          15.50 (5.60)        0.97
Final Grade                                        75.77 (6.95)         72.81 (10.97)          78.96 (5.12)        3.38
* p < .0038 (.05/13)

Discussion
The goal of this study was to understand how learners "listen" in online discussions. Three distinct patterns were
identified: Superficial   Listeners,  Intermittent Talkers; Concentrated   Listeners,    Focused    Talkers;  and  Broad
Listeners, Reflective Talkers. Below we contextualize these findings in past research on online interaction styles
and discuss their implications for research and practice.

Comparisons with Past Research, Implications for Future Research
At one   extreme,  Cluster   1 "Superficial Listeners,  Intermittent  Talkers"   had  perfunctory   engagement     in the
online discussions, spending little time listening to others, and talking sporadically. This behavior resembles that
of Barab et al.'s (1997) "Disenchanted Volunteers" who showed little interest in exploring more information
than   necessary. The     Superficial Listeners  also  show    a similar  pattern to    de  Valle   and Duffy`s   (2007)
"Minimalist" cluster who tried to fulfill their course requirements with a minimum of effort. However, contrary
to their context  where    minimalist   learners could  protract  the duration    taken  to  complete   their work,   our

© ISLS                                                                                                                 93
CSCL 2011 Proceedings                                                                                     Volume I: Long Papers

Superficial Listeners were forced to participate within the timeline of a week-long discussion. Thus even though
they divided their participation into an average of seven short sessions per discussion, these were concentrated
within a single week, potentially leading to a more coherent participation experience. Similar to del Valle and
Duffy's finding that minimalists managed to complete their course successfully with no difference in the quality
of their final product, our Superficial Listeners showed an equal level of performance in their course grade with
the other clusters. This may present evidence for a blended context of what del Valle (2006, p116) notes is well
known to practitioners but not often discussed in the literature: "the reality of a number of [distance education]
learners  who  focus   on  course    completion  with   a  low commitment      that results not  in attrition, but  in course
completions with the minimum work possible." It may be that in this case, Superficial Listeners' low level of
interaction with the discussion was enough to develop a sufficient understanding of the ideas being discussed.
Another alternative is that the instructor of the course did not make the content of the discussions forums central
to the course  and    its evaluation.  In  future  research,  we   will work   in a   more  controlled  context  to examine
whether   listening   in  this superficial     way  impacts   what   individuals  learn    from  and   contribute  to  online
discussions. We will also test whether this stems from a work-avoidance approach to their online discussions
and if so, examine their motivations for this.
          Cluster 2,  "Concentrated       Listeners, Integrated   Talkers"   interacted  with the   discussion  forum   for a
similar amount of time overall as the Superficial Listeners, but with longer sessions than this group and fewer
session than the Broad Listeners. Thus, their participation was condensed, focusing on listening to particular
parts  of the  conversation    in a  limited   number   of extended  sessions.    del Valle   &  Duffy  (2007)  characterize
similar behaviors seen in their learners as "task-oriented" ­ focused on fulfilling requirements expeditiously.
However while their task-focused learners used a similar number of learning resources to their mastery learners,
our Concentrated Listeners listened to fewer comments from their peers than the Broad Listeners. Interestingly,
similar to our results, del Valle & Duffy found that their task-focused learners performed as well on the final
performance measure for the course as learners in the mastery cluster and Barab et al. (1997) refer to learners
with   performance    oriented  behaviors    as "model    users." This  suggests    that a task-focused  orientation   is  not
necessarily a bad thing; future research is needed to determine whether the concentration of participation and
number of messages listened to impacts individual learning in a discussion or the quality of comments made.
          Finally, Cluster 3, "Broad Listeners, Reflective Talkers" were high volume participants who spent the
most time in the system, with a large numbers of sessions and listening events per assignment, as well as posts
and reviews. Compared with the clusters found by del Valle & Duffy (2007), these learners seem quite similar
to their "mastery-oriented" group (high amount of sessions, time, and learning resources used). However, they
differed from Barab et al.'s (1997) mastery group (called "cyber cartographers") who spent more time on fewer
navigation choices. Our learners showed increased breath of participation (rather than depth); they viewed many
more   posts, but spent   a similar   time  to  the  other clusters  interacting  with   each post. These   findings   can be
interpreted in several ways. First, it is possible that in this context of a discussion composed of relatively short
messages (192 words on average) the time they spent per message (just under five minutes) was sufficient for
deep engagement; thus breadth of engagement is a more important measure of listening quality. Second, it is
possible  that even   learners    in this "mastery"   cluster  are  not engaging    with   posts at a  very deep   level  and
interventions to support this process are needed. Finally, it is possible that they engaged deeply with some posts
but not others and this behavior was not revealed by the average time. In addition, similar to learners in the other
clusters, Broad   Listeners    scanned    50%   of  the posts  they  viewed,   suggesting   that this  may  be   a  useful  or
necessary strategy to manage participation in a many-message forum. Future research is needed to understand
the motivations   behind    these    listening behaviors.  Additional   work   is also   needed  to examine    the  reflective
talking behavior observed for this cluster: why are these learners repeatedly returning to their own posts, is this
supportive of their learning, and how might such behaviors be encouraged in other learners?

Implications for Practice
Because this line of research is still in an early stage, it would be premature to present strong prescriptions for
practice. However, the results of this study do suggest several potential ways to support productive listening
behaviors that can be explored with design-based research. First, because Superficial Listeners tend to distribute
their participation in multiple short sessions, keeping discussions somewhat compact in duration (e.g. one to two
weeks) may help to concentrate their involvement and lead to more coherent participation. Second, because the
increased listening observed for Broad Listeners was due to a greater number (not length) of interactions with
the tool  and  individual   posts,   designing  conversations   that encourage    or  require learners  to  engage  multiple
discrete times may encourage more extensive listening behaviors. One way we have started to explore this is by
requiring  posts  at  discrete  times  during    the discussion   week   (e.g. Monday/Tuesday,       Wednesday/Thursday,
Friday/Saturday),    though    there  are certainly  other  strategies  that can  be  used.   Finally, the  high  number    of
delayed reviews seen for Cluster 3 (Reflective Talkers) suggests that reflective visitation of one's own posts can
be explored as a tool for supporting metacognition and synthesis of learning in online discussions.

© ISLS                                                                                                                      94
CSCL 2011 Proceedings                                                                                       Volume I: Long Papers

Conclusion
Past research on online discussions has focused primarily on contributions to online discussions. However, a
conceptual   model    of online  discussions   as  conversations     also  necessitates     attention  to   learners'  listening
behaviors.   This study  showed    that listening  represents  a  very    large proportion    of the  time  learners   spend in
online  discussions   (almost three  quarters  of  their time  in this  case).  Similar    to research  on  lurkers   in online
communities (Nonnecke & Preece, 2000) this reinforces the prevalence of often invisible forms of participation
and highlights the importance of investigating these behaviors using methodologies such as the click-stream
approach employed here. In addition, listening is a substantial and important component of online discussions
that can potentially be targeted for design (e.g. via scripting, see Fischer et al., 2007). This study identified three
distinct styles through which learners interacted with online discussions to listen to their peers. While similar to
mastery,   task  and  minimalist   approaches   found    for   other contexts   (del   Valle  &   Duffy,    2007),  this study
pinpointed   the  specific listening (and  speaking)  behaviors      that make   up   such  styles  in  the context   of online
discussions.  Future   work  can   investigate the   stability of these   styles    across different   learners and   contexts,
examine their relationship to discussion quality and learning, explore techniques for early detection of particular
styles and research design-based interventions to support productive interactions in online discussions.

References
Arvaja,  M.   (2007).  Contextual   perspective   in analysing    collaborative     knowledge    construction   of  two   small
         groups in web-based discussion. International Journal of Computer-Supported Collaborative Learning,
         2(2-3), 133-158.
Barab, S. A., Bowdish, B. E., & Lawless, K.A. (1997). Hypermedia navigation: Profiles of hypermedia users.
         Educational Technology Research and Development, 45(3), 23-41.
Barab,  S.   A., Kling,  R., &  Gray,   J. H. (2004).  (Eds.).   Designing      for virtual communities     in  the service  of
         learning. Cambridge, UK: Cambridge University Press.
Boulos, M. N., & Wheeler, S. (2007). The emerging web 2.0 social software: An enabling suite of sociable
         technologies in health and health care education. Health Information and Libraries Journal, 24, 2-23.
del Valle    (2006).  Online    learning:  Learner   characteristics    and     their approaches     to managing       learning.
         (Unpublished doctoral dissertation). Indiana University, Bloomington Indiana.
del Valle, R., & Duffy, T. M. (2007). Online learning: Learner characteristics and their approaches to managing
         learning. Instructional Science, 37(2), 129-149.
De  Wever,    B., Schellens,   T., Valcke,    M., &  Van     Keer,   H.   (2006).   Content   analysis  schemes     to analyze
         transcripts of online asynchronous discussion groups: A review. Computers & Education, 46(1), 6-28.
Fischer, F., Kollar, I., Mandl, H., & Haake, J. (Eds.). (2007). Scripting computer-supported communication of
         knowledge. Cognitive, computational, and educational perspectives. New York, NY: Springer.
Herring, S. (1999). Interactional coherence in CMC. Journal of Computer-Mediated Communication, 4(4).
Hewitt, J. (2003). How habitual online practices affect the development of asynchronous discussion threads.
         Journal of Educational Computing Research, 28(1), 31-45.
Hewitt, J. (2005).    Toward an understanding of how threads die in asynchronous computer conferences. Journal
         of the Learning Sciences, 14(4), 567-589.
Hewitt,  J., Brett, C.,  & Peters, V.   (2007). Scan  rate:    A new    metric  for   the  analysis of  reading  behaviors   in
         asynchronous computer conferencing environments. American Journal of Distance Education, 21(4),
         215-231.
Kear, K. (2001). Following the thread in computer conferences. Computers and Education, 37(1), 81-99.
Luppicini,   R.  (2007).   Review  of   computer   mediated    communication        research   for  education.   Instructional
         Science, 35(2), 141-185.
Nonnecke, B., & Preece, J. (2000). Lurker demographics: Counting the silent. Proceedings of CHI 2000. The
         Hague: ACM Press.
Stahl, G. (2003). Building collaborative knowing: Elements of a social theory of learning. In J. W. Strijbos, P.
         Kirschner    &  R.  L. Martens    (Eds.), What   we    know    about   CSCL    in  higher   education   (pp.  53-85).
         Amsterdam, NL: Kluwer.
Suthers, D. (2006) Technology affordances for intersubjective meaning making: A research agenda for CSCL.
         International Journal of Computer-Supported Collaborative Learning, 1(3), 315-337.
Thomas, M. J. W. (2002). Learning within incoherent structures: the space of online discussion forums. Journal
         of Computer Assisted Learning, 18, 351-366.
Ward, J. H. (1963). Hierarchical grouping to optimize an objective function. Journal of the American Statistical
         Association, 58(301), 236-244.

Acknowledgments
This work was supported by the Social Sciences and Humanities Council of Canada.

© ISLS                                                                                                                       95
