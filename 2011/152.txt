CSCL 2011 Proceedings                                                                                   Volume I: Long Papers

                                Digital Media in the Classroom:
A Study on How to Improve Guidance for Successful Collaboration
                                and Learning in Student Teams
Carmen Zahn, Karsten Krauskopf, Friedrich W. Hesse, Knowledge Media Research Center, Konrad-Adenauer-
                                       Strasse 40, 72072 Tuebingen, Germany,
               Email: c.zahn@iwm-kmrc.de, k.krauskopf@iwm-kmrc.de, f.hesse@iwm-kmrc.de
    Roy Pea, Stanford Center for Innovations in Learning (SCIL), Stanford, CA, USA, roypea@stanford.edu

         Abstract: Digital video technologies provide a variety of functions to support collaborative
         knowledge construction. Yet, for novice learners, positive outcomes also depend on effective
         guidance of group interactions. In this paper, we present empirical evidence for the use of
         web-based     video tools  to support    students'  collaborative learning  in  a history   class. In an
         experiment with 16-year old learners (N=148) working with a history topic, we compared two
         contrasting   types   of guidance    for   student  collaboration  in  dyads   (cognitive   task-related
         guidance or social interaction-related guidance). We also compared two types of video tools.
         Both  types   of guidance   and    tools were   aimed  at  supporting   students'  active,   meaningful
         learning and critical reflection. Results indicate that social interaction-related guidance was
         more effective in terms of learning outcome (e.g., critical reflection skills) than cognitive task-
         related guidance.   The    different tools  did not  yield significant  differences   in learning.  The
         practical implications of these results are discussed.

Introduction
Computational    technology    and  digital media    can greatly   enhance   the   possibilities for  creative knowledge
construction  in social  learning   situations. However,     there are open    questions related   to guidance   of group
interactions in desirable directions, especially when novice learners face complex authentic learning tasks: For
example, a major concern expressed from the instructional perspective is how instructive guidance should be
designed in accordance with human cognitive functioning (e.g., Kirschner & Sweller, 2006). In addition, CSCL
research has emphasized the necessity of considering the complex relations between tasks, tools, interaction
processes and learning outcomes (e.g., Van Drie, Van Boxtel, Erkens, & Kanselaar, 2003). In our contribution,
we  tap  into these   issues by   examining     the example    of  digital video   technologies   used  for  collaborative
knowledge construction in a classroom setting. Specifically, we investigate in an experiment how instructive
guidance  can  be     balanced  for middle-school     students  in  order   to support   skill-intensive    socio-cognitive
processes during a short collaborative design task for history learning with different digital video tools.
         The potential of digital video technologies reaches far beyond the dynamic presentation and illustration
of visual information. With digital video tools, learners may zoom into and out of digital video sequences, they
may insert hyperlinks into videos in order to relate visual information to other instructional materials, and they
may arrange video sequences for discussion and reflection. Such functions are expected to afford, for example,
detailed observations    (e.g., Smith   &   Reiser,  2005),   multiple  perspectives    (e.g.,   Goldman,   2004)   or  the
understanding  of  complex     concepts in    ill-structured domains   (Spiro,  Collins, &  Ramchandran,       2007).  The
affordances of digital video technologies can be restructured for youthful learners in classrooms, so that students
can either create their own representations (e.g., multimedia documents) or arrange video contents in order to
understand and explain complex subject matter (Zahn, Pea, et al., 2005). This usage, in the sense of learning
through design (e.g., Kafai & Resnick, 1996), goes far beyond teacher-centered approaches where videos on
curriculum topics are only watched by individual learners or in whole-class models.
         Over the last several years, we have investigated collaborative design with video tools. Evidence from
our experimental studies has indicated that specific affordances of video tools (e.g., of WebDIVERTM, Pea, et al.
2004), when employed in design tasks for history learning, can support learners' social interactions to become
more   productive than    those performed     with  simple   technological  solutions,  resulting  in improved    learning
outcomes (e.g., Zahn, Pea, Hesse & Rosen, 2010). Yet, initial field studies with 16-year-old students (Zahn,
Krauskopf, Hesse, & Pea, 2010) showed that the positive effects of video tools were sometimes limited to an
"action-level", and students would have needed more guidance to optimize their collaborative design process.
This finding is consistent with findings from Barron (2003) showing that student groups can have problems
engaging in productive knowledge-building conversations during video-based mathematics problem solving. It
is also consistent with related evidence showing that collaborating students need help in organizing, planning
and conducting    scientific inquiries  (Edelson,   Gordin,   &   Pea, 1999),   in scientific  argumentation    (Kollar &
Fischer, 2004) and in accomplishing scientific design projects (Kolodner, et al. 2003).
         Two   sources   of  problems   can   hinder productive    socio-cognitive  processes    when  students   perform
design tasks with digital video tools: The complexity of collaboration with video tools and the complexity of

© ISLS                                                                                                                  152
CSCL 2011 Proceedings                                                                                    Volume I: Long Papers

collaborative   design.   We    have   demonstrated     in prior   research   how   specific video    tools  can   influence
collaborative learning (e.g., Zahn, Pea, Hesse & Rosen, 2010). In the present study, we take into account their
differential complexity (Zahn, Pea et al. 2005) when they are used as design tools for learning. Design tasks
generally   consist of   creating  and   structuring content   for an  anticipated  audience  according    to  the aesthetic
standards of the media at hand. They include the setting of design goals and complex processes of knowledge
transformation, as was proposed earlier by related cognitive research (e.g., Bereiter & Scardamalia, 1987, Goel
& Pirolli, 1992; Hayes, 1996). According to Détienne (2006) collaborative design includes the management of
task interdependencies and of multiple perspectives. Correspondingly, design activities relate to the levels of the
design problem/design solution and group cooperation. Moreover, when designers use complex and sometimes
unfamiliar digital tools (video tools in our case), they coordinate their collaboration by establishing a social
problem space that is distributed over the cognitive systems of at least two people and a digital artifact, creating
new coordination problems familiar in distributed cognitive systems (Streek et al., 2011). Based on this shared
context, they negotiate their choices of design goals and their understanding of content, task schemas, genre
knowledge, and task relevant strategies (as in collaborative writing, e.g., Lowry, Curtis, and Lowry, 2004). The
importance of the shared (multimodal) context for design was repeatedly emphasized (Détienne, 2006).
          Consequently,     although   designing  video    or other artifacts  with digital  tools is highly   desirable   for
students, because     it is cognitively   engaging,  students    may   sometimes    be cognitively    overwhelmed      by  the
complexity   of  having   to  find  a design   solution, manage    the group    and use an  unfamiliar  digital  tool.    They
actually may need guidance throughout the process so that learning through design can take place. Based on
previous  research    on  the nature  of  design (e.g.,  Détienne,  2006),  we   might  provide    such guidance,     tackling
either cognitive design task-related issues or social interaction-related issues (similar to Fischer et al.'s (2002)
distinction of   content-specific     and content-unspecific     instructional  support  or  Weinberger     et al.'s   (2005)
epistemic vs. social scripts). It is still open whether guiding students' design activities or their social interactions
would lend important support for successful task completion - or whether students might feel restricted by too
much guidance and be impeded in their creativity and learning. Also, the mediating role of the digital video
tools for collaboration under such conditions is quite unclear. Hence, in our study, we compared the two forms
of guidance using two types of video tools, and we explored whether interactions would occur.

Experimental Study

Method
Participants: 148 students (81 male, 65 female, 2 no answer) from four different German high schools located
in Southwestern Germany participated in the study. Their mean age was M = 16.2 years (SD = 1.0). Prior to the
study we obtained written consent from the students' parents and the school administration. The sample size
varies minimally (see Tables 1 to 3), due to problems with data availability from stored design products and
video taped interactions.
          Study  design:    The   study  was   conducted   in  a computer   classroom   set  up at  our    institute. Classes
accompanied by their respective teachers came to the institute on regular school days and as part of their regular
history curriculum.      Upon  arrival  they were    randomly    grouped   into dyads   and  assigned   to one  of    the four
experimental conditions of a 2 x 2 study plan. The first factor Guidance (cognitive design-related vs. social
interaction-related) determined which type of instructive guidance was provided to support the collaborative
accomplishment of a visual design task: guidance either emphasizing the cognitive aspects of the design task
(e.g., setting a design     goal, planning   a design concept,    tailoring information  for  an   audience),  or  guidance
focusing on smooth collaboration (e.g., developing common ground about design goals, and design decisions,
determining communication rules for discourse practice). The second factor Video Tool determined whether the
students worked with WebDIVERTM (Pea, et al., 2004) or Asterpix as their design tool: The tools differed on a
generic level in either supporting collaborative analysis (WebDIVER tool for guided noticing) or collaborative
linking of information (Hypervideo tool Asterpix). With WebDIVER, learners' cognitive/collaborative analysis
is heightened    by   their ability to  zoom   into  and   out of  digital video  sequences,  and   arrange    digital video
sequences for discussion and reflection. With the Hypervideo tool Asterpix, the collaborative ability to insert
new knowledge artifacts into an existing digital video is heightened by hyperlinks relating visual information to
other materials. All other circumstances were kept constant across conditions.
          Task: A visual design task based on a historical newsreel was employed. This task had been carefully
developed for the purpose of studying computer supported history learning with digital video tools in a realistic
classroom (e.g., Zahn, Krauskopf, Hesse & Pea, 2010). It follows central educational goals in the domain of
history  in German       middle   school  education  (Krammer,     2006).   Furthermore,  it is theoretically   founded     in
cognitive   and  collaborative    frameworks     of  advanced    learning   and  knowledge    building   approaches       (e.g.,
Scardamalia, 2002). During this task, students work on a newsreel about the Berlin blockade in 1948, so that it
can be published, e.g., on a website of a virtual history museum. They are asked to analyze and comment on the
newsreel so that future visitors of the virtual museum can develop a good understanding of both the content and

© ISLS                                                                                                                     153
CSCL 2011 Proceedings                                                                                   Volume I: Long Papers

the style   of the  newsreel    as   a propaganda     instrument.     To accomplish  the   task, the students    can  use  a
collaborative video tool (see Tools section). The constructive activity of designing content for a web page of a
virtual history museum provides learners with a framework for comparison and re-organization of knowledge,
as they produce their own ideas and work creatively with them. During the collaborative design process, it is
assumed   that  learners  appropriate   the   video  content  to  their  own  thinking  purposes   and develop     advanced
thinking skills. The learning goal and a special challenge for the students is to understand that the newsreel is
not only "showing" the history topic (Berlin 1948), but that the newsreel itself is a history topic (i.e., a newsreel
as an historical means for propaganda). In other words, historical content knowledge is closely intertwined with
developing advanced thinking skills (Scardamalia, 2002), like being able to analyze and critically reflect on
video messages.
         Materials and Tools: The video used in the visual design task is a digitized version of an historical
newsreel originally produced by the Allied forces (US/Great Britain) and shown to the German public during
the Berlin blockade in 1948. It covers news information about the airlift established in 1948 by the Allied forces
when Russia tried to cut off Berlin from traffic of goods. It consists of 95 single pictures and lasts five minutes.
The  video  used   in the   transfer task  is a  modern   65-second    TV-Clip   by the German     Green Party   (Buendnis
90/Die Gruenen) from the 2006 nationwide election in Germany. The texts used in the experiment contain 350-
1500 words each. The content of the texts provides detailed information on three sub-topics: accounts of the
historical context of Berlin in post-war Germany, information on media history and newsreels in post-World
War II Germany, and a short introduction on film theory. Guidance was implemented in text-based form within
the computer    environment     used   for general   task instruction.   The texts  differed between   conditions    in their
descriptions   of how    one  should   best   proceed to   solve    a visual design  problem.    The video    tool used   for
computer-supported learning in the visual design task was either WebDIVER (see Figure 1a) or Asterpix (see
Figure   1b).   WebDIVER         is    one    of  the   software      programs    developed   in   the   DIVER       Project
(http://diver.stanford.edu) at Stanford University. It is based on the metaphor of enabling a user to "dive" into
videos  for expressing    points of    view   regarding   precise spatio-temporal   video  areas  of one or   more    source
videos. Asterpix is a commercially available hypervideo tool. It is based on the idea of enabling users to select
areas of interest and place graphical hyperlinks into a source video.

Figures  1  a  and b.  Graphical   user   interfaces of   the collaborative  (hyper-)video   tools used  in the    study: (a)
WebDIVERTM (right), (b) Asterpix (left).

         With   the   functions offered    by WebDIVER,       users   can select either a temporal   segment   or  a spatio-
temporal   sub-region    of a video    by  mouse-controlling      a rectangular  selection frame   (acting  like   a camera
viewfinder) to "pan" and/or "zoom" into view only that subpart of a video that they wish to feature, and then
interpretively annotating their selection via a web interface. Each dive movie clip and its associated annotations
is represented in a panel in the dive, and a remix of the video clips and annotations can be played to experience
the dive. Asterpix was a Web 2.0 tool (http://www.asterpix.com/, no longer available) with functions based on
the hypervideo     idea: Users   could    isolate dynamic,    sensitive   regions  within  video   materials, provide     text
commentaries to these regions and add links to other web resources. The links could further be discussed by
means of an integrated e-communication tool. Thus, users could include their own annotations and knowledge
in a video and share them with others in a group or community (cf. Zahn et al., 2005).
         Procedure: A week before the students came to our lab, they filled in questionnaires that assessed their
prior knowledge and other control variables. The experimental sessions consisted of the following steps: In Step
1 (preparation phase), the students individually read the overall instructions, including the different types of
guidance (either guidance for effective design or guidance for effective social interactions during design). Then
they read the history/media texts, and watched the video showing the historical Berlin-Blockade newsreel from
1948. They briefly practiced the use of the video tools to establish familiarity. In Steps 2, 3 and 4 (collaborative

© ISLS                                                                                                                    154
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

design and learning phase) the participants worked collaboratively in dyads at a computer. In Step 2 (planning),
those  students  in   dyads in the social  interaction-related  guidance   condition  were  asked    to  write down    the
content they would like to cover in their design products and how they would like to coordinate their design
work. Those students in dyads in the cognitive design-related guidance condition were asked which design goals
they would aim for. In Step 3, the dyads were asked to design their product according to their initial ideas using
either WebDIVER or Asterpix. In Step 4 (evaluation) the dyads were asked to evaluate the quality of their own
products and teamwork. When students were done, they continued with Steps 5 and 6 (test phase), where self-
assessment   questionnaires    and knowledge      tests were   completed   individually. In Step     7,  the participants
individually accomplished a transfer task (TV-ad, see Materials section). They were then thanked and released
and went back to their schools with their teachers. During the whole procedure, the teachers were present and
tutors were also available for any questions or technology problems.
         Measures:     To assess prior   background     knowledge  in the  domain of  history,  computer     expertise or
expertise in film and media production, a pre-questionnaire (self-assessment) and a multiple choice knowledge
test were administered. To assess the effectiveness of our text-based instruction as implementation of guidance
(manipulation check), we asked the subjects to select a maximum of three alternatives from six statements about
the task's characteristics (3 social characteristics, e.g., "one of the most important aspects of the learning unit
was good communication" and 3 design characteristics, e.g., "one of the most important aspects of the learning
unit was  to design   for a target audience").    To assess  collaborative design performance,    the   design  products
created by the dyads with WebDIVER or Asterpix were analyzed. From these products, the following categories
of data  were obtained:     "video selections/sensitive   areas with  comments",   "style  features  commented",     and
"interpretations" in the comments. Additionally, dyadic interactions were captured with a webcam and a screen
recorder (Camtasia Studio by TechSmith). The proportions of talking time in the categories "design planning",
"design action", "design evaluation", "technical issues", "problems", and "off task" (related to total amount of
talking time) were    extracted from  these video    data using  video  analysis software  (Videograph©).      To assess
treatment  effects  on  learning outcomes,   a  post-test   was  administered, consisting   of  a multiple   choice   test
measuring historical topic knowledge and a transfer task tapping advanced visual analytic skills. The multiple
choice post-test consisted of 8 items. (Sample item: "At the beginning of 1946 Germany is... a) ...a unified
nation, b) ...divided  into four sectors, c)... divided   into an  Eastern and a Western    part, d) ...divided  into  16
Länder." The theoretical maximum of this test was 13 points, and it had a satisfactory internal consistency,
Cronbach's  = .71. The transfer task part of the post-test was assigned to reveal skills of critical analysis and
reflection in response to a video message. It consisted of two questions relating to a political TV-ad from the
2006 nationwide German government elections. ("Please analyse the following video sequence by answering
the questions 1) Which film techniques were used? 2) What might have been the intention of using them?"). The
questions were open ended.

Results
We will first present results substantiating the comparability of our conditions, and then results obtained from
quantitative analyses of the design products and post-tests. Due to assumed interdependence of students working
in one dyad, we determined dyads as the unit of analysis and used data aggregated within dyads (cf. Kenny,
Kashy & Cook, 2006). The level of significance for all analyses was set to .05.
         Comparability    of the   conditions:  2 x  2  between  subjects  ANOVAs     with  the factors   Guidance   and
Video   Tool  revealed  no   significant differences    between  the  conditions concerning    participants'   age, prior
experience with computers in general and video software in particular, their history grade, or their dispositional
interest in history (all p > .10). The dyads also did not differ significantly between conditions concerning within-
group composition related to age, gender, prior knowledge, history grade, or historical interest (all p > .10). In
addition, student dyads did not differ in their appraisal of the task, the appraisal of their teamwork or the amount
of invested mental effort during task work (all p > .10), indicating that the participants' overall positive attitudes
towards  task and     performance  were   similarly  high   in the four conditions.  In  sum,   the  conditions   can  be
considered comparable. However, historical knowledge showed a marginally significant interaction, F(1, 68) =
3.86, p = .05, partial 2 = .05, showing that for students working with WebDIVER, those participating in the
cognitive design-related guidance condition scored higher on the pretest (M = 10.23, SD = 2.55) than students in
the social interaction-related condition (M = 8.22, SD = 2.20), t(34) = 2.53, p = .02. For students working with
Asterpix,  there were   no  significant  differences.   All ANOVAs      reported here were   also    run as  ANCOVAs
controlling for interest in history and prior knowledge, and they are reported when they show different results.
         Manipulation Check: The means and standard deviations of students' choices in the question tapping
their understanding of the task are shown in Table 1. An ANOVA revealed no significant difference between
conditions concerning their scores in "design task" characteristics, Fs < 1, ns, but a significant difference for the
"social task" characteristics for the factor Guidance, F(1, 68) = 15.51, p < .001, partial 2 = .19. More "social
task" items were chosen by students who had received social interaction-related guidance than by students who
had  received   cognitive   task-related design   guidance.    Our text-based  implementation     of guidance   by   task

© ISLS                                                                                                                 155
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

instructions can thus be considered effective for eliciting the students' awareness of the design problem in all
conditions and the students' increased awareness of the social demands of the collaborative design task in the
social interaction-related conditions.

Table 1: Means (M) and Standard Deviations (SD) for the manipulation check.

                                  Selective video editing tool                    Integrative video editing tool
                                        (WebDIVERTM)                                       (Asterpix)
                                  CDG                     SIG                     CDG                     SIG
                               (n = 18)                  (n = 18)               (n = 19)                (n = 17)
                             M           SD          M            SD          M           SD         M           SD
  Manipulationcheck ­ social0.81        0.75         1.37       0.65         0.71         0.49      1.31         0.58
  Manipulationcheck ­ design1.44        0.65         1.30       0.49         1.40         0.63      1.40         0.62
Note. CDG = cognitive design related guidance, SIG = social interaction related guidance

         Design Performance: The means and standard deviations of the scores of the dyads' design products
concerning numbers of commented video selections, style features and interpretations are presented in Table 2.
Interrater reliability for style features and interpretations were satisfactory, Cohen's   .94. ANOVAs revealed
a significant main    effect  for the factor  Guidance:   The   mean   scores  in all  the mentioned    indicators were
significantly higher for the products of dyads in the condition with social interaction-related guidance, than for
those from dyads in the condition with cognitive design-related guidance, in terms of number of comments, F(1,
67) = 6.46, p = .01, partial 2 = .09, number of style features, F(1, 67) = 4.78, p = .03, partial 2 = .07, and
number of interpretations, F(1, 67) = 4.63, p = .04, partial 2 = .07. Hence, design performance in the visual
design task was higher in the social interaction-related guidance conditions than in the other conditions. No
further main or interaction effects were found. Thus, the two forms of video tools were not used in different
ways - at least in relation to the quantitative indicators of design performance we applied here.

Table 2: Means (M) and Standard Deviations (SD) for the quality indicators of students' design performance.

                                  Selective video editing tool                    Integrative video editing tool
                                        (WebDIVERTM)                                       (Asterpix)
                                  CDG                     SIG                     CDG                     SIG
                               (n = 18)                  (n = 18)               (n = 19)                (n = 14)
                             M           SD          M            SD          M           SD         M           SD
  Number of
  commented                 4.11        3.38         6.61       3.03         4.11         2.38      5.43         3.65
  video selections

  Number of stylefeatures   0.14        0.48         1.22       2.26         0.29         0.77      0.64         1.17
  Number ofinterpretations  0.11        0.47         0.89       1.53         0.32         0.82      0.64         1.15
Note. CDG = cognitive design-related guidance, SIG = social interaction-related guidance

         Historical Topic Knowledge: Analyses of the scores from the multiple choice post-test on knowledge
about  the history    topic revealed  a total mean   score M   =  7.54 (SD   = 2.46)   out of  13  possible points. We
conducted a mixed 2 x 2 x 2 ANCOVA with the two between-subjects factors Guidance and Video Tool and the
within-subjects factor Pre-Post-Test to test for differences in the gain in individual factual knowledge. After
controlling for   the  differences in   pre-test scores,  the results still showed   a significant  increase in  factual
knowledge over time, F(1, 67) =34.80, p < .001, partial 2 = .34. However, there were no significant differences
between the conditions, Fs < 1, ns, and no significant interaction, F(1, 67) = 1.93, p = .17 indicating that the
students in both conditions had developed an understanding of the historical content.
         Critical  Analysis   and  Reflection:   The students' written  answers   to  the transfer task questions  were
coded independently by 2 raters. For the coding procedure, coders considered a pre-defined default solution

© ISLS                                                                                                               156
CSCL 2011 Proceedings                                                                                      Volume I: Long Papers

created by an expert in visual media production (first author of this paper). The solution comprised exemplary
stylistic features    used in   the  TV-ad     (e.g., camera,     music,  montage),     as well   as   examples   for  correct
interpretations  of  such  elements    (e.g., close-up  of   a person's  face  aims   at creating  emotional    involvement).
Based   on  this example,    raters  counted     the  number   of  named   style features     and  interpretations.  Also,  the
elaborateness of the answers was rated on a 3-point Likert scale (1 = simple, 3 = elaborate). Interrater reliability
was satisfactory for the number of style features, Cohen's  = .91, and the elaborateness rating, Cronbach's  =
.80. However, rater agreement for the number of interpretations of these style features was very low, Cohen's 
= .10. Closer analyses revealed that the raters differed greatly with regard to how strictly they applied the coding
scheme. For further analyses we decided to only use the coding of the more conservative rater. The analysis of
the transfer test results revealed a total average of M = 1.97 (SD = 0.74) for "number of style features", M = 0.37
(SD = 0.23) for "number of interpretations" and M = 1.19 (SD = 0.47), and for "elaborateness of the answer".
ANOVAs revealed that the means (see Table 3) of all these indicators were significantly higher in the answers
of students  in  the  conditions   with social   interaction-related   guidance,    than   in the conditions    with  cognitive
design-related   guidance:   number    of style   features,    F(1, 68)   =7.96, p    =  .01, partial  2  =  .11,   number  of
interpretations, F(1, 68) = 4.36, p = .04, partial 2 = 06, elaborateness of the answer, F(1, 68) = 4.11, p = .047,
partial 2 = .06. Overall, effect sizes were of medium to large size. There were no effects of the video tool
factor, Fs  <  1.1,   ns, or any   significant   interactions,  Fs  <  1,  ns. Thus,    although   all students   developed  a
comparable   understanding      of the topic,  the   learning  outcomes   in   terms  of advanced    thinking   skills (critical
analysis and reflection) were higher when social interaction was supported in the student dyads.

Table 3: Means (M) and Standard Deviations (SD) for the tests tapping factual knowledge and indicators of the
transfer task.

                                   Selective video editing tool                     Integrative video editing tool
                                        (WebDIVERTM)                                           (Asterpix)
                                 CDGb                        SIGc                   CDG                         SIG
                                (n = 18)                 (n = 18)                  (n = 19)                  (n = 17)
                             M          SD            M           SD           M            SD           M             SD

                                     Transfer test ­ critical analysis and reflection

 Number of stylefeatures     1.77       0.63         2.37         0.51         1.72        0.78         2.06          0.87
 Number ofinterpretations    0.34       0.23         0.43         0.26         0.30        0.21          .42          0.19
 Elaborateness ofthe answer  1.09       0.35         1.31         0.40         1.08        0.44         1.31          0.63
Notes. aTheoretical maximum = 13. bCDG = cognitive design-related guidance, cSIG = social interaction-related
guidance.

          Dyadic Interactions: For analyses of dyadic interactions, we coded the proportions of time students
were   engaged   in  activities belonging     to one  of  the  categories  "design    planning",   "design   action",  "design
evaluation", "technological issues", "problems" and "off task" (related to total amount of talking time, M =
21.52 minutes, SD = 4.46). 20% of the videos were coded by a second rater and agreement was on average
satisfactory, median of Cohen's  = .64. However, 2 x 2 ANOVAs with the two between-factors Guidance and
Video Tool yielded no significant differences between the conditions (see Figure 2). Further analyses on a more
fine-grained level are ongoing and will be available at the time of the conference.

Discussion
Our results provide evidence from an experimental study that helps to answer the question of how to improve
guidance for student teams solving a complex authentic design task for history learning with the support of web-
based video tools. Results indicate that while using either of the advanced video tools we offered was generally
effective, differences in the types of guidance we implemented (cognitive task-related vs. social interaction-
related guidance) resulted in different learning outcomes. Firstly, the immediate design products of the dyads'
task work   were  of  better  quality.  Secondly,     individual  students scored    significantly higher    in a transfer test
evaluating  critical  analysis   and   reflection    skills. Concerning    factual  knowledge      about the    topic  ("Berlin
blockade"),  no  differences    and  no  trade-off    effects  in performance    in   a  multiple-choice  posttest    emerged.
Moreover,   during    the  students' dyadic    interactions,   similar amounts     of time    were devoted   to   the  subtasks

© ISLS                                                                                                                      157
CSCL 2011 Proceedings                                                                                      Volume I: Long Papers

"design planning", "design action", "design evaluation", "technical issues", "problems" and "off task" behavior
in all conditions.    Thus,  the differences  in the  transfer  test were    neither  at costs  of  other  learning outcome
measures, nor could they be explained by a first (superficial) analysis of specific students' interaction time spent
on task.  This   finding  was  not   confined to   a specific   tool used    in  our study:  Results  show    that given the
conceptual differences of the video technologies (WebDIVER and Asterpix) described above, the benefits of
supporting   the social  problem   space  persist. We     thus conclude   that   the dyads   with  social interaction-related
guidance learned more than the dyads with cognitive task-related guidance, and we conjecture that even given
different affordances for the two video tools, social interaction-related guidance improved the quality of dyadic
interactions  on  a   deeper content  level.  And    this leads   us to  the question    of  how   exactly that quality  was
improved. In a next cycle of analyses we will investigate differences in the content of dyadic interactions and be
able to present the first results by the time of the CSCL conference. These findings will add further answers to
the question of how instructive guidance can be balanced for middle-school students in order to support skill-
intensive socio-cognitive processes.
          When    interpreting   the results reported    here  to draw   conclusions     for school  practice,  we  need  to
consider the following issues: In this study we created a highly controlled, computer-supported experimental
setting, thereby enabling us to draw causal conclusions. We exposed students to a short-time visual design task
for a regular history lesson, which is different from large design projects performed over several weeks. So the
results cannot be generalized to such projects. However, we compared our results from this experiment with the
results from an earlier field study in a real, "noisy" classroom situation with a comparable sample of students
and with the same short task and test items (Zahn, Krauskopf, et al. 2010). Results revealed general gains in
factual knowledge (pre- to post-tests) similar to those obtained in the field. No indications of influences of the
artificial experimental situation (positive or negative) were found. From the analyses, we may thus conclude that
students of the age group investigated here seem to have sufficient working patterns for completing short design
tasks  (establishing   a design  problem  space),    but  not  necessarily   for social  interaction (establishing  a social
problem   space). This    might  be  the case because     design  tasks  are often   used   in school-based   education  and
students are familiar enough with them to perform the necessary activities. However, they seem to be less able
to activate effective ways of team interaction from their everyday school experiences. In other words: Guidance
repeatedly emphasizing the aspects of design problem solving thereby focusing on the design product may not
improve the learning addressed here, but guidance improving collaborative activity (coordinating teamwork and
communication) can. For design-based interventions such as this, the result may be somewhat unsurprising, but
certainly worth highlighting. The strength of the social interaction-related guidance described here is such that it
calls for further analysis across a broad range of collaborative learning environments. For teachers this issue
would be important in practice if, indeed, their guidance of students' collaborative task work in real lessons
were focused on social interaction processes. This perspective is consonant with related views across different
domains and digital media (e.g., Barron, 2003) ­ and hopefully stimulates further CSCL research.

References
Barron, B. (2003). When smart groups fail. The Journal of the Learning Sciences 12 (3). 307-359.
Bereiter, C., &   Scardamalia,     M. (1987).  The   Psychology      of Written   Composition.     Hillsdale, NJ:  Lawrence
          Erlbaum Associates.
Détienne,  F.    (2006).  Collaborative   design:    Managing     task  interdependencies       and  multiple   perspectives.
          Interacting with Computers, 18(1), pp 1-20.
Edelson,  D.C.,   Gordin,    D.N.  &  Pea,   R.D.  (1999).    Addressing    the  Challenges     of  Inquiry-Based   Learning
          Through Technology and Curriculum Design. The Journal of the Learning Sciences, 8 (3&4). 391-450.
Fischer, F., Bruhn, J., Gräsel, C. & Mandl, H. (2002). Fostering Collaborative Knowledge Construction with
          Visualization Tools. Learning and Instruction 12. 213-232.
Goel, V., & Pirolli, P. (1992). The structure of design problem spaces. Cognitive Science, 16, 395-429.
Goldman, R. (2004). Video perspectivity meets wild and crazy teens: Design ethnography. Cambridge Journal
          of Education, 2(4), 147­169.
Hayes, J.R. (1996). A new model of cognition and affect in writing. In M. Levy & S. Ransdell (Eds.), The
          Science of Writing. (pp. 1-27). Hillsdale, NJ: Erlbaum.
Kirschner & Sweller (2006). Why Minimal Guidance During Instruction Does Not Work: An Analysis of the
          Failure   of   Constructivist  Discovery,   Problem-Based,        Experiential,    and   Inquiry-based   Teaching.
          Educational Psychologist, 4(2). 75-86.
Kafai, Y. B., & Resnick, M. (Eds.). (1996). Constructionism in Practice: Designing, Thinking, and Learning in
          a Digital World (pp. XII, 339 S.). Mahwah, NJ: Lawrence Erlbaum Associates.
Kolodner,  J. L., Camp,     P. J., Crismond,  D.,  Fasse,   B.,  Gray,  J.,  Holbrook,   J., et al. (2003).   Problem-Based
          Learning Meets Case-Based Reasoning in the Middle-School Science Classroom: Putting Learning by
          DesignTM Into Practice. Journal of the Learning Sciences, 12, 495-547.

© ISLS                                                                                                                    158
CSCL 2011 Proceedings                                                                            Volume I: Long Papers

Kollar, I., Fischer, F., & Slotta, J. D. (2007). Internal and external scripts in computer-supported collaborative
         inquiry learning. Learning & Instruction, 17(6), 708-721.
Lowry, P. B., Curtis, A., & Lowry, M. R. (2004). Building a Taxonomy and Nomenclature of Collaborative
         Writing to Improve Interdisciplinary Research and Practice. Journal of Business Communication, 41,
         66-99.
Pea, R., Mills,  M.,   Rosen, J., Dauber,  K., Effelsberg, W.,  & Hoffert.  E. (2004, Jan-March). The  DIVERTM
         Project: Interactive Digital Video Repurposing. IEEE Multimedia, 11(1), 54-61.
Pea, R. D. (2006). Video-as-data and digital video manipulation techniques for transforming learning sciences
         research, education and other cultural practices. In J. Weiss, J. Nolan, J. Hunsinger, & P. Trifonas
         (Eds.), International    handbook  of virtual  learning environments   (pp. 1321­1393).  Dordrecht,  The
         Netherlands: Kluwer Academic.
Scardamalia, M. (2002). Collective Cognitive Responsibility for the Advancement of Knowledge. In B. Smith
         (Ed.), Liberal Education in a Knowledge Society (pp. 67-98). Chicago: Open Court.
Smith,  B.,  &   Reiser,  B.  J.  (2005). Explaining   behavior  through observational  investigation and  theory
         articulation. Journal of the Learning Sciences, 14, 315­360.
Spiro, R. J., Collins, B. P., & Ramchandran, A. (2007). Reflections on a post-Gutenberg epistemology for video
         use in ill-structured domains: Fostering complex learning and cognitive flexibility. In R. Goldman, R.
         D. Pea, B. Barron, & S. Derry (Eds.), Video research in the learning sciences (pp. 93­100). Mahwah,
         NJ: Erlbaum.
Streeck, J., Goodwin, C., & LeBaron, C. (2011, in press) (Eds.). Embodied interaction: Language and body in
         the material world. Cambridge: Cambridge University Press.
Van Drie, J., Van Boxtel, C., Erkens, G., and Kanselaar, G. (2003). Supporting Historical Reasoning in CSCL.
         In B. Wasson, R. Baggetun, U. Hoppe, & S. Ludvigsen (Eds.), Designing for Change in Networked
         Learning     Environments.  Proceedings    of the International Conference    on Computer    Support  for
         Collaborative Learning - CSCL 2003, (pp. 93-102). Bergen, NO: InterMedia.
Weinberger, A., Ertl, B., Fischer, F., & Mandl, H. (2005). Epistemic and social scripts in computer-supported
         collaborative learning. Instructional Science, 33(1), 1-30.
Zahn,   C., Pea, R.,   Hesse,  F.  W., Mills,  M.,  Finke,  M.,  &   Rosen, J.  (2005). Advanced  Digital  Video
         Technologies to Support Collaborative Learning in School Education and Beyond. In T. Koschmann,
         D.  Suthers,  &  T.-W.   Chan (Eds.), Computer    Supported Collaborative   Learning 2005:   The Next 10
         Years (pp. 737-742). Mahwah, NJ: Lawrence Erlbaum.
Zahn, C., Pea, R., Hesse, F.W. & Rosen, J. (2010). Comparing Simple and Advanced Video Tools as Supports
         for Complex Collaborative Design Processes. The Journal of the Learning Sciences. 19(3). 403-440.
Zahn, C., Krauskopf, K., Hesse, F.W. & Pea, R. (2010). Digital Video Tools in the Classroom: How to Support
         Meaningful    Collaboration   and Critical Thinking  of  Students? In: M.S.  Khine   & Saleh, I.M.  New
         Science of Learning: Computers and Collaboration in Education. New York: Springer.

© ISLS                                                                                                          159
