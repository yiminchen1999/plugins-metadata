CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

       Collaborative Writing: Too Much of a Good Thing? Exploring
       Engineering Students' Perceptions Using the Repertory Grid

       Anindito Aditomo, CoCo Research Centre, Sydney University, and Faculty of Psychology, Surabaya
                                      University, aadi4954@uni.sydney.edu.au
     Rafael A. Calvo, School of Information Technologies, Sydney University, rafael.calvo@sydney.edu.au
            Peter Reimann, CoCo Research Centre, Sydney University, peter.reimann@sydney.edu.au

         Abstract: Students' perceptions of technology-supported collaborative writing (CW) and peer
         reviewing     are  important   because    these   perceptions  affect  adoption    decisions,   initial
         engagement,     and continued   reliance  on   collaboration/peer feedback    as a learning  resource.
         This paper describes and demonstrates the utility of the Repertory Grid Technique to probe
         such perceptions. Combining interviews and written surveys, this study uncovered constructs
         that engineering students' use to think about CW/peer-reviewing, and interesting patterns of
         relations among those constructs. For instance, while students perceived activities that involve
         the construction of personal arguments (such as CW) to be exciting and effective for learning,
         they   also  judged such  activities  to be time-consuming    and  stressful. This  study also  found
         interesting differences in the construct systems of high- and low-performing students.

Introduction
The potential of writing as a learning activity has long been recognized (e.g., Emig, 1977). From a cognitive
perspective, writing has the potential to foster deep understanding of the subject matter. This is because writing
involves the construction of, and interplay between, conceptual problems (what to say) and rhetorical problems
(how to say it) (Bereiter & Scardamalia, 1987). From a socio-cultural perspective, and more specifically through
the lens of genre theories, writing assignments provide a context in which students can acquire and practice
rhetorical skills and strategies useful to integrate into a discipline-specific discourse community (Gee, 2004).
         The  importance     of writing in higher   education  is well recognized.   Recent  nationally  commissioned
reports from the US and UK, for instance, highlight the central role of writing in graduates' ability to participate
effectively in   the  knowledge   economy     (Davies,   Swinburne,   & Williams,    2006;   National  Commission    on
Writing in American Schools and Colleges, 2003). Looking at engineering education more specifically, writing
is also recognised as a key graduate attribute. And because much of writing in professional practice is done
collaboratively  (e.g.,  Ede  &   Lunsford,   1992   show  that   85%  of  the documents     produced    in offices  and
universities have at least two authors), there is a clear need for developing students' collaborative writing skills.
         Although there is plenty of evidence for writing as a potent learning activity, there is no guarantee that
students will enact their writing assignments productively. One way to enhance the probability that students will
use writing activities for deep learning is to embed writing in a social context. A rudimentary, but frequently
used   form of   writing consists  of individual   or   collaborative writing  (CW)    combined  with   peer  reviewing
(Topping, 2005). A major advantage of CW and peer review is that they can be conducted with large numbers
of students. Indeed, CW and peer reviewing can be seen as an answer to the specific pedagogical challenge that
arises when employing writing in settings with a large number of students, e.g. for undergraduate education:
How can guidance (scaffolding) and (formative) feedback on writing be provided, given the teacher:student
ratio? This necessitates looking for alternative resources, in the form of self-guided learning, peer feedback, and
guidance/feedback that can be provided by computational means.
         Our research team have begun to develop an online writing environment with components specifically
designed to support the peer review process (Calvo, O'Rourke, Jones, Yacef, & Reimann, 2010), reflection on
writing products (Villalon, Kearney, Calvo, & Reimann, 2008), and reflection on writing process (Southavilay,
Yacef,  & Calvo,   2010).  Our   inquiry  into CW    and  peer reviewing   currently follows  two  lines. First,  we are
interested in understanding how students write by examining process data. Second, we are also interested in
students' perceptions and subjective experiences of CW and peer reviewing. The study reported here is part of
this second  line of   inquiry. The study    aimed   to explore engineering   students'   perceptions of  CW   and  peer
reviewing. In addition, the study also examined the utility of a variant of the Repertory Grid Method as an
approach to assess the structure of students' perceptions.
         The paper begins with a brief summary of prior studies on students' perceptions of writing, along with
the  theoretical perspective    informing  those  studies. Next,  the  repertory grid   approach   to capture    students'
perceptions is described, followed by the study's data collection methods, analysis, and main findings. We close
by   discussing  the  implications  for  the  design  and  integration  of computer    supported   CW    pedagogy    and
technology into undergraduate engineering education.

© ISLS                                                                                                                128
CSCL 2011 Proceedings                                                                                     Volume I: Long Papers

Students' Perceptions/Conceptions of Writing
We   are  interested  in students'    perceptions    of  CW    and   peer reviewing,     and   in their perceptions  of   the
technologies made available to them, because these perceptions may affect not only how and to what extent
students engage with the pedagogy and the technology initially, but also be an important factor affecting the
self-guided employment of writing and of peer support as tools for continuous professional development.
          One research tradition that provides a theoretical framework that links students' perceptions, learning
behavior,  and subsequent     outcomes      is phenomenography       (Marton &   Booth,   1997).  Phenomenography's       key
insight is that learning is relational: a learning activity is always the product of the relation between the student
and the task. Students who see a task differently will enact it in different ways. Phenomenographic studies have
identified two basic ways of conceiving a learning task: cohesive (as orienting towards transforming personal
understanding) and fragmented (as orienting towards collecting information or memorizing). Students adopting
a cohesive conception typically engage at deeper cognitive levels than those adopting a fragmented conception
(Marton & Saljo, 2005).
          Several phenomenographic studies have investigated students' views of writing. For instance, based on
interviews  with   history   and  psychology     students, Hounsell   (1984)  identified   different   conceptions  of essay
writing. Some students talked about essays as a presentation of a personal argument or perspective; other talked
about essay writing as presenting a string of ideas and facts/data, without an overall organizing argument or
perspective. A study by Prosser and Webb (1994) found that students' adopting the more cohesive conception
(i.e. essay are argument) also adopted a deeper approach (e.g. making decisions on what needs to be included in
the essay based on the overall argument) and produced better quality essays. These associations have also been
demonstrated by more recent, larger scale studies (Ellis, Taylor, & Drury, 2007).
          While phenomenography has proved to be a useful framework, studies informed by phenomenography
have   almost exclusively     conceptualized     experience    in terms of   the cohesive-fragmented       and deep-surface
distinctions. We   suspect   that students'    perceptions   and  experiences  of CW     and   peer reviewing  may   include
other dimensions that are also important to explore. Hence, we need a method to capture students' perceptions
without relying too much on a priori or pre-determined dimensions. To this end, we see the Repertory Grid
Technique (RGT) as a promising approach. The RGT was developed mainly in psychology based on George
Kelly's Personal Construct Theory (Kelly, 1991). Kelly's theory is compatible with phenomenography: both
agree that what matters most is not reality as such, but how people see or experience it. Kelly proposed that
differences in people's perceptions the world are due to (not necessarily explicit) theories that people hold about
respective aspects of the world, and that these theories affect perception through constructs, defined as "...a way
in which some things are construed as being alike and yet different from others" (Kelly, 1991, p. 74). Constructs
develop and change over time as a function of experience, but are relatively stable compared to the speed with
which   situation  and  context   change.      Furthermore,   Kelly  suggested   that each   individual   possesses  a finite
number of constructs at any point in time, and that these constructs are related to each other to form a system.
The next section describes RGT in more detail.

The Repertory Grid Method
One of our aims in this study is to identify a method that can help capture students' perceptions with the goal of
improving   upon   the  design   of  pedagogy     and  technology,   as well  as  gauging    the  effects  of differences  in
perceptions   on  learning    outcomes.     This requires   a  method   that works    with   a small   number   of  students,
delivering  rich  data necessary     for informing    design   decisions, as  well    as with  larger   number  of  students,
necessary for generalizing findings. The method we employed to satisfy these demands is based on Repertory
Grid Technique (RGT, Fransella, Bell, & Bannister, 2004).
          RGT has a long and productive history in social psychology and clinical psychology, but also in areas
such as marketing research and information systems research (see Curtis, Wells, Lowry, & Higbee, 2008; Tan &
Hunter, 2004 for reviews of applications in the information systems area).               A major advantage compared to
survey methods is that RGT does not only elicit peoples' ratings but also the dimensions along which these
ratings are made. In its canonical format, RGT proceeds by presenting participants with a set of elements (the
objects  of perception,  such     as social    partners, car  models,  or in  our  case:  teaching/learning    methods    and
technologies) and then eliciting from participants in a systematic manner the constructs they use to distinguish
and  to group  the elements.     Importantly,    the constructs,  or  dimensions   for   comparison,   are not given   to the
participants, but generated by them during grid elicitation.
          A typical   method     to  elicit constructs   would    be an interview   where    the  interviewer  presents   the
participant with sets of three elements (e.g., three learning technologies) and then asks the participant to select
two elements that are similar, and distinct from the third, and then to label the dimension that forms the basis for
this triangulation    (e.g., interactivity   with  the   poles Low    and  High).  Repeating      this triangulation for  all
combinations of elements yields a multidimensional space in which each element occupies a position. Over this
data representation, one can for instance calculate similarity measures that can be further subjected to qualitative
analysis,  cluster analysis,     or  dimension    reduction    methods    (e.g., principal   component     analysis;   multi-

© ISLS                                                                                                                    129
CSCL 2011 Proceedings                                                                                 Volume I: Long Papers

dimensional scaling). Such data can be analyzed on the individual level as well as pooled over participants. For
more descriptions of the various elicitation and analysis methods, as well as software tools, the reader is referred
to tutorials such as Fransella et al. (2004).
          A major practical drawback of RGT is the time it takes to conduct the construct elicitation, in particular
if the elicitation is done by interview. Since (engineering) students have little time, and we did not have the
means to pay our research participants, we employed a combination of RGT and standard survey methodology.
A small number of volunteering students were interviewed with the goal to elicit their construct system, and the
main   constructs  were   then used   as the basis  for  a survey that was  distributed   amongst  a  larger number  of
students. While this has the disadvantage of potentially glossing over interesting individual construct systems, it
has the advantages of being much more rapidly applied and of reducing interviewer bias.

Research Questions and Methods
This study addressed two main questions: How do engineering students' perceive CW and peer reviewing? And
are there any relations between students' perceptions and their writing performance?

Participants and Course Context
Participants in this study were 3rd-year engineering students enrolled in a course titled E-Business Analyses and
Design in Semester 1, 2010. Nine students (4 males, age 20 to 23) from the course volunteered to participate in
the interviews. Thirty-nine students (31 male) volunteered to participate in the survey. (This sample represented
73.6%     of the whole  class.) The   course  focused    on "aspects of analysis,   project specification, design,  and
prototype that lead up to the actual build of a website or application."
          Of particular interest for this study was the writing assignment, which required students to work in
pairs and write an e-business proposal. While this was a group task, there was a section of the proposal that each
student had to write individually to obtain individual marks. After the submission of the proposal, each student
had to read and write a review of another group's proposal (the peer review was also graded). Students were
then asked to revise their submitted proposal based on the peer review and tutor feedback. The CW and peer
reviewing were performed in an online environment (iWrite).

Online Writing Environment
Our on-line writing environment (`iWrite') provides students with tutorials on writing for different disciplines,
assignment     information, and    tools for  writing,   improving   their writing,  reviewing   and   submitting  their
assignments (Calvo, O'Rourke, Jones, Yacef, & Reimann, 2011). To instructors, it provides a complete solution
for scaffolding the write-review-feedback cycle of a writing activity.       Specialist writing instruction content is
built into the technology, and management tasks which would be highly time-consuming for large classes are
handled automatically. In the course investigated here, iWrite was used to support an assignment that combines
CW and peer reviewing.

Data Collection
Six interviews were conducted to elicit the constructs students used to think about learning activities. Three of
the six interviews were conducted with pairs of students. Each interview took 20-30 minutes. In the interviews,
students were shown triads of learning activities and were asked: "Here are three learning activities. Choose two
among these three, and think about how they are similar to each other, but different from third." This procedure
was first demonstrated using an example triad: taxi/private car/public bus. The learning activity triads were: (a)
reading textbooks/reading articles/attending lectures, (b) Peer reviewing/individual oral presentations/group oral
presentations,     (c)    attending    lectures/tutorials/peer    reviewing,     (d)   writing     individually/writing
collaboratively/reading   textbooks.   For   each triad, the interviewer   wrote a   phrase or  word   to represent the
student's answer as his/her construct and asked whether the student agreed with the phrase/word.
          Each of the interviews produced 5 to 11 constructs (median: 7). While some constructs were commonly
present in 2 or 3 of the interviews, no constructs appeared in all 6 interviews. More in-depth analysis can be
done   on  the interview  data  to  explore  the  interviewees' individual  construct  system.   This  paper, however,
focuses on the pattern of perception across the whole class sample. For the purpose of this paper, we report that
the interviews   elicited a total  of 31  constructs. Because   a pilot study  indicated   that we could   only include
approx. 10 constructs (given the time constraints), we had to select from the pool of 31 constructs.         We did so
by  first examining    whether  the 31   constructs could   be grouped  based  on   their  similarity in meaning.  This
resulted in 15 groups of constructs. From this, for the survey, we selected 11 constructs that were mentioned by
more than 1 student. These 11 constructs are listed in Table 1 in the next section, and the 4 excluded were:
"interactive/non-interactive",    "provides   clues   about   important    materials/not",  "requires    communication
skills/not", and "depends on one's own motivation/supervised".

© ISLS                                                                                                               130
CSCL 2011 Proceedings                                                                                   Volume I: Long Papers

           The survey was distributed on paper and online. The questionnaire asked students to rate five learning
activities which they experienced in the course, plus what students' consider to be an "ideal" learning activity,
on a scale from 1 to 5 in terms of the 11 constructs elicited from the interviews.

Findings

Interrelations between the Constructs
To explore   the interrelations  between    constructs students    used in thinking   about  learning  activities, we  first
performed an exploratory factor analysis (Oblimin rotation with Kaiser Normalization was used). The factor
analysis suggested a 4-factor solution which accounts for 67.26% of the total variance. Sampling adequacy
(KMO)     was  measured   at  0.644,  which   is  acceptable, while   Bartlett's sphericity   test  was significant   (chi-
square=587.8, p< .0001). The factor analysis results are shown in Table 1.

Table 1: Factor analysis results (loadings of less than .3 are not shown).
       #                                 Constructs                                          Factor loadings123    4
    1       Requires construction of own argument (1) vs. does not (5)                .789
    2       Requires independent research (1) vs. does not (5)                        .763
    3       Involves peer discussion (1) vs. no peer discussion (5)                   .578             .409
    4       Boring (1) vs. exiting (5)                                                -.547   .510               -.388
    5       Effortful (1) vs. effortless (5)                                                  .782
    6       Time consuming (1) vs. not time consuming (5)                                     .754
    7       Stressful (1) vs. relaxing (5)                                                    .738               -.391
    8       Can be done anywhere (1) vs. only in certain places (5)                                    -.887
    9       Can be done anytime (1) vs. only in certain times (5)                                      -.869
    10      Structured (1) vs. unstructured (5)                                                                  .807
    11      Effective (1) vs. not effective (5)                                       .318    -.355              .726

           The first  factor may be   interpreted  as  "Student-centeredness",   with   more    student-centered   learning
activities requiring  students  to perform   their own   research,  construct   their own   argument,   and  involve   peer
collaboration.  The   second   factor may    be  interpreted as "Demand",      with   more  demanding     activities being
effortful, time  consuming,   stressful, and  boring.  The   third factor  was  interpreted  as "Flexibility", with   more
flexible activities being constrained by neither time nor location. The fourth factor is more difficult to interpret,
as it is composed of "Structuredness" and "Effectiveness for Learning". This implies that that students tend to
perceive structured activities as being more effective than unstructured ones.
           The cross-loading of the "Boring/exiting" construct is worth noting. On the one hand, this construct
loads with the "Student-centeredness" factor, indicating that students tend to perceive student-centered activities
as exiting. "Boring/exiting"    also  loads  with  the "Structure  and  Effectiveness"   factor, showing    that activities
perceived to be structured are also perceived to be boring. On the other hand, "Boring/exiting" loads with the
"Demand" factor, implying that activities perceived as demanding are also perceived as boring. This pattern
highlights the challenge of engaging engineering students: to be perceived as exiting, a learning activity needs to
be unstructured and student-centered, but at the same time relaxing and requiring little effort and time.
           The cross-loading of the "Effectiveness" construct is also interesting to note, in particular because it
follows the opposite pattern to the "Boring/exiting" construct. While "Effectiveness" loads most strongly with
"Structuredness", it also loads with the "Student-centeredness" and "Demand" factors. The directions of these
loadings indicate that activities which are more student-centered and demanding (time/effort) were also seen to
be more effective for learning.

Students' Perceptions of Collaborative Writing and Peer Reviewing
How do engineering students perceive CW and peer reviewing, vis a vis other learning activities? In addressing
this question, we used the factor analysis results above to simplify the 11 original constructs by combining those
which    loads strongly (above   .7)  and  exclusively  onto  a single  factor. This  resulted   in the 7  constructs: (1)
Student-centeredness     (combination     of  "independent      research"   and  "construction      of  argument"),    (2)
Effectiveness,  (3)  Structuredness,  (4)  Demand   (combination    of  "time",  "effort",  and "stress"), (5) Flexibility
(combination of "anywhere" and "anytime"), (6) Excitingness, and (7) Peer discussion. (Note: to further aid
interpretation, some of the scores have been reversed such that higher scores reflect stronger perception in that
construct; possible score ranges from 1 to 5 for all constructs).

© ISLS                                                                                                                  131
CSCL 2011 Proceedings                                                                             Volume I: Long Papers

 Figure 1. Perceived Student-Centeredness and Effectiveness; Error Bars Represent 95% Confidence Intervals.

         As Figure 1 (left panel) shows, CW was seen to be the second most student-centered activity (after
individual  writing),    while attending lectures and  reading  course  materials the least.  Interestingly, both
collaborative and individual writing were seen as more student-centered than an ideal learning activity. In other
words, writing was seen to involve too much construction of personal argument and independent research. Peer
reviewing, on the other hand, was considered to be ideal in terms of student-centeredness.
         In terms of learning benefits (Fig. 1, right panel), CW, individual writing, and peer reviewing were all
seen as no more effective than attending lectures. All learning activities fell short of students' expectations in
this regard. Peer reviewing, in particular, was seen to have the least benefit for the students' learning; it is seen
as slightly less effective than CW (Wilcoxon z = -2, p = .045), individual writing (Wilcoxon z = -1.72, p =
.085), and reading (Wilcoxon z = -2.331, p = .02).
         There seems to be relatively little variation in the perceived level of structure across the five learning
activities (Figure 2, left panel). CW and peer reviewing were seen to be the least structured activities, although
only   slightly less  structured than ideal (the difference  between  ideal and peer reviewing  was statistically
significant, z = -2.242, p = .025).

  Figure 2. Perceived Structuredness and Demandingness; Error Bars Represent 95% Confidence Intervals.

         In terms     of perceived  demand  (Figure 2, right panel), individual writing, peer reviewing, and   (in
particular) CW were all judged to demand more time/effort and more stressful than an ideal learning activity.
Peer reviewing seems to pose slightly less demand than CW. While it is quite easy to see why the writing-
related activities were seen as demanding, it is worth noting that the lectures and particularly reading materials
were also deemed too demanding. Hence, designing a learning activity that meets students' expectations in this
regard may be difficult.

© ISLS                                                                                                           132
CSCL 2011 Proceedings                                                                                Volume I: Long Papers

        Figure 3. Perceived Flexibility and Excitingness; Error Bars Represent 95% Confidence Intervals.

         With regards to flexibility (Figure 3, left panel), attending lectures was seen to be the least flexible,
while individual writing and reading were the most. Interestingly, CW was considered to be less flexible than
ideal  (although still  more  flexible than attending    lectures), despite  the availability   of the online  writing
environment. Peer reviewing was seen to be more flexible than CW, but still slightly less flexible than ideal.
With regards to level of excitement (Figure 3, right panel), none of the five learning activities met students'
expectations. However, CW, peer reviewing, and individual writing were all perceived to be more exciting than
attending  lectures   and reading  course  materials.  CW   was     unsurprisingly  seen  to  involve  the   most peer
discussion. This, however, was more than what students would have liked. On the other hand, peer reviewing
and individual writing, along with the other learning activities, were all seen to involve too little peer discussion.

Relations between Students' Perceptions and Writing Performance
Do   students' perceptions   of  CW   and  peer reviewing   predict  their  writing  marks?   Simple   non-parametric
correlation tests were performed to examine this question. Results indicated that students who obtained better
writing marks   also  tended  to perceive: CW   to be  more effective   for  learning (r = .348;   p=  .032) and  more
exciting (r = .298, p = .065); and peer reviewing to be less structured (r = - .342, p = .036), involve less peer
discussion (r = - .376, p = .02), and more exciting (r = .287, p = .07). These significant correlations are mostly in
line with  expectations:  students who  see  CW    and peer reviewing    as  exciting and/or  beneficial  for learning
would likely adopt more productive approaches in their writing. The other two correlations (between higher
marks with perceptions of less structure and peer discussion in peer reviewing) are less obvious and need further
exploring.
         In addition   to the correlation  analysis, we  also compared      the  construct system   of high   and  low
performing  students.   This  analysis utilizes the  unique structure   of  repertory  grid  data,  which  allows  the
application of principle  components   analysis  on  the constructs  to produce   a  2-dimensional   map   whose  axes
represent the first two extracted factors, onto which each learning activity can be plotted. This kind of analysis
has the advantage of depicting the structure of students' whole construct system, as opposed to looking at single
constructs separately. For this analysis, the high performing group comprised of six students who scored 8 or
more (out of 10), while the low performing group comprised of five students who scored 4 or less in their CW
assignment.  The  average   construct  ratings were  calculated as   a basis of  the  principle components    analysis,
which was performed using Chris Evans' program (http://www.psyctc.org/grids/). The results (Figure 5) showed
some striking differences between high and low performing students.
         In the construct system of high performers (Figure 5, left panel), CW is placed quite close to the ideal
learning activity. More specifically, CW is considered to be exiting, effective, student-centered, involves a lot of
peer discussion, unstructured, and simultaneously posing low demand. In contrast, in the construct system of
low performers (Figure 5, right panel), CW is placed far from the ideal learning activity and is perceived to be
ineffective, unstructured, not exiting, and not student-centered.
         Another difference between high and low performers is related to the construct of "structuredness": in
the high-performers' construct system, "structuredness" is associated with level of demand, but not necessarily
with student-centeredness, effectiveness, nor excitingness. The opposite is true in the construct system of low
performers: "structuredness" is strongly associated with student-centeredness, effectiveness, and excitingness.
In other words, low performers (but not for high performers) seem to expect more structure to be able to see the
learning and motivational value of an activity.

© ISLS                                                                                                              133
CSCL 2011 Proceedings                                                                                Volume I: Long Papers

   Figure 5. Construct System of High Performing (Left Panel) and Low Performing (Right Panel) Students.

Discussion and Conclusions
This study aimed, firstly, at revealing students' perception of (technology-supported) peer review pedagogy, an
arguably rudimentary but frequently employed method for collaborative learning in undergraduate education.
Secondly,   we   were    interested in  relations between    students'    perceptions and   their success    on  writing
assignments.
          We found that writing, particularly when done in groups, was perceived to be quite student-centered.
This indicates students' awareness that writing requires them to do some independent research and construct
their  own  argument.    CW   and peer  reviewing  were   seen  to be   moderately  exciting,  more  so  than   attending
lectures  and  reading.  However,    on average,  writing  and   peer   reviewing  were   seen to be   only  moderately
effective  for learning,  not  more  effective   compared    to attending  lectures   and reading.  In  addition, while
individual  writing   was  (as predicted) considered  to  be  flexible, CW    was  considered  to  be  only  moderately
flexible. This indicates that in performing their writing assignment, many of these students still see the need to
have   face-to-face   meetings, despite   the possibility of  online,   asynchronous   collaboration   afforded  by   the
technology.
          Comparisons with students' imagined ideal learning activity provided some more insights. CW was
seen to be ideal only in terms of structuredness. In terms of the other constructs, however, CW did not meet
students' expectations: it was seen to be too student-centered and demanding, and at the same time not effective
and flexible enough. Peer reviewing was as more ideal in terms of student-centeredness, structuredness, and
flexibility, but still less effective and slightly more demanding than ideal.
          These findings highlight some of the challenges of introducing CW to engineering students. If CW is
seen   as too  stressful and  demanding   too much   time/effort,  while  at the  same  time   providing little learning
benefits, then it would be difficult to persuade engineering students to adopt a deep approach to their writing
assignments. On the positive side, these students still considered writing and peer reviewing to be more exciting
and student-centered than attending lectures and reading course materials. Hence, the students were aware of
some of the positive aspects of CW and peer reviewing. It is this dimension of students' perception that lecturers
can tap into when trying to motivate students to adopt productive approaches to CW/peer reviewing.
          This study   also  demonstrates   that the repertory  grid  technique  (RGT)    can  be fruitfully applied  to
explore the multi-faceted nature of students' perceptions. The specific approach we adopted ­ using constructs
elicited through interviews in a follow-up survey ­ proved both useful and practically viable. Although it may
gloss over individual students' unique construct systems, this approach provided insights into students' complex
view of CW and peer reviewing. For instance, from the findings we can point out specific aspects of CW that
students appreciate and other aspects which they don't. We were also able to demonstrate not only whether, but
how high performers' construct systems differ from the low performers'.
          Furthermore,    the  approach employed     here yielded  insights   that enrich  the traditional   findings of
phenomenographic      studies. Whereas    phenomenography       focuses on   cohesive and  fragmented   conceptions   of
learning, our study suggests that affective dimensions (e.g. exitingness) and pragmatic effort calculation (e.g.
demandingness) are also important parts of students' experience of CW and peer reviewing. When we consider
a richer  set of dimensions    of students' perceptions,  it is difficult to dismiss  the engineering  students   in this

© ISLS                                                                                                                134
CSCL 2011 Proceedings                                                                            Volume I: Long Papers

sample as mere surface learners: While most saw CW and peer reviewing as demanding tasks, they were also
aware that those tasks require time, effort, independent work, and the construction of personal arguments.

References
Bereiter,  C.,   & Scardamalia,  M.  (1987).  The psychology   of  written composition.  Mahwah,    NJ:   Lawrence
          Erlbaum Publishers.
Calvo, R. A., O'Rourke, S. T., Jones, J., Yacef, K., & Reimann, P. (2010). Collaborative writing support tools
          on the cloud (accepted for publication. IEEE Transactions on Learning Technologies.
Calvo, R. A., O'Rourke, S. T., Jones, J., Yacef, K., & Reimann, P. (2011). Collaborative writing support tools
          on the cloud. IEEE Transactions on Learning Technologies, 4(1), 88-97.
Curtis, A. M., Wells, T. M., Lowry, P. B., & Higbee, T. (2008). An overview and tutorial of the repertory grid
          technique   in information systems  research. The  Communications    of the Association  for Information
          Systems, 23, 38-62.
Davies, S., Swinburne, D., & Williams, G. (Eds.). (2006). Writing Matters: The Royal Literary Fund Report on
          Student Writing in Higher Education. London: The Royal Literary Fund.
Ede,   L. S., &  Lunsford,  A.  A. (1992). Singular  texts/plural authors: Perspectives  on collaborative  writing:
          Southern Illinois Univ Pr.
Ellis, R.  A., Taylor,   C. E., &  Drury, H. (2007).  Learning science   through  writing: associations with prior
          conceptions    of writing  and  perceptions   of a  writing  progam.    Higher Education     Research &
          Development, 26(3), 297-311.
Emig, J. (1977). Writing as a mode of learning. College Composition and Communication, 28(2), 122-128.
Fransella, F., Bell, R., & Bannister, D. (2004). A manual for repertory grid technique (2nd ed.). West Sussex:
          Wiley.
Gee, J. P. (2004). Language in the science classroom: academic social languages as the heart of school -based
          literacy In E. W. Saul (Ed.), Crossting Borders in Literacy and Science Instruction: Perspectives in
          Theory and Practice (pp. 13-32). Newark, DE: International Reading Association.
Hounsell, D. (1984). Essay planning and essay writing. Higher Education Research & Development, 3(1), 13-
          31.
Kelly,    G.  A. (1991).  The   psychology of personal     constructs (Original work   published   1955).  London:
          Routledge.
Marton, F., & Booth, S. (1997). Learning and Awareness. New Jersey: Mahwah.
Marton, F., & Saljo, R. (2005). Approaches to learning. In F. Marton, D. Hounsell & N. Entwistle (Eds.), The
          Experience of Learning: Implications for Teaching and Studying in Higher Education (3rd (Internet)
          ed., pp. 39-58). Edinburgh: University of Edinburgh.
National Commission on Writing in American Schools and Colleges. (2003). The Neglected "R": The Need for
          a Writing Revolution. New York: College Entrance Examination Board.
Prosser, M., & Webb, C. (1994). Relating the process of undergraduate essay writing to the finished product.
          Studies in Higher Education, 19(2), 125-138.
Southavilay, V., Yacef, K., & Calvo, R. A. (2010). Process mining to support students' collaborative writing.
          Paper presented at the Educational Data Mining, Pittsburgh, PA, USA.
Tan,   F. B.,  &  Hunter, G.  M.  (2004).  Cognitive research in  information   systems  using the Repertory Grid
          technique.  In  M. E.  Whitman   &  A. B.  Woszcsynski   (Eds.), The  handbook   of  information systems
          research (pp. 261-290). Hershey, PA: Idea Group Inc.
Topping, K. J. (2005). Trends in Peer Learning. Educational Psychology, 25(6).
Villalon, J., Kearney, P., Calvo, R. A., & Reimann, P. (2008). Glosser: Enhanced feedback for student writing
          tasks. Paper presented at the 8th IEEE International Conference on Advance Learning Technologies
          (ICALT) (Santadar, Spain, July 1-5, 2008; accepted March 2008).

Acknowledgements
This project was funded by an Australian Research Council Discovery Project grant (DP0986873). We thank
the students who have generously given their time to participate in this study.

© ISLS                                                                                                           135
