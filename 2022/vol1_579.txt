         Examining Learners’ Cognitive Engagement in Danmaku
                              Comments
                                         Zhenyao Cai*, Shiyao Wei*,
                              zc2535@tc.columbia.edu, sw3550@tc.columbia.edu,
                                    Teachers College, Columbia University

         Abstract: Danmaku is an emerging commenting system of video platforms, displaying users’
         comments on the top of the video. Limited studies have been conducted on learners’ cognitive
         engagement with educational videos that embed Danmaku. In this paper, we used a content
         analysis method to categorize instructional behaviors that cause learners’ responses and further
         evaluate cognitive engagement. We identified that certain instructional behaviors cause more
         responses and higher-level learners’ cognitive engagement.

Introduction
Aside from MOOC, User-Generated Content video platforms are becoming an important part of online informal
learning. Commenting systems are embedded in video platforms to facilitate collaborative learning among viewers.
Danmaku is a commenting system that allows viewers to post comments while watching a video. Comments will
be displayed at the top of the screen for all current and future viewers. First introduced for interactive
entertainment purposes, Danmaku has found its way into educational videos on a wide range of topics during the
last ten years (Zhang & Cassany, 2018). This research explores the following questions: What types of
instructional behaviors lead to more Danmaku discussions? How do learners’ comments reflect their levels of
cognitive engagement?

Methods
We collected 10,383 Danmaku comments from 4 educational video lectures uploaded on Bilibili, a widely used
user-generated content video platform with Danmaku feature. Our data analysis follows three steps: 1) Identify
comment peaks (N=10) in each video. 2) Use Instructional Behavior Scheme to categorize the instructional
behaviors. 3) Use Chi’s ICAP framework to categorize user comments in each comment peak and evaluate their
cognitive engagement (see Figure 1).
         Figure 1
         Data Analysis Procedure




Comment distribution over video timeline
As shown in Figure 2, the X-axis is the video time split into 10-second clips, and the Y-axis denotes the counts of
Danmaku in each interval. For the accuracy of the learners’ behavioral study, we eliminated irrelevant data. We
identified 40 comment peaks, 10 in each video, with 1,405 comments in total.
Instructional behavior coding scheme
Based on our preliminary observation of the relationship between user reactions and instructional behaviors, we
identified 7 instructional behaviors that incite discussion comments.
    Table 2
    Coding scheme of types of instructional behaviors that incite viewers’ participation




CSCL2022 Proceedings                                   579                                                  © ISLS
  Instructional Behaviors                                         Description
         Anecdote         Introduce an account of an interesting incident.
          Analogy         Compare a concept with information that is familiar to learners.
       Pose questions     Raise a question about a concept or idea to encourage discussion.
   Controversial content Talk about ideas or express opinions that lead to disagreement.
      Difficult content   Introduce abstruse or abstract concepts that require prerequisite knowledge to understand.
     Provide examples Give examples to explain certain concepts.
     Provide resources Use physical or graphic education tools to assist teaching.
Cognitive engagement coding scheme
Referring to Chi's ICAP framework (2009), we developed a scheme to evaluate learners’ cognitive engagement
when they post comments and calculated cognitive engagement scores presented in each comment.

   Table 3
   Coding scheme for evaluating learners' cognitive engagement
  Cognitive engagement       Behaviors                                    Description
                              Endorse        Repeat  the video content or endorse instructors’ opinions.
    Active (score = 1)        Paraphrase        Use their own words to repeat the concepts.
                                 Correct        Point out obvious flaws, such as pronunciations and typos.
                                 Explain        Add supplement information to help others understand an idea.
 Constructive (score = 2)
                                Connect         Express thoughts linking to prior knowledge or experience.
  Interactive (score = 3) Meaningful Question Post a relevant question that requires other viewers’ answers.
                          Meaningful Response Answer questions raised by instructors and other viewers.
                              Argue/defend      Defend a statement with specific arguments or references.
   Off-task (score = 0)                         Post comments that are irrelevant to the lecture content


Findings and discussion
Different instructional behaviors lead to different levels of cognitive engagement. Posing questions (Mscore=2.51,
SD=0.51), introducing difficult content (Mscore=1.67, SD=0.57), and discussing controversial issues
(Mscore=1.55, SD=0.78) lead to higher-level cognitively engaged commenting behaviors, meaning learners are
taking further steps to construct knowledge actively. Telling anecdotes (Mscore=0.53, SD=0.17) and making
analogies (Mscore=0.62, SD=0.14) score much lower. In one video lecture with advanced materials, learners
respond to anecdotes (40%) and analogies (20%) more often. This might be explained by a lower cognitive
threshold required to discuss anecdotes and analogies. In the video with more advanced content, the ratio of off-
task comments over total comments is the highest (36.67%, Mean = 27.19%) and the cognitive engagement score
is the lowest (0.92, Mean = 1.33).
          We also found that learners are more reluctant to pose questions compared to answering questions. One
question posted by learners has more than one response from other learners (Mean=2.63, SD=1). It is possible
because in the Danmaku system, users do not get notifications when their posted questions are answered, so they
have low motivation to post questions.
          Our study suggests that Danmaku has the potential to benefit both instructors and learners in online
video-centric learning environments. For instructors, Danmaku comments help them estimate what types of
instructional behaviors cause positive discussions such that they can plan or redesign their course content and
teaching strategies accordingly. For learners, Danmaku comments not only enable positive interaction between
beginners and more experienced learners but also work as a rich resource for future learners.

References
Chi M. T. (2009). Active-constructive-interactive: a conceptual framework for differentiating learning activities.
        Topics in cognitive science, 1(1), 73–105.
Zhang, L.-T., & Cassany, D. (2020). Making sense of danmu: Coherence in massive anonymous chats on
        bilibili.com. Discourse Studies, 22(4), 483–502.




CSCL2022 Proceedings                                     580                                                   © ISLS
