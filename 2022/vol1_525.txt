          Artificial Intelligence and Ambitious Learning Practices
                Cindy E. Hmelo-Silver (co-chair), Indiana University, chmelosi@indiana.edu
         Sadhana Puntambekar (co-chair), University of Wisconsin–Madison, spuntambekar@wisc.edu
                     Krista Glazewski (co-chair), Indiana University, glaze@indiana.edu
                  LuEttaMae Lawrence, University of California, Irvine, luettaml@uci.edu
                     Nikol Rummel, Ruhr University, Bochum nikol.rummel@rub.edu
                     Vincent Aleven, Carnegie Mellon University, aleven@cs.cmu.edu
                   Gautam Biswas, Vanderbilt University, gautam.biswas@vanderbilt.edu
                      Suraj Uttamchandani, Indiana University, suttamch@indiana.edu
                         Asmalina Saleh, Indiana University, asmsaleh@indiana.edu
                            Haesol Bae, Indiana University, haebae@indiana.edu
                           Thomas Brush, Indiana University, tbrush@indiana.edu
                     Bradford Mott, North Carolina State University, bwmott@ncsu.edu
                   James Lester, North Carolina State University, mailto:lester@ncsu.edu
                    William Goss, University of Wisconsin–Madison, wgoss2@wisc.edu
                  Dana Gnesdilow, University of Wisconsin–Madison, gnesdilow@wisc.edu
                         Rebecca Passonneau, Penn State University, rjp49@psu.edu
                         Purushartha Singh, Penn State University, pxs288@psu.edu
                           ChanMin Kim, Penn State University, cmk604@psu.edu
         Marcelo Worsley (Discussant), Northwestern University, marcelo.worsley@northwestern.edu

         Abstract: This symposium will provide opportunities for discussion about how Artificial
         Intelligence can support ambitious learning practices in CSCL. To the extent that CSCL can be
         a lever for educational equitable educational change, AI needs to be able to support the kinds
         of practices that afford agency to students and teachers. However, AI also brings to the fore the
         need to consider equity and ethics. This interactive session will provide opportunities to discuss
         these issues in the context of the examples presented here.

Introduction
Artificial Intelligence (AI) offers opportunities for supporting computer-supported collaborative learning and the
kinds of ambitious learning practices associated with CSCL. We have recently argued that CSCL could be a lever
for educational equity through the use of ambitious learning practices (Uttamchandani, et al., 2020). By ambitious
learning practices we mean pedagogies that encourage collaboration, dialogue, inquiry, and productive
disciplinary engagement (Engle & Conant 2002; Glazewski & Hmelo-Silver, 2019). We call these learning
practices because they require much responsibility and agency from learners. For example, problem-based
learning, knowledge building, and other forms of collaborative inquiry, often involve disciplinary practices such
as explanation and modelling. These approaches abound in CSCL (Jeong et al., 2019; Hmelo-Silver & Jeong,
2022) but are resource-intensive both in terms of technology and the demands on teachers and learners. Recently,
Gomez et al. (2021) have argued for the importance of considering scale to really consider diversity, equity, and
inclusion in CSCL. AI offers that potential for scaling ambitious learning practices for diverse learners. In
particular, the incorporation of AI into CSCL provides new opportunities. These opportunities include analyzing
and providing adaptive support for collaboration, providing feedback for students engaged in complex tasks, and
reducing the cognitive load for teachers as they orchestrate student learning as well as future capabilities that we
are only beginning to imagine (Roschelle et al., 2021). Thus, we would like to extend this argument to the potential
for AI to advance these opportunities while trying to avoid the dystopian futures that Rummel, Walker, and
Aleven (2016) characterized in their depiction of students in a highly productive, yet highly mediated and
prescribed, learning environment.
          An important piece of the potential of AI includes attending to diversity, equity, and inclusion as well as
the ethical challenges that might be posed in ways that foster meaning making and agency. Ultimately, the benefits
of any innovation should be felt and experienced by everyone, which requires our design and implementation
approaches to expressly leverage affordances for a diverse range of learners. Unlike dystopian visions of AI, the
papers in this session have created learning environments that support agency for both students and teachers. In
creating these environments, the authors have considered, at least implicitly, how power is negotiated across
learners, teachers, and AI-augmented resources. These environments are designed to foster rich interactions that
empower learners to engage in ambitious learning practices and concomitantly, empowering teachers with tools




CSCL2022 Proceedings                                    525                                                   © ISLS
to manage the required but complex classroom orchestration (Dillenbourg et al., 2018; van Leeuwen et al., 2019).
These are the tools that can enable scaling of ambitious CSCL environments but with the caution that our designs
must reflect attention to equity and ethics (Roschelle et al., 2021).
          This symposium will be organized with time for brief large group presentations that introduce each of
the papers and smaller group discussions. Together, the papers document design, development, and empirical
research efforts. Indeed in the past year, much research has been design-focused because of the COVID-19
pandemic.
          Each presenter will have 5 minutes to share the major points of their paper and also address
 the following questions:

    1)   How did AI support developing learning environments that support ambitious learning practices?
    2)   What did AI uniquely afford?
    3)   How does your learning environment deal with issues of diversity, equity, and inclusion?
    4)   What are the ethical challenges that you have faced?

Small groups will then have 12 minutes to discuss the papers and create a slide to summarize their discussion.
The discussant, Marcelo Worsley, will then comment on the themes of the session and open up for a whole group
discussion, with a goal of foregrounding challenges related to issues of diversity, equity, inclusion and ethics.

Acknowledgements
This research was supported by NSF DRL # 2112635 and DRL # 2019805.

Ethical Consideration for Designing AI to Support Dynamic Learning
Transitions
LuEttaMae Lawrence, University of California Irvine
Nikol Rummel, Ruhr University, Bochum
Vincent Aleven, Carnegie Mellon University

Since individual and collaborative learning have different strengths, one way to leverage the benefits of both is
by allowing students to dynamically switch between the two modes based on their needs at the moment. Managing
dynamic transitions as students simultaneously work on different tasks is an ambitious learning practice because
it entails high orchestration load for teachers and careful personalization of learning transitions (Uttamchandani
et al., 2021). To support teachers, we investigated how AI and students can have a voice in deciding when these
transitions occur and how (Echeverria et al., 2020). However, designing orchestration tools with shared
participation requires explicit reflection on the equitable and ethical considerations regarding how these parties’
agency, bias, and privacy are accounted for in the tool (Holmes et al., 2021). The contributions of our paper
include findings regarding how teachers want to share control with students and the AI during dynamic transitions.
We share challenges to consider when leveraging AI in ambitious learning practices including navigating tensions
of agency, considering privacy and transparency, and reflecting on biases.
           The orchestration tool we developed and discussed in this paper helps teachers identify students who
may benefit from collaborative learning, pair and unpair students, and monitor their progress. The tool is
positioned in the context of two AI-based tutoring systems, Lynette, an individual problem-solving tutoring system,
and APTA, a collaborative tutoring system that supports mutual peer tutoring (Walker et al., 2014). We collected
data from 12 middle school math teachers participating in three design phases, including constructing low-fidelity
prototypes, feedback sessions, and user testing. We collected video data, observation notes, and artifacts from
activities and used thematic analysis to explore what teachers needed while orchestrating dynamic transitions
regarding shared control and the use of AI.
           A major theme was the need to include shared control between the AI and the teachers, rather than shared
control across all parties (e.g., teacher, students, and AI). Teachers rarely trusted the AI to make the decisions
alone, and while some teachers thought it was good to let the students ask to be paired with someone, many found
it too much to manage. They described needing the power to determine transitions between individual and
collaborative learning, not students or the AI. Teachers’ agency was important in facilitating learning transitions
because they could use social and contextual factors from students combined with data presented in the tool.
Teachers shared that data presented in the tool should be objective data, including progress, hints, and errors.
They described that sensitive information including classroom dynamics and social relationships should not be
embedded in the algorithm because this data is continuously changing and poses privacy issues for students. Many




CSCL2022 Proceedings                                   526                                                 © ISLS
teachers felt that sharing objective data with the system was equivalent to sharing an assignment or test; therefore,
was not a privacy concern. Finally, several teachers reflected on the potential for AI to hold themselves
accountable. For instance, one teacher described that the orchestration tool could help create new collaborative
pairs that have not worked together before by helping him reflect on his biases (e.g., not pairing students together
whom he assumed would not work well).
           Throughout our design process, and in preparation for initial pilot studies, we highlight three challenges
that we grapple with around equity and ethics when using AI to support ambitious learning practices.
           Navigating tensions of agency and user boundaries. Our project has explored how students' voices can
be embedded in dynamic learning transitions (Echeverria et al., 2020), yet we found in our design process that
many teachers were somewhat apprehensive about sharing control. Ignoring these concerns could cause teachers
to not use our technology because it breaks their boundaries for how they run their classroom, yet not including
students' voices compromises students’ agency in advocating for their own learning. This tension between
stakeholders is important to consider how we make decisions and whose voices we include. Our future work will
explore design features that give students agency in dynamic transitions, while navigating the boundaries of
teachers about holding power in the classroom.
           Privacy and transparency of data. Many teachers described that sharing data about students’ learning
process (e.g., hints, errors) in the orchestration tool was synonymous with data they collect in their classrooms
(e.g., tests, assignments), but more subjective data like classroom dynamics overstepped students’ privacy. There
are many issues of privacy and consent in AI education systems, wherein students should have the ability to
consent, or at least have transparency, about what data is being collected and how it is used (Holmes et al., 2021).
While algorithms have the potential to support ambitious learning practices, designers need to be sensitive to what
data is collected and whose perspectives are prioritized regarding privacy. In the present work, we report on the
needs of teachers, however, our past (Echeverria et al., 2020) and future work will continue leveraging students'
voices, recognizing that even if teachers do not see privacy concerns, does not mean students feel the same about
the use of their data.
           Reflecting on bias. Teachers in our study had the impression that the AI was an unbiased party and could
help them make more objective transitions. While we hypothesize shared control between parties has the potential
to mitigate issues of bias by embedding accountability across humans and AI, it also runs the risk of exacerbating
existing inequities. Our tool leverages both strengths and struggles of students to inform dynamic transitions, but
we recognize the need to help teachers interpret this data and be explicit about how the AI’s suggestions can be
biased and could be used to harm and police children (Holmes et al., 2021). To do so, we need to evaluate our
algorithms to identify and address any biases that may emerge and embed accountability and transparency across
all parties.

Acknowledgments
This research was supported by NSF Cyberlearning grant #1822861.

AI-Empowered STEM Learning in Open-Ended Environments
Gautam Biswas, Vanderbilt University

Our research group focuses on developing Open-Ended Learning Environments (OELEs) in STEM domains that
adopt a constructivist epistemology to support the acquisition of domain knowledge along with critical thinking
and problem-solving skills (Biswas, et al., 2016). Students working in these environments have a specified
learning goal, e.g., construct a model of a scientific process. To facilitate ambitious learning and problem solving
(Uttamchandani, et al., 2020), we have adopted AI and Machine Learning methods that provide students with
tools and resources that support hypothesis generation, solution construction, and hypothesis verification and
refinement in different phases of learning. Betty’s Brain (Biswas, et al, 2016), C2STEM (Hutchins, et al, 2020a),
and SPICE (Zhang, et al, 2019) are examples of OELEs developed by our group.
         In all of our systems, we adopt AI-driven modeling representations (e.g., causal maps, block-structured
programming languages) that are intuitive, visual, and executable. The ability to execute their evolving models
helps students develop important reasoning, explanation, and debugging strategies (Biswas, et al, 2016; Zhang, et
al, 2021). In recent work, we have exemplified the importance of AI representations in developing Domain
specific modeling languages (DSMLs) to scaffold students’ computational modeling of scientific phenomena
(Hutchins, et al., 2020b). DSMLs play an important role in students’ synergistic learning of the STEM domain
and computational thinking concepts and practices (Zhang, et al., 2021).
         However, OELEs can pose significant challenges, especially to novice learners who lack prior
knowledge in the domain. In past studies, we have observed that students have difficulties in keeping track of the




CSCL2022 Proceedings                                    527                                                   © ISLS
tools provided in the learning environment, and combining the use of these tools in an effective manner to
accomplish their goals. These problems are further exacerbated because students’ self-judgment and strategic
thinking abilities may not be well developed, and they may underestimate the effort required to accomplish their
tasks.
          To help students understand and overcome these challenges and make progress in their learning tasks,
we have developed adaptive scaffolding mechanisms in our OELEs that can monitor and interpret student
difficulties, and provide adequate support to help them overcome these difficulties. To reliably interpret and
respond to individual student difficulties, we have adapted model-driven learning analytics and data-driven
sequence mining methods in machine learning to understand students’ difficulties. With this understanding, we
have also developed response mechanisms that are contextualized to match students’ current task activities and
be compatible with their current level of proficiency (Kinnebrew, et al., 2017). Results of studies we have run in
middle school classrooms have shown that our adaptive scaffolding mechanisms led to improved student learning
and use of more effective learning strategies (Basu et al, 2017, Hutchins, et al., 2021).
          More recently, we have extended our approaches to provide adaptive scaffolding in collaborative
learning-by-modeling environments (Snyder, et al, 2019). The focus of our scaffolds has been to help students
solve problems by decomposition, and to help them develop debugging strategies to find and correct errors in
their computational models. This has led to important challenges in attributing students’ difficulties to their lack
of knowledge of the science content, or their inability to translate their science knowledge into the correct
computational forms. We have used discourse analysis to better characterize students’ difficulties, by developing
algorithms that facilitate automated interpretation of students’ knowledge co-construction approaches and their
social modes of interaction. We are currently developing deep learning based NLP techniques for automated
online analysis of discourse, and designing virtual agents that can act as an additional collaborative companion in
delivering these scaffolds. On the one hand, we believe that our adaptive scaffolding approaches using our AI/ML
methods increase equity and diversity by providing support to a wide variety of learners in their learning and
problem solving tasks. On the other, there are a number of open questions about how we may tailor these methods
and our adaptive scaffolding mechanisms to account for cultural and socio-economic differences among learners.

Acknowledgments
This research was supported by NSF (IIS) Cyberlearning award # 2017000 and a NSF STEM+C award DRL-
1742195

Combining Student and Teacher Feedback for Effective Science Writing
William Goss, University of Wisconsin-Madison
Purushratha Singh, Penn State University
Sadhana Puntambekar, University of Wisconsin-Madison
Dana Gnesdilow, University of Wisconsin-Madison
ChanMin Kim, Penn State University
Rebecca Passonneau, Penn State University

In this paper, we will discuss how we are supporting students in grades 6-8 to write explanations in science. We
conducted two participatory design studies with a total of 14 teachers to understand what feedback will be
useful to their students, and how the information from students’ writing should be presented to teachers. We will
present data from these studies and also from our classroom studies using the automated feedback provided to
students. Our approach to design includes working with teachers and students from a range of backgrounds and
with differing levels of writing ability. Writing science explanations is challenging for students especially
students who might struggle with writing in English. The examples from students with different backgrounds
that we are using during our design process will provide us with information on the difficulties students
experience in writing. Further, our dashboard will be available to support teachers working with students with
special needs in classrooms. This provides a way to support teachers to be sensitive to students who need
additional help, when a single teacher may not have the time to provide such individual support.
          Using evidence to build scientific explanations and make claims is a central practice by which scientific
knowledge is generated and learned (Berland & Hammer, 2012; Reiser, Berland, & Kenyon, 2012). However,
students often do not understand what a scientific explanation is and frequently write incomplete, non-causal
accounts of scientific phenomena (Seah, 2016), often without using data (Sandoval & Millwood, 2005).
Additionally, the complex, iterative, and time-consuming nature of writing explanations limits the timeliness and
quality of teachers’ feedback (Berland et al., 2016; Duschl & Bybee, 2014). We address these issues by providing
feedback to students both during and after they write explanations in science. Additionally, a teacher dashboard




CSCL2022 Proceedings                                    528                                                  © ISLS
will provide information to teachers about students’ writing, which they can use during class discussions. The
teacher dashboard will give insights to teachers about how well students are understanding the material they are
being taught, and give teachers the ability to address incorrect conceptions as they occur in the classroom. Our
design includes providing students with feedback at two stages–during writing and after completion of writing
explanations. In both stages, our focus will be on supporting students to include three key aspects of writing
science explanations, i.e., description of a scientific phenomenon, (2) providing explanation of relations including
causal relations; and (3) use evidence or patterns of data to support explanations which we adapted from Braaten
and Windschitl (2011).
          Support during the writing process: In the first stage, our focus will be on providing prompts that
cover all aspects of a scientific explanation mentioned above. Students’ explanations will be examined in real
time for descriptions of the phenomena, connections they are making, and for use of evidence. We will utilize
simple text mining techniques to ensure key ideas are mentioned in student responses, places where explanations
about key ideas could be strengthened. By examining past student responses, analyzed either by an automated
system or manually, we can determine how students represent ideas in their writing, and use the best responses.
This general technique can be applied to both equations and data as well, so students can be alerted when they are
overusing, or more likely, underusing these components to back their claims. As our project is used in more
classrooms, with more students, we will continue to collect more data to allow us to provide more accurate
feedback that is tailored to individual students.
          Support after students complete their explanations: To provide students with feedback on their
writing, we are adapting PyrEval—a wise crowd approach to content analysis (Passonneau et al., 2018; Gao et al.
2019a&b). The PyrEval software contrasts with previous work on automated writing support through its focus on
identifying complete propositions, and comparing the meanings of full propositions to recognize paraphrases of
the same content. In addition to quantitative scores on importance of ideas in a student passage, it also produces
a qualitative assessment that identifies which phrases used by the student correspond to more or less important
ideas. The original version of PyrEval constructs a model of important propositions derived from a small set of
reference passages independently written to the same prompt by expert writers—the wise crowd. It implements a
manual annotation method that was originally developed to assess the content of source-based summaries, e.g.,
reading comprehension passages. From pre-trained, high-quality vector representations of words in a large
vocabulary, it creates vector representations of propositions, essentially atomic tensed clauses. The original
version assigns a higher importance weight to ideas that are expressed in more of the wise crowd passages.
Through reliance on meaning vectors extracted from the wise crowd samples, the method assesses similarity of
meaning (content units) in a student passage to the model content units. For use in a middle-school setting with a
known curriculum, we have adapted PyrEval to use a content model that is partly derived automatically from
historical essays, and partly manually curated to align well with a rubric. Its ability to provide quantitative and
qualitative assessment of propositions provide a foundation to develop curriculum-specific and student-specific
feedback.
          We will also provide teachers with feedback on students’ writing. We will combine data such as the
content that was covered, how the content was presented, and relate that with the strengths and deficiencies found
in students’ writing.

Acknowledgments
This research was supported by NSF DRK-12 collaborative awards #2010351 and #2010438.

Human-centered Automation and Deliberately Limited Labels as Design
Principles of Ambitious Learning Practices
Suraj Uttamchandani, Indiana University
Asmalina Saleh, Indiana University
Haesol Bae, Indiana University
Krista Glazewski, Indiana University
Cindy E. Hmelo-Silver, Indiana University
Thomas Brush, Indiana University
Bradford Mott, North Carolina State University
James Lester, North Carolina State University

Ambitious learning practices are a natural way for CSCL scholars to conceptualize the relationship between
technology and equity. However, these practices are fundamentally a political approach to thinking about
pedagogy and require deep consideration of work that is explicitly sociopolitically and ethically informed if




CSCL2022 Proceedings                                    529                                                  © ISLS
they are to achieve their aims (Uttamchandani et al., 2020). Equity-oriented studies in the learning sciences,
for instance, often rely on promoting heterogeneity and utilize qualitative methodologies for understanding
and measuring learning (Uttamchandani, 2018). This task alone can be challenging in the CSCL context and
even more so when we factor in the role of AI in education. Because of their use of learning analytics, AI
projects may rely on a “normed” student model and flag those that are deviant (Aguilar, 2018). Further, AI
models tend to rely on quantifying and objectifying learning in order to function effectively. Separately from
this tension is the fact that AI technologies have and continue to be used with minoritized communities in
dangerous ways that make people wary of AI (for example, for privacy reasons) (e.g., Noble, 2018). In this
paper, we explore how we began to navigate these tensions through two principles: (1) human-centered
automation and (2) deliberately limited labels.
          We explore these tensions in the process of designing an orchestration assistant (OA) to support
middle school teachers and students to collaboratively investigate phenomena in complex ecosystems while
engaging with a problem-based learning scenario in a game-based learning environment, CRYSTAL ISLAND:
ECOJOURNEYS. Because such environments require demanding facilitation approaches, the OA leverages a
teacher dashboard, and extends the dashboard in ways that aim to support teachers in more successful
classroom orchestration (Dillenbourg et al., 2018; van Leeuwen et al., 2019). The OA will provide teachers
with real-time information about groups’ participation, progress, and nature of their scientific discussion. It
will have prospective tools to support teachers in lesson planning before class, concurrent tools to support real
time classroom orchestration, and retrospective guidance to support teachers in reflecting on how class went.
          AI technologies play a significant role in the design of the orchestration assistant. Machine learning
techniques are deployed to create models of how students engage with the learning environment, and are the
basis for understanding what information should be presented to a teacher (for example, because student
activity is somehow unusual). In addition, recommender systems can help discover teacher preferences and
patterns of use regarding group prompts or individual assistance. This in turn, can support teachers with
varying teacher expertise and instructional background. Computer vision techniques are deployed to process
students’ gaze, facial expression, and body posture to further ascertain and triangulate information about
students’ engagement or participation. AI techniques provide a way for teachers to monitor multiple students
at the same time, and support teachers in understanding their instructional practices by learning about their
preferences and facilitation strategies.
          In designing an orchestration assistant to support ambitious learning practices, several design
considerations at the intersection of ethics, equity and AI emerged. We consistently reminded ourselves that
the orchestration assistant is a human-in-the-loop technology, where human decision-makers are ultimately
responsible for taking consequential pedagogical actions. We were animated by a principle of human-centered
automation. Although dramatic, we use this term to intentionally move against dominant discourses that
envision the primary role of AI in the classroom as to automate things like giving feedback. While some
automation is part of our design, a principle of human-centered automation allowed us to focus on what is not
being automated: the decisions teachers make about what to say, to which groups of students, and when. Then,
AI technology is designed to help support those decisions through giving teachers a comprehensive, yet
tightly-focused and actionable amount of information about learners. The role of the AI, then, is truly to
support a teacher but never to replace one, and any automated features should be about “freeing up” the
teacher to make the kinds of consequential pedagogical decisions that only a teacher can given their
professional vision (van Leeuwen et al., 2019), and that are necessary for successful ambitious learning
practices. For example, the orchestration assistant provides the teacher with student information, but does not
evaluate teachers’ performance or reaction to that information. Instead, it provides teachers information about
their facilitation strategies in relation to specific group profiles and requests that the teachers evaluate the
effectiveness of these strategies.
          We were also guided by a principle of deliberately limited labels to enable teachers to think and act
expansively. While AI is often useful to sort and categorize students, we are cautious of how these groupings
are typically labeled and how they frame and sometimes even diagnose learners. We are especially cautious
about deficit framings that are routinely applied to students with disabilities, students of color, and other
minoritized students. For example, while groups progress through the game at different rates, it was crucial to
us that we did not label groups as “slow.” Similar framings to avoid were labeling students as “bad
collaborators” or “off-task.” Instead, we considered the information teachers needed to know because they
could contextualize that information, placing emphasis on descriptive but not diagnostic information. For
example, teachers are given information about where each group is in the game, without interpretation from
the AI labeling a group “behind.” Rather, we focused on the extent that student participation in groups are
relatively similar to one another. Then, the teacher is empowered to re-specify what is “normal” in their
classroom, or even abandon this idea. This also has the advantage of helping balance between giving teachers
too much raw data to be interpretable vs. over-interpreting such data.
          The principles of human-centered automation and deliberately limited labels provide a path to




CSCL2022 Proceedings                                   530                                                  © ISLS
continue thinking at the intersection of critical perspectives and AI technologies to design for ambitious
learning practices.

Acknowledgements
This work is supported by the National Science Foundation through grants IIS-1839966, and SES-1840120.

References
Aguilar, S. J. (2018). Learning Analytics: at the Nexus of Big Data, Digital Innovation, and Social Justice in
         Education. TechTrends, 62(1), 37-45. https://doi.org/10.1007/s11528-017-0226-9
Basu, S., Biswas, G., Kinnebrew, J.S. (2017). Learner modeling for adaptive scaffolding in a Computational
         Thinking-based science learning environment. User Modeling and User-Adapted Interaction, 27(1), 5-
         53.
Berland, L. K., & Hammer, D. (2012). Framing for scientific argumentation. Journal of Research in Science
         Teaching, 49(1), 68-94.
Berland, L. K., Schwarz, C. V., Krist, C., Kenyon, L., Lo, A. S., & Reiser, B. J. (2016). Epistemologies in
         practice: Making scientific practices meaningful for students. Journal of Research in Science
         Teaching, 53(7), 1082-1112.
Biswas, G., Segedy, J.R., & Bunchongchit, K. (2016). From Design to Implementation to Practice – A Learning
         by Teaching System: Betty’s Brain. International Journal of Artificial Intelligence in Education, 26(1),
         350-364.
Braaten, M. & Windschitl, M. (2011). Working towards a stronger conceptualization of scientific explanation
         for science education. Science Education, 95, 639-669.
Dillenbourg, P., Prieto, L. P., & Olsen, J. K. (2018). Classroom Orchestration. In F. Fischer, C. E. Hmelo-
         Silver, S. R. Goldman, & P. Reimann (Eds.), International Handbook of the Learning Sciences (pp.
         180–190). London, UK: Routledge.
Duschl, R. A., & Bybee, R. W. (2014). Planning and carrying out investigations: An entry to learning and to
         teacher professional development around NGSS science and engineering practices. International
         Journal of STEM Education, 1(1), 12.
Echeverria, V., Holstein, K., Huang, J., Sewall, J., Rummel, N., & Aleven, V. (2020, September). Exploring
         Human–AI Control Over Dynamic Transitions Between Individual and Collaborative Learning. In
         European Conference on Technology Enhanced Learning (pp. 230-243). Springer, Cham.
Engle, R. A., & Conant, F. R. (2002). Guiding principles for fostering productive disciplinary engagement:
         Explaining an emergent argument in a community of learners classroom. Cognition and Instruction, 20,
         399-484.
Gao, Y., Chen, S, & Passonneau, R.J. (2019a, Nov.). Automated Pyramid summarization evaluation. Proceedings
         of the 23rd Conference on Computational Natural Language Learning, (pp. 404–418). Hong Kong,
         China
Gao, Y., Driban, A., McManus, B. X., Musi, E., Davies, P. M., Muresan, S., & Passonneau, R. J. (2019b, August).
         Rubric reliability and annotation of content and argument in source-based argument essays.
         In Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational
         Applications (pp. 507-518).
Glazewski, K. D., & Hmelo-Silver, C. E. (2019). Scaffolding and supporting use of information for ambitious
         learning practices. Information and Learning Sciences, 120(1/2), 39-58.
Gomez, K., Gomez, L. M., & Worsley, M. (2021). Interrogating the role of CSCL in diversity, equity, and
         inclusion. In International Handbook of Computer-Supported Collaborative Learning (pp. 103-119).
         Springer.
Hmelo-Silver, C. E., & Jeong, H. (2022). Synergies Among the Pillars. In Handbook of Open, Distance and
         Digital Education (pp. 1-16). Springer Singapore. https://doi.org/10.1007/978-981-19-0351-9_83-1
Holmes, W., Porayska-Pomsta, K., Holstein, K., Sutherland, E., Baker, T., Shum, S. B., ... & Koedinger, K. R.
         (2021). Ethics of AI in education: towards a community-wide framework. International Journal of
         Artificial Intelligence in Education, 1-23.
Hutchins, N.M., Basu, S., McElhaney, K., Chiu, J., Fick, S., Zhang, N., & Biswas, G. (2021). Coherence across
         conceptual and computational representations of students’ scientific models. In E. de Vries, J. Ahn, & Y.
         Hod (Eds.), 15th International Conference of the Learning Sciences – ICLS 2021 (pp. 330-337).
         International Society of the Learning Sciences.




CSCL2022 Proceedings                                   531                                                   © ISLS
Hutchins, N.M., Biswas, G., Maróti, M., Lédeczi, Á., Grover, S., Wolf, R., … & McElhaney, K. (2020a).
         C2STEM: a System for Synergistic Learning of Physics and Computational Thinking. Journal of Science
         Education and Technology, 29(1), 83-100.
Hutchins, N. M., Biswas, G., Zhang, N., Snyder, C., Lédeczi, Á., & Maróti, M. (2020b). Domain-specific
         modeling languages in computer-based learning environments: A systematic approach to support science
         learning through computational modeling. International Journal of Artificial Intelligence in Education,
         30(4), 537-580.
Jeong, H., Hmelo-Silver, C. E., & Jo, K. (2019). Ten Years of Computer-Supported Collaborative Learning: A
         meta-analysis of CSCL in STEM education during 2005-2014. Educational Research Review, 100284.
Kinnebrew, J., Segedy, J.R. & Biswas, G. (2017). Integrating Model-Driven and Data-Driven Techniques for
         Analyzing Learning Behaviors in Open-Ended Learning Environments. IEEE Transactions on Learning
         Technologies, 10(2), 140-153.
Noble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism. New York University
         Press.
Passonneau, R. J., Poddar, A., Gite, G., Krivokapic, A., Yang, Q., Perin, D. (2018). Wise crowd content
         assessment and educational rubrics. International Journal of Artificial Intelligence in Education, 28(1):
         29-55.
Reiser, B. J., Berland, L. K., & Kenyon, L. (2012). Engaging students in the scientific practices of explanation
         and argumentation. The Science Teacher, 79(4), 34.
Roschelle, J., Lester, J. & Fusco, J. (Eds.) (2020). AI and the future of learning: Expert panel report [Report].
         Digital Promise. https://circls.org/reports/ai-report.
Rummel, N., Walker, E., & Aleven, V. (2016). Different Futures of Adaptive Collaborative Learning Support.
         International Journal of Artificial Intelligence in Education, 26, 784-795.
Sandoval, W. A., & Millwood, K. A. (2005). The quality of students' use of evidence in written scientific
         explanations. Cognition and Instruction, 23(1), 23-55.
Seah, L. H. (2016). Understanding the conceptual and language challenges encountered by grade 4 students
         when writing scientific explanations. Research in Science Education, 46(3), 413-437.
Snyder, C., Hutchins, N., Biswas, G., Emara, M., Grover, S., Conlin, L. (2019). Analyzing Students’ Synergistic
         Learning Processes in Physics and CT by Collaborative Discourse Analysis. In Proceedings of the
         International Conference on Computer Supported Collaborative Learning, Lyon, France (pp. 360-367).
Uttamchandani, S. (2018). Equity in the learning sciences: Recent themes and pathways. In J. Kay & R. Luckin
         (Eds.), International conference of the learning sciences (ICLS) 2018, volume 1 (pp. 480–487).
         International Society of the Learning Sciences.
Uttamchandani, S., Bhimdiwala, A., & Hmelo-Silver, C. E. (2020, 2020/09/01). Finding a place for equity in
         CSCL: ambitious learning practices as a lever for sustained educational change. International Journal of
         Computer-Supported Collaborative Learning, 15(3), 373-382.
van Leeuwen, A., Rummel, N., & Van Gog, T. (2019). What information should CSCL teacher dashboards
         provide to help teachers interpret CSCL situations? International Journal of Computer-Supported
         Collaborative Learning, 14(3), 261-289.
Walker, E., Rummel, N., & Koedinger, K. R. (2014). Adaptive intelligent support to improve peer tutoring in
         algebra. International Journal of Artificial Intelligence in Education, 24(1), 33-61.
Zhang, N., Biswas, G., & Hutchins, N.M. (2021). Measuring and Analyzing Students’ Strategic Learning
         Behaviors in Open-Ended Learning Environments. International Journal of Artificial Intelligence in
         Education.
Zhang N., Biswas G., McElhaney K.W., Basu S., McBride E., Chiu J.L. (2020). Studying the Interactions Between
         Science, Engineering, and Computational Thinking in a Learning-by-Modeling Environment. AIED
         2020. Lecture Notes in Computer Science, vol 12163 (pp. 598-609). Springer, Cham.




CSCL2022 Proceedings                                   532                                                 © ISLS
