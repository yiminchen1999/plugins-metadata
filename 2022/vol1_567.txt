           Development of an instrument to assess the quality of
                   collaboratively constructed notes
               Isis Tunnigkeit, Leonie vom Bovert, Julia Eberle, Sebastian Strauß & Nikol Rummel
       isis.tunnigkeit@rub.de, leonie.vombovert@rub.de, julia.eberle@rub.de, sebastian.strauss@rub.de,
                                             nikol.rummel@rub.de
                                           Ruhr-Universität Bochum

         Abstract: We developed a rating scheme to assess the quality of information pooling and
         reaching consensus in collaboration through the rating of a shared text document.

Introduction
During CSCL, we often explicitly encourage learners to share and elaborate on relevant information and instruct
groups to discuss not only shared, but also initially unshared information. But even if participants share all
important information verbally, they may fail to properly document it in writing and may not use it during their
collaboration and decision-making process. In situations, where large amounts of information from different
perspectives have to be considered, this may cause a loss of information and unfavorable outcomes. Therefore,
students are often encouraged to take notes during synchronous collaboration.
          Notes that students construct synchronously in collaborative settings can be categorized as text-based
artifacts (Trausan-Matu & Slotta, 2021). These artifacts serve the intersubjective knowledge building by making
the shared information visible and persistent (Stahl, Ludvigsen, Law & Cress, 2014). In being documented, this
information becomes the groups’ intersubjective knowledge and basis for decision-making and helps avoid long-
term loss of information. In addition to overcoming the information pooling dilemma (Stasser & Titus, 1985),
collaborative notes help the group to maintain awareness of consensus that was already reached. Consequently,
collaborative notes serve to support the central CSCL processes information pooling and reaching consensus that
are included in the dimensions that determine the quality of computer-supported problem solving and learning
processes proposed by Meier et al. (2007).
          Collaborative notes, thus, should be included in the analysis of CSCL settings, complementing the
analysis of video and log data. However, these notes have not received much attention in the analysis of data from
CSCL settings so far. With this contribution, we would like to put forward a rating scheme that allows us to
quantify and analyze the groups’ persistently shared information in collaborative notes and relate it to various
data sources.

Development of the Rating Scheme
The rating scheme was developed in the context of a study that aimed at fostering collaboration skills in higher
education students. Participants collaborated in groups of three via a video-conference tool. During the study
participants had to find a joint solution for two complex, open-ended problems in a learning phase and in a testing
phase respectively. Each learner received an individual role description with complementary information. To
solve the problem, pooling of the individual information was necessary. We encouraged the groups to use a shared
digital notepad to document their information sharing and decision finding processes.
          To quantify the qualitative aspects of the collaborative notes in the shared digital notepad, we opted for
a regular code and count approach. The unit of analysis is on the group-level, as specific notes cannot be traced
back to individual learners. We developed the rating scheme in an iterative process. For the initial development,
we used a sample of N=10 collaborative notes which we collected in a pilot study with 30 higher education
students. In this first step, we developed an initial set of codes by adapting the aspect joint information processing
including the dimensions information pooling and reaching consensus by Meier et al. (2007) and applied them to
the collaborative notes. We focused on these two dimensions because we expected them to manifest in the
collaborative notes since they document the discussion and problem-solving process.
          For the information pooling dimension, we broke down the assignment and role material into units of
information that we expected to appear in the collaborative notes because of their vital function for the joint
solution. From the units of information, we generated the codes on the information pooling dimension. Each
participant had a maximum of seven units of information to share with the group, containing requirements,
arguments and a solution proposal.
          The dimension of reaching consensus gives attention to the process of decision making. It aims at
discussing and critically evaluating information in order to make a joint decision. We created sub-codes based on
the way consensus was presented and elaborated in the pilot sample. Some groups highlighted pro and contra




CSCL2022 Proceedings                                     567                                                   © ISLS
arguments for different solution proposals with ‘+/-’ symbols for example. Groups differed in how elaborate their
final solution was: they ranged from simply stating ‘solution: first idea’ to explaining the final idea in detail and
justifying it with arguments. Therefore, the codes for evaluation of information and joint solution were rated
depending on how elaborate and consistently the information was processed and included in the final solution.
           We added grounding as a third dimension, after reviewing the remaining uncoded information in the
collaborative notes of the pilot sample. Grounding includes the introduction of participants and the designation
of a common goal.
           In a second step, we refined the initial rating scheme by writing out the codes concisely. We then applied
it in a laboratory study. The refined coding-scheme was used with a sample of N = 11 collaborative notes of 33
participating higher education students so far. The sample was coded and rated by two independent raters.

Result
The final rating scheme consists of three dimensions with several sub-codes: 1) Information pooling consists of
the three sub-codes unique requirements and arguments, unique solution proposals, and unshared information of
each role. If shared in the notes, the units of information in this dimension scored 0.25, 0.5 or 1 point depending
on their importance for the solution-finding process. 2) Reaching consensus consists of the five sub-codes sorting
information (by role or solution proposal), indication of pros and cons for each solution proposal, recording of a
consensual final solution, recording of requirements met/not met by the final solution and justification of the final
solution. Each sub-code is rated as non-existing (=0), partially found (=1) and consistently found (=2). 3)
Grounding consists of the three sub-codes indicating roles (=1), role names (=1) and indication of the common
goal (=1). Altogether, groups can reach a total of 25 points (information pooling=10, reaching consensus=12,
grounding=3) in the learning and the testing phase, respectively. The score indicates the quality of the group's
joint information processing and can then be used in statistical analysis.
          The two independent raters reached an Inter-Rater-Agreement of Cohen's Kappa=.66, which can be
interpreted as substantial agreement. We resolved remaining disagreements by mutual discussion and were able
to reach consensus in all cases. We successfully applied the rating scheme on a dataset of N=33.

Discussion and Outlook
We developed a rating scheme for synchronously and collaboratively constructed notes that document information
pooling and decision-making processes in CSCL settings. The rating scheme offers an additional way to assess
how well groups document their information pooling and decision-making process in writing and allows for
comparison between groups and different experimental conditions. The rating can be included in statistical
analyses. It has the potential to complement video data and can, therefore, help shed light on the role of
intersubjective knowledge building during information pooling and decision-making processes. We can assume
that groups which score higher on the information pooling dimension in their collaboratively constructed notes
also share more information verbally and discuss information more extensively. However, consistently noting
down information might also slow down or hinder the solution finding process. Therefore, the next step is to
further validate the newly developed rating scheme by comparing it to video data of the collaboration processes.

References
Meier, A., Spada, H., & Rummel, N. (2007). A rating scheme for assessing the quality of computer-supported
         collaboration processes. International Journal of Computer-Supported Collaborative Learning, 2(1), 63–
         86.
Trausan-Matu, S. & Slotta, J. (2021): Artifact Analysis. In: Cress, U., Rosé, C., Wise, A. & Oshima, J. (Eds.)
         (2021): International Handbook of Computer-Supported Collaborative Learning. Springer Nature.
Stahl, G., Ludvigsen, S., Law, N. & Cress, U. (2014): CSCL artifacts. International Journal of Computer-
         Supported Collaborative Learning, 9, 237–245.
Stasser, G., & Titus, W. (1985). Pooling of unshared information in group decision making: Biased information
         sampling during discussion. Journal of Personality and Social Psychology, 48(6), 1467–1478.

Acknowledgments
This research was funded by the German Federal Ministry of Education and Research (grant number:
16DHB3027). We want to thank Katharina Teich and Astrid Wichmann for their invaluable feedback and the
KoLiBRI project team for their support.




CSCL2022 Proceedings                                    568                                                   © ISLS
