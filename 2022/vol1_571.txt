Joint Choice Time: A Metric for Better Understanding Collaboration
                 in Interactive Museum Exhibits
                    Matthew Berland, University of Wisconsin-Madison, mberland@wisc.edu
                   Vishesh Kumar, Northwestern University, vishesh.kumar@northwestern.edu

         Abstract: In this paper, we propose a new metric – Joint Choice Time (JCT) – to measure how
         and when visitors are collaborating around an interactive museum exhibit. JCT uses a common
         “diversity metric” both for collaborative choices and for potential outcomes. We provide an
         implementable description of the metric, results from using the metric with our own data, and
         potential implications for designing museum exhibits. In our case, we applied the metric to a
         live exhibit game called “Rainbow Agents” in which museum visitors either play independently
         or work together to tend to a virtual garden using concepts from computer science such as agent-
         based modeling, programming, and parallelism. Our data showed that diversity of meaningful
         choices positively correlated with both dwell time and diversity of positive and creative
         outcomes.

Introduction
Science museums aim to support visible, transparent explorations and experimentation of different phenomena.
They carry unique potential to support many simultaneous "social configurations" in their visitorship – alone,
with family, friends, school groups etc. The social potential of museums is crucial to the experience, but there is
a dearth of quantitative measures describing how those social configurations affect people’s learning in the
museum. Loomis (1974) identified the need for research and design around how people collaborate to learn in
museums. Designing exhibits to specifically encourage pathways of social interaction and learning has the
potential to surface the social and community nature of the learning experience (Heath & Vom Lehn, 2013).
Thus, we as the designers sought to foreground social interaction around computer science content in designing
Rainbow Agents (Pellicone et al., 2019), a computing education game which situates players as programmers of
animals who sow seeds and water plants in a virtual garden. Visitors program their Rainbow Agents to
successfully grow and tend to a vibrant garden – using different programmable state machines presented as
friendly garden animals. Two touchscreen-based controllers are situated in front of a large, shared display. One
broader goal is to better understand how to develop experiences and games that support collaborative learning
across social configurations. Toward that end, we present an analysis of Rainbow Agents gameplay where we
try to understand the efficacy of off-table behavior through visitors’ in-game actions.

Joint Choice Time: A Lens on Interactive Museum Exhibit Design
Interactive museum exhibits can be tricky to measure, in part due to a diffuse set of learning goals, modalities,
and perspectives. In this paper, we detail a new metric – Joint Choice Time (JCT) – designed to measure how
visitors interact with an exhibit and with each other in ways that prioritize making choices simultaneously. In
contrast to simpler "count" metrics such as "time on task" or "joint dwell time", JCT prioritizes the meaningful
or disciplinary decisions that visitors make in an interactive exhibit. We provide an example using anonymous
log data collected from Rainbow Agents, a museum game designed to teach computer science. We find that as
JCT increases, all in-game "scoring" metrics also increase. There is value in developing a simple and portable
metric for quantifying, exploring, or identifying those choices. We call this “joint choice time”, aiming for a
quantified catalog of “choice moments.” “Choice moments” refers to moments of “consequence [for further
gameplay that must] alter the game” (Fullerton, 2019). In Rainbow Agents, almost every user action that results
in a change to the game state requires a meaningful choice. Our choice moments of focus span placement of
agent-flags and choice of cards.
          The EXTIRE framework (Berland et al., 2013) suggests that exploration of and tinkering with both
choices and outcomes can be a useful proxy for understanding creative, playful learning. As such, we used the
standard Simpson’s Diversity Index (SDI, Simpson, 1949), a simple metric applied widely across fields, to see
the range of exploration both of choices and outcomes. Though the fit is not perfect – SDI “prefers” a wider
variety of possibilities with a smaller number of “data collection events” – it is a well-tested metric with known
benefits and deficits, and it has been used in other visitor-focused museum education research (e.g., Roberts et
al., 2014). The basic SDI measure represents the probability that any two randomly chosen entities are of the
same type. For a sequence of actions, more exploratory behavior would be represented by a lower probability
that randomly chosen pairs of actions look the same. This metric can be calculated over time buckets (i.e.,
actions per unit time), action buckets (i.e., # of actions in a bucket), or in relation to other kinds of diversity (i.e.,




CSCL2022 Proceedings                                       571                                                     © ISLS
ratio of different plants and orbs to different cards used). To recognize the diversity emerging from collaborative
work, we contrast changes in diversity over time when visitors are solo versus playing jointly. In our analyses,
sdi outcomes is the SDI of the different plant possibilities on the rainbow agents shared garden; sdi choices is
the SDI of the different card and machine possibilities across players. Minutes played is the number of minutes
in either a joint or solo session with the exhibit. Active players is 1 if someone was using the exhibit alone, and
2 if two people were playing at the same time (i.e., jointly).

Results
The regression indicates a clear significant influence of both the number of joint choices (solo = 318, joint =
1373) on the diversity of the outcomes (F(df = 3, n =1733) = 105.3, p < .001, R2 = .16) even when controlling
for minutes played (solo mean = 2.93 minutes; joint mean = 9.11 minutes).

Discussion and Conclusions
The work presented here should serve as a valuable step towards identifying moments in which people are
having meaningful interactions with the exhibit and with each other. Joint Choice Time (JCT) is a relative
measure of the diversity of collaboratively making exhibit-impactful choices and the diversity of possible
outcomes. Both diversity measures come from the standard "Simpson’s Diversity Index" in ways that are
applied to game log data. While the use of “diversity of experience” as a proxy for valuable
interactions/outcomes may seem counter-intuitive, this approach is grounded both in theories of learning
(Schwartz & Arena, 2013) and educational game design (Gee, 2004). JCT is simple to code and trivial to
compute. Finally, one can readily design systems to maximize it. Our results consistently show two things: 1)
Visitors who work with other people spend more time making choices; and 2) As visitors spend more time
making choices together, more positive outcomes result (regardless of time spent). Furthermore, unlike
many outcome measures, JCT is amenable to being “gamed.” When dwell time is gamed, visitors may feel their
time is wasted. However, JCT motivates both collaborative choice making and diversity of outcome. If visitors
voluntarily spend time making a diverse array of choices with other visitors in ways that generate a diverse
array of outcomes, it is more likely to feel like a meaningful, social, educational experience for both parties.

References
Berland, M., Martin, T., Benton, T., Petrick Smith, C., & Davis, D. (2013). Using learning analytics to
         understand the learning pathways of novice programmers. Journal of the Learning Sciences, 22(4),
         564-599.
Fullerton, T. (2019). Game design workshop: A playcentric approach to creating innovative games. AK
         Peters/CRC Press.
Gee, J. P. (2004). What video games have to teach us about learning and literacy. Palgrave MacMillan.
Heath, C., & Vom Lehn, D. (2013). Interactivity and Collaboration: New forms of participation in museums,
         galleries and science centres. Routledge.
Loomis, R. (1974). Social Learning Potentials of Museums. American Educational Research Association
         (AERA 1974).
Pellicone, A., Lyons, L., Kumar, V., Zhang, E., & Berland, M. (2019, October). Rainbow Agents: A
         Collaborative Game For Computational Literacy. In Extended Abstracts of the Annual Symposium on
         Computer-Human Interaction in Play Companion Extended Abstracts (pp. 597-604).
Schwartz, D. L., & Arena, D. (2013). Measuring what matters most: Choice-based assessments for the digital
         age. The MIT Press.
Simpson, E. H. (1949). Measurement of diversity. Nature, 163(4148), 688–688.

Acknowledgments
For this work we thank our project team including Leilah Lyons, Mac Cannady, Eric Greenwald, Stephen Uzzo,
Eda Zhang, Maxine McKinney de Royston, and many others including staff at the museums operating Rainbow
Agents and hosting numerous visitors. Any opinions, findings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.
This material is based upon work supported by the National Science Foundation under Grant No. 1713439.




CSCL2022 Proceedings                                    572                                                   © ISLS
