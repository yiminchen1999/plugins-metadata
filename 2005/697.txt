      Exploring                 Collaborative                     Aspects               of    Knowledge
   Building Through Collaborative Summary Notes

                Jan van Aalst                  John Kamimura                          Carol K.K. Chan
         Faculty of Education                   British Columbia                     Faculty of Education
       Simon Fraser University                 School District 40             The University of Hong Kong
               vanaalst@sfu.ca              jkamimura@sd40.bc.ca                  ckkchan@hkucc.hku.hk

       Abstract. We explore the use of collaborative summary notes in Knowledge ForumTM (KF) as a
       way to capture the distributed nature of knowledge advances among groups of students building
       knowledge together. The purpose of this exploration is to develop assessments that can be used
       for  scaffolding    the  discourse   and   promoting     ideas  within   the   community,    as well   as   for
       evaluation.     The unit  of   analysis was  the  group   on   KF.  Students   in  two  high  school   classes
       collaborated    on  a  progressive   inquiry exploring    aspects  of  a  recent SARS    outbreak   and  some
       related  topics.  They   were  asked to  write  collaborative,   co-authored,  summary   notes  to  make   the
       nature and importance of the knowledge advances they achieved clear for their peers. The findings
       indicate that note ratings were positively related to the number of co-authors and the number of
       views (different discussion spaces) in which students had worked.

       Keywords: Knowledge building, assessment

INTRODUCTION
Theories  informing     CSCL    (Computer   Supported    Collaborative     Learning)  posit  learning  as collaborative   and
distributive (Brown, Collins, & Duguid, 1989; Salomon, 1993; Stahl, 2002), and more emphasis is now placed
on learning as participation in the practices of a culture (Roth & Tobin, 2002). Assessment practices have not
kept pace with these developments (Shepard, 2001). Chan and van Aalst (2004) identified three problems with
teacher-administered assessments. First, assessments need to capture both individual and collective aspects of
learning. Second, there is a need for assessments to capture both the learning outcomes and the (collaborative)
learning process. Third, there is a need for greater alignment of learning, assessment, and instruction. Currently,
it is widely    recognized that   assessment    is part of  the  instructional   process  and   it plays  a   central role in
scaffolding    (i.e., guiding)   student  learning  (Shepard,    2001).   With    the changing     conceptions   of   learning
emphasizing     social  and   constructive  nature  of   learning,  there  is   a need    to  develop  social-constructivist
assessments that give students the responsibility to assess their collaborative processes and learning outcomes.
    An example of an educational approach using a CSCL technology is `knowledge building', defined as "the
production     and continual    improvement    of  ideas of  value  to  a  community,     through  means   that  increase  the
likelihood that what the community accomplishes will be greater than the sum of individual contributions and
part of broader cultural efforts" (Scardamalia & Bereiter, 2003, p. 1370). Knowledge building emphasizes that
knowledge is the achievement of a community, and is improvable by means of discourse (Scardamalia, 2002).
Although much of a knowledge building discourse takes place in face to face interactions, a CSCL environment
is often used to support it and to provide a reliable trace of how ideas are developing. Students can use this trace
to  reflect on   the   community's    learning.    The software    most    often  used    by  proponents   of   Bereiter  and
Scardamalia's version of knowledge building is Knowledge ForumTM (KF), which has some specific features
designed    to support  working   with  knowledge.     Some   of  these features  are different ways   to  link  notes  (e.g.,
adding them as references to a new note), and views. A view refers to a space where notes are located, similar to
a "conference" in other CSCL environments. Students can create new views when, for example, a need for a new
discussion is emerging and they need a space for that discussion.
    van Aalst, Chan, and Lee developed a portfolio-based approach to assess the process of knowledge building
(Chan  &    van  Aalst,  2003,   2004;   Lee,  Chan,   &    van  Aalst, this  volume).    They  introduced  a  small   set of
"pedagogical    knowledge      building  principles"   describing     collective  and   individual  aspects   of knowledge
building:   (a) working    at the cutting   edge,  (b) progressive    problem    solving, (c) collaborative   effort, and  (d)
identifying high points of the discourse. For example, their principle `working at the cutting edge' requires that
students  collectively   raise  significant problems,    that is,  problems   that   take the  range   of ideas  within    the
community as well as the available authoritative sources of knowledge into account; it further requires that the
community      investigates  at least some  problems     of this  kind. Chan     and  van Aalst    (2003) asked  students  to
develop  electronic    portfolios in  KF,   using  clusters  of  notes  in the   KF   database  as artifacts. This  approach
revealed some metacognitive benefits, as students realized that the need of developing these portfolios helped

                                                              
them understand how they could best align their work in KF with knowledge building theory. Whereas these
studies examined     distributed phenomena,       the unit  of analysis   in  the assessment    was     the individual  learner.
More   research is needed    to improve    the  coherence   of the  assessment    task  and the    phenomenon    that   is being
assessed: collective phenomena should also be assessed at a collective unit of analysis (Stahl, 2002).
    A pedagogical problem highlighted by literature on knowledge building is that the completion of tasks takes
center  stage in   school (Bereiter   &   Scardamalia,     1993;   Hewitt,    2002).   This does      not mean   that  tasks are
unimportant   (see  Collins,    2002,   for a   discussion),   but that   the tasks  are  more  prominent     in the    students'
thinking about what they are doing than the learning goals. Students are more likely to say that they are writing
an  essay than  that they   are trying  to  articulate  lessons  learned  from   their analysis of    a problem, so   that those
lessons learned can find their way into the community's knowledge base. Although Hewitt analyzed the problem
in terms of instructional design and teacher roles, assessments also contribute to the problem because assessment
and instruction are "two sides of the same coin" (National Research Council, 1996; Shepard, 2001).
    The  goal   of this  study  was   to  explore    an assessment    strategy   designed   to  capture   collective as well  as
individual aspects of knowledge building. Most of the analysis focuses on a collective unit of analysis--a group
on KF. The students were asked to write collaborative summary notes to make the nature and importance of
what they learned clear for their peers. These notes were coauthored by all students in a group who were judged
by the students to have made significant contributions to that learning. The task required that students reflected
on the distributive nature of knowledge.

METHOD

Participants
The participants were students in a grade ten course on career preparation and research techniques (n = 21) that
was  part of  a pre-IB  (International   Baccalaureate)   program,    and a   grade  eleven course     on  computers   and  their
impact on a "global society" (n = 19), both taught by the same teacher at an inner city school in a metropolitan
center in Western    Canada.    Some   of  the  students   (approximately     40%)   were  familiar   with  KF.  However,    the
students did not have prior experience conducting an extended collaborative inquiry.

The     teacher
The teacher (the second author) had ten years of experience teaching mathematics and computer studies in middle
and high school. He completed a masters degree focusing on cognitive strategy instruction in 2002 and was in
his third year  of teaching  with   KF.    Prior  to  starting with KF    in  2001,    he attended    a four-day workshop    on
knowledge building led by Scardamalia and colleagues. The teacher gradually attempted to integrate knowledge
building  more   fully  into his teaching.     In the first year he taught    grade  eight  mathematics     and  posted  weekly
"challenge   problems."   His    belief  that   students   needed   considerable    skill  development      (factoring, solving
equations, etc.) to prepare for the next grade was an obstacle in attempting a more discourse oriented approach to
mathematics teaching (e.g., Lampert, Rittenhouse, & Crumbough, 1996). The next year, he taught a grade nine
course on personal development and research techniques that offered more flexibility. However, in this course he
also felt that students first needed to develop research skills before attempting knowledge building and he had
relatively little time available for knowledge building. The teacher's approaches up to this point reflect an often
held expectation    that students   need    to  develop   foundational    skills  before   they can     successfully  engage  in
knowledge building, rather than developing those skills in the context of student-directed inquiry. In the year of
this study, the teacher was ready for a more extensive implementation of knowledge building and agreed to a
two-month    student project    starting  within   a  few   weeks  of  starting  the course    (i.e., without  taking   time for
foundational skill development).

Procedures
At  the beginning   of  the  school year    the teacher and    researcher met  several  times   to discuss   how  to  make   the
pedagogical knowledge building principles (Chan & van Aalst, 2003) more central to the class's work, as well
as the role and nature of the final products the students should produce. A two-month unit was then designed in
which   students   could  investigate    some     problems   then   of  interest  to   Canadians--SARS,       Avian    Flu,  and
computer  viruses.   These   topics were    current, and   had a   loose  connection   to  the curriculum:    research   for the
grade ten class, and the use of a CSCL environment for the grade eleven class. The two classes shared a KF
database and worked on the same topics; the students were divided into four groups with an equal number of
students from each grade in each group. Each group had its own virtual workspace in KF and was not required
to interact with the other groups. Both classes had daily access to a computer lab during class time. A three-
phase inquiry model was used to provide some structure to students by which they could manage their inquiry
(van Aalst, 1999). This was considered necessary because both the teacher and students had limited experience
with extended collaborative student projects. The three phases of the project are described below.

                                                               
   Phase   one(two   weeks):   The  students   read widely  in  this  general  area, using  internet   resources as well   as
paper  resources. The   goal here   was to enable   students   to identify   some  problems   that  they could   investigate
(Polman, 2000). The students were then encouraged to prioritize a few of these problems and to develop brief
proposals. The goal of this process was to ensure that each group had promising ideas for inquiry, as well as
adequate  resources.  The  end  of  phase  one  resulted in  collaboratively   written  proposals  (in KF).  To  do  prepare
these  proposals,  students   first developed   a  process  for   prioritizing the problems   that   had  emerged,     as the
students in each group came form both classes and did not all meet face to face.
   Phase two (four weeks): The students researched their problems collaboratively, reading information on the
internet and from other sources. The students were encouraged to evaluate the likely credibility of the sources
(i.e., a web site by the World Health Organization could be more trustworthy than one by a person not declaring
his/her credentials),  and  to  examine    the evidence  for   the    claims made    in the  sources.  Some    papers  from
professional journals were introduced by the researcher        to improve the collection of trustworthy sources     students
were using.
   Phase   three  (two  weeks):  Collaborative    Summary    Notes    were   introduced  as a way   to  articulate what   the
group had learned about each problem it had investigated and on which it felt it had made some progress. These
notes  followed  a scientific  genre in  which  students   (a) stated  the problem   on  which   they  were  reporting;   (b)
explained the background of the problem, linking to their work in phase 1 in which they identified problems; (c)
described  what   they  did  to investigate  the   problem   and   reported  the  main   findings; and   (d) explained    the
significance of the findings as well as their limitations. The instructions to students, provided by the researcher,
stated: "Each note should report what the class has learned about a specific question. Do not write notes about
questions  that you  think   you did  not  learn   much  about.   ... Overall, there may    need to  be  perhaps   20  to  30
notes, but it may also be considerably less." These instructions also pointed out that a specific student could be
a co-author of several collaborative summary notes.

Data    sources,     measures,       and   analyses
The following data were collected:
   Server log data: To provide a general description of the KF database, the Analytic Toolkit for KF (Burtis,
1998) was used to examine the following variables: number of notes written, number of notes that were linked
to other notes,  number   of  views  worked    in,  and percentage    of notes in  the  database that  a student   had read.
According  to   Burtis, these   data are  basic  indicators  of   knowledge    building. Students   are  expected   to make
connections between ideas, which is typically represented by a high percentage of notes that are linked to other
notes.
   Ratings of collaborative Summary Notes: The collaborative summary notes were evaluated with the rubric
shown in Table 1. This rubric was provided to the students by the researcher and follows a style similar to other
rubrics used by the students at this school. All the summary notes were scored independently by the researcher
and a research  assistant specializing in educational technology, leading to an inter-rater agreement of 82%.

                                                          Table 1
                                 Rubric for Assessing Collaborative Summary Notes
 Criterion        D                        C                           B                               A
 Structure        At least two             At least one                All parts are complete, but     All parts are
                  components of the        component of the            the note may be longer          complete and
                  note are superficial     note is superficial or      than necessary and lacks        reasonably
                  or missing (1)           missing (2)                 focus (3)                       succinct (4)

 Co-authors       Not done (1)             Significant                 Most students who               All students who
                                           omissions in the            contributed to the ideas        contributed to the
                                           author list, or it is       and work are co-authors;        ideas and work are
                                           just a list of friends      there may be some               co-authors, but no
                                           (2)                         students who made only          students who
                                                                       minimal contributions. (3)      made only
                                                                                                       minimal
                                                                                                       contributions are
                                                                                                       coauthors (4)

Findings;         Significant errors in    Some reported               Findings are factual;  the      Findings are
significance      the reported             findings are                importance is explained         factual;
                  findings;                incorrect;   the            clearly, but some               the importance
                  importance of            reported importance         limitations are not pointed     and
                  findings is not          of the findings is          out (6)                         limitations are
                  pointed out (2)          questionable (4)                                            clearly
                                                                                                       explained (8)

                                                            
RESULTS

ATK     indices
The two    classes  collectively wrote   491 notes  (not  including the collaborative   summary   notes).  To  examine  if
there were differences in participation levels in KF, as measured by the ATK indices, a Group on KF by Grade
MANOVA       of   the three ATK    indices  was   performed.  The  findings  indicated   that there were   no  statistically
significant main effects. However, there was a significant Group by Grade interaction for Notes Written, F(3, 32)
=  5.19, p =  .005,   h2  = .33. Further  analysis  revealed that this  was because  in  group B,   grade eleven  students
wrote considerably more notes than grade ten students (on average16, compared with 6). Table 2 shows means
and standard deviations for notes created, the percentage of notes that were linked, and the percentage of notes
read for the four groups on KF.

                                                          Table 2
                                   Mean (SD) ATK Statistics for Four Groups on KF
                              Group A                Group B                 Group C              Group D
   Notes Created              14.9 (4.7)             11.2 (6.4)              15.9 (5.3)           13.1 (3.3)
   % Notes Linked             47.1 (18.0)            40.9 (18.5)             50.4 (15.3)          45.3 (17.3)
   % Notes in database        30.5 (13.7)            31.7 (20.3)             18.6 (4.7)           20.0 (5.2)
   Read

   These findings indicate that participation levels were somewhat higher than reported in other studies. For
example,   Hsi    (1997)  found  that  grade eight  students  wrote  on  average  4.82   notes over  an  18-week    period.
However, the percentage of notes linked was lower than expected. In some other classrooms, this measure was in
excess of 80%.

Initiating    the     inquiry
In phase one, the students did background reading and formulated research questions. Collectively, the students
contributed 200 notes during this phase (40.7% of the database), reflecting that students spent considerable effort
to articulate,  refine and  prioritize problems.  Of  the 200  notes,  55 notes   (27.5%)   were single   notes, 89  notes
(44.5%) were in 31 threads of 2-5 notes, and 56 notes (15.5%) were in 7 threads of 6-10 notes. These thread
lengths are commonly observed in online discussions (Hewitt, 2003). Within each group, between 42 and 50%
of the notes were read.
   The different groups each used approximately one-third of the notes in phase one to organize the task. (Not
all students had face to face contact, as they were from two classes.) For example, "... We're a little concerned
that not everyone will be gaining equal knowledge on these topics because some of us will not be as articulate
or as good in research as the others. Also, we will be true `experts' on only the subjects we researched on. It's
important    that everyone  has  a good   idea about  all of the subjects to be   covered." (a group  D   student).  Other
notes reported information that students found, and further questions that emerged.
   At the end of phase one, the students formulated research questions and voted on these to come up with a
small number of questions that they could research further in phase two. For this the researcher provided sample
notes which included the question, background, proposed procedures, and expected outcomes. Group D chose to
focus on the following questions. 1) How does fear affect our outlook on viruses? 2) What is the most effective
way to   minimize     the spread of  Avian   Flu? 3) What  caused   the recent  outbreak in China?   How   did   it return?
Other groups focused on the economic impact of SARS and on avian flu. For example, group A asked "Why
does the Avian Flu only transfer by being in close proximity to poultry and not through eggs or meat?" Group
B asked "Why has the media blown the SARS incident into such a large media explosion? If they hadn't have,
would   it have   become    a larger  problem?"   The discourse   leading up   to the research   questions merits   deeper
analysis   than  we can   provide  here, but from  these  examples  it  appears that all groups  arrived   at explanation-
seeking questions (e.g., Lipponen & Hakkarainen, 1997).

Collaborative         Summary       Notes
The students submitted 32 collaborative summary notes describing their knowledge advances. The notes were
evaluated using the rubric shown in Table 1; the rubric assessed the structure of the notes (4 points), the extent
to which students correctly gave credit to the contributions of collaboration (4 points), and the reporting of the
findings (8 points). The total of these scores was divided by four to obtain a note score between 0 and 4. We
first present one sample summary note and analyze its features in terms of the rubric, and then report the note
ratings  for all  summary   notes.  Ten  of  the 32  summary   notes  can be viewed   on  the  internet in a  virtual tour
(www.educ.sfu.ca/kb/KF_Databases/KF_Databases.htm, last visited February 28, 2005).

                                                             
Sample summary note
The note  shown    in Figure  1  was  written    by  a grade  10 student,  and  was  co-authored   by  two  other    grade 10
students and three grade 11 students.
     Research         Question      What    is    the  economic    impact     of  small-scale      or   large-scale
     quarantine?       How    much    are      we   willing     to   damage    the    economies      of    affecting
     countries      to   ensure   that     Avian     flu   doesn't   spread?     How  much    is   it  costing    the
     government       to  have   birds     tested,     in   relation     to   how  much    it's   costing     poultry
     farmers    to    slaughter   their     chickens?
     Background       Looking    at   the  SARS      outbreak    that   occurred    last   year,    many   countries
      and  their     economies      were   affected.       The   tourism    industry     for    many   cities     like
      Toronto    experienced        a   major     decrease      in   the   number     of   tourists      that     were
      visiting.     Everyone     was  scared      and    worried   about    getting    infected.     Now   that   the
      Avian    Flu    is  spreading,       again     the    fear   of   getting    infected,      or  having      your
      chicken    get   infected     is  everywhere.        There   have   been   outbreaks    here    in  BC,    close
      to  home,     so   it   is  important        and   interesting       to  look   at   how    this   virus    has
      impacted   our   economy,     and    how    worse  things    might   get.
     Method     To  find  information,         I  read   information     from   different     websites.    I   mainly
      looked    for    news     articles,         or   sites     that    belonged     to    the    WHO     or    other
      organizations,      because      I   think     that   these    are   reliable   sources,      and  have     good
      information      about    the   Avian      Flu   and   its   consequences.      I    also   read   the     notes
      posted    by everyone     in  our    group,    and   posted  my   own   notes  to  share    the   information
      I  found.
     Findings      I  found   that    the    main    country    that   has   been  affected     by   this  virus     is
      Thailand.     It   has  seen    a  13%   drop    in   the  number    of  international      arrivals.      Also,
      during    the   first  three    months      of  this  year,    the   export   value    of  poultry    products
      in  Thailand    had   a significant         decrease   (94%,   and   frozen   products    dropped    68%).
      Besides    Thailand,      Vietnam    has    also   been   affected    and   is  expected     to  have    a  cost
      of  $690   million     for  the    culling      of poultry.     An   outbreak   in   Hong    Kong   will    cost
      over  $10    million    (US),     and    the    outbreak    here   in   the   Fraser    Valley     could    cost
     about   $3  million      a  week.     This   shows    that  the   Avian   Flu   is  causing     damage    to the
     world's    economy,      even   though     it   might   not   be  as   bad  as  SARS.    It  wasn't    expected
     that   Avian     Flu would     have   such     a  great   impact,    and   some  experts     are  saying     that
     the   costs   aren't    too  bad    in  some    areas,   when   compared     to SARS.
     Importance       of  Findings      So,    by  looking     at  the   economic    impact     of  Avian   Flu,     we
      can  see   how   something     small,      and   maybe   not   very  important     can  become     a very   big
      problem.   This    virus   began     in  birds,    but  has  spread     to  humans   as well.    This    spread
      is  creating     fear   among    everyone.       Also,   starting    in   Asia,   this    virus    has   spread
      over  the    globe.     So  many     chickens      are   being    killed,    farmers      are   losing     their
      businesses,     and   this    is  creating       a huge    loss   of  money.   Earlier      it  was   expected
      that  the    Avian   Flu   wouldn't      have    such   a  great    impact,    and   would    be   lower    than
      SARS.    Maybe   the    amount    isn't     as   great    as   it  was   for   SARS,    but    it  shows    how
      something    small    can  spread     and   get   bigger,    and  could   lead  to   a great    loss.
                                                           Figure 1
                                           Sample Collaborative Summary Note

    This note   received an  overall  rating   of 2.5  out of 4.0, and   was  ranked 19  out  of  32  (1 being   the  highest
score). All of the sections were present, but some sections could have been done better. example, the background
section  could  have provided   links   to specific   notes the  group  had written  as part of  the work   it had   done  to
develop the research questions. The note received 3 out of 4 for structure.
    With regard to authorship, the note was co-authored by six students, which may be taken as a self-report of
how the main author thought the learning was distributed over group members. In some places, the main author
wrote in the first person ("To find information, I read information from different websites") suggesting that we
are dealing with    the   main   author's  personal    learning.   There  also  could   have  been   evidence    for specific
contributions made by co-authors, for example, by linking to notes written by them. Therefore, the note received
2 out of 4 for crediting co-authors. Many of the other summary notes were written in first person and lacked
specific credit to co-authors,   as was    the case  for this  note. This   suggests  that although   the  notes  may   have
reflected what the group had come to understand as a result of collaboration, the students needed more guidance
and time to make the notes reflect that. It is likely that many of the notes were written on behalf of the author
group by a single author.
    The note reported some findings and explained what they contributed to the class's understanding of Avian
Flu. However, the note does not accurately reflect what the group discussed and, by the teacher's observation,
understood. Certainly, after nearly a month of research        on  these questions   (after phase one)  by six   students  we

                                                              
would expect to see more evidence for understanding. The note received 5 out of 8 for reporting findings and
implications. The ability to capture what the group had learned was a problem with many of the notes.
  Overall, we were very pleased with most of the notes, including this one. However, our analysis indicates
that work could be done with the class to improve its understanding of and proficiency at some of the processes
involved  in creating a summary   note. Coming     late in the  course, the students were  rushed in  completing   the
assignment.  In future, students could  write summary      notes throughout  various    inquiry projects,  and thereby
have opportunities to improve them over time.
Quantitative analysis
Table 3 shows the scores for the different sections of the collaborative summary notes, as well as the overall
scores.

                                                        Table 3
                                 Evaluation of 32 Collaborative Summary Notes
                                                           Min.   Max.      Mean        Std. Dev.
                 Note Structure                             1       4        3.06         1.19
                 Co-authors Named                           1       4        2.09         1.09
                 Findings and Implications                  4       7        5.13         0.83
                 Note Score                                1.50    3.50      2.57         0.61

  Attention to the note structure was generally as expected (research question, background, method, findings,
and importance of findings), although in some cases one or two sections were underdeveloped. For the properly
naming of co-authors the mean score was 2.09 out of 4. Some notes listed students as co-authors but did not
make clear what the contributions of the co-authors were. For example, the students could have cited notes by
co-authors more  often  in the summary   notes,  or they   could have   described their contributions in   words. The
Findings and Importance of Findings sections were generally somewhat underdeveloped (mean score 5.13 out of
8). Some notes described the findings in general terms without going into the specifics of what the group had
learned.
  The 32 notes were divided into two levels with note scores below and above the median score. As Table 4
shows, group B wrote a relatively high number of notes with scores below the median (7 of its 9 notes) whereas
group C wrote relatively few summary notes (5, compared with 9 for the other groups). Group A had the highest
proportion of notes above the median. Although there were some between-group differences, no corresponding
differences were found for grade level.

                                                        Table 4
                                 Classification of Collaborative Summary Notes
                                                  Group A          Group B        Group C       Group D     Total
  Note rating           above median                 6                  2            3            4          15
                        below median                 3                  7            2            5          17
  Total                                              9                  9            5            9          32

  The notes were also examined for the impact of the number of co-authors (not the rating the notes received for
this) on the overall note ratings. As Figure 2 shows, notes receiving scores below the mean tended to have fewer
co-authors than  notes  with overall ratings  above  the   median;  a   Mann-Whitney    test showed   this effect was
statistically significant (Z = -2.97, p = .007).

                                                         
                    Co -Authors
                                 8

                                 7

                                 6                                 320

                                 5                                 4

                                 4

                                 3

                                 2

                                 1

                                 0
                                   N=                           17                                       15
                                                     Be low Me dia n                          Above Median

                                                                           Figure 2
                                      Number of co-authors with Note ratings below and above median

Exploring     the   collaborative                 summary              notes     as    assessments

Summary Note scores
There are many ways to obtain measures of collective (i.e., group) and individual achievement, and we explore
the following two:
·    Group Score: The sum of the scores for the summary notes by the group divided by the umber of students
     in the group.
·    Individual Score: The highest of the overall ratings of notes that the a student co-authored.
   Table 5   shows   the           group   scores, as  well as         the group   averages   and  standard       deviations  of  the individual
scores. As one may expect, not every student co-authored at least one note: 17 grade ten students (81.0%) and
16 grade eleven   students             (84.2%)   were co-authors          of  at least one  summary         note. In  this study, the  summary
notes  were  not used            for formal  student   evaluation;         if they had  been,  the teacher        would have  worked   with  the
students more    to ensure            that their contributions         to  KF    would  be  counted towards          their grade. Therefore, we
report statistics only for students who co-authored at least one collaborative summary note.

                                                                           Table 5
                                             Group Score and Mean (SD) of Individual Score
                                                    Group A                      Group B           Group C                 Group D
       Students in Group                                11                         10                       10                9
       Co-authors in Group                              10                         8                        7                 8
       Group Score                                     2.27                       1.88              1.45                     2.67
       Mean Individual Score                           3.20                       2.34              3.14                     3.19
       SD of Individual Score                           .39                        .48              .38                      .53

   As Table 5 shows there were considerable variations in the group scores. The group scores are influenced by
three factors. (1) The proportion of the students in the group who actually were co-authors of at least one note.
This  ranged from   .70            for group  C  to .91 for        group   A,    and is a measure  of       the extent  to  which learning  is a
distributive property            of  the group.  If it is low,         it  suggests    that some   students       were  not  represented by  the
summary notes. (2) The productivity of the group, the number of summary notes divided by the number of co-
authors. Some groups may have learned more than other groups or took the assignment more seriously. In this
study, this  measure            ranged   from .72   (group  C)         to  1.125  (groups   B and  D).      (3)   The quality  of the  summary

                                                                              
notes, as described by the rubric. These measures combine to form the group score as shown by the following
formula:
     GS = Â n i N ¥ fin ¥ NSi
Here GS is the group score, n the number of co-authors, N the number of students in the group, fi the frequency
of note score NSi, and the summation is over the different note scores for a group.
    Regarding    the   individual  scores,   one  may  expect   grade    eleven  students  to  outperform    grade    ten  students
because   they  are academically     more   advanced.  However,      a dependent    samples   t-test showed     this  was  not    the
case, t(31) = .545, p = .59, two-tailed. A one-way ANOVA revealed a significant Group on KF effect, F(3, 29)
=  7.096,  p =  .001,  h2   = .42; a post-hoc  test (Tukey-Kramer) showed        that  the mean   for group  B   was    lower   than
the means for all the other groups, with no differences among groups A, C, and D.
Relationship between individual scores and ATK indices
Among the 32 students who co-authored at least one summary note, the individual scores were correlated with
the number of views on which a student had worked, r = .42, p = .017. Regression analysis of the ATK data
showed that Notes Created was the strongest predictor of Views Worked On, adjusted                   R2 = .24.,     p =   .01. (This
is usually   considered     a moderate   association,  see   Abrami,   Cholmsky,      &   Gordon,    2001.)  Although      previous
research has revealed a relationship between Notes Created and measures of understanding (van Aalst, 1999), in
this study there was no direct relationship between Notes Written and the individual note scores. What mattered
more than writing notes was to create and work on multiple views. The creation of views is to some extent an
emergent property of the discourse--students create views as needed by their inquiry; Bereiter (2002) has argued
that emergence     is  an important    feature of  knowledge    building  (also  see  Sha  and  van   Aalst, this    volume).     So,
potentially the individual summary note scores capture an important aspect of knowledge building.

DISCUSSION                AND      IMPLICATIONS
In a well-functioning scholarly community, people are rarely begin a research project to produce a paper. Instead,
they work on problems that interest them and that can advance the state of knowledge in a discipline (Bereiter &
Scardamalia,    1993).    When    they feel they   are making    progress,    they  engage  in  a variety   of  tasks--including
writing papers--to make that learning available to the discipline for debate, further testing, and application. In a
scholarly community, understanding a problem is not enough. The understanding achieved must make impact
on the state of knowledge in that field, and that means that people must work to promote their ideas. Yet, when
we look at many implementations of CSCL technologies--KF included--the purpose of online discussion and
"research"   is to learn  enough    to write   a paper  that  does   not  serve  such   a  function.  That   is one    reason   why
proponents of knowledge building often speak of the task-oriented nature of schooling (Hewitt, 2002; Bereiter &
Scardamalia, 1993).
    In this study we explored an assessment task that may help us do better. The premise of the task was that
learning,  is   distributed,   and  that at  least  some     assessment   tasks    should  capture   the  distributed     nature   of
achievement. The students were asked to prioritize problems on which they would work collaboratively and then
wrote collaborative      summary     notes;  they   were  asked  to    acknowledge    the  contributions  of    all students    who
contributed to   the   group's    current understanding.     In this   study, the   assessment   task came   at  the    end    of the
course, was designed by the researcher rather than the teacher, and was not part of the formal evaluation scheme.
No doubt, the students saw it as "just another assignment." In future, the task needs to be designed by the class,
and it needs to be embedded in knowledge building discourse (Scardamalia, 2002), so that the summary notes
can be used to promote ideas. In this regard, the use of an inquiry model in which different inquiries had the
same  temporal     scale  (van    Aalst, 1999)   was   constraining.   In a   real  knowledge   building    community      (e.g.,   a
scientific community),        new  inquiries   are  beginning   all  the time,   and  different  groups   report    their  findings
whenever   they    are ready   to be reported.   Thus,  we   need  to  think  about  a knowledge     building   community       in  a
more fluid way than the inquiry model allowed. Then students write collaborative summary notes throughout
the  life of the community        (once the  community    has   had  a  chance   to develop   to  some   extent),     and there   are
opportunities for gradual improvement of the practice of writing collaborative summary notes.
    Our analysis of the summary notes identified several promising effects. First, more than 80% of the students
made contributions       to at least one  summary      note. That   is an indicator    of  what  Scardamalia    (2002)    calls   the
"democratization      of knowledge,"     and it  can   be used  to   reflect  on and   improve   the  class  discourse.    Second,
summary      notes  with    more   co-authors    received    higher    ratings.  This  effect  marks    a  possible     benefit    of
collaboration,   presumably     through   the  diversity  of the   ideas  and   perspectives  accounted   for   in    the summary
notes. However, for many notes this finding was based on self-reports and not on evidence identifying specific
contributions to understanding by individual students. Third, the weakest aspects of the notes in terms of the
ratings were summarization and making the importance of findings clear. This is not surprising as the students
had little experience with the task, but it does suggest that cognitive strategy teaching (the teaching of framing
questions, summarization, etc.) is necessary to improve this aspects of the notes. Nevertheless, we suggest that
it is not necessary to deal with this issue before knowledge building, as had been the teacher's practice in the
past. Indeed, we propose that cognitive strategy instruction should be situated in the class's efforts to improve

                                                                
on  the knowledge   building  discourse,   as   revealed    by  assessments   of this kind.  Previously,  we   argued for  a
similar scaffolding function of assessment in the context of portfolios based on pedagogical knowledge building
principles (Chan & van Aalst, 2003).
    Most of our analyses used the group on KF as the unit of analysis, and some analyses revealed significant
differences among these groups. Data from this assessment can therefore be used to interpret how the group is
doing as a community. In this study, group membership remained fixed throughout the class's work, but that is
not necessary. Groups can be assembled as needed by specific lines of inquiry that emerge in the class's work,
and a group that works together for a short time can contribute one or more summary notes to the community
discourse.
    Students are individuals, and we cannot completely escape evaluating individual students. In this study, we
went for simplicity  and   used  the  best  score   from    all the  summary   notes  a  student  co-authored  to  create an
individual score. This is clearly a subjective choice, and other researchers and teachers may prefer         to use central
tendency measures such as the mean or median. The measure we used had a medium correlation with the number
of views a student worked on. Although the number of notes created was a predictor of views worked in, it was
not  correlated with the  individual    scores. This  finding    is different from   previous findings   indicated that   the
number of notes created is a strong predictor of conceptual understanding (van Aalst, 1999). The current finding
may reflect emergent properties of knowledge building, viz. that a group creates new views to accommodate the
needs of the discourse.
    We see the assessment task we have discussed as prototypical. Additional assessment tasks are needed that
explore  different ways   of  obtaining    individual  scores   that can  be  used to   scaffold  and evaluate  knowledge
building. Additional research is also needed to examine relationships among the summary note scores and other
assessments such as growth of domain knowledge and a range of trait variables. It also requires research to
establish the findings reported above in settings where the assessment task is used for formal evaluation.

ACKNOWLEDGMENTS
This research was supported by a Discovery Parks grant from Simon Fraser University and the Social Sciences
and  Humanities    Research  Council    to the  first author    and  a grant  from The   University   of Hong  Kong    Vice
Chancellor   Research    Fund  to  the   first  and   third  authors.  We  thank   the   students for  their inquiries  and
collaborative summary notes, as well as Andrea Sator, who provided classroom assistance.

REFERENCES
Abrami, P.C., Cholmsky, P., & Gordon, R. (2001) Statistical analysis for the social sciences: An interactive
        approach . Needham Heights, MA: Allyn & Bacon.
Bereiter, C., & Scardamalia, M. (1993) Surpassing ourselves: An inquiry into the nature and implications of
        expertise. Chicago, Illinois: Open Court.
Brown,   J.S.,  Collins, A.,  &  Duguid,    P.  (1989)   Situated    cognition and   the culture  of learning. Educational
        Researcher, 18, 1, 32-42.
Burtis, J. (1998) The analytic toolkit. The Ontario Institute for Studies in Education, The University of
         Toronto: Knowledge Building Research Team.
Chan,   C.K.K.,  van Aalst,   J. (2003)    Assessing     and scaffolding  knowledge     building: Pedagogical   knowledge
        building   principles and    electronic portfolios.     In  B.  Wasson,   S.  Ludvigsen,   and   U.  Hoppe  (eds.),
        Designing for change in networked learning environments. Proceedings of the International Conference
        on  Computer     Support  for   Collaborative    Learning    (pp. 21-30).  Dordrecht,    the  Netherlands: Kluwer
        Academic Publishers.
Chan,   C.K.K.,    & van    Aalst,   J.  (2004)  Learning,      assessment,   and  collaboration   in  computer-supported
        environments. In J. W. Strijbos, P.A. Kirschner, and R. Martens (Eds.), What we know about CSCL in
        higher  education:  and  implementing    it   in higher    education  (pp. 87-112).   Dordrecht,  the  Netherlands:
        Kluwer Academic Publishers.
Collins, A. (2002) The balance between task focus and understanding focus: Education as apprenticeship versus
        education as research. In. T. Koschmann, R. Hall, and N. Miyake (Eds), CSCL2: Carrying Forward the
        Conversation (pp. 43-47). Mahwah, NJ: Lawrence Erlbaum.
Hewitt, J. (2002) From a focus on task to a focus on understanding: The cultural transformation of a Toronto
        classroom.   In. T.   Koschmann,     R.  Hall,    and    N.  Miyake    (Eds),   CSCL2:    Carrying   Forward      the
        Conversation (pp. 11-41). Mahwah, NJ: Lawrence Erlbaum.
Hewitt,  J. (2003).  How   habitual   online   practices affect  the development     of asynchronous   discussion  threads.
        Journal of Educational Computing Research, 28, 1, 31-45.
Hsi, S.  (1997). Facilitating    knowledge   integration    in  science through   electronic  discussion: The  multimedia
        kiosk forum. Unpublished doctoral dissertation, University of California, Berkley, CA.
Lampert,    M.,  Rittenhouse,    P.,  &    Crumbaugh,       C.   (1996)   Agreeing    to  disagree:   Developing   sociable
        mathematical  discourse.   In   D.R.   Olson   &    N.  Torrance  (Eds.),  Handbook    of  education   and  human
        development (pp. 731-764). Cambridge, MA: Blackwell.

                                                             
Lipponen,    L., & Hakkarainen,   K. (1997).  Developing   culture of inquiry in computer-supported    collaborative
       learning.   Proceedings of  the Computer-Supported     Collaborative    Learning (CSCL      97) Conference,
       University of Toronto, 10-14 December, 1997.
National Research Council (1996) National science education standards. Washington, DC: National Academic
       Press.
Polman,   J. (2000)  Designing project-based  science: connecting  learners  through  guided inquiry.   New  York,
       NY: Teachers College Press.
Roth,  W.-M.,    &  Tobin, K.  (2002)  College   physics teaching:  from   boundary  work to border    crossing and
       community    building.  In P.C. Taylor,  P.J. Gilmer, and   K. Tobin  (Eds.), Transforming   undergraduate
       science teaching: Social constructivist perspectives (pp. 145-174). New York: Peter Lang.
Salomon, G. (Ed.) (1993) Distributed cognition: Psychological and educational considerations. Cambridge, UK:
       Cambridge University Press.
Scardamalia, M. (2002) Collective cognitive responsibility for the advancement of knowledge. In B.
         Smith (ed.), Liberal education in a knowledge society (pp. 67-98). Chicago: Open Court.
Scardamalia, M., & Bereiter, C. (2003) Knowledge building. In Encyclopedia of education (2nd ed., pp. 1370-
       1373). New York: Macmillan Reference, USA.
Shepard, L. E. (2000) The role of assessment in a learning culture. Educational Researcher, 29, 7, 1-14.
Stahl, G. (2002)   Rediscovering  CSCL.  In  T. Koschmann,   R. Hall,  and  N. Miyake   (Eds.), CSCL   2: Carrying
       forward the conversation (pp. 169-181). Mahwah, NJ: Lawrence Erlbaum.
van Aalst,   J.  (1999) Learning,    knowledge   building, and     subject matter knowledge     in school  science.
       Unpublished doctoral dissertation. University of Toronto, Toronto, ON, Canada.

                                                         
