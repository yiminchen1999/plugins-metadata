            Students Assessing Their Own Knowledge
    Advances in a Knowledge Building Environment

       Eddy Y.C.        Lee                     Carol K.K. Chan                            Jan van Aalst
       Raimondi College                       Faculty of Education                      Faculty of Education
h9297168@hkusua.hku.hk                      University of Hong Kong                    Simon Fraser University
                                             ckkchan@hkucc.hku.hk                        vanaalst@sfu.ca

       Abstract. We describe the design of a knowledge-building environment and examine the roles of
       knowledge-building   portfolios   in  characterizing  and  scaffolding  collaborative inquiry.  Three
       classes of Grade 9 students in Hong Kong used Knowledge Forum (KF) under several design
       conditions. Results showed (1) Students working on portfolios guided with knowledge building
       principles showed more participation, deeper inquiry and conceptual understanding than students
       working on KF only, or producing KF portfolios with no principles, (2) Students' knowledge-
       building   inquiry and  discourse    were   related   to their  conceptual  understanding,     and  (3)
       Knowledge-building     portfolios  provided    ways   for  identifying  and characterizing  collective
       knowledge advances in the community.

       Keywords: Knowledge building, assessment, portfolios, inquiry, computer discussion forums

INTRODUCTION
There  is now   increased  evidence   of the  cognitive   benefits of  computer   supported  collaborative  learning.
Research using asynchronous networked environments has shown how they help students advance understanding
and inquiry, construct knowledge socially, and develop subject-knowledge understanding (CaMile, Guzdial, &
Turns, 2000; Knowledge Forum, Scardamalia & Bereiter, 2003). Despite much progress, there remain questions
regarding the integration of assessment, instruction and curriculum in CSCL classrooms, and specifically about
the design of assessment to support and characterize learning and collaboration in classroom context.
    Whereas networked computer discussion is becoming increasingly popular, many challenges and difficulties
exist  pertaining to the  quality and  variability in student   participation (Hewitt, 2003; Lipponen,   Rahikainen,
Lallimo, & Hakkarainen, 2003). As well, there are issues concerning teacher assessment of students learning.
Investigators have come to recognize that asking student to interact and discuss on computer forums does not
necessarily lead to high-quality discourse. Hence the questions, How can students best learn about inquiry and
collaboration when engaging in computer-supported discourse? How can classroom assessments tap into the
theoretical nature   of  collaborative process     while  providing   pedagogical  support   in scaffolding   student
understanding?    This study examines the designs and roles of electronic portfolio assessments in characterizing
and   fostering collaborative inquiry  in   the  context  of Knowledge     Forum,  a   computer-networked     learning
environment (Scardamalia & Bereiter, 2003).

Knowledge Building as Collective Cognitive Responsibility
In this paper, knowledge building is defined as "the production and continual improvement of ideas of value to a
community" (Scardamalia & Bereiter, 2003, p. 1370) emphasizing `improvable ideas' and `collective cognitive
responsibility." Similar to the process of scientific and scholarly inquiry, ideas are viewed as conceptual artifacts
that can be examined and improved by means of public discourse within the knowledge-building community. In
knowledge-building    communities,   students   make  progress   not  only in  improving their  personal  but also  in
developing collective knowledge through progressive discourse. Knowledge building, according to Scardamalia
(2002) may be summarized in a set of twelve knowledge building principles (i.e., epistemic agency, improvable
ideas, community     knowledge,    diversity  of   ideas,  rise-above, authentic   problems,   constructive   uses of
authoritative sources) identifying distinctive features and dynamics of the process.
  To support working with knowledge, Knowledge ForumTM (KF), a web-based discussion forum, has been
designed. A KF database is entirely created by students. Using networked computers, a number of users can
simultaneously create notes (text or graphics) to add to the database, search existing notes, comment on other

                                                          
students' notes,   or organize  notes  into   more  complex     structures.  The   communal   database   serves as  an
objectification of the community's   advancing knowledge.       Features of KF are   designed to help students  reframe
and advance ideas. For example, when writing a note in KF, students can add other notes as references,          thereby
creating an integrated web of notes (ideas) as their work proceeds. The visual linkages between ideas provide an
important image for students, reflecting the interconnected and dialogical nature of knowledge that underpins the
knowledge building perspective. Scaffolds or sentence starters such as `My Theory' and `I Need to Understand'
are metacognitive prompts that can also be used to make the communicative intent of the information clear. For
example, the scaffold `My Theory' indicates that the information presented in the note is conject ural, and that it
should be subjected to critique, testing, and application.

Learning, Assessment, and Collaboration
A   major  thrust  of CSCL   studies  is  quantitative  and   qualitative  analyses  of collaborative  processes,   and
evaluation and assessment of systems and designs (e.g., Dillenbourg, Eurelings, & Hakkarainen, 2001; Stahl,
2001). Yet much less attention has been given to formative, embedded, and transformative aspects of assessment
in collaborative inquiry, that is, how assessment can be used to scaffold students' collaborative inquiry and
understanding. Analyses of computer discourse in computer networked environments and forums are common;
current approaches focus on researcher-designed tools and analyses; but few are designed to provide scaffolds or
to foster agency for students in CSCL classrooms.       Despite the popularity of forums and networks, investigators
have come to realize that putting students together does not mean they will engage in collaborative inquiry and
deep discourse.    Problems  exist with   low and  variable   participation  rates  and quality of  discourse.  In the
following, we examine several issues about the alignment of learning, assessment and collaboration:
Assessment of Learning and Assessment for Learning
There have now been major shifts in paradigms of learning and instruction, and current views propose that
assessment play the dual roles of scaffolding learning and measuring it (Bransford, Brown, & Cocking, 1999;
Black & William, 1998; Gipps, 2002; Shepard, 2000). Assessments need to be designed so that they are parts of
the instructional  processes in    fostering  learning. The   scaffolding    aspect of  assessment, sometimes   called
assessment for learning (Black & William, 1998), involves designing assessments in ways that foster learning.
Despite major shifts in assessment reforms, little work has been conducted in aligning learning, assessment with
collaboration in CSCL settings. Even though high-level goals are professed in computer-based instruction, when
it is time for assessment, superficial knowledge is often emphasized (Chan & van Aalst, 2004; Reeve, 2000).
Students need to be given the agency to assess their own and community knowledge advances.                 Assessment
should be designed as a tool that both measures and fosters deeper inquiry and collaboration.
Assessment of Individual and Collective Aspects of Learning
Collaboration is valued in a wide range of social constructivist learning approaches, and there has been much
research progress on collaboration (e.g., Koschmann, Hall, & Miyake, 2002). On the other hand, learning is
nearly always evaluated at the level of individual learning outcomes in assessing the effectiveness of systems and
designs (e.g., Dillenbourg et al., 2001). For example, Scardamalia, Bereiter, and Lamon (1994) emphasized a
public knowledge building discourse. Yet they provided only assessments such as reading levels and depth of
explanation at the individual differences level. This choice is problematic because when a theory is contributed to
the public discourse   and  the community     works on   it, the theory   no  longer belongs  just to the student  who
contributed it. It belongs to all in the community who worked on it. Students' individual learning attainments are
important; however, there is a need to examine how we can assess collective aspects of knowledge advances.
Assessment of Content and Process.
Constructivist epistemology    says  that knowledge     is constructed.   If we  want  to  prepare students for future
learning--with less dependence on a teacher--we need to teach them to execute, monitor, and regulate the
knowledge construction process. This would suggest that we must value not only what academic content is
learned,  but also how   students  achieve   the learning.   In higher  education,   there may  be  some  emphasis  on
constructivist teaching and learning using asynchronous networked environments, but when assessment is carried
out, primarily discrete knowledge and skills are considered.     Even in more sophisticated environments involving
peer learning, when group process is assessed, the assessment tends to focus on superficial features, such as
whether   students are contributing  "equally" to  the  group   work.   We   submit  that assessment  should   tap both
collaborative process and knowledge products.

Assessment of Knowledge Building and Portfolios
This study aims to examine the roles of student-directed portfolio assessment in characterizing and scaffolding
collaboration  and    understanding. In   the CSCL      literature, there are  several  examples   of student-directed

                                                           
assessment: self and peer-assessment in the SMART Environment (Vye, Schwartz, Bransford, Barron, Zech
(1998), and reflective thinking in Thinker Tools (White, Shimoda, & Fredericksen, 1999). In our earlier studies,
we have   examined    the use   of student-directed  portfolio   assessments  to   characterize    and  foster  knowledge
building. We first designed knowledge-building principles and electronic portfolios for a graduate class (van
Aalst & Chan, 2001) and further refined the designs in a Grade 12 classroom using communal portfolios (Chan
& van Aalst, 2003). Students were asked to identify exemplary clusters of notes of their own and the class' best
work  and  write   a rise-above  portfolio  note  referencing  these   notes and    explaining   the selection.   We  also
examined individual knowledge advances using the notion of depth of explanation (Hakkarainen, Lipponen, &
Jarvela,  2002). Students' participation in  database   usage  (e.g., number  of   notes read,  written,  linked, revised)
was assessed using server-log data with a programme called Analytic Toolkit developed by the Knowledge-
Building Team (Burtis, 1998).    Across different studies, we have found that portfolio scores were correlated with
participation and conceptual understanding (Chan & van Aalst, 2003). Whereas portfolios commonly refer to
individual's best work, we pioneered the notion of knowledge building portfolios for which students are asked to
identify collective knowledge advances documenting the community's best work and progress.
   The present paper continues this line of inquiry addressing the problem of assessing individual and collective
knowledge advances in evaluating knowledge building. There are several refinements in our design: First, the
earlier studies  were  conducted   with  graduate  students  and  Grade   12 students    in   small classes.   We want  to
examine, here, whether electronic portfolios can be extended to younger students in larger classes, thus exploring
its value as a teacher assessment approach. Second, we earlier used four knowledge building principles for note
selection; we now extend the use of knowledge building principles as scaffolds for student note writing as well as
note selection.  In particular, we ask students to write an essay on the basis of the portfolios thus investigating the
relations between    collaborative process   and  knowledge    products. Third,    our earlier studies   included  several
components in the learning environment, and portfolio assessment was only one of them.              Although it is typical
of studies in technologically rich classrooms, the roles of knowledge-building principles and portfolios have not
been  specifically   examined.  In particular, it is not   clear whether  it is   the  portfolio   task itself or the task
augmented with the use of knowledge building principles that brought about the positive effects. This paper
describes  our   refined design  for knowledge-building      portfolios. As  well,    we  examine    specifically  several
classrooms   using   Knowledge     Forum   (KF)   only, KF    with    portfolios, and  KF   with    portfolios  guided  by
knowledge-building principles. While we recognize the complexity of classroom conditions, the comparison may
help to illuminate the roles of knowledge building principles and portfolios.
   In   sum,   the goal   is to examine    a knowledge-building       environment     using   portfolio  assessments    for
characterizing and assessing collaboration and conceptual understanding. There are several objectives: (1) To
examine   whether    students  using portfolio   assessments   with   knowledge     building   principles  showed     more
participation,  deeper inquiry  and  conceptual   understanding    compared   to   their counterparts,   (2)   To examine
different ways to assess knowledge building and investigate whether knowledge building inquiry and discourse
are related to students' conceptual understanding, and (3) To examine how knowledge building principles and
portfolios characterize and scaffold collective knowledge advances.

METHOD AND DESIGN

Participants
The participants were 119 students studying in four grade-nine Geography classes in a regular high school in
Hong    Kong,  taught  by the   same teacher.  Three    of the classes  were  engaged    in   knowledge   building  using
Knowledge Forum with different conditions. The fourth one was a comparison class that was not using KF;
students in this class were required to submit a paper and pencil portfolio. The students at this school had high
average abilities, they studied from English textbooks, and wrote in English on KF. Students were taught by an
experienced    geography  teacher   with over   12  years   of teaching  experience;     he   also  had  several  years of
experience using knowledge building pedagogy and Knowledge Forum.

The Classroom Setting
Knowledge Forum was implemented in the geography curriculum starting in the second semester                for a period of
three months. The teacher integrated knowledge building pedagogy with the school curriculum. A number of
curriculum  units  were  taught including  "Ocean    in Trouble",  "Rich  and     Poor ," and "Saving   our  Rainforests".
Students were asked to discuss the topics on Knowledge Forum after school, and problems emerging in the
computer discourse were discussed in class.      Students in the comparison class also worked after school because
they needed to submit a paper-and-pencil portfolio.

                                                           
Design of the Learning Environment

The course was organized and informed by the knowledge-building pedagogy; students worked on Knowledge
Forum  as they  generated   questions,   posed   alternative theories  and hypotheses,  brought in   new   information,
considered different students' views, and reconstructed their own understanding. Knowledge Forum was not
used as an addition of computer software to the classroom activities; instead the knowledge-building principles
and the work with Knowledge Forum were integrated with classroom instruction.
Developing a Collaborative Classroom Culture
Before the implementation of Knowledge Forum, students were provided with learning experiences acculturating
them into the practices of collaborative learning.   Such learning experiences are particularly important for Asian
students who are generally more used to a didactic mode of teaching.           Several group learning activities were
included, for example, jigsaw learning and collaborative concept mapping.
Introduction to Knowledge Building and Knowledge Forum
Knowledge building was implemented in the three classes in early February.           The teacher created a view called
"World Problems and How to look after the W orld" that was used as the focal problem. Three sub -views were
included: "Rich and Poor", "World Oceans", and "Tropical Rainforests" that link up the fragmented topics of the
textbooks to allow for sustained inquiry.    Typically the teacher wrote an introduction that explains the purposes
of each view. As with other knowledge-building classrooms, students posed questions and problems; they made
conjectures, examined different explanations, revised their `theories'as they examined each other 's KF notes.
Deepening Knowledge Building Discourse and View Management
As the number of notes increased with time, teachers worked with students and identified sub-themes and created
rise-above views.  Clusters of notes were grouped, and key issues highlighted with the class.      Students were also
asked to pose `rise-above' notes. View maintenance and continuous updating of views in the database made it
easier for the community to identify the focus and themes of notes. Student could see more easily what was
current in the views and focus their reading and writing.
Embedded and Concurrent Assessment Using Knowledge Building Portfolios
After the introduction  of   Knowledge    Forum   and    some  initial  work,  there were differences   in  instruction:
Whereas students in the  "KF class"   continued   to engage in KF discussion only, students in "KF with portfolios
class" were required to submit an electronic portfolio with a selection and explanation of four clusters of good
discussion notes in the database.   Students in "KF with knowledge -building portfolios class" also needed to do
this task, but they were provided with a set of knowledge-building principles as scaffolds in note writing and
note selection (Table 1). Based on Scardamalia's set of knowledge -building principles,        we have developed a
smaller set designed for use as pedagogical and assessment tools. We adapted the guidelines from earlier studies,
so they could be more accessible to middle-school students.
  A brief description is given for the knowledge-building principles (for details, see Chan & van Aalst (2003):
(1) Working at the cutting edge.   This principle is related to epistemic agency, and it is based on the idea that a
scholarly community    works    to advance   its collective  knowledge.    For  example,  scientists do  not work   on
problems of only personal interest, but on problems that can contribute something new to a field. (2) Progressive
problem solving. The basic idea is that when an expert understands a problem at one level, he or she reinvests
learning resources into new learning. In the scholarly community, we often find one study raises new questions
that are explored in follow-up studies. (3) Collaborative effort.       This principle focuses on the importance of
working on shared goals and values in developing community knowledge. (4) Monitoring personal knowledge.
This principle is based on the idea that metacognitive understanding is needed for knowledge-building work.
Specifically, it requires students to have insight into their own learning processes.     It is similar to progressive
problem   solving in   that it documents   the   history of  ideas or   problems--but  now  the focus    is placed  on
metacognitive processes. (5) Constructive uses of authoritative sources. This principle focuses on the importance
of keeping in touch with the present state and growing edge of knowledge in the field. To make knowledge
advancement requires making references, building on, as well as critiquing authoritative sources of information.

Data Sources

Analytic Toolkit and Database Usage
The Analytic Toolkit (ATK, Burtis, 1998) provided an overview of student participation using information on
database usage. Several quantitative indices include: (a) Number of notes written, (b) Number of notes read, (c)
Number    of scaffolds used;   scaffolds are thinking prompts    (e.g., I  need to understand)  to   guide writing and

                                                          
collaboration, (d) Number of notes revised; revision is an important metacognitive process; (e) Percentage of
notes linked to other notes, and (f) Percentage of notes with keywords that can help others to search the notes.

                 Table 1. Teacher Guidelines on Knowledge Building Principles and Portfolios

You need to select four best clusters of notes together with a summary note that explains why you have
selected the notes. Use the principles and criteria to help you with note selection.
Principle One: Working at the Cutting Edge
·   Identify knowledge gaps, inconsistencies and ask productive questions
·   Pose problems that extend the edge of understanding of the community
·   Pose problems with potential for continual discussion and inquiry (i.e., interest many people)
Principle Two: Progressive problem solving
·   Show continual efforts to grapple with problems posed by classmates
·   Pose notes aimed at addressing the original problem and questions arising from them
·   Show sustained inquiry: Identify the problem, solve the problem, but keep asking new questions
·   Reinvest efforts to keep solving new problems to improve ideas
Principle Three: Collaborative Effort
·   Use various KF functions such as references and rise-above to make knowledge accessible
·   Summarize different ideas and viewpoints and put them together as a better theory
·   Help classmates to extend and improve their understanding
·   Encourage classmates to write notes that follow the other principles
Principle Four: Monitoring Own Understanding
·   Explain what you did not know and what you have learned
·   Recognize discrepancies and misconceptions and new insights; trace own paths of understanding
·   Show your new ways of looking at things (questions, ideas, issues) after examining other KF notes
Principle Five: Constructive Uses of Different Sources of Information
·   Use information from other sources ( Internet, newspaper...etc) to support or explain your ideas
·   Bring together classroom learning, information from textbook, classmates'KF notes
·   Provide contrasting or conflicting information   to what is printed in the textbook

Depth of Inquiry and Depth of Explanation
Computer notes consisting of responses and questions were examined for assessing knowledge-seeking inquiry,
based on earlier research on depth of explanation (Hakkarainen et al., 2002). Students'    responses were coded on
a 7-point scale to distinguish the levels of depth of inquiry, and students'questions were coded on a 4 -point scale
(Chan &    van Aalst, 2003). These    levels ranged  from fragmented    responses  to paraphrasing information   to
inferences to explanatory inquiry.
Knowledge Building Portfolios
Students were   asked to  prepare  a  portfolio of four  clusters of   notes in which they provided   evidence   for
knowledge-building principles (i.e., cutting edge, progressive problem solving, collaborative effort, monitoring
own knowledge, constructive uses of resources).      In their selection, they needed to include their own notes as
well as others'notes in the database. They also needed to write an explanatory statement for each cluster on why
these notes best demonstrated evidence of knowledge building. Portfolios were coded on both explanation and
evidence of knowledge building on a 6-point scale.
Conceptual Understanding
To  assess students'  conceptual  understanding   of the  domain   in  question, students in all classrooms were
administered the following writing task:  "We have been exploring three major world problems, namely `Rich
and Poor',  `Ocean   in Trouble',  and `Deforestation'.  In not   less than  300 words, express  your view on    the
following question: Who and how should we look after the World?" Students' respo nses to the writing task were
coded using rubrics and schemes regularly used in the school.

                                                        
RESULTS

Class differences on participation, collaboration and conceptual understanding

Participation and Collaboration Shown on Database Usage
We first examined students' overall participation and collaboration based on database usage on Knowledge
Forum. The general descriptive picture from Analytic Toolkit indicated a sizeable usage of the databases: There
were totals of 661, 302, and 1090 written notes, respectively, contributed by the three classes (KF, KF with
portfolio, and KF with knowledge-building portfolio). The average number of notes written were 16, 8, and 27
for the three conditions, respectively, in a 3-month period.  To simplify presentation, the ATK indices were
combined using factor analyses: Factor One called ATK Knowledge Building Inquiry Index (i.e., write, read,
scaffold) explained 42.6% of the variance, and Factor II called ATK Knowledge Building Visual Organization
Index (i.e., keyword, link) explained 10.1% of the variance. ANCOVA analyses controlling for differences in
academic achievements showed that students in different design conditions had different participation scores, F
(2, 113) = 7.31, p<.001. Table 2 shows that KF class with kb portfolios had a higher ATK Inquiry index than
Knowledge Forum (KF) class, and KF class with portfolios scored higher on Inquiry Index than KF class.     There
were no significant differences for the Visual Organization index.
Depth of Inquiry and Depth of Explanation
The entire set of computer notes including questions and responses were scored.       An overall weighted score
called Depth  of Inquiry was   computed   based  on quality  and   frequency of    questions. ANCOVA     analyses
controlling for differences in academic achievements showed that KF with kb portfolios class had significantly
higher mean scores than the other two classes, F(2, 113) = 9.23, p<.001 (Table 2). Students' written responses
were also scored and computed to obtain an overall weighted score called Depth of Explanation. ANCOVA
showed that KF with kb portfolio class had a significantly higher mean score than KF with portfolio class, F =
3.98, p = .021 (Table 2). These results suggest that students scaffolded with knowledge building principles and
portfolios participated more, and they produced deeper questions and explanations.
Conceptual Understanding
The means of conceptual understanding scores based on a writing task were 5.5 for no KF class, 5.2 for KF
class, 5.2 for KF class with portfolios, and 7.0 for KF class with knowledge-building portfolios. ANCOVA
analyses indicated that significant differences were obtained favoring KF with knowledge-building portfolios
over other classes, F=6.6, p<.001.

             Table 2. Scores on Participation, Inquiry, and Explanation Across Design Conditions

                 Class                   KF              KF with Portfolio         KF with portfolio and
                                                                                        principles
                                    M        SD           M            SD            M            SD
             ATK Inquiry           -.45      .37         .03           .83          .44            1.2
                                    b                    a, b                        a
              ATK Visual           -.17      .82         .01           .96          .18            .92
             Organization
           Depth of Inquiry        1.85     1.34         2.24         1.33          3.59           1.6
                                    a                     b                         a, b
         Depth of Explanation      3.55     1.21         3.01         1.25          4.33         2.15
                                                          a                          a
       Note: Means in a row sharing subscripts are significantly different. p<.01.

Relations among Participation, Inquiry and Conceptual Understanding
We examined the relations between students' ATK participation and depth of inquiry with their conceptual
understanding for all students working  on KF.  We  used students' scores  on Hong    Kong    Attainment  Tests as
covariates, controlling for the effects of academic achievement.   Participation was measured by ATK with the
two factors of Inquiry and Visual Organization. Depth of inquiry was assessed by students' weighted scores on
questions and responses.  Correlation coefficients show that ATK Inquiry Index, was significantly correlated
with Depth of Inquiry (r=.39, p<.001), Depth of Explanation (r=.35, p<.001) and writing (r=.16, p<.05). ATK
Visual Organization Index was significantly correlated with the Depth of Inquiry (r = .48, p<.001) and Depth of

                                                      
Explanation (r = .27, p<.05). Both inquiry and explanation scores were correlated with writing (r = .20, p<.01).
These findings show that participation on KF and depth of inquiry were related to conceptual understanding.

              Table 3. Correlations among Participation, Inquiry and Conceptual Understanding

                                    ATK inquiry     ATK visual         Depth of      Depth of
                                                    organization       inquiry       explanation
       ATK visual                   .52***
       Depth of inquiry             .39***          .48***
       Depth of explanation         .35***          .27**              .27**
       Writing                      .16*            .02                .20**         .20**
       Note: *p <.05; **p < .01; ***p < .001

Relations among Participation, Inquiry, KB Portfolios and Conceptual Understanding
We also examined the relations between students' knowledge building portfolio scores with other measures for
the KF with kb portfolio class (n=29). We used scores on Hong Kong Attainment Tests as covariates controlling
for the effects of academic achievements. The knowledge building portfolios were rated on a 6-point scale both
on the explanatory statements and the selection of notes. Knowledge building portfolio ratings were significantly
correlated with ATK Inquiry (r=.35, p= 08). As well, knowledge building portfolio ratings were significantly
correlated with essay writing reflecting conceptual understanding (r=.37, p=.066), both at .10 level. Students
showing more evidence of knowledge building in their portfolios scored higher on conceptual understanding.

Characterizing Individual and Collective Knowledge Advances
Students were asked to produce four clusters of notes with explanations in their portfolios. Two examples are
provided here to illustrate the differences of portfolios with and without principles. As well, the portfolio note
guided by knowledge-building principles helps to characterize individual and collective knowledge advances.

   Figure 1. A portfolio note illustrating a knowledge-building principle and collective knowledge advances

The Theme of the Discussion The effects of chemicals on the oceans    ... It began with the question "Do
shipwrecks [such as] the Titanic add pollution to the world' s oceans?"M. y Interpretation At first, I thought
that my question was quite debatable1 . But in the end, I still thought that shipwrecks weren't as harmful
as they seemed to be. I thought that after decomposition of oil spills, the oceans could return to their initial
form, but this idea was heavily criticized by my classmates. They all thought that shipwrecks brought serious
threats to the oceans2 3 . ...They said that if oil was spilt into the oceans, it could kill many animals before the oil
could be decomposed. Mr. Lee told us that if a certain species is killed, it might break the food chain. Therefore,
oil spills are quite dangerous to our oceans. I was [shown] that oil spills were far more serious than I ever
expected.  Then, CW corrected a stupid mistake that was made by me. He told me that the Titanic ran on coal,
not on oil. Therefore, I realized that I actually had a problem with my question. Then, the first evolution came.
ER suddenly asked if the oil from an oil spill is an ocean resource4 . Naturally, CW answered this question5 .
Here's the second evolution. CY started to argue that tankers carrying chemicals are more dangerous
than oil tankers6 , CW and I didn' t agree thoug7h. We thought that although cyanide is more poisonous than oil,
cyanide is soluble in water. Therefore, its effects on the oceans are less than those of oil8 . WY agreed with this
9 , SL too. He said that oil is difficult to clean up, and could kill heaps of wildlife, but I still had my questions...
Are oil spills really that bad to the oceans? After 50 years or so, the oil would start to decompose and the
corals would grow on the shipwreck, it' d become an artificial reef, what' s the problem with tha10t?CW agreed
with me that shipwrecks aren't really that bad in the long term "water wave will wash the oil and make them into
smaller particles and decompose them in the following years!"11  TY also pointed out that pollution is
proportional. Oil spills could help the environment-- "the resources used up " and the curve of the pollution
is proportional. So if we can control the use the resources , we can also reduce the level of pollution ~"12
Principle 2 Improvable Ideas/Progressive Problem Solving I [think] that this is a principle 2 note because in
this cluster of notes, many new and improved questions have evolved from one simple note in the
beginning. Reasons In the beginning, I was asking about shipwrecks, soon the discussion turned to
chemicals and finally a new concept was pointed out (pollution is proportional). Every time there was a
question, we'd solve it, think of another question and solve that as [we] get better answers and more
questions.
Note: The number in superscripts are computer notes in the databases included as reference notes

                                                     
   Figure 1 shows an example illustrating how portfolios might help to identify and characterize knowledge-
building episodes in the community, and how they scaffold the student's reflection and understanding. At the
beginning, Student A referred to a question he had posed, "Do shipwrecks add pollution to the world's oceans ?"
Instead of asking a typical textbook question, Student A posed what might be called an authentic problem with
potential for inquiry (Scardamalia, 2002). Student A identified diverse ideas from his classmates and explained
how   they differed  from  his views.  In examining   the discourse,   Student A also  became    more aware   of   the
`mistakes' (misconceptions) he had (Titantic used coal not oil).    The portfolio note illustrated how the students
worked collaboratively on the problem, pushing for new understanding, rather than having premature closure.
   As they pursued the problem, Student A wrote that he had the `first evolution' [insight] when someone asked
whether an oil spill can be a resource. He then described another evolution when the classmates discussed
whether oil spills or chemical pollutions are more serious. Further inquiry of the problem led to improved ideas
and new realizations ­ proportionality and control of resources as ways to control pollution. The portfolio note
helps demonstrate that knowledge building involves a problem-centred collaborative inquiry process where new
ideas are  examined,   debated,   and improved  upon.  As  the student  explained,  "At first, I was  asking  about
shipwrecks, soon the discussion turned to chemicals and finally a new concept was pointed out (pollution is
proportional). Every time there was a question, we'   d solve it, think of another question and  solve that as well to
get better answers and more questions."
     Figure 2. An example of a portfolio without knowledge-building principles showing shallow discourse

This topic is ocean in trouble. The question is "Oil spill is a kind of pollution. But where does it come from?
From an accident of a ship or from nature?"1 This is a simple question, I don'   t think nature can make oil spill
occur. 2 3 4 These three notes have answered the big question of oil spill. Oil [comes] from the ground and [it
is] transported by ship. But some accidents have happened [and] the oil spills on the surface of ocean. Oil spill is
a serious problem of pollution; it kill[s] the marine wildlife and make[s] the world problem [creating] lack of
fishes. The other most interesting note comes from "Why a small amount of oil will be formed when it is raining?
"5 Before I see this note, I don' t know the rain contains oil, I think this is silly to say "Oil Rain!".There are three
answer[s] to the notes, that include:" Internet says that the rain may contain a small amount of oil."6 ", the car
fumes contain some toxic chemicals, and a little amount of oil may still be in the smoke. So, the smoke goes up
and [gets into] the rain. "7 and "the soil is fat and may contain oil, so when rainwater come through, oil may
[be] flushed away with the rainwater..."8 I think the acceptable answer is [that] smoke with water vapour is
absorbed by the Sun, and [it]condenses to from cloud [and] finally forms rain.
Note: The number in superscripts are computer notes in the databases included as reference notes

   We provided an example of a different kind of note when students also found exemplary notes from the class
on the same    theme  without  having    been given  the  scaffolds of the knowledge-building    principles. In  this
example, the selection of question is different: Student B identified a note that asked quite a general question -
where does an oil spill come from? He then wrote he found three notes that answered the question and the
problem was considered solved. The same situation occurred again ­ This time the question was more interesting
but Student B still used the strategy of finding three notes that answered the question and found the most
acceptable one. The notion of improvable idea or collective advances cannot be found in this note. Instead the
student seemed to be more engaged in a form of premature closure focusing on finding the correct answers.

DISCUSSION
We have described a knowledge-building environment augmented with the use of portfolios and knowledge-
building  principles  to characterize  and scaffold  collaborative  inquiry. Primarily  we turned   over agency    to
students, asking them to assess their own and the community's knowledge advances in the computer discourse ,
using an   electronic portfolio.  We  extended  our  earlier work   from graduate  students    and senior-secondary
students to middle-school students in large classes. We used knowledge building principles more intensively as
both  note writing  and  note  selection guidelines. The  findings  show that  students provided   with knowledge-
building principles as scaffolds participated more and engaged in deeper inquiry. Consistent with our earlier
work (Chan & van Aalst, 2003), knowledge building      activity was related to students'conceptual understanding.

Knowledge Building Portfolios as Scaffolds for Collaborative Inquiry
We first examine the roles of knowledge-building principles and portfolios and consider how they may scaffold
collaborative inquiry. In this study, we had several design conditions. The results showed that student provided
with knowledge-building principles participated more and engaged in deeper inquiry than their counterparts. A
system of knowledge-building principles was postulated by Scardamalia (2002) for theorizing the dynamics and

                                                         
processes of knowledge building. Thus far, researchers used the framework of knowledge building principles to
analyze the databases. We adapted the principles and turned over to students the responsibility for identifying
knowledge-building episodes in their computer discourse. In doing that, knowledge-building principles become
not just analysis tools, but pedagogical and assessment tools for scaffolding knowledge building. We propose
that when students work on identifying knowledge building episodes, the principles can be a form of scaffold
that helps them recognize what constitutes productive discourse. As they see different models, they would be
able to move towards producing better notes and engaging in deeper discourse. Protocol examples indicated that
Student  A  was  able to use  the principle  `progressive   problem solving'  to     explain how ideas   evolved and
improved over time. By contrast, Student B was merely identifying good answers to questions classmates posed.
Without knowledge-building principles or other criteria, students could easily see collaboration as discussion
and producing good answers. That may explain why many students are reluctant to participate in discussion on
networked   environments.  Knowledge     building   principles as scaffolds   may    help students   understand  what
constitutes progressive  discourse. As   the goal   of knowledge   building  is improvable     ideas (Scardamalia  &
Bereiter, 2002), we made that explicit to students; then that could become a goal of the community.

Alignment of Learning, Assessment and Collaboration
  We have designed an environment that was intended to address certain gaps for designing assessment in
CSCL classrooms. Earlier, we noted three of these issues: Assessment of learning versus assessment for learning,
assessment of individual and collective advances, and assessment of processes and content. First, the knowledge
building portfolios play dual  roles  of characterizing   and  fostering  collaboration.  Commonly,    assessment  is
concerned   with analyzing the collaborative     process or   evaluating what students    have  learned.  Knowledge-
building portfolio assessment is designed so that self- and peer-assessments foster inquiry and understanding. As
shown above (Figure 1), in identifying exemplary clusters of notes and providing explanations, students must
browse through the database and synthesize their own and collective understanding. Fragmented understanding,
scattered discussion, and superficial work might be avoided.     The assessment approach examines collaboration
as well as provides a tool for deepening inquiry. Second, this study included several measures (e.g., ATK, depth
of inquiry) to assess knowledge building. Specifically, we designed knowledge-building portfolios that capture
both individual and collective aspects of knowledge building.    As shown in the portfolio example (Figure 1), the
student was not merely describing his personal work; he was describing how a problem was addressed by a
group of students, what views they held, what misconceptions were identified, what critical incidents took place,
and how the idea was gradually improved. Knowledge building postulated by Bereiter and Scardamalia (2002) is
analogous to scientific inquiry in scholarly and scientific communities. Even middle-school students can be
engaged in a process similar to the writing of scholarly reviews when someone integrates differing ideas/studies
to provide the `state of knowledge' for a certain problem/theme. Knowledge-building portfolios capture both
collective knowledge advances as well as students' growth in understanding. Third, the portfolios showed that
content  and process  were both   assessed.  The    portfolio example    illustrated how  students   were engaged  in
progressive  problem  solving (see  Figure   1); it also provided  rich  information   about  how  they   have gained
subject-matter knowledge (e.g., oil spills as resources, proportionality, control of resources).
  It may be useful to note the limitations of this study. Due to the complexity of classroom life, comparison of
design conditions across classrooms necessarily faces many problems common in           technology studies. Whereas
the quantitative findings are included, caution needs to be exercised in interpreting them. These different design
conditions, however, help us to understand more fully how knowledge building works.              We also emphasize
examining portfolios can help characterize and assess both individual and collective understanding. Ongoing
analyses and inter-rater reliability are being conducted. In terms of pedagogical implications, earlier we noted
problems and challenges of low and variable participation rates and problems with teacher assessment. The
portfolio approach may be a way to address the problems, in that students need to write some notes before they
can have enough notes to do the portfolios. Or at least they would need to do substantial reading of others' notes
when putting together the portfolios.  We also noted the problems of teachers having difficulties with reading
hundreds or even thousands of notes. The two-pronged approach of Analytic Toolkit providing an overview as
well as the portfolios--a synthesis of what goes on in computer discourse-- can help teachers recognize and
assess overall participation as well as critical incidents of knowledge building in the community. They would be
able to identify areas where students may have problems and what progress they have made.
  In sum, we have extended our earlier work examining portfolio assessments and demonstrated more clearly
the roles of knowledge building principles. We propose that when students are provided with the principles, they
can become more aware of what productive discourse entails; the principles are scaffolds for their knowledge-
building progressive inquiry. As well, students are not merely focused on their own work, they are engaged in
characterizing the community's best work and progress. Our approach of making knowledge building explicit to
students is consistent with current emphasis on alignment of learning with assessment (e.g., Shepard, 2000). We

                                                         
have  extended   the idea of  portfolio as assessing individual   to community   progress  and  demonstrated  how
knowledge-building portfolios may characterize and scaffold collective knowledge advances.

REFERENCES
Black, P. & William, D. (1998). Assessment and classroom learning. Assessment in Educational Principles,
        Policy and Practice, 5, 7-74.
Bransford, J.D., Brown, A.L., & Cocking, R.R. (1999). How people learn: Brain, mind, experience and school.
        National Research Council.
Burtis, J. (1998). Analytic Toolkit for Knowledge Forum. Centre for Applied Cognitive Science, The Ontario
        Institute for Studies in Education/University of Toronto.
Chan, C.K.K., van Aalst, J. (2003). Assessing and scaffolding knowledge building: Pedagogical knowledge
        building   principles and   electronic  portfolios. In B.   Wasson, S.  Ludvigsen,  and U. Hoppe    (Eds.),
        Designing for change in networked learning environments. Proceedings of the International Conference
        on Computer      Support for Collaborative   Learning   (pp. 21-30). Dordrecht,  the  Netherlands: Kluwer
        Academic Publishers.
Chan,  C.K.K.    &   van  Aalst, J.  (2004).   Learning,    assessment and   collaboration in computer-supported
        environments. In J.W. Strijbos, P.A. Kirchner, & R. L. Martens (Eds.), What we know about CSCL and
        implementing it in higher education (pp. 87-112). Kluwer Academic Publishers.
Dillenbourg, P., Eurelings A., and Hakkarainen, K. (Eds.) (2001). European perspectives on computer-supported
        collaborative learning: Proceedings of the First European Conference on Computer-Supported
        Collaborative Learning (pp. 20-28), University of Maastricht, Maastricht, the Netherlands.
Gipps, C.V. (2002). Sociocultural perspectives on assessment. In G. Wells & G. Claxton (Eds.), Learning for life
        in the 21st century (pp. 73-83). Oxford, UK: Blackwell.
Guzdial, M. & Turns, J. (2000). Computer-supported collaborative learning in engineering: The challenge of
        scaling up assessment. In M.J. Jacobson & R.B. Kozma (Eds.), Innovations in science and mathematics
        education: Advanced designs for technology in learning (pp.227-257). Mahwah, NJ: Lawrence Erlbaum
        Associates.
Hakkarainen, K. , Lipponen, L. & Järvelä, S. (2002). Epistemology of inquiry and computer-supported
        collaborative learning. In T. Koschmann, R. Hall, & N. Miyake (Eds.), CSCL 2: Carrying forward the
        conversation (pp. 11-41). Mahwah, NJ: Lawrence Erlbaum Associates.
Hewitt, J. (2003). How habitual online practices affect the development of asynchronous discussion threads.
        Journal of Educational Computing Research, 28, 31-45.
Koschmann, T., Hall, R., & Miyake, N. (Eds.)(2002). CSCL2: Carrying forward the conversation. Mahwah, NJ:
        Lawrence Erlbaum Assoiates.
Lipponen, L., Rahikainen, M., Lallimo, J. & Hakkarainen, K. (2003). Patterns of participation and discourse in
        elementary students'computer -supported collaborative learning. Learning and instruction, 13, 487-509.
Reeve, T. C. (2000). Alternative assessment approaches for online learning environments in higher education.
        Journal of Educational Computing Research, 23, 101-111.
Scardamalia, M. & Bereiter, C. (2003). Knowledge Building. In Encyclopedia of Education, Second Edition.
        New York: Macmillan Reference, USA.
Scardamalia, M. (2002). Collective cognitive responsibility for the advancement of knowledge. In B. Smith
        (Ed.), Liberal education in a knowledge society (pp. 67-98). Chicago: Open Court.
Shepard, L. (2000). The role of assessment in a learning culture. Educational Researcher, 29, 1-14.
Stahl, G. (Eds.) (2001). Computer support for collaborative learning: Foundation for a CSCL community.
        Mahwah, NJ: Lawrence Erlbaum Associates.
van Aalst, J., & Chan, C.K.K. (2001, March) Beyond "sitting next to each other": A design experiment on
        knowledge building in teacher education. In P. Dillenbourg, A. Eurelings, and K. Hakkarainen (Eds.),
        European perspectives on computer-supported collaborative learning: Proceedings of the First
        European Conference on Computer-Supported Collaborative Learning (pp. 20-28), University of
        Maastricht, Maastricht, the Netherlands.
Vye, N.J., Schwartz, D.L., Bransford, J.D., Barron, B.J., Zech,L. & The Cognition and Technology Group at
       Vanderbilt  (1998).  SMART     environment    that   support monitoring, reflection and  revision. In D.  J.
       Hacker, J. Dunlosky & A. C. Graesser (Eds.), Metacognition in educational theory and practice (pp.305-
       346). Mahwah, NJ: Lawrence Erlbaum Associates.
White, B.Y.,   Shimoda,   T.A.,  &   Fredericksen,  J. R.    (1999). Enabling   students to  construct theories of
       collaborative  inquiry  and   reflective learning:    Computer   support  for metacognitive  development.
       International Journal of Artificial Intelligence in Education, 10, 151-182.

                                                         
