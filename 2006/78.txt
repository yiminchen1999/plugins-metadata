              From Mechanical to Meaningful Classroom Questions
                    Elizabeth S. Charles, Sabina Karkin, Christopher Kramer, and Janet L. Kolodner
                    Georgia Institute of Technology, 801 Atlantic Drive, Atlanta, GA 30332-0280
               Email: echarles@cc.gatech.edu, gtg741a@mail.gatech.edu, gtg921q@mail.gatech.edu,
                                                     jlk@cc.gatech.edu

          Abstract:   While   observing   two  project-based     inquiry    classrooms,   we  noticed  and  became
          intrigued by  the  markedly    different development     of science   discourse  practices across the   two
          classes. Both were taught by the same teacher, used the same curriculum materials, engaged in the
          same  learning  activities, and  were    comprised    of equally   engaged  and    high achieving   honors
          students. Yet over a 20-week period, the question-asking and answering practices of students in
          the two classes diverged considerably. While students in Class A were still struggling to adopt the
          practices modeled by the teacher, students in Class B were taking the initiative to ask each other to
          explain trends identified   in investigations   and working    out  explanations   together. Investigating
          differences between   these  two  near-identical   enactments     has allowed   us to identify  changes  in
          question-asking practices that lead to productive interpretations and science discourse. We offer
          explanations for the differences between the classes and for the changes observed over time.

          While   observing  two   Learning   by     Design  classrooms     that were   part  of  a  larger research   project
investigating the development of scientific reasoning in middle school students, we noticed and became intrigued by
the markedly different development of science discourse and inquiry practices across the two classes. Classes A and
B were the first and second periods of the day, respectively. Both were taught by the same teacher, used the same
curriculum materials, engaged in the same learning activities, and were comprised of equally engaged and high
achieving honors students. Yet over a 20-week period, the question-asking and answering practices of students in
the two classes diverged considerably. While students in class A were still struggling to adopt the inquiry practices
modeled   by  the teacher,   students  in Class    B were    engaging  together   in sense-making    discussions,  taking   the
initiative to ask each other to explain trends identified in investigations, and working out scientific explanations
together. We   hoped    that by studying    development      of practices   across   these two   classes, we  could   develop
understanding of factors that might foster and hinder development of productive inquiry practices.          We thus decided
to trace  the ways  students' question-asking      and  answering  practices    changed with  repeated   practice and  teacher
guidance across the two classes. We analyzed our data to identify the questioning and answering practices of the two
classes at different points in time, the teacher practices with respect to modeling and facilitation, and patterns of
student participation. We then analyzed the data to answer two questions:
    1.    What teacher practices and patterns of student participation are present in Class B but not Class A that
          might have fostered growth of more sophisticated question-asking and answering practices in Class B?
    2.    What practices and patterns were evident in Class A that might have hindered such growth?

Background
          The best inquiry approaches to learning provide context and motivation for learners to both ask and answer
good questions. Development of these question-asking and answering skills and practices requires having repeated
opportunities to ask questions, to work at formulating answers, and to reflect on how such discourse and actions
influence further investigation and understanding (Krajcik, Blumenfeld, Marx, Bass & Fredricks, 1998; Scardamalia
& Bereiter, 1991). But research shows that opportunities and affordances for asking and answering questions are not
enough. The literature also tells us that learners need support to articulate and reflect on their ideas (Linn & Songer,
1991;  Scardamalia    &  Bereiter, 1991),  and  it   is best when     these supports  operate   within the  learner's zone  of
proximal development (Vygotsky, 1978). Both the cognitive apprenticeship (Collins, Brown & Newman, 1989) and
socio-cultural literatures (Lave & Wenger, 1991; Vygotsky, 1978), using somewhat different language, suggest that
development    of skills and  practices   requires   experiencing  others   doing  an activity   well, trying to  do  it as an
individual, having lots of opportunities to repeatedly practice it in a scaffolded environment, and reflecting on the
practice in ways that enhance capabilities. In other words, learning to ask and answer questions should benefit from
repeatedly and deliberatively modeling and coaching of enactments of these activities.

                                                              78                                                    ICLS 2006
        Productive   questioning    goes  beyond    requests  for mere   facts  and generally   aims    to elicit some   type  of
knowledge    construction, for   instance asking    respondents   to  formulate  generalizable   rules,   make    predictions  on
hypothetical  cases, reveal   contradictions,  or   challenge conclusions    or  beliefs (Collins    &  Stevens,   1982).   Such
questions might be quite simple in form (e.g., What would happen if you changed...?), but still can elicit complex
answers  and  knowledge    construction.    As students'   question-asking   capabilities   develop,    we  should   see   greater
frequencies of question-asking, questions being asked in more articulate ways, and shifts from requests for factual or
procedural information to requests for explanations as students become more knowledgeable about content (e.g.,"
why does it work" instead of "how does it work" (Collins & Stevens, 1982). We should also expect the development
of questioning   capabilities,  the development     of interpretation   capabilities,  and  the  development      of answering
capabilities to develop in conjunction with each other.

        The literature also tells us that capabilities and skills required to ask productive questions ­ and maybe to
correctly interpret their purpose and intention ­ calls for disciplinary knowledge and metacognitive skills not usually
seen in young    learners (Scardamalia    &  Bereiter, 1991).  It  is  reasonable to  suggest   that if young     learners are to
develop these  capabilities,   they  will require   opportunities  to  both  gain  domain    knowledge     and    have  time   for
reflection leading   to  individual  and  group   construction    of  knowledge.    In  the classrooms     we  were    studying,
deliberative  repeated   public  practice of  question-asking  and     answering  happened   during     structured  whole-class
public activities. These sessions gave the teacher and other students opportunities to model good questioning and
answering and to coach and scaffold students as they participated in presenting their work and discussing the results
of other groups (Ryan & Kolodner, submitted). In particular, certain questions were modeled and used to focus
students' attention and foster their capabilities of using scientific reasoning (e.g., What's your recommendation?
What's your rule of thumb?). The aim was for students to begin constructing meaning through these conversational
sequences.

Methods

Context and setting
        Learning by Design (LBD; e.g., Kolodner, Camp, Crismond, Fasse, Gray, Holbrook, Puntembakar, Ryan,
2003) is a project-based inquiry approach to science education. Students learn science in the context of designing
working  artifacts  that  require  targeted  science  content  for   their successful   design. The    school  year  begins    by
engaging   students  in scientific reasoning   using  relatively  simple   concepts  in the context    of  designing   relatively
simple artifacts (e.g., of a parachute) before having them move on to reasoning about more complex concepts in the
context of  designing    more   complex   artifacts (e.g., a vehicle   and  its propulsion  system).    Early experiences     are
designed to help students develop foundations for scientific reasoning and designing, and the intention is to help
students increase the sophistication of their scientific reasoning capabilities throughout the school year. Sequencing
calls for teachers to model, then coach and scaffold targeted capabilities and skills as in a cognitive apprenticeship
approach (Collins, Brown & Newman, 1989). LBD's activities are sequenced in repeated action-discourse cycles
that give learners opportunities to think through and plan what they are going to do, carry out their plans, interpret
their results, and make presentations for their peers to critique. For example, before committing to a design, the class
as a whole identifies variables that may be causally related to performance (messing about activity), and then small
groups (composed of 3 or 4 students) each select one variable to investigate (running experiments activity). When
investigation is completed,    small groups   make   public  whole-class    presentations   (poster  session  activity)  of their
findings and try to offer a design recommendation based on trends in their data and scientific justifications for each
recommendation.     The    class   then   discusses  the   reliability  of  the  findings   and   the   believability    of   the
recommendations. They attempt to attribute scientific explanations to trends in data and to use those as the basis for
judgments of believability of each design recommendation.         Later, they move on to designing based on these results,
presenting and justifying their design ideas to the class (pin up session activity), and iteratively getting to working
designs, examining the behavior of artifacts they design, helping each other explain (in gallery walks) the reasons
their artifacts are not working as well as they wanted, and helping each other use science to decide on next steps
towards designing a better-performing artifact. Enactment includes a wide variety of opportunities for learners to
present their reasoning to each other for discussion.

        Our focus in this paper is primarily on Vehicles in Motion, which targets learning about forces and motion.
During this unit, students learn science in the context of iteratively designing and testing a coaster car and two
propulsion   systems (balloon    engine   and rubber-band    engine),  eventually   designing   a vehicle   that  can   navigate

                                                              79                                                       ICLS 2006
several  hills. As   the  unit progresses,  we   expect   the explanations     of how their  vehicles  work   to   include  more
sophisticated use of science. We focus our data analysis on the specific activity of poster sessions, and we selected
several  that were    critical to the development    of   both question-asking     practices and   science  (weeks   5, 14, 15).
Examining these poster sessions gave us the chance to observe students engaging in sense-making activities related
to scientific   inquiry  and   argumentation.   As described,    poster sessions   involve the  public reporting   of results of
experiments conducted by the small groups. During these presentations and the discussions that follow, students are
responsible for evaluating data, applying domain knowledge to explain observed and measured performance, and
attempting to understand the explanations, recommendations and claims of their peers. We examined transcripts
made from videotaped data of the two grade-8 physical science classes discussed. Classes A and B were made up of
19 and 21 students, respectively. The majority of these students were classified as high achievers. The teacher had
three years of experience teaching LBD and many more teaching science.

Methodology
         We adopted a case study approach in our analysis (Merriam, 1998), telling the story for each class of the
ways their discourse changed over time and the roles of teacher and students in that discourse. Using a small sample
of data taken from representative presentations made during key poster sessions in the Vehicles unit (weeks 14 and
15), we identified typical ways that students engaged in question-asking, interpreting and answering, and the small
moves between students and teacher that revealed what conditions led to certain questions (asked by teacher or
students) being answered (or not answered) in certain ways. Questions were categorized into four types (design,
procedure,  data/conjecture,    and   science), and  answers   were   categorized   into  five types  (the  question  types plus
coordination of data and science) representing most likely intentions and interpretations of the discourse. Design
questions and answers focused on how to build the artifact; procedural on controls of variables; data/conjecture on
performance     behaviors   and   results; and  science   on  physics   concepts   and/or  representations  (e.g., force   vector
diagram).  Coordination     answers   were  attempts   to establish  connections   between   data  and scientific  explanations
(initially, data and design issues). Note that the ways in which these questions and answers were articulated, and
how the discourse unfolded, sometimes required coding several speaking turns, which included several speakers.
Also of interest were the changing ways the two conversational sequences, previously mentioned, were used and
interpreted   (i.e., recommendations       and rules of   thumb).   At  first, these phrases   held  indeterminate    meanings,
sometimes eliciting design answers, at other times data answers. Later on, however, "rules of thumb" came to mean
a generalized recommendation with a science explanation attached (when actually stated it was often contextualized,
e.g., "two balloon engines create more force of air pushing on the balloons, which pushes the car..."). To establish a
baseline for participation, we used the same coding to analyze a poster session from week 5 of the school year.

         To study the development of questioning, interpreting, and answering capabilities in conjunction with each
other, we charted patterns of question-asking and answering (adjacency pairs) (Goodwin & Heritage, 1991). We
studied these paired statements as systems of interdependent and changing parts to trace what is changing in the
questions being      asked and  the ways    in which they    are interpreted   and responded   to. In  this way,   we can   track
changing ways of asking questions, types of questions asked, interpretations, ways of answering, and sophistication
of answers. To allow us to track student questioning behaviors with respect to teacher modeling of question-asking,
we also separated out teacher and student participation, and the types of questions the teacher asked over time. We
expected to see shifts among students in the frequency of their participation in question-asking, the structural forms
students used   to   ask questions,  and   the kinds of   questions  being asked,    with  shifts from requests  for  factual or
procedural information to requests for scientific explanations (e.g., from "how does it work" to "why does it work").
We expected their interpretations and answers to gain sophistication over time. In order to examine these within-
class differences (weeks 5, 14, & 15) and facilitate the comparison between classes, we present the data in two
tables at the end of the next section (see Table 1 & Table 2). Note that to complete the picture of change over time
we also include in these tables data from week 20, though they are not intended to address the research questions.

Case Study Analyses

         Class A. During week 5's poster session, students in Class A enthusiastically participated in the activities
by engaging in question-asking (16 questions, 3.6% of the total turns). The majority of questions (see Table 1) were
clearly targeted     at eliciting procedural   aspects  of experiments,    and    presenters had   no  problems    appropriately
interpreting and answering them (e.g., "Where did you guys say you like measured it from?" "Was it the same
person doing the stopwatch?"). On three occasions, however, one student's questions had the more sophisticated

                                                                 80                                                   ICLS 2006
intention of eliciting a scientific explanation (e.g., Kory asks, "This is just, a question because I'm curious, but when
you dropped the parachute... didn't it affect how... it fell?"). In these instances, the responding students did not see
this intention but answered as though the question referred to design-related issues by referring to its construction
(e.g., "When we were making it (gestures at parachute), this [the strings], were also, like, even at the top (holds up
parachute)).

         In this early poster session, the teacher found many opportunities to establish the types of participation she
expected from students (12% of the total turns; 64% of teacher discourse). Sometimes she explicitly told them what
they should be doing, sometimes she told them by asking rhetorical questions, and sometimes she modeled the kinds
of inquiry concerns they should be thinking about, primarily focusing on procedure questions (e.g., "How many
times did  you do  each  variable?"). She did   not    spend   much   time   modeling    discourse related to data issues  or
scientific explanation. A notable part of this session, because it is repeated consistently throughout the course of the
LBD units, was her use of the conversational starter ("So if you're going to generalize your recommendation..."). In
this instance, "recommendation" may have referred to design or to data (i.e., performance results) considerations. In
the following  sessions, we see  students  continue    to use     the term   "recommendations"     without  attending to  the
"generalize" aspect of the teacher's modeling. We think this may partly account for differences observed between
classes.

         The poster session in week 14 was the first poster activity for the Vehicles unit (the balloon engine car).
The percentage of questions asked during this session increased significantly (8% of total turns). For the most part,
student questions were targeted equally on design and procedural issues and were interpreted as such (see Table 1).
Some students also asked questions that could be considered data-related questions (e.g., "So it wasn't moving?").
But, only on one occasion did such questioning elicit an answer that was more sophisticated than the questioner
might  have  intended.  On  the surface,  it was     a question    about   data    ("Did it [the  balloon  car] actually  roll
backwards?") and could have been answered with a yes or no, but it was answered with an attempt to coordinate
data with behavior of the artifact (see line 2.452).

         2.452  Josh: Yeah, it rolled, and then it came back.         And, and the second, the two straws, had a
         little more push on it, which there wasn't enough to get our car really going.            And so it kind of
         went forward and then came back again.        But not as much as the first trial, maybe like 1 or 2 cm.
         And then the third trial it, had enough to start the car moving.       That was the most, the problem we
         had the most. Was getting our car to, actually go forward.

         During this poster session, the teacher asked approximately the same number of questions as before, and
this time she made small steps in modeling inquiry discourse that included a call for summarizing what had been
learned from the experiments using science as backing (i.e., "rules of thumb" statements; questions about science).
When she did so it was primarily in a rhetorical statement ("Right, you just told me in your rule of thumb that the
difference had to do with friction, right?"). Turning to individual students, once again it was Kory, previously the
sole student to attempt using the teacher modeled talk, who attempted to include this conversational sequence in her
presentation ("And our rule of thumb is when building a balloon car..."). Interestingly, although students had just
spent three weeks learning about motion and forces and how to draw force diagrams, they did little reporting of
scientific explanations and asked no science questions of each other.

         Week 15's poster session had a rocky start. Although the majority of students were ready to participate, the
noise from a few stragglers visibly disturbed the teacher, resulting in the class at large being admonished for such
behavior. This may have changed the ways in which the students engaged in questioning because few questions
were raised in the beginning of the period, and then all questioning came from one student, Josh. Two other students
eventually asked questions, but limited primarily to data related issues (16 questions, 17% total turns). As before,
these questions were   simple (e.g.,  "Why   is one    [trial] like,  50 off  from  the  other?")  and were   interpreted and
answered literally (e.g., "I don't know, we blew it up and it just, went. Well, the first one actually kind of curved a
little bit, so I guess we lost distance, in the curve."). A few questions, however, had the possibility to be interpreted
in a more sophisticated way (e.g., "Can the straw be too long?"), but such questions also were answered as if design
related (e.g., "I don't know, I recommend keeping it, you shouldn't add distance, just keep it how it is."). Only once,
what  appeared  to be  a data question   ("Why    would   you     count   it if it touched   the wheels   though?"), elicited
explanations that included mention of the newly introduced science concepts (see lines 3.192 ­ 3.197).

                                                               81                                                   ICLS 2006
         3.192   Clint: Uh, allow more room for the balloon to, push and create force, which means don't...
         3.194   Ashok: Like, pull on the t-...
         3.195   Clint: (talking over Ashok) Create less friction, and...(gestures)
         3.196   Ashok: Allow the balloon to exit more air.
         3.197   Clint: Like, push more air, like...   If, if it has friction it will (gestures) stretch the balloon...

         In this session, the teacher-generated questions remained high (17% total turns; 57% of teacher discourse).
Many of her questions were phrased as data related questions, but also could have been interpreted as asking for
science  explanations  (e.g., "Did you  notice   anything  about    the initial speed?"). Notably  different from       previous
sessions was the teacher's first-time explicit use of the rules of thumb (a conversational sequence with a specific
purpose calling for scientific explanations) rather than simply asking for recommendations (e.g., "Ok, can you read
me your    rule of  thumb?").  Even    with  this modeling,    only   two of    the five groups  used  the  rules of     thumb
conversational sequence in their presentations; students in this class tended, even in week 15, to report and ask about
recommendations without expressing or asking for the science behind them.

         Class B. Week 5's poster session showed students in Class B as equally engaged in classroom activities
as their peers in Class A. Similarly, their question-asking constituted 5% of the discourse; however, the majority of
Class B's   questions  (50%)   were  clearly  intended   to  elicit information     about  the data-related  aspects     of   the
experiment (see Table 1). Like Class A, participation was concentrated primarily around the question-asking of one
student, Bess.  Bess  took  a  leading  role as  the class' question    asker.  In  the process, she   introduced a     style of
questioning that elicited attempts at explanations from her peers (e.g., "I noticed like... do you think that affected
your, um, time?"). This conjecture style questioning seemed to also allow peers to reflect on their actions, and along
the way, they attempted to offer more sophisticated answers coordinating data with design (e.g., "What we were
trying to figure out wasn't like, if the number of strings mattered.    So I guess, it didn't really occur to us that it would
matter.").

         When    it came to   the teacher's  modeling  and   scaffolding   of   question-asking, Class  B  had a  somewhat
different experience than Class A. She spent almost the same amount of time asking questions (10% of total turns,
52%   of teacher  discourse),  but this time  she  began    the session   by  explicitly  establishing her expectations       for
appropriate presentations (see lines 3.023). In doing so, she made clear what the students were being asked to do
from the start. Her questions too were more focused and modeled explicit concern for precision when it came to
conducting experiments.

         3.023 Teacher: You will tell us about your experiment, tell us how you did your experiment, share
         your data with us, share your averages with us, tell us what your recommendations are.              Now,
         those of you who are listening, your responsibilities are to... Does everybody understand what we
         we're going to do?

         During week 14's poster session, students in Class B continued to develop more ways of participating, and
increased the percentage of questions asked (from 5% of the total turns to 12%). Although students clearly were still
interested in finding out about design-related issues (see Table 1), this time, an equal number of questions (6) were
directed at asking about newly introduced science concepts, referencing in particular, the novel representation of
force vector diagrams   (e.g., "Well   then  for  your force   vector   diagrams,   wouldn't the friction be bigger      on the,
without the cups?").

         In this instance, the teacher was no longer the only one modeling question-asking using the phrase "rules of
thumb". Rather, this phrase, which engenders the notion of generalization and use of science, was now commonly
used by a number of students (e.g., Scot asks, "What's your rule of thumb?"). Also notable was Bess' changing
ways  of participating, demonstrated    by   her  adoption  of  the teacher's   previously   modeled evaluative   tone    when
asking about rules of thumb ("So, then wouldn't your rule of thumb be like, don't have too many balloons because
they create friction, not don't let balloons rub on wheels?"). With these increased uses of the rules of thumb phrase
by students (asking for science explanations), we saw the teacher change the focus of her discourse (6% of total
turns, 42% of teacher discourse), calling attention to the need for refinement of observational skills and coordination
of science explanation (e.g., "Ok that brings me to the next question, which is do you think there may be some factor
with all the balloons touching, not just touching the wheels of the car or the ground or anything like that, but the
balloons touching each other?").

                                                             82                                                    ICLS 2006
       In week 15, the Class B students did not substantially increase the percentage of codeable questions asked
in previous poster sessions (15%). Noticeably, however, both the focus of questions and the forms of questioning
and answering  changed  (see Table   1 &  2). The  majority of  questions    were  science related (38%) and  elicited
attempts to offer science explanations or to coordinate the data with science (e.g., "But don't you want the velocity
too, along with the distance?"). Even questions that previously might have been interpreted as design or data related
elicited attempts to include science concepts in the responses (e.g., "Why do you recommend using four or five cups
when those aren't  consistently your best  results?"). The  manner  in     which   answers were constructed was   also
noteworthy. Whereas previously, individual students would answer questions, now the presenting group as well as
others jointly shared in constructing answers (see lines 3.183 ­ 3.192).
       3.183   Blake: Wouldn't it be, more equal for every trial, if you put one cup and put a straw in it
                      and then, put two and a new straw up, and put it in it, and it just keeps going up that
                      way?
       3.187   Victor: No, because you'd have weight.
       3.188   Scot: No, because it would have a different mass.
       3.189   Victor: A different mass.
       3.190   Ying: Different mass.   It goes... (gestures downward)
       3.192   Bess: Yeah but, it didn't work...
       As  students  increased   control  of  the classroom  discourse,     asking  and answering   questions without
prompting, the teacher's questioning again declined (25 questions; 4% of total questions, 37% of teacher discourse).
As in week 14, she focused on modeling finer nuances of data interpretation and discussing issues that might be
interpreted as precursors to statistical significance (e.g., "But if you look at the overall trend, when you had one cup,
you had significantly less distance and significantly lower velocity...").

Table 1: Comparison of questions-asking by Class A and Class B students.

     Question                Week 5                  Week 14                    Week 15               Week 20
       Types           Class A     Class B     Class A      Class B        Class A   Class B    Class A     Class B
    Design-relatedquestions1           4           6          5              4          6           1          5
 Procedure-relatedquestions10          4           5          1              2          1          11          8
  Data/Conjecturequestions5            8           3          4              9          8           9          12
  Science-relatedquestions0            0           0          6              1          7           2          7
      Totals             16            16         14         16              16         22         23          32

Table 2: Comparison of answers/responses to questions by Class A and Class B students.

      Answer                 Week 5                  Week 14                    Week 15               Week 20
       Types           Class A     Class B     Class A      Class B        Class A   Class B    Class A     Class B
    Design-relatedanswers1             4           6          5              2          6           3          4
 Procedure-relatedanswers10            4           6          1              1          2           7          8
       Dataanswers       5             8           1          4              3          5          10          9
  Science-relatedanswers 0             0           1          4              4          9           5          7
    Coordinationanswers  0             0           0          1              3          1           0          4
      Totals             16            16         14         15              13         23         25          32

                                                         83                                                   ICLS 2006
Discussion
          There   were  quantitative  and   qualitative differences  between   the question-asking  practices  developed   in
Classes A and B. While students in Class A primarily asked and answered questions focused on design, procedure,
and data related issues, students in Class B, lead by Bess' conjecture type questions, began to ask greater numbers of
science-related   questions.   Such   questioning   elicited  science   explanations   and    allowed   students to  attempt
coordinating data with science, one of the hallmarks of scientific reasoning (Koslowski, 1998). Although questions
used changed over time, with equal frequency, similarly-worded questions and conversational phrases were used
repeatedly but    asked for  and   elicited different   responses, suggesting  that  their meaning  and   interpretation had
changed. Notably, the use of the conversational phrase referencing "recommendations" was a weak cuing question
for productive  science    discourse, whereas   the   conversational   phrase "rules of  thumb"   became   a  strong cue   for
generalization and use of science. We suggest that if teachers are to model phraseology, those phrases should have
specific meanings that students can practice and grow to use better, rather than phrases that may have such taken for
granted  meanings    that  they cannot be   interpreted   in new   ways and   take  on more   sophisticated  meanings  (e.g.,
"recommendation").      In other  words,    conversational   phrases   become  cultural  resources, as  their meanings     are
collaboratively produced and used, hence, students' develop certain repertoires we can consider science talk. If we
help establish and support useful repertoires, the knowledge building and learning affordances of public venues like
the poster session may be more readily recognized and acted on by learners.

          Lastly, we   note  the importance    of the   teacher attending  to  the  modeled   practices of  certain  types of
discourse. For instance, early on in Class B's question-asking practice, one student (Bess) stood out from the others.
Her conjecture style question-asking was later adopted and sustained by others (weeks 14 & 15). This type of talk
fostered the discourse typically associated with productive inquiry and collaborative knowledge building (Karkin,
Charles, Kolodner, 2006, poster in ICLS proceedings). In supporting such students, we allow them to model within
the zones of proximal development of their peer, possibly reaching more students than the teacher's modeling alone
(Vygotsky,    1978). In Class   A, the teacher  did   not adequately   support students'   answers  to peer  question-asking
attempts (Kory, Josh). In doing so, she missed opportunities to foster equal levels of productive science discourse.

References
Collins,  A., Brown,    J. S., & Newman,     S. E.  (1989).   Cognitive  apprenticeship:   Teaching   the crafts of  reading,
          writing, and mathematics. In L. B. Resnick (Ed.), Knowing, learning, and instruction: Essays in honor of
          Robert Glaser (pp. 453­494). Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.
Collins, A.,  &   Stevens,  A.L. (1982).    Goals and   strategies of  inquiry teachers.   In R. Glaser (Ed.),   Advances  in
          instructional psychology (Vol. 2, pp. 65-119). Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.
Goodwin, C. & Heritage, J. (1990). Conversation Analysis. Annual Review of Anthropology, 19, 283-307.
Kolodner , J.L., Camp, P.J., Crismond, D., Fasse, B.B., Gray, J., Holbrook, J., Puntambekar, S. & Ryan, M. (2003).
          Problem-Based Learning Meets Case-Based Reasoning in the Middle-School Science Classroom: Putting
          Learning by Design into Practice. Journal of the Learning Sciences, 12(4), 495-547.
Krajcik, J., Blumenfeld, P.C., Marx, R.W., Bass, K.M., & Fredricks, J. (1998). Inquiry in project-based science
          classrooms: Initial attempts middle school students. Journal of the Learning Sciences, 7 (3&4), 313-350.
Lave, J., &   Wenger,   E.  (1991).   Situated Learning:     Legitimate peripheral  participation.  Cambridge:   Cambridge
          University Press.
Linn, M. C., & Songer, N. B. (1991). Teaching thermodynamics to middle school students:                What are appropriate
          cognitive demands? Journal of Research in Science Teaching, 28, 885-918.
Merriam, S.B. (1998). Qualitative research and case study applications in education: Revised and expanded form
          case study research in education. San Francisco: Jossey-Bass Publishers.
Scardamalia, M. & Bereiter, C. (1991). Higher levels of agency for children in knowledge building: A challenge for
          the design of new knowledge media. Journal of the Learning Sciences, 1(1), 37-68.
Ryan, M.T. & Kolodner, J.L. (2006). Investigation of teacher practices and curriculum tools to develop explanation
          and scientific reasoning skills in project-based inquiry classrooms. Manuscript submitted for publication.
Vygotsky,  L.S.   (1978).  Mind   in  society: The  development     of higher  psychological   processes.  Cambridge,    MA:
          Harvard University Press.

Acknowledgements
This research is funded by the National Science Foundation. We acknowledge the contributions of our fellow LBD
researchers and thank them for their efforts during the data collection, and support during the analysis and writing.

                                                               84                                                   ICLS 2006
