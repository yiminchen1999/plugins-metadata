     Motivation in Project-Based Classrooms: New measures better
                                 coupled to students' experiences

                                                Phillip Herman, Louis Gomez
                             School of Education and Social Policy, Northwestern University
                             Email: herman@northwestern.edu, l-gomez@northwestern.edu

          Abstract:   Project-Based    Science  (PBS)    has  traditionally been   proposed    as  a  comprehensive
          approach to classroom teaching and learning that is designed, in part, to better motivate students to
          learn.  As    PBS  units  became    more widespread     in schools,  initial evaluations    of their impact
          focused   primarily   on documenting     important  learning   outcomes   such   as performance      on  unit
          assessments    and    standardized  exams  (Herman,       Mackenzie,   Sherin,   &   Reiser,   2002).    The
          motivational impact of PBS units is not so well documented. In particular, little has been done to
          study motivation across PBS units or across school years. Traditional measures of motivation, first
          developed primarily by educational and developmental psychologists, were essentially inherited
          by the  learning   sciences  community    and   have  not   been  efficient  indicators  of the  impact   of
          curricular innovations on student motivation. We argue for new motivation-related measures that
          are more closely coupled to the actual experiences of students in projects and report on our initial
          attempts to develop such measures.

Introduction
          This article reports on our efforts to document the motivational patterns of 7th graders in an urban school
setting whose teachers implemented one or more PBS units during the 2003-2004 school year. Each project was
developed   either  by  the Center  for  Learning  Technologies      in Urban  Schools   (LeTUS)     or  the Investigating    and
Questioning our World through Science and Technology (IQWST) group. Each of these collaborations works to
develop curricular units that support project-based learning in science classrooms.        Each unit was designed to: align
with local,  state,  and national   standards,  be contextualized    in real-world  problems,   allow    for sustained  student
inquiry, embed learning technologies, foster collaboration, and provide educative materials for teachers (Schneider,
Krajcik,  &  Marx,    2000).    These  projects were  relatively    long-term  (6-12   weeks),   problem-focused,     and   they
integrated concepts from a number of disciplines or fields of study (Blumenfeld, Soloway, Marx, Krajcik, Guzdial,
& Palinscar, 1991).

Motivation in Project-Based Science Classrooms
          PBS units are designed to be motivating. Though curriculum designers might disagree about how explicit
increasing student motivation should be as a goal of PBS curriculum design, it is clear that, at least initially, PBS
was advanced as an alternative to typical science classrooms that were viewed as formulaic and not necessarily
supportive of student motivation. Features of the work that students do in PBS classrooms, such as using computers
and  the  Internet   to  study  real-time  Earthquake    data  patterns,  are  intended    to foster  interest  and   cognitive
engagement. By focusing on formative rather than summative assessment, students might be more willing to take
chances, be more intrinsically motivated, and be less peer-comparative. By studying authentic problems, such as
why some finches on the Galapagos Islands die while others do not, students may be more goal-directed in their
learning, report being more self-regulated, or have higher levels of self-efficacy in regards to arguing from and about
real-world data. Though such motivation claims are plausible, they have not been extensively documented in large
numbers of classrooms. To some extent, this may be due to the prevalence of a design-based research paradigm
(Design-Based    Research    Collective, 2003)  in PBS    settings.  In design-based   research,  the curricular   design team
typically works    closely  with teachers  and  students   to  support  implementation     of the  unit, provide   professional
development to teachers, "work out the kinks" in the technology or activities, and study the overall implementation.
Researchers  and    teachers often  report that students   are "more    interested" or  "engaged"     during   the projects -- a
finding that is typically documented using qualitative methods, such as teacher and student interviews, classroom
observations,    and  analyses   of   student  work  and   artifacts.   These  qualitative    studies have     been  critical  in
understanding    the subtle  ways   in which   motivation  and  learning   are related  in these  classrooms.   However,      this
intensive, qualitative approach is typically limited to a few of the "first enactors"; that is, these studies are limited to
teachers  working    closely   with university   researchers   who   provide   ongoing   access    to their  classrooms.    Few
motivation-focused      studies have   included    large numbers     of  classrooms,   and    even fewer     have   studied   the

                                                              250                                                     ICLS 2006
motivational impact of enacting multiple or multiyear PBS curricula.     High-quality qualitative studies of motivation
in PBS   classrooms require   a  sustained commitment    that is  expensive and   time consuming    once the number    of
implementing classrooms rises into the hundreds. Significantly, such work also requires a deep understanding of the
designers'  intentions,  each  teacher's pedagogical   priorities for the  units, and  the  context  of each   classroom
implementation. Though each PBS unit varies considerably in its focus, design, and implementation, efforts such as
IQWST are working to develop a comprehensive PBS middle school curriculum that has some key elements in
common    across projects.  These elements  include   focusing  on performance    assessments,  working  with  real data,
analyzing models, and constructing scientific arguments. As such comprehensive PBS curriculum efforts grow, it
will become more and more important to develop instruments that are both sensitive to the motivational impact of
student  participation  in multiple PBS    units and  practical enough  in  their administration  to allow  for a   better
understanding of the motivational impact of PBS units on thousands of middle grades students.

         We have worked to understand the motivational impact of PBS on 7th graders for several years. In order to
understand how innovative units are impacting student motivation, it is important to understand, and account for, the
longitudinal trends in student motivation during the middle grades.     Maehr and Midgley (1991) and Pintrich (2000)
have documented how motivation typically declines as students move from upper elementary to the middle grades.
Students report that they are less intrinsically motivated, have lower levels of self-efficacy and self-concept, have
less interest in school in general, and have less interest in particular subjects such as science. If motivation is in
decline  in the middle   grades, what are  the   implications for the learning sciences, and    how  should  those  of us
concerned with motivation think about and document changes in motivation associated with participation in PBS
units that are, in part, designed to be motivating?

New Measures of Motivation
         We argue that new measures need to be developed that are more closely coupled to the work that students
do in PBS classrooms, and that such measures be sensitive enough to account for multiple implementations of PBS
units or even multiple-year implementations of innovative middle grades science curricula. Based on prior work, we
have noted the inconsistent relationship between typical measures of motivation, such as scores on scales from the
Patterns of Adaptive Learning Survey (PALS) (Midgley et al., 2000), and student achievement as measured by unit
tests or standardized exams. For example, in some cases, a Mastery goal orientation predicts achievement; in others
it is unrelated to achievement. Interest in science does not necessarily increase during a PBS implementation. Such
inconsistencies make it difficult to argue that participation in the PBS units is motivating to students. Some of this
inconsistency is likely due to problems with student self-reports and administration of the surveys, with the variation
in implementation of the PBS units, with declining motivation in the middle grades. But, some of the inconsistency
is likely attributable to the content of the measures and the fact that these measures were not necessarily intended to
measure the motivational impact of innovative learning environments, but rather to describe developmental trends in
motivation. So, measures that may be good indicators of whether 7th graders are more or less intrinsically motivated
than 8th graders may    not be  good indicators   of whether  students  who participate  in PBS   units in 7th grade   are
therefore more intrinsically motivated than their 7th grade peers who do not.

         In order to better document the motivational impact of participation in PBS units, we developed and piloted
new measures that we hoped would be more closely coupled to the work that typically occurs in PBS classrooms
and that would predict student performance on a variety of indicators. Specifically, we believed that students who
successfully engage in activities, such as representing and arguing from real-world data, should report higher levels
of self-efficacy when queried about their confidence to perform such a task. We also believed that PBS classrooms,
because they are so different from more traditional classrooms with which teachers and students are familiar, might
be perceived as more confusing to students than regular classrooms. That is, students may be less clear about what is
expected of them in PBS classrooms -- in which students are investigating, representing data, engaging in inquiry,
identifying problems and solutions, etc. -- than in more traditional classrooms in which they can more easily intuit
what is expected of them. We base this conjecture on teacher interviews and comments over several years in which
teachers worry that their students are more confused if the teachers move from directing instruction to being more
like guides to learning in the classrooms. We developed items that we believed addressed both the self-efficacy of
students in these classrooms and the degree to which they expressed confusion or negative affect about classroom
expectations. In  total, we   developed  3  new   scales (Self-efficacy for Science    Inquiry, Know    how  to do,  and
Confused/Negative Affect) that we hoped might more consistently relate to achievement and that would be more
closely coupled to the work that students do in PBS classrooms. Table 1 lists the items that make up each of the
scales.

                                                           251                                                 ICLS 2006
Table 1: Items that comprise each of the scales

"Self-efficacy for Science Inquiry" scale (12 items)
      Stem: "How confident are you that you can...."
      Design an experiment that would test a hypothesis?
      Make a graph or chart to present science data?
      Give an oral presentation to your class about a scientific problem?
      Explain to someone how a graph you made presents important information about some science question?
      Challenge a statement made by another student or your teacher using data as your evidence?
      Work together with other students to study a scientific problem?
      Use the Internet to find data about a scientific problem you are studying?
      Use the computer to analyze data about a problem you are studying?
      Come up with a scientific question to investigate?
      Figure out the answer to a hard scientific question, without being given the answer by a teacher or finding
       it in a book?
      Figure out what kind of data you would need to answer a science question or problem?
      Identify a scientific question or problem that you could investigate?
"Know how to do" scale (5 items)
      I know what to do when we write science papers and reports in this class.
      I know what to do when we make presentations in this class.
      I understand the assignments in this class as well as the other students.
      I know how to analyze data in this class.
      I know how to use data to support what I say about a science question or problem.
"Confused/Negative Affect" scale (4 items) (Reverse scored)
      I'm not sure I have the skills to do well in this class.
      I don't understand what I need to do to be successful in this class.
      Sometimes I'm confused about what my teacher wants me to do in this class.
      My teacher pushes me too hard.

                                                        252                                                  ICLS 2006
Methods
          Surveys were administered to 587 7th graders in October of 2003 and to 174 of those same students in
May/June of 2004. It was impossible to get all teachers to agree to re-administer the same survey at the end of the
year because of time constraints. Science teachers administered the surveys. Items on the survey included our scales
listed above and items from the PALS that measured Academic self-efficacy, Mastery, Performance Approach and
Performance Avoid goal orientations, Classroom Mastery, and Teacher Press for Understanding. Science interest
was measured using a scale developed by LeTUS researchers at the University of Michigan. Each of these items
included  a 5-point   Likert-type scale ranging  from "Not    at all true" to "Very   true". Valuing Science  (Eccles &
Wigfield,   1993)    measured how   useful  students thought    science was   for their future plans.  Self-concept  was
measured by adapting Marsh's (1991) self-concept scale to focus on science self-concept.            We collected student
scores on   the 7th  grade Standardized  Science Exam    (ISAT)   which    represents our achievement   outcome for  the
current study. The ISAT was administered in early April of 2004.

Results
          We report correlations between motivation measures and student achievement in Tables 2 and 3. We use
both  the survey  data  from  October   and May/June     in order to  examine  how    consistently any of the scales are
correlated with achievement. That is, if there is an initial correlation from the presurvey in October, is the pattern of
correlations similar at the end of the year? Are the correlations reasonably consistent across time? Table 2 shows
that all three of the scales we developed are correlated with performance on the ISAT as are measures of Self-
concept, Approach and Avoidance Orientation, Classroom Mastery, and Self-efficacy. Individual Mastery, Valuing
Science, Science Interest, and Teacher Press for Understanding did not predict performance on the ISAT. On the
postsurvey (Table 3), "Know how to do" and " Confused/Negative Affect" were again correlated with achievement.
Self-efficacy for Science Inquiry was not included on the postsurvey. On the postsurvey, Avoidance orientation and
Classroom Mastery were no longer correlated with achievement on the ISAT, though they were on the presurvey.
Scale  reliabilities (Cronbach's  alpha) were   .88  for Science   Inquiry, .81   for "Know   how   to do", and .64   for
"Confused/Negative Affect".

Table 2: Significant Correlations between scales and performance on a Statewide Standardized
Science Exam (ISAT)           at Pre: N=587 (7th grade)

Scale                                                    Significant correlation with ISAT (p<.05)
Science Inquiry Self-Efficacy                            .33
Know how to do                                           .25
Confused--Reverse Scored                                 .36
Self Concept                                             .46
Approach orientation                                     -.23
Avoid orientation                                        -.24
Self-Efficacy                                            .18
Class mastery                                            -.09

Not significant is Mastery, Science Interest, Teacher Press, Valuing science

                                                            253                                                 ICLS 2006
Table 3: Significant Correlations between scales and performance on a Standardized Science
Exam (ISAT) at Post: N=174 (Subset of the same 7th graders)

Scale                                                   Correlation with ISAT
Science Inquiry Self-Efficacy                           Not on post survey
Know how to do                                          .36
Confused--Reverse Scored                                .38
Self Concept                                            .48
Approach orientation                                    -.16
Avoid orientation                                       Not significant
Self-Efficacy                                           .26
Classroom Mastery                                       Not significant

Not significant is Avoidant orientation, Classroom Mastery, Valuing science, Individual Mastery, Science Interest,
Teacher Press for Understanding

Summary of Results
        The measures we developed to indicate students self-efficacy for inquiry, the degree to which
they know how to do certain inquiry and classroom tasks, and their affect towards the work and their
teachers all predicted achievement on a high-stakes science exam. The pattern of correlations was similar
pre to post, except in the case of self-efficacy that was not included on the postsurvey. The correlations
were higher than most other motivation-related measures such as goal orientation, general self-efficacy,
and science interest. As a first step, these results are encouraging and warrant further empirical
development of these types of measures.

Discussion
        We argue for a renewed focus on the motivation-related impact of participation in PBS curricula. As the
Learning Sciences matures, we will have to develop better and more efficient ways of measuring motivation in
designed learning environments in order to not only inform design but also to convince stakeholders of the value of
participation in such units.   Just as efforts to understand and document student learning in PBS classrooms were
influenced by  students' opportunities    to learn (Porter, 1993), we   think it is important  to  better understand  and
document students' opportunities to be motivated during implementation of innovative curricula. It is a given for
many   curriculum designers    that these  environments are  more  interesting or   motivating  to many   or all students.
However,   relatively little large-scale work  has  documented   the motivational   benefits of such  participation. It is
important to do so and to better understand the connection between motivation and learning in these environments.
It is challenging to develop surveys, or other easily administered measures, that are reliable, valid, and helpful to
document student motivation at one point in time. It is even more difficult to develop measures that can reflect
meaningful changes in student motivation over time. That is, it is hard to develop measures that are sensitive enough
to show change within a school year or over the course of a relatively short project. If projects are 10-12 weeks in
length and students   participate   in two projects a year,  what  kind of motivational   changes   should   or  could  be
expected? We do not have the answers to this problem but argue that we need to develop measures that can help us
understand such changes for a large number of students.      The measures we propose are first steps. Much empirical
and conceptual work needs to be done to develop theoretically and psychometrically strong measures. But that work
is important.

Motivation and Learning
        The value of participation in PBS units should not just be measured solely in terms of learning outcomes.
Higher  student motivation,    including   perhaps  a positive  affect towards   learning science,   might   be  of equal
importance as specific learning outcomes. PBS units require fairly high levels of student motivation to facilitate the
kind of learning we care about. If students are unmotivated, they will not engage in the projects at the heart of PBS
work. Motivation and learning must work in concert so that the PBS work can reach the desired level of cognitive

                                                            254                                                  ICLS 2006
complexity that designers originally intended. Motivation is not unidimensional. It is more useful to develop profiles
of students' motivation that might include a number of factors, such as engagement, interest, self-beliefs, goals, and
affect. In some cases, participation in PBS might engender increased levels of student self-efficacy to interpret data
presented in graphs. In other cases, if students have had a positive learning experience in science, and they recognize
it as a positive experience, at the end of the year they might reflect on their experience in science class and make the
judgment that "I enjoyed that class, I learned a lot and I would be willing to take a science class like that in the
future." Such an outcome would have apparent value above and beyond the learning that occurred. Krarabenick
(2005) labeled that phenomenon a "residue" that exists at the end of the experience and argues that supporting such
beliefs is an important goal of teachers and therefore should be a goal of curriculum designers. We do not assert that
motivation  is more  important  than learning but  rather  that the two are inextricably linked.  In fact, the  kind of
motivation we most care about is in the service of learning. We do not want students merely to be interested in
computers. We want them to be motivated to use computers in service of their learning.        We developed measures
that we believe are moving in that direction. They measure motivation-related constructs in a way that is specific to
the work that students do in one PBS unit but are general enough that, if there is enough similarity in the design and
implementation   of the units, the measures  should  allow for   documentation of  the cumulative   effects, if any, of
participation in multiple enactments of PBS units.

Distal/Proximal distinctions in motivation
        The work of Ruiz-Primo and colleagues (Ruiz-Primo, Shavelson, Hamilton, & Klein, 2003) has influenced
our thinking as we try to develop the right motivation-related measures for PBS classrooms. Though their work
focused on assessing learning at various levels of distance from the implementation of any curricular unit, we think
there is an analogous distance that needs to be accounted for when studying student motivation in similar settings.
Such a frame requires documentation of what students were exposed to during implementation and a matching to
several assessments that are at varying levels of remove from the initial experiences during implementation. Some
experiences  are more   common     during  implementation  and   might  be  more  influential on   student motivation.
Therefore, we might expect that levels of self-efficacy around working with data might change over the course of a
data-intensive implementation but that a student's valuing of science for future goals might be harder to change.
Similarly, when looking for the motivational impact of participation, we would expect that assessments that are
proximal to implementation (such as teacher's perceptions of student interest) should show higher levels of student
interest than assessments that are more distal, such as end of the year surveys that ask students if they are interested
in science. Such  a framework   is only beginning   to influence  our work,  but  we believe  that the proximal/distal
distinction, and the distinction between measuring specific self-efficacy for a well-defined task and measuring more
general self-efficacy for "science" (Pajares, 1997), will help us develop measures that can more accurately describe
the motivational impact of participation in PBS activities.     We propose that all such measures be coupled to the
work that students are likely to do, and to do consistently, in PBS classrooms.   Traditional measures of motivation
are often unsuitable  for the  purposes of  curriculum  designers,  and that designers  should   be  cautious  in using
measures  that have  been developed   for  other purposes. Much   work  needs  to be done to  document     motivational
improvements in the middle grades during a period of overall motivational decline.

References

Blumenfeld, P., Soloway, E., Marx, R.W., Krajcik, J.S., Guzdial, M., & Palinscar, A. (1991). Motivating
       project-based learning: Sustaining the doing, supporting the learning. Educational Psychologist,
       35, 149-164.

Design-Based     Research      Collective.  (2003).    Design-based     research:  An    emerging      paradigm    for
       educational inquiry. Educational Researcher, 32(1), 5-8.

Herman, P., Mackenzie, S., Sherin, B., & Reiser, B. (2002). Assessing student learning in project-based
       science classrooms: Development and administration of written assessments. Proceedings of the
       5th International Conference of the Learning Sciences. Seattle: WA.

                                                          255                                                 ICLS 2006
Karabenick, S. A. (2005). Discussant's comments at the Annual Meeting of the American Educational
         Research Association Conference, Montreal, Canada.

Maehr, M., & Midgley, C. (1991). Enhancing student motivation: A schoolwide approach. Educational
         Psychologist 26, 399-427.

Marsh,    H. W.   (1992). Self  Description Questionnaire,        II. Sydney,    New  South Wales,   Australia:
         University of Western Sydney. (Original work published 1990)

Midgley, C., Maehr, M. L., Hruda, L. Z., Anderman, E., Anderman, L., Freeman, K. E., Gheen, M.,
         Kaplan, A., Kumar, R., Middleton, M., Nelson, J., Roeser, R., & Urdan, T. (2000). Manual for the
         Patterns of Adaptive Learning Scales. University of Michigan: Ann Arbor.

Pajares,  F.  (1997).   Current  directions in   self-efficacy     research.     Advances  in   Motivation  and
         Achievement, 10, 1-49. New Jersey: Lawrence Erlbaum.

Pintrich, P.  (2000). Multiple goals, multiple   pathways:      The   role of goal  orientation in learning and
         achievement. Journal of Educational Psychology, 92, 544-555.

Porter, A. (1993). Brief to policymakers: Opportunity to learn. Center on Organization and Restructuring
         of Schools. Retrieved March 1, 2006, from
         http://www.wcer.wisc.edu/archive/cors/brief_to_principals/BRIEF_NO_7_FALL_1993.pdf

Ruiz-Primo, M. A., Shavelson, R. J., Hamilton, L. & Klein, S. (2002). On the Evaluation of Systemic
   Science Education Reform: Searching for Instructional Sensitivity. Journal of Research in Science
   Teaching, 39(5), 369-393.

Schneider, R. M., Krajcik, J., & Marx, R. W. (2000). The role of educative curriculum
   materials   in reforming  science  education. In B.       J. Fishman    &  S. F. O'Connor-Divelbiss  (Eds.),
   Proceedings of the Fourth International Conference of the Learning Sciences. Mahwah, NJ: Erlbaum.

                                                         256                                               ICLS 2006
