     Fostering Scientific Habits of Mind in the Context of Online Play
                                      Constance Steinkuehler & Marjee Chmiel
                    University of Wisconsin-Madison, 225 North Mills Street, Madison WI 53706
                                     steinkuehler@wisc.edu, muchmiel@wisc.edu

         Abstract: In today's increasingly "flat" world of globalization, the need for a scientifically literate
         citizenry  has only   grown  more   urgent; yet, by some  measures,   we  have  done a   poor job at
         fostering the right scientific habits of mind in schools. Recent research on informal games-based
         learning   indicates that  such technologies/communities   may  be   one viable alternative ­ not to
         teachers and classrooms but to textbooks and science labs. In this paper, we provide empirical
         evidence    substantiating previous  claims  about  the potential of games  for  learning   and offer
         specific design heuristics that might inform their future production and use. Using codes based on
         AAAS benchmarks and Chinn and Malhotra's (2002) framework for evaluating inquiry tasks, we
         examine the scientific habits of mind that characterize online discussion forums of the MMOG
         World of Warcraft and the features of the game ­ both as designed object and emergent culture ­
         that appear to foster them.

Scientific Literacy: More than Stones
         In 1905, at a gathering of the world's greatest minds in the physical sciences, Henri Poincare reflected on
the rapid progress of scientific inquiry and the means through which the scientific community at the turn of the 20th
century and beyond would refine our understanding of the world. In his historical address, Poincare warned against
the seduction of reducing science to a domain of seeming facts, stating, "Science is built up of facts, as a house is
built of stones; but an accumulation of facts is no more science than a heap of stones is a house" (1905/2001, p.141).
One hundred years later, his admonition against the framing of science as a "rhetoric of conclusion" (Schwab, 1962,
p.24) still holds, with science scholars and educators from Dewey on repeatedly warning us against the teaching of
science as only content rather than process. In Dewey's own words, "the future of our civilization depends upon the
widening spread and deepening hold of the scientific habit of mind [italics added]... the problem of problems in our
education is therefore to discover how to mature and make effective this scientific habit" (1910, p.127).

         In   today's increasingly   "flat"  world (Friedman,    2005) of  massive   globalization   and technological
interconnectivity, the need for a scientifically literate citizenry in the United States has only grown more urgent; yet,
by some measures, it seems we have done a poor job at fostering the right habits of mind in our schools. Currently
only one in five Americans are scientifically literate (Miller, 2004) despite mandatory instruction. In a recent study
of contemporary classroom practice, Chinn and Malhotra (2002) found that standard "inquiry" activities not only
failed to engender scientific habits of mind but in fact actually fostered epistemological beliefs directly antithetical
to them. Recent assessment of high school laboratory activities by the National Research Council (Singer, Hilton, &
Schweingruber, 2005) reach similar conclusions: science labs, long heralded as the site for engaging students in
science practice, fail. Meanwhile, as our national quandary over how to teach scientific theory of human origins
demonstrates (Chmiel & Owens, 2005), the misconception of science as "built up of facts" rather than intellectual
practices only compounds, leaving the public increasingly hostile to the scientific enterprise itself (Elsner, 2005).
Perhaps  as   Gates  (2005)   argued  in his National Education   Summit   address, American  schools    have    become
obsolete: "Training the workforce of tomorrow with the high schools of today is like trying to teach kids about
today's computers on a 50-year-old mainframe. It's the wrong tool for the times" (¶12).

Leveraging Online Play
         But, if our educational system is not the right "tool for the times," what is? Despite dismissals as "torpid"
and  inviting "inert  reception" (Solomon,   2004) in some   mainstream  press, videogame   technologies  may     be one
viable alternative ­ not to teachers and classrooms but rather to textbooks and science labs. Recent studies indicate
that the intellectual activities that constitute successful  gameplay  are  nontrivial, including  the construction   of
identities (Gee, 2003; Steinkuehler, in press), collaborative problem-solving (Squire, 2005; Steinkuehler, 2006; cf.
Nasir, 2005), literacy practices that exceed our national standards (Steinkuehler, 2005b), systemic thinking (Squire,
2003), and, as one might expect, computer literacy (AAUW, 2000; Squire & Steinkuehler, 2005). Games, however,
are more than just the sum of their intellectual practices (as important as those may be); they are, in fact, simulated
worlds:

                                                           723                                                ICLS 2006
         The first step towards    understanding   how   video  games  can  (and   we  argue,  will) transform
         education is changing the widely shared perspective that games are "mere entertainment." More
         than a multi-billion dollar industry, more than a compelling toy for both children and adults, more
         than a route to computer literacy, video games are important because they let people participate in
         new worlds. (Shaffer, Squire, Halverson, & Gee, 2005)

         As simulations, games allow "just plain folk" (Lave, 1988) to build situated understandings of important
phenomena (physical laws, for example) that are instantiated in those worlds amid a culture of intellectual practice
that render those phenomena culturally meaningful (Steinkuehler, 2006). Their potentials for learning have not gone
unnoticed, and the last two years have witnessed a marked rise in interest across various academies in leveraging
game  technologies  toward educational    ends: the Woodrow      Wilson   Foundation's  Serious    Games    Initiative, the
Games, Learning and Society program at the University of Wisconsin-Madison, the Education Arcade project at
MIT, the Games for Social Change Movement, and Stanford University's Media X "Gaming To Learn" Workshop,
to name a few.

         One genre of videogame in particular offers distinctive promise in terms of fostering scientific habits of
mind: massively multiplayer online games. Massively multiplayer online games (MMOGs) are 2- or 3-D graphical,
simulated worlds played online that allow individuals to interact, through their digital characters or "avatars" not
only with the designed environment in which activities take place but also with other individuals' avatars as well.
Previous  ethnography   of such    online worlds    demonstrates    their function  as  naturally    occurring   learning
environments (Steinkuehler, 2004, 2005a), yet the forms of scientific argumentation, model-based reasoning, and
theory-evidence coordination that arise in the context of MMOG play warrant further investigation. In MMOGs,
individuals collaborate to solve complex problems within the virtual world, such as figuring out what combination
of skills, proficiencies, and equipment are necessary to conquer an in-game boss monster. As part of developing
efficient and effective solutions, players are customarily expected to research various game strategies and tactics by
consulting on- and offline manuals, databases, and discussions and by using such knowledge as the basis for in-
game action. Thus, as part of standard gameplay (particularly beyond the beginning levels), individuals share their
own  hypotheses  about  what strategies work    by proposing    models  for solutions, justifying  their "theories" with
evidence (such  as tabulated mathematical   results aggregated    across  multiple trials), and debating    the merits   of
conflicting hypotheses ­ not as aimless contentious discussion (although there is a bit of that as well) but rather as
part and parcel of the  collective intelligence (Levy,  1999)   amassed   through patterned   participatory consumption
(Jenkins, 1992), the hallmark of interactive "entertainment" media such as games.

         Innovative NSF projects such as Harvard University's River City (e.g., Dede, Ketelhut, & Ruess, 2003) and
Indiana University-Bloomington's Quest Atlantis (e.g., Barab, Arcici, & Jackson, 2005) have begun to tackle the
complexities of designing MMOGs for science learning, offering proof of concept of the argument presented above.
Yet, as Lave and Wenger (1991) note, understanding informal contexts for learning is crucial if we are to forward
educational theory  and practice   beyond the   contexts we  ourselves  contrive.  Therefore,  in  order to forward     our
understanding of the forms of scientific reasoning that emerge as a natural part of gameplay in informal MMOGs
and the design features that appear to foster them, this paper presents an examination of an online forum discussion
of the "off the shelf" MMOG World of Warcraft. In this investigation, we analyze a threaded discussion in which
participants attempt to work out a best-fit solution to one of the MMOG's in-game mechanics: the "druid talent
build." Using codes based on the AAAS benchmarks for scientific literacy (AAAS, 1993) and Chinn and Malhotra's
(2002) theoretical framework   for  evaluating  inquiry  tasks, we highlight  the  scientific habits of  mind   displayed
within the discussion and the features of the game ­ both as designed object and emergent culture ­ that appear to
foster them. Our goal here is to move beyond arguments about the potentials of MMOGs for learning by ferreting
out which specific scientific literacy practices emerge within such game-related online communities (and which do
not) and then, based on  those findings,  take  a first step toward developing    MMOG      design heuristics that might
inform and enable future instructional design.

Data Collection & Research Methods
Context of the Research & Data Corpus
         The context for this investigation is World of Warcraft, a successful MMOG released in November 2004
and currently boasting the single largest share of the market in North America and well over four million subscribers
globally. The game is set in a fantasy world in which players of various classes (eight total) wander the environment
hunting, gathering, questing, battling, and crafting in order to strengthen or "level" their character in various ways.

                                                           724                                                  ICLS 2006
The data analyzed for this particular study consist of a threaded discussion that took place mid-October of 2005 on
the "druid forum" of the official World of Warcraft website. Although there are a number of relevant online forums
to be found, the official website alone features 24 separate forums totaling well over 40,000 separate, active threads;
therefore, we chose to limit our data corpus by selecting a discussion thread that (a) was contained within one of the
character class-related forums (rather than, say, the general discussion forum which includes off-topic socializing),
(b) related to  specific in-game   problem-solving    (here,  druid  talent builds, discussed   below),   (c) began   with  a
question (given the forms of reasoning under investigation), and (d) had a high number of "unique account views"
(i.e., was read by a large number of individual players). The discussion thread selected for analysis, comprised of 75
individual posts by 31 individuals, was entitled "Imp Mark of the Wild" and the content of the first post consists of a
single, simple question: "Why is it nearly every template I see skips this ability?" A bit of context is necessary,
however, in order to make sense of this initial query.

         In World of Warcraft, players individualize their avatar by allocating talent points, earned through time
spent  hunting  in  game, across   the various tiers  within   their class-specific   "talent  tree" (see   Figure  1). "Imp
[Improved] Mark of the Wild" refers to one talent that one class of players, druids, can choose to invest in. These
refinements, represented as selections within the talent trees, are commonly manifested as statistical improvements
of some form or another to one's current abilities. For example, by investing five talent in the "Improved Mark of
the Wild" branch on the skill tree rather than another, a druid can get a 35% increase in the effect of their armor-
enhancing buff spell named "Mark of the Wild," thereby improving her function in some collaborative problem-
solving situations  and  decreasing her  capability  in others.  Such  choices    impact  one's contributions    to in-game
collaborative  problem-solving; therefore,  a great   deal of  communal     value placed  on   making    wise choices   when
developing one's particular "talent build." Players convene in online discussion forums to discuss and debate the
merits of different builds, at times even refusing to play with others who have made choices that go against the
communal wisdom developed therein. Thus, World of Warcraft participants have good reason to pay close attention
to forum discussions as they represent the collective work of many toward developing best-fit solutions for specific
groups, and it is not unusual to have discussion threads that receive 300,000+ unique account views. In the forum
thread analyzed herein, a non-druid player asks why a skill improvement called "Improved Mark of the Wild," is left
out of many recently fan-posted druid talent templates or "builds." In response, community members offer various
competing theories, arguments, and evidence for what constitutes the most efficacious use of the limited resource of
talent points.

Method of Analysis
         In order to assess the scientific habits of mind that characterize (or fail to characterize) the data corpus
examined   here, we   developed  a set  of codes   based   in combination   on a  subset  of   the AAAS     benchmarks     for
scientific literacy (AAAS,  1993)   and Chinn  and   Malhotra's   (2002)    theoretical framework    for evaluating  inquiry
tasks. Both  reports have  been quite  influential in science   education,  with  the   former serving   as the basis   of the
National Research Council's (1996) Science Standards and many state science standards for K-12 education in the
United States. The codes were selected from these sources based on a combination of a priori assumptions about the

                                                           725                                                     ICLS 2006
forms of scientific reasoning such   spaces   ought to generate     (e.g. understanding   systems and  feedback  among
components of a system) and previous games related literature (Gee, 2003; Squire, 2003, 2005; Steinkuehler, 2004,
2005a, 2005b). Our goal was to focus on scientific reasoning as "the building of houses" rather than the "collection
of stones" per the vision of science practice articulated by Poincare (1905/2001) and science education forwarded by
Dewey  (1910)  and  Schwab   (1962); therefore,   important  aspects   to  scientific understanding  that are specific to
content knowledge rather than practice per se (e.g. an understanding of natural forces), are notably absent. However,
given the focus of our interests (scientific practices rather than content) and the nature of the phenomenon under
investigation (a simulated world  that makes    no  claims   of correspondence      with the natural one), we  felt   such
omission was justified. Figure 2 below includes the full list of 21 codes; Table 1 presents a subset (given space
constraints) of their definitions. Both authors, each of whom had over a year of participant observer experience
within the game, coded a subset of roughly 12% of the data corpus to establish interrater reliability (92%); one
author then coded the remainder of the data corpus.

Table 1. A subset of the analytic codes used to assess scientific habits of mind.
 Scientific Discursive Practices
  · Build on Others' Ideas. Restate or summarize others accurately what others have said, ask for clarification or
    elaboration, and express alternative positions (AAAS, 1993)
  · Multiple Forms of Argument. Employ multiple forms of argument, not only simple deductive reasoning (Chinn &
    Malhotra, 2002)
 Model-Based Reasoning
  · Systems    Analysis. Understanding  systems    analysis, specifying   its boundaries and  subsystems,  indicating its
    relation to other systems, and identifying its inputs and outputs (AAAS, 1993)
  · Mathematical Models as Insight. Understanding mathematical modeling as finding a mathematical relationship that
    behaves in the same ways as the objects/processes under investigation and that such models may or may not give
    insight into how those objects/processes work (AAAS, 1993)
 Understanding Theory & Evidence
  · Pragmatic Understanding of Theory. Understanding that, no matter how well a theory fits observations, a new
    theory might fit them as well or better and that the ongoing process of testing, revising, and occasionally discarding
    theories leads to better but not to absolute truth (AAAS, 1993)
  · Theory-Data Coordination. Coordinating one's theoretical model with multiple sets of complex, sometimes partially
    conflicting data (Chinn & Malhotra, 2002)

Findings
        The results from this analysis are presented in Figure 2, which shows the percentage of posts that exhibit
each scientific habits of mind for which we coded. Here, we see the saturation of key characteristics of scientific
reasoning skills across the set of 75 posts that comprise the selected threaded discussion. Several interesting patterns
emerge from this analysis.

Figure 2. Proportion of posts within the data corpus that exhibit each scientific habit of mind under examination.

                                                          726                                                   ICLS 2006
Scientific Discursive Practices
        First, scientific discursive practices such as collaborative knowledge construction, building on the ideas of
others, and the use of counterarguments are the most prevalent scientific habit of mind exhibited by posts within the
discussion. That World of Warcraft players engage in mindful discussion and debate should come as no surprise
given the "collectively intelligent" (Levy, 1999) nature of such communities; however, it is interesting that forms of
scientific argumentation are prevalent within this informal context given previous findings that indicate that such
practices do not come naturally and are difficult to foster (Kuhn, 1991; Osborne, Erduren, & Simon, 2004). In these
data, is not unusual for participants to explicitly reference the reports of others, question one another's results, and
leverage mathematical data as evidence for one's thesis. The following post illustrates:

        I see this over and over again in threads and I think it is myopic. Playing the percentages alone is
        narrow   and limited thinking... Repeat  after   me, an  increase is an  increase... would   you   rather
        have 285 or 385, 12 or 16, 20 or 27? ...like everything else in this amazingly complex game, there
        are trade-offs and often times things are situational.   Furor [alternative to Improved Mark of the
        Wild], as a couple of the other posters point out, is solo-buffing whereas MoTW [Mark of the
        Wild] is group-buffing. [post #59]

Model-Based Reasoning
        Second,  forms  of  model-based   reasoning such    as understanding  systems,    feedback   mechanisms     among
their components, and the usefulness of describing such relationships mathematically are also regularly displayed by
discussion participants (close to one third of all posts),  although to a   lesser extent than   the scientific discursive
processes discussed above. Given the design of character improvements within the game (i.e. the druid talent tree),
participants are faced with the challenge of finding the best-fit solution to a problem of limited resources (talent
points) for distribution across multiple variables, each with their own mathematical relationship to underlying avatar
characteristics (e.g., hit points, mana points, regeneration speed). Thus, within the fantasy context of orcs and druids,
heals and buffs, participants sometimes find themselves engaged in explicit analyses of complex systems. Consider,
for example, the following post in which a participant compares various potential states of the druid talent tree in
order to claim the superiority of one final template or build over another:

        ...To get  what  I  want  to get in Balance  [first  subsystem  of   the druid talent  tree] while   still
        majoring in Feral [second subsystem] (31/32pts), I can only afford 5 points for Restoration [third
        subsystem]. Considering the rest of my build (Feral), I'm far better off getting instant rage/ energy
        on shift [benefits of "Furor, an alternative to "Mark of the Wild"] than I am blowing those points
        on IMoTW [Improved Mark of the Wild].        Keep in mind, IMoTW [Improved Mark of the Wild]
        only increases MoTW's [Mark of the Wild's] effect by 35%, it is not an overall 35% buff. At L60
        [level 60] that translates to +100 armor, +4 attributes and +7 to resists over the unimproved L60
        [level 60] MoTW [Mark of the Wild]. While every little bit helps, for those precious 5 points,
        Furor [alternative to Improved Mark of the Wild] helps a lot more... [post #3]

        Notice, however, that two key scientific habits of mind related to model-based reasoning are entirely absent
within the data corpus examined here: (1) awareness that, even in simple systems, it may not always be possible to
accurately predict the result of changing some part or connection ("expect noise"), and (2) realizing that even a close
match between a model's predictions and one's observations does not necessarily mean that the model is the only
"true" model  or one that   would  work  ("not equating    model with `Truth'").   Both   habits of  mind  are  crucial to
understanding the appropriate function and use of models in science, yet neither emerges throughout the discussion.
One explanation may be that model-based reasoning in the context of synthetic worlds takes on the characteristics of
reverse engineering, operating under the assumption that there is a single correct algorithm underlying phenomena
and it is only a matter of finding it (discussed below).

Understanding Theory & Evidence
        Finally, scientific habits of mind  related to    understanding the  function  and   relationship  of theory  and
evidence are noticeably rare among posts within the discussion. Although participants do, on occasion (roughly one
tenth of all posts), engage in heuristic rather than simple algorithmic reasoning and transform their observations into
alternative data formats, other related scientific habits of mind are nearly or completely absent. In only three percent
of the posts do  individuals tackle  the potential generalizability  of their solutions   and  we    find no  evidence  of
individuals coordinating their theories with multiple sets of data, reason through uncertainty in their arguments, or

                                                           727                                                   ICLS 2006
displaying a pragmatic understanding of theory (defined above). If we treat the entire discussion group as our unit of
analysis (aggregating across all 31 individuals), these features actually emerge as participants collectively engage in
comparing    various data-warranted     claims; however,   it  remains   an open  question     as   to  whether   individual
participants  might  be  ascribed such  habits  of mind  rather than the group  as   a whole.    If so, it may  be  that the
disputative nature of online forum discussions (a product of the fact that agreements are rarely posted, Hine, 2000)
simply discourages expressions of uncertainty, noise or doubt.

Design Implications
         Again, our goal has been not only to provide empirical evidence to substantiate claims of the potential of
MMOGs as sites for studying science learning but also to offer a beginning set of heuristics that might inform the
future design of intentional learning environments. Analysis of the scientific habits of mind that characterize the data
corpus examined here reveal patterns in the forms of scientific argumentation, model-based reasoning, and theory-
evidence coordination that arise in the context of online discussion of MMOG play. These patterns point to certain
characteristics of MMOGs, both as designed objects and emergent cultures, that seem to afford the emergence of
some scientific habits of mind and constrain others, characteristics of off-the-shelf MMOGs that may be of interest
to designers of online mediated environments specifically for science education. Given the preliminary nature of this
data analysis, however, these design recommendations are still tentative, yet we argue they might productively serve
as a worthwhile starting point for future design experiments of virtual worlds.

         MMOGs are designed experiences ostensibly analogous to any well-crafted piece of instruction, yet they
are also fully realized simulated worlds exhibiting emergent, unpredictable properties. Unlike the simple one or two
variable  experiments    characteristic of   science classrooms   (Chinn,   &   Malhotra,     2002),    MMOGs     (1)  offer
multivariate problems of real complexity and of genuine social import to those solving them. Based on these data,
we would argue that model-based reasoning can be fostered by giving groups complex systems to collaboratively
understand whose outputs are consequential for each individual. (2) Problem-solvers are therefore stakeholders in
that efficient and effective solutions become the basis for future action, both their own and that of their peers. For
example, in the environment studied here, the outputs of the system actually change the very nature of one's virtual
body or avatar; therefore, individuals have a vested interest in finding and sharing potential solutions. Moreover,
while  science classrooms  often  focus   on questions that  can be  answered   with Google,     MMOGs      capture a  more
authentic sense of inquiry into (3) problems whose solutions are generally unknown and require distributed teams of
people doing simultaneous, partially overlapping, partly conflicting lines of research ­ much like science out "in the
wild." Thus,   the forms  of  inquiry   such virtual worlds   afford are  authentic  even     though   synthetic. Scientific
discursive practices emerge when participants are given the chance to solve such problems in contexts where there is
(3) individual  opportunity  to make    a  genuine  contribution to  the collective  intelligence   (Levy,  1999)   of their
community. In such contexts, solutions developed by one person are referenced, debated, and built upon by other
participants. The  resulting forms  of   argumentation   and  model-based   reasoning     set an  impressive  standard   for
scientific thinking to which our designed learning environments (e.g. River City, Quest Atlantis) typically aspire.
However, model-based reasoning in the context of synthetic worlds also appears to take on the characteristics of
reverse engineering, with participants operating under the assumption that there is indeed a single correct algorithm
underlying phenomena and it is only a matter of finding it. Such conditions are bound to be true of any game-based
learning environment since the worlds contained therein are simulations based on algorithms, their interaction, and
some added dose of random noise. Therefore, virtual worlds designed specifically for science learning might do well
to include "what if" comparisons between the simulated world and the natural world it (partially) models. Activities
which (4) prompt learners to reason through, on a meta-level, the function and role of simulations within a given
domain   of  study might  mitigate  the   propensity toward   essentialized notions    of theory    and its relationship  to
evidence.

References
AAUW. (2000). Tech-savvy: Educating girls in the new computer age. Washington DC: American Association of
         University Women Educational Foundation.
AAAS. (1993). Benchmarks for science literacy. New York:        Oxford University Press.
Barab, S.,  Arcici,  A., &   Jackson,   C. (2005).   Eat your   vegetables  and do   your     homework:     A design-based
         investigation of enjoyment and meaning in learning. Educational Technology, 45(1), 15-21.
Chinn, C. A. & Malhotra, B. (2002). Epistemologically authentic inquiry in schools: A theoretical framework for
         evaluating inquiry tasks. Science Education, 86(2) 175-218.

                                                           728                                                    ICLS 2006
Chmiel, M.U. & Owens, T. J. (2005). Anti-evolution literature and its hidden pedagogical value: confronting the
         `creationism'  dilemma.  Presented   at the Eighth  International History, Philosophy, Sociology    &  Science
         Teaching Conference Leeds, UK, July 15-18.
Dede, C., Ketelhut, D. & Ruess, K. (2003). Motivation, usability, and learning outcomes in a prototype museum-based
         multiuser virtual environment. In P. Bell, R. Stevens, & T. Satwicz, (Eds.), Proceedings of the Fifth ICLS.
         Mahwah, NJ: Erlbaum.
Dewey, J. (1910). Science as subject matter and as method, Science, 31(787), 121-127.
Elsner, A. (2005, October 28). Is US becoming hostile to science? CNN.com. Retrieved October 31, 2005 from
         http://www.cnn.com/2005/TECH/science/10/28/science.debate.reut
Friedman, T. L. (2005). The world is flat. New York: Farrar, Straus, and Giroux.
Gates,  B. (2005, February  26).  National  Education   Summit   on High   Schools. Retrieved October   31,  2005  from
         http://www.gatesfoundation.org/MediaCenter/Speeches/BillgSpeeches/BGSpeechNGA-050226.htm
Gee, J. P. (2003). What video games have to teach us about learning and literacy. New York: Palgrave.
Hine, C. (2000). Virtual ethnography. London: Sage.
Jenkins, H., III. (1992). Textual poachers: Television fans & participatory culture. Routledge: New York.
Kuhn, D. (1991). The skills of argument. Cambridge, UK: Cambridge University Press.
Lave, J. (1988). Cognition in practice. Cambridge UK: Cambridge University Press.
Lave, J. & Wenger, E. (1991). Situated learning. Cambridge: Cambridge University Press.
Levy, P. (1999). Collective intelligence. (Robert Bononno, trans.). Cambridge MA: Perseus Books.
Miller, J. D. (2004). Public understanding of, and attitudes toward, scientific research: What we know and what we
         need to know. Public Understanding of Science, 13(3), 273-294.
Nasir, N. S. (2005). Individual cognitive structuring and the sociocultural context: Strategy shifts in the game of
         dominoes. The Journal of the Learning Sciences, 14(1), 5-34.
National   Research Council. (1996). National    Science Education   Standards.   Washington  DC:   National   Academy
         Press.
Osborne, J., Erduren, S., & Simon, S. (2004). Enhancing the quality of argumentation in school science. Journal of
         Research in Science Teaching, 41(10), 994-1020.
Poincare, H. (2001). Science and hypothesis. In S. J. Gould (Ed), The value of science: Essential writings of Henri
         Poincare, (pp. 7-180). New York: The Modern Library. (Original work published 1905).
Schwab, J. J. (1962). The teaching of science as enquiry. Cambridge MA: Harvard University Press.
Shaffer, D. W., Squire, K.D., Halverson, R., & Gee, J.P. (2005). Video games and the future of learning. Phi Delta
         Kappan, 87(2), 105-111.
Singer, S. R.,  Hilton, M., & Schweingruber,     H.  A.  (2005)  America's  lab report:  Investigations in  high school
         science. Washington DC: The National Academy Press.
Solomon, A. (2004, July 10). The closing of the American book. The New York Times, p. A17.
Squire, K.  (2003).  Replaying    history: Learning   world  history through    playing  Civilization III. Unpublished
         dissertation. Bloomington IN: Indiana University, Bloomington.
Squire, K.D. (2005). Educating the fighter. On the Horizon 13(2), 75-88.
Squire, K.  D.  &   Steinkuehler, C. A.    (2005). Gaming    and the significance   for information   literacy learning.
         Presented at the ALA Midwinter Conference, Boston, January 14.
Steinkuehler, C. A. (2004). Learning in massively multiplayer online games. In Y. B. Kafai, W. A. Sandoval, N.
         Enyedy, A. S. Nixon, & F. Herrera (Eds.), Proceedings of the Sixth ICLS (pp. 521­528). Mahwah, NJ:
         Erlbaum.
Steinkuehler, C.A. (2005a). Cognition and learning in massively multiplayer online games: A critical approach.
         Unpublished dissertation. Madison WI: University of Wisconsin-Madison.
Steinkuehler,  C. A. (2005b).  The   literacy of   massively multiplayer   online gaming   versus national   standards.
         Presented at the Annual Meeting of AERA, Montreal Canada, April 11­15.
Steinkuehler, C. A. (2006). Why game (culture) studies now? Games and Culture, 1(1), 1-6.
Steinkuehler, C. A. (in press). MMOGaming as participation in a Discourse. Mind, Culture, & Activity.

                                                           729                                                 ICLS 2006
