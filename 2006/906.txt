                               PD3: A Handheld Observation Tool
                               to Support Instructional Leadership

        Mark Chung, William R. Penuel, SRI International, 333 Ravenswood Avenue, Menlo Park, CA 94025
                                Email: mark.chung@sri.com, william.penuel@sri.com

        Abstract: We designed and developed a handheld classroom walkthrough to support data-based
        decision  making   about    professional  development  and school  improvement    planning.  We  used
        methods   of  participatory   design   to maximize   the usability and   value of   our technology to
        policymakers, school leaders, and teachers, who had different and conflicting goals and concerns.
        We describe design decisions that met their constraints and led to a tool with potential for wide
        adoption, and impact at the local level.

Introduction
        An enduring goal of school reform has been to prepare principals to be better instructional leaders in the
school  (Andrews  &  Soder,    1987; Bossert,   Dwyer,   Rowan,  & Lee,  1982;   Hallinger, Bickman,   &  Davis, 1996;
Spillane, Halverson, & Diamond, 2001).      Although scholars and reform advocates differ in their definition of what
constitutes instructional leadership, there is agreement that it involves principals taking a more active role in guiding
the improvement of instruction in the school.     To guide instruction, principals need to know what is happening in
classrooms, and one model that has gotten increasing attention among state, district, and local school leaders is a
"classroom walkthrough," first brought to the research community's attention by Elmore's (1997) examination of
leadership in New York's District 2.

        A classroom walkthrough is a brief visit by a principal designed to give an instructional leader a snapshot
of what is happening in a teacher's classroom.       The focus of the walkthrough can be on teacher's instructional
practice, the content they are teaching, or on student engagement.    Principals can use the data to determine whether
teachers may need immediate coaching to improve instruction (as in the District 2 model), to inform professional
development and school improvement planning, or as part of a collective data-based decision making process at the
school.

        In 2004, the Miami Museum of Science (MMOS) contracted our research team to design a handheld tool
and Web site to support principals in conducting walkthroughs focused on mathematics and science instruction.
MMOS had observed that few principals felt comfortable making judgments about their teachers' mathematics and
science instruction and believed a handheld tool that could prompt principals what to look for when making a visit to
a classroom could help them and that data from the tool could also be used to inform professional development
decision-making at the school level. Using methods of participatory design (Schuler & Tamioka, 1993), we sought
to maximize the value of our technology to policymakers and school leaders by involving them in design.       As part of
our project,  MMOS      staff, district  administrators, and   school leaders  and   teachers contributed  to scenario
development, requirements analysis, interaction design, and user testing. In this poster, we illustrate some of the
design decisions we had to make along the way and explain why the contributions of stakeholders were so critical in
framing the SRI team's discussion of those decisions and in ensuring that the technology could yield valid data
about teachers' instructional practices.

Design Decisions We Faced
Developing a Common Understanding of Goals
        Our stakeholders ­ state policymakers, district staff, principal trainers, and former teachers ­ had different
and conflicting goals  and  concerns.    State policymakers  were  interested in a  tool that would  become   part of a
principal's toolkit for becoming better instructional leaders. Principals were eager to have a decision support tool
and wanted to give feedback on visits to teachers. Teachers wanted assurances of privacy - that the data could not be
linked  back to them -  and    were concerned   about accurate representation of their   teaching. We worked  with  the
stakeholders to develop a set of personas, or fictitious users to inform our design process, and scenarios of usage
involving the personas. To address the privacy issue, we initially proposed not collecting teacher IDs, but ultimately
put this decision in the tool for maximum flexibility across schools and districts.

                                                           906                                                 ICLS 2006
Observing Content: Who Can Be a User?
         We felt that being able to matrix instructional strategies with the content taught was important for selecting
among    subject-specific professional   development   opportunities.    However,   there was    disagreement  among     the
stakeholders as  to  whether  principals  would  be   able to identify   the topic of a  lesson  reliably. District  content
specialists had little confidence in the ability of non-subject matter experts to discriminate between benchmarks.
They maintained that content experts should observe content and principals should observe instruction. This would
create a validity   problem   for  the matrix  approach.   Principals  countered   that  they  have   scope and   sequence
documents to know what to expect each week. Another option for them is to ask the teacher; if visits were scheduled
in advance,  the  principal  could  ask  the  teacher what  topic was    to  be  covered  ­  but this   would not   work  in
unannounced visits. We decided to allow the principals to select the high-level strand as an alternative to selecting a
benchmark, since we had consensus that a principal would be able to determine the strand with sufficient accuracy.

Selecting Displays of Data
         We  presented    a  focus group   of retired principals  with   a  task that asked   them  to  decide on    teacher
professional development opportunities given a variety of data displays we were considering including in the tool.
The participants wanted the display to be simple and easy to use with no memorization, and said that the time they
could  spend   using the  application   was   extremely  limited. They     wanted   the tool  to indicate   deficiencies in
professional development     and  indicate a  course  of action.  Given  the  low   number   of  visits anticipated, it was
unrealistic to expect the tool to do an analysis, and prescriptive use of the tool was beyond our scope of work.
Instead, we addressed the desire for simplicity and a minimal number of visits required by repositioning the tool as
part of a larger data collection process for school improvement and limiting the number of representations to two:
box plots and scatter plots.

Discussion
We argue that our project illustrates an important general theoretical principle that should guide learning sciences
research if it is to have impact at the local level: stakeholders' own goals, expected uses of designs, and constraints
on their time must all be considered when developing tools intended to have a positive impact on the educational
system. Future research using this tool could investigate its direct effects on principal leadership practice and its
indirect effects on classroom instruction and, more distally, student learning.

References
Andrews, R. L., & Soder, R. (1987). Principal leadership and student achievement. Educational Leadership, 44(6),
         9-11.
Bossert, S., Dwyer,   D.,   Rowan,   B.,  &   Lee, G.  (1982).  The   instructional management      role of   the principal.
         Educational Administration Quarterly, 18(3), 34-64.
Elmore, R. F. (1997). Investing in teacher learning: Staff development and instructional improvement in Community
         School District #2. NY: National Commission on Teaching and America's Future.
Hallinger, P., Bickman,   L., &    Davis, K.  (1996). School    context, principal  leadership  and student   achievement.
         Elementary School Journal, 96(5), 498-518.
Schuler, D., & Tamioka, A. (Eds.). (1993). Participatory design: Principles and practices. Hillsdale, NJ: Lawrence
         Erlbaum Associates.
Spillane, J. P., Halverson, R. R., & Diamond, J. B. (2001). Investigating school leadership practice: A distributed
         perspective. Educational Researcher, 30(3), 23-27.

                                                            907                                                   ICLS 2006
