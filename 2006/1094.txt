                Argumentative Knowledge Construction in CSCL
  Armin Weinberger, Knowledge Media Research Center, Konrad-Adenauer-Str. 40, 72072 Tübingen, Germany
     Douglas Clark, College of Education, Payne 203F, Arizona State University, Tempe, AZ 85287-0911, USA
 Gijsbert Erkens, Research Centre Learning in Interaction, Utrecht University, Heidelberglaan 1, 3584 CS Utrecht,
                                                           NL
  Victor Sampson, College of Education, Payne 203F, Arizona State University, Tempe, AZ 85287-0911, USA
  Karsten Stegmann, Knowledge Media Research Center, Konrad-Adenauer-Str. 40, 72072 Tübingen, Germany
 Jeroen Janssen, Research Centre Learning in Interaction, Utrecht University, Heidelberglaan 1, 3584 CS Utrecht,
                                                           NL
 Jos Jaspers, Research Centre Learning in Interaction, Utrecht University, Heidelberglaan 1, 3584 CS Utrecht, NL
Gellof Kanselaar, Research Centre Learning in Interaction, Utrecht University, Heidelberglaan 1, 3584 CS Utrecht,
                                                           NL
     Frank Fischer, Knowledge Media Research Center, Konrad-Adenauer-Str. 40, 72072 Tübingen, Germany
 Email: a.weinberger@iwm-kmrc.de, Douglas.B.Clark@asu.edu, G.Erkens@fss.uu.nl, victor.sampson@asu.edu,
k.stegmann@iwm-kmrc.de, j.j.h.m.janssen@fss.uu.nl, j.jaspers@fss.uu.nl, G.Kanselaar@fss.uu.nl, f.fischer@iwm-
                                                          kmrc.de

         Abstract:  Knowing     how   to  argue  is a prerequisite  to  participation in  scientific discourse.  In
         argumentative knowledge construction, learners collaboratively construct and engage in arguments
         with  the goal    of  learning  to argue   within a   domain.   Students   have   difficulties,   however,
         constructing   and    evaluating  arguments.  Computer-supported        collaborative learning    (CSCL)
         attempts to address these difficulties by providing students with additional resources and tools to
         visualize and guide their argumentation. This symposium presents results from empirical studies
         on   facilitating and  analyzing   argumentative  knowledge     construction  in  CSCL.     These  studies
         assess the structural and conceptual quality of learners' arguments; provide sequential analyses of
         how learners exchange arguments in discourse, and investigate the relationship between cognitive
         processes of learners and the construction of arguments in discourse.

Argumentative Knowledge Construction in CSCL
         Current research suggests that argumentative knowledge is an important component of critical thinking and
decision-making  in everyday    situations  (Kuhn,  1991)  and   understanding   and  participating  in  scientific discourse
(Driver, Newton, & Osborne, 2000; Sandoval & Millwood, 2005). The term argumentative knowledge refers to an
understanding of how to examine and evaluate data and then construct arguments for and against a course of action
or point of view. Students in secondary schools and universities, however, have difficulties constructing reasoned
arguments   and evaluating     the  arguments    of others (Duschl     & Osborne,     2002; Kuhn,    1991).    This  lack   of
argumentative   knowledge      has fuelled  research  on   how   to  facilitate learners' construction     of argumentative
knowledge (Perkins, 1989; Kuhn, Shaw, & Felton, 1997).

         In argumentative knowledge construction learners engage in argumentation in order to learn how to argue
within a domain    (Kuhn    et al, 1997).  But  engaging   students  in argumentative    knowledge    construction   raises a
paradox: participating in argumentative discourse with the goal to learn how to argue within a domain may be the
best way  to  develop students'    argumentative    knowledge,   but students'   understanding  of   how   to construct and
evaluate arguments  may     interfere with  this process.  To address    this concern, a  number     of computer-supported
collaborative  learning    (CSCL)   environments     have  been   designed    to  support   students    as they  engage     in
argumentative knowledge construction.

         Current research suggests that CSCL environments have a number of advantages over traditional forms of
classroom instruction for facilitating the process of argumentative knowledge construction (Andriessen, Baker, &
Suthers, 2003; Joiner & Jones, 2003; Kirschner, Buckingham Shum, & Carr; 2003; Marttunen & Laurinen, 2001;
Weinberger & Fischer, 2006). First, CSCL encourages peer interaction, which has been successfully drawn upon to
facilitate argumentative knowledge construction (Kuhn et al., 1997; Schwarz, Neuman, Gil, & Ilya, 2003). Second,
in CSCL environments, asynchronous communication can be used as a way to encourage learners to construct and
(re-)evaluate arguments     by providing   them  with  as  much  time   as they   require when  generating     comments     or

                                                            1094                                                    ICLS 2006
responding to the comments of others (Joiner & Jones, 2003; Pea, 1994). Third, CSCL environments can implement
special tools    and  scaffolds   to  guide learners    in  effective argumentative    knowledge    construction.  For example,
Kirschner   et   al. (2003)  developed    a tool   that enables   learners  to visualize single  arguments     and sequences   of
argumentation while Jermann and Dillenbourg (2003) developed tools that script and scaffold learners' interaction
by assigning and prompting roles for the learners. Taken together, this body of research suggests that computer-
supported collaborative learning environments can facilitate the development of argumentative knowledge.

Research Presented
         Building     upon   this research,   this symposium     provides   new  insights   into the  teaching  and  learning  of
argumentation. The papers (a) discuss ways to provide students with additional resources and tools to visualize and
guide their argumentation, (b) present results of empirical studies on different facets of facilitating and analyzing
argumentative knowledge construction in CSCL, and (c) introduce new ways to assess the structural and conceptual
quality of learners' arguments and their understanding of argumentation. Taken together, these studies emphasize
that argumentation is more than a cognitive activity of coordinating data around claims; it is also a social practice of
persuasion and collaborative knowledge construction.

Visualizing participation to facilitate argumentation
Gijsbert Erkens, Jeroen Janssen, Jos Jaspers, & Gellof Kanselaar
Research Centre Learning in Interaction, Utrecht University

Introduction and Theoretical Background
         Participation     and   equality   of   participation   are  important  prerequisites   for  effective  and   beneficial
collaborative    learning    (Cohen,    1994;  Weinberger      &  Fischer,  2006).  Unfortunately,    students  do  not  always
participate equally     in   argumentative    discussions    in CSCL     environments    (Lipponen,   Rahikainen,   Lallimo,   &
Hakkarainen, 2003). However, Michinov and Primois (2005) and Zumbach, Hillers, and Reimann (2004) suggest
that providing a way for students to visualize levels of participation in a discussion can stimulate participation and
thus  facilitate argumentative    knowledge      construction.   Providing  a  visualization of  students' participation creates
opportunities    for social  evaluation  and   constitutes   a  possible motivational  incentive  to  increase group   members'
participation  (Shepperd,    1993).   Providing    a visualization    of participation also  raises students'  awareness   of the
constructive, communicative, and social processes taking place during argumentative discussion (Kreijns, 2004).

         In order     to investigate    the degree   to which    visualization  of  participation   stimulates group   members'
participation rates and facilitates argumentative knowledge construction, a new tool was added to an existing CSCL-
environment (Virtual Collaborative Research Institute/VCRI, Jaspers, Broeken, & Erkens, 2004). This Participation
Tool visualizes the contributions of each group member to the group's online communication (see Figure 1). Each
student is represented by a sphere. The distance of a sphere to the group center indicates the number of messages
sent by the student; whereas the size of the sphere indicates the average length of messages. The Participation Tool
therefore visually     clarifies  the   quantity and    the  homogeneity/heterogeneity    of  participation.   An  earlier study
demonstrated that, compared to control group students, students with access to the Participation Tool (treatment
group students) participated more actively during online collaboration (more and longer utterances) and engaged
more deeply in the coordination of social activities (Janssen, Erkens, Kanselaar, & Jaspers, in press). These findings
raise two   new      questions.   (1) Is  participation    a sufficient   condition for  effective   argumentative   knowledge
construction? (2) Does improving participation also improve the quality of argumentative knowledge construction?

Methods and Data Analysis
         We conducted sequential analyses of the arguments group members constructed. In lag-sequential analysis
(Bakeman & Gottman, 1997; Wampold, 1992), the transition patterns between the arguments in a discourse protocol
can be statistically tested on different intervals (lags) between the events. The computer program Multiple Episode
Protocol Analysis (MEPA), which was developed at Utrecht University, is used for sequential analysis and coding
of argumentative      discussions    of collaborating   students. The    chat  protocols of  52  treatment  group   students  (17
groups) and    17    control group    students (5  groups)   were  analyzed.   These   students  (age 16-18)   worked  for eight
lessons in groups of three or four students on an inquiry-based group task as part of their history curriculum. The
communicative function of each chat utterance was coded into `dialogue acts'. The dialogue acts were organized
into 28 sub-categories within five main categories of communicative function: argumentative (indicating a line of

                                                                1095                                                   ICLS 2006
argumentation or reasoning), responsive (answers to questions and proposals), informative (transfer of information),
elicitative (questions or proposals requiring a response), and imperative (commands).

                                       Figure 1. Screenshot of the Participation Tool
Results and Conclusions
          The results of our analyses show that Participation Tool students engage in a higher number and frequency
of argumentative dialogue acts. This increase is due to an increase in counter arguments and conditional arguments.
Furthermore,    results  of sequential  analyses indicate    that treatment   groups  use different argumentation    patterns
compared    to  control  groups. More   specifically, treatment    groups engage   in longer  sequences   of   argumentation.
Finally,   sequential   analysis indicates  that successful    groups    (those who   write  better  reports)  use   different
argumentation patterns than less successful groups. Not only does the Participation Tool help students construct
arguments, it also helps students construct arguments in specific cycles with their group members. In conclusion,
visualizing participation appears to facilitate argumentative knowledge construction by raising students' awareness
the manner in which they are collaborating, thereby stimulating them to construct more arguments and engage in
different  argumentation     patterns. In  our  future   research,   we  will try to  facilitate argumentative    knowledge
construction further by visualizing argumentative discourse of participants during online collaboration.

Scripting Online Discussions: Effects on Argumentative Discourse, Cognitive Processes,
and Knowledge Acquisition
Armin Weinberger, Karsten Stegmann, & Frank Fischer
Knowledge Media Research Center (KMRC), Tübingen

Introduction and Theoretical Background
          A   central goal  of university  education   is to  develop   students' ability to understand   and  participate in
argumentative   discourse   within   a specific field of  study.  In argumentative   knowledge    construction,  learners  are
believed   to  expand   their  argumentative    and domain-specific     knowledge  on  a  cognitive  level  by  constructing
arguments and counterarguments as they solve a complex problem case in their domain (Andriessen, et al., 2003;
Marttunen & Laurinen, 2001; Weinberger & Fischer, 2006). Learners, however, often do not know how to engage in
argumentative discussions (Kuhn, 1991).

          Recently,    computer-supported       collaboration  scripts    were    developed   to   facilitate  processes   of
argumentative   knowledge      construction (Jermann     & Dillenbourg,   2003).  Based   on  O'Donnell's     (1999) scripted
cooperation approach, computer-supported collaboration scripts pre-structure roles and activities, e.g., by providing
text prompts that guide learners to engage in specific interaction patterns (Baker & Lund, 1997; Nussbaum, Hartley,
Sinatra, Reynolds, & Bendixen, 2002). We hypothesize that scripts for argumentative knowledge construction can
guide learners as they construct arguments and in so doing, their argumentative knowledge can be improved on a
cognitive  level. Results   so   far show  that  scripts  can facilitate specific  discourse  activities, such  as epistemic
activities that aim   to construct   knowledge,  but  this does   not always  contribute  to the  facilitation of knowledge
acquisition (Mäkitalo, Weinberger, Häkkinen, Järvelä, & Fischer, 2005). Some scripts appear to hinder cognitive
processes by oversimplifying the learning task (Reiser, 2002; Weinberger, Ertl, Fischer, & Mandl, 2005). However,
little is known about the relationship between the construction of arguments in discourse and the cognitive activities

                                                             1096                                                   ICLS 2006
of  individual learners. If scripts facilitate  the  construction  of arguments   in  discourse,  do they also facilitate the
cognitive elaboration of knowledge?

Methods and Data Analysis
         We conducted two experimental studies with different foci of analysis in a CSCL environment with groups
of three students enrolled in Educational Science. In the first study (n = 60), we analyzed the effects of a computer-
supported  collaboration  script that  aimed    to support  the construction   of single arguments     on the processes   and
outcomes of argumentative knowledge construction (see figure 3) based on the written online discussions of the
learners with regard to the epistemic quality of arguments (i.e., the extent the arguments contributed to solving the
learning task by applying specific theoretical concepts) and the formal argumentative quality of arguments (i.e., the
extent the arguments included claims, warrants, data, and qualifiers). In the second study (n = 54) with the script for
the  construction of single  arguments     (vs. control)   we  also   analyzed  the cognitive processes    of argumentative
knowledge construction based on think-aloud protocols during the text-based collaboration, regarding the level and
focus of elaboration, as well as their relation to the respective discourse activities.

                     Figure 3: Input mask remodeled by a script for constructing single arguments
Results and Conclusions
         Results  of the  first  study show     that computer-supported     scripts  can facilitate  specific processes   and
outcomes of argumentative knowledge construction. Learners with scripts construct arguments of higher structural
quality and acquire more argumentative knowledge than learners without scripts. Results of the second study show
that constructing   formally    adequate   arguments   in   discourse  fosters  cognitive  processes    and   acquisition   of
argumentative   knowledge.   The    acquisition  of  domain-specific   knowledge,     however,   depends  on   the epistemic
quality of  arguments    constructed  in online    discussions  and   the focus of   elaboration. Learners'   activities on a
cognitive level are generally closely related to discourse activities as well as to individual knowledge acquisition.
Learners   who acquire   more   domain-specific    knowledge    than  average  spend  more effort   to cognitively elaborate
single arguments rather than to construct many arguments with little cognitive elaboration.

Evaluating Argumentation in Science: New Assessment Tools
Douglas Clark & Victor Sampson
College of Education, Arizona State University

Introduction and Theoretical Background
         Researchers   have  developed     several  different methods   to investigate argumentative    discourse.  To   date,
most of these investigations have relied heavily on Toulmin's (1958) model of argument structure in one way or
another (e.g., Erduran, Osborne & Simon, 2004). In these studies, emphasis is placed on the identification of the
structural features of arguments    (e.g., claims,   data, warrants,  backings,   and rebuttals). Such  approaches   seek   to
identify the absence or presence of the components of argument and use this information to assess argumentation
quality. These types of structural analyses of student arguments have contributed a great deal to our understanding
of how students assimilate the desired practices of argumentation and provide a great deal of information about the
form and type of reasoning that students use when they construct arguments based on their everyday experiences
(Driver et al., 2000). However, they provide little information about (a) the types of argumentative knowledge and

                                                              1097                                                 ICLS 2006
skill young people bring with them to their science classrooms, (b) how students ideas about the nature of science
influence the ways they participate in argumentative discussions, and (c) how students' conceptual ideas about the
subject matter change as a result of participation in dialogic argumentation.

The Instruments
        Specifically,   this  study presents         (a)  an   analytic scheme     for assessing   argumentative       discourse    in
asynchronous   online  environments   that       extends    beyond the  structural  analysis that has been  the focus      of     much
argumentation research, (b) The Nature of Science as Argument Questionnaire (NSAAQ) which evaluates students'
epistemological commitments related to argumentation, and (c) an Argumentation in Science Rating Task (ASRT)
which evaluates the criteria used by students for evaluating the quality of arguments and argumentative discourse.

        An    analytic scheme  for  assessing         argumentative   discourse  in  asynchronous   online  environments.          Our
scheme  first scores   the individual comments           in terms  of structural operation,  grounds  quality,  and      conceptual
quality. Each comment is coded in the context of its parent comment. Structural operation is a categorical (nominal)
code representing the   comment's   role        or intended  role  in a co-constructed   dialogic  argument. Sample        structural
operation categories include: claim, rebuttal against grounds, organization of participation, and off-task comments.
Grounds Quality is an ordinal code with four levels representing the quality of grounds included with a comment: no
grounds (level 0), explanation only (level 1), explanation with evidence (level 2), and explanation that coordinates
evidence (level 3). Conceptual Quality is an ordinal code with four levels representing the conceptual quality of the
scientific subject matter including non-normative (level 0), transitional (level 1), normative (level 2), and nuanced
(level 3) use of content. After coding the individual comments, the discussion is parsed into discourse episodes
based on the second-order comments. This is a completely mechanical process based on responses to the initial seed
claims. We then assign a structural quality code to each discourse episode based on the structural operation codes of
the constituent comments. The structural quality code is an ordinal code with six levels measuring the opposition
within the episode   from   a structural        (not conceptual)  perspective.  These   structural quality levels      include    non-
oppositional episodes (level 0), argumentation with claims or counterclaims but no grounds or rebuttals (level 1),
argumentation with claims or counterclaims and grounds but no rebuttals (level 2), argumentation with grounds and
a single rebuttal (level 3), argumentation with multiple rebuttals (level 4), and argumentation with multiple rebuttals
and at least one rebuttal against grounds (level 5).

        The Nature of Science as Argument Questionnaire (NSAAQ).                    This instrument was developed in order to
identify important aspects of an individual's epistemological beliefs related to the role argumentation plays in the
generation and evaluation of scientific knowledge. We hypothesize that the difficulties students have engaging in
scienitifc argumentation that are so well documented in the literature may be explained, in part, by exmining the
epistemological commitments they have about the nature and limits of scientific knowledge.             If students do not share
the same epistemological     committments          that guide  and  constrain  scientific argumentation    within      the scientific
community, then it is unlikely that students will engage in scientific argumentation in a way that reflects the norms
of the scientific community.   The NSAAQ is designed to measure and characterize an individual's epistemological
beliefs regarding: (a) the nature of scientific knowledge; (b) the methods used to generate scientific knowledge; (c)
how scientific knowledge should be evaluated; and (d) whether or not science is a social and cultural practice. The
NSAAQ consists of 26 contrasting alternatives items (see figure 4) divided into four subsclaes.                 The validity and
reliability of the NSAAQ was examined using a methodological framework proposed by Gubba and Lincoln (1990)
who suggest that a credible instrument must have strong construct and criterion validity in addition to being reliable.

                  Viewpoint A                     A not B  A >B   A=B    B>A   B not A              Viewpoint B
         Science is best described as a processof exploration and experiment.1234 5       Science is best described as a processof explanation and argument.

                           Figure 4. An example of a NSAAQ contrasting alternatives item
       The Argumentation in Science Rating Task (ASRT).               Scientists construct arguments by relating the evidence
they have gathered to the conclusions they reach through the use of warrants and backings (Erduran, Simon, &
Osborne, 2004).  Scientists also challenge the acceptability or validity of the claims proposed by other scientists by
challenging the evidence, warrants, and backings that were used to justify a given conclusion (Latour & Woolgar,
1986; Longino, 1990).      Therefore, the ASRT was developed in order to assess the criteria used by students for
evaluating the quality of arguments and the quality of challenges to arguments used during argumentative discourse.
The ASRT consists of six items, three that focus on the quality of argument that can be used to justify a claim and

                                                                 1098                                                      ICLS 2006
three that focus on the quality of a challenge to an argument.                 For each item, individuals are asked to rank six
arguments or six challenges to an argument in terms of quality.               An example of an ASRT is shown in figure 5.               The
validity and    reliability of the  ASRT     was examined     using   the    same   methodological           framework    that   was  used  to
develop and validate the NSAAQ.

          Claim: Objects that are in the same room are the same temperature even though they feel different                  Your
          because...                                                                                                       Ranking
          ...when we measured the temperature of the table, it was 23.4OC, the metal chair leg was 23.1OC, and the
          computer keyboard was 23.6OC.

          ...good conductors feel different than poor conductors even though they are the same temperature.
          ...objects that are in the same environment gain or lose heat energy until everything is the same temperature.
          Our data form the lab proves that point: the mouse pad and plastic desk were both 23OC.
          ...objects will release and hold different amounts of heat energy depending on how good of an insulator or
          conductor it is.

          ...our textbook says that all objects in the same room will eventually reach the same temperature.
          ...we measured the temperature of the wooden table and the chair leg and they were both 23OC even though
          the metal chair leg feels colder.  If the metal chair leg was actually colder it would have been a lower
          temperature when we compared it to the temperature of the table.

                                             Figure 5. An example of an ASRT item
Results and Conclusions
        The inter-rater reliability of argumentative coding scheme, which is designed to provide a reliable method to
parse, code, and analyze student argumentation in asynchronous online forums based on structure, grounds, and
conceptual quality of individual comments, is 93% for structural operation, 94% for conceptual quality, and 95% for
grounds quality. Taken together, these statistics indicate that the coding scheme is reliable despite its complexity.
The construct validity of the NSAAQ and the ASRT has been established by assessing the content, face, translation,
and discriment    validity    of the instruments.     The   criterion      validity of the  NSAAQ            and ASRT      was   assessed   by
examining the convergent and concurrent validity of the instruments based on their psychometric properties.                           Hence,
these instruments are likely to give data from which valid conclusions can be drawn. This means that the NSAAQ
and the ASRT are likely to be useful tools for researchers who wish to measure the degree in which an individual's
epistemological beliefs reflect those of the scientific community and the criteria used by students for evaluating the
quality of arguments and argumentative discourse.

References
Andriessen, J., Baker, M., & Suthers, D. (Eds.). (2003). Arguing to learn. Confronting cognitions in computer-supported
         collaborative learning environments. Dordrecht: Kluwer.
Bakeman,     R. &  Gottman,    J.M.  (1997).   Observing   interaction:    An  introduction to     sequential    analysis.    Second  Edition.
         Cambridge: University Press.
Baker,  M.,  &   Lund, K.   (1997).  Promoting   reflective interactions    in a CSCL   environment.         Journal of    Computer   Assisted
         Learning, 13, 175-193.
Bell, P. (2004). Promoting disciplinary-sensitive argumentation across history and science in the elementary school classroom. In
         Y. B. Kafai, W. A. Sandoval, N. Enyedy, A. S. Nixon, & F. Herrera (Eds.), Embracing Diversity in the Learning
         Sciences. Proceedings of the International Conference of the Learning Sciences. Mahwah, NJ: Erlbaum.
Cohen, E. G. (1994). Restructuring the classroom: Conditions for productive small groups. Review of Educational Research,
         64(1), 1-35.
Driver,  R., Newton,   P.,  &  Osborne,  J.  (2000). Establishing  the     norms of  scientific   argumentation      in   classrooms. Science
         Education, 84(3), 287-313.
Duschl, R. A., & Osborne, J. (2002). Supporting and promoting argumentation discourse in science education. Studies in Science
         Education, 38, 39-72.
Erduran, S.,  Simon,   S.,  &  Osborne, J.   (2004). TAPing   into argumentation:      Developments     in     the application   of Toulmin's
         argument pattern for studying science discourse. Science Education, 88, 915-933.
Gubba, E. G., & Lincoln, Y. S. (1990). Fourth generation evaluation. Newbury Park, CA: Sage
Hewson, P. W. (1985). Epistemological commitments in the learning of science: Examples from dynamics. European Journal of
         Science Education, 7, 163-172.
Janssen, J., Erkens,   G.,  Kanselaar, G.,   & Jaspers, J.  (2005, in  press).   Visualization    of participation:      does it contribute to
         successful computer-supported collaborative learning? Computers & Education.

                                                                1099                                                                ICLS 2006
Jaspers, J., Broeken,  M., &   Erkens,   G. (2004).  Virtual  Collaborative Research  Institute  (VCRI)  (Version  2.0). Utrecht:
          Onderwijskunde Utrecht, ICO/ISOR.
Jermann, P., & Dillenbourg, P. (2003). Elaborating new arguments through a CSCL script. In P. Dillenbourg (Ed.), Learning to
          argue (Vol. 1, pp. 205-226). Dordrecht: Kluwer.
Joiner R., & Jones S. (2003). The effects of communication medium on argumentation and the development of critical thinking.
          International Journal of Educational Research, 39(8), 861-971
Kirschner, P., Buckingham Shum, S. J., & Carr, C. S. (Eds.). (2003). Visualizing argumentation. Software tools for collaborative
          and educational sense making. Dordrecht: Kluwer.
Kreijns, K. (2004). Sociable CSCL environments: Social affordances, sociability, and social presence. Unpublished PhD thesis,
          Open Universiteit, Heerlen, The Netherlands.
Kuhn, D. (1991). The skills of argument. Cambridge: University Press.
Kuhn, D., Shaw, V., & Felton, M. (1997). Effects of dyadic interaction on argumentative reasoning. Cognition and Instruction,
          15(3), 287-315.
Lipponen, L., Rahikainen, M., Lallimo, J., & Hakkarainen, K. (2003). Patterns of participation and discourse in elementary
          students' computer-supported collaborative learning. Learning and Instruction, 13(5), 487-509.
Mäkitalo, K., Weinberger, A., Häkkinen, P., Järvelä, S., & Fischer, F. (2005). Epistemic cooperation scripts in online learning
          environments: Fostering learning by reducing uncertainty in discourse? Computers in Human Behavior, 21(4), 603-
          622.
Marttunen,   M.,  &  Laurinen, L.  (2001).  Learning    of  argumentation skills in networked    and face-to-face  environments.
          Instructional Science, 29, 127-153.
Michinov, N., & Primois, C. (2005). Improving productivity and creativity in online groups through social comparison process:
          New evidence for asynchronous electronic brainstorming. Computers in Human Behavior, 21(1), 11-28.
Nussbaum, E. M., Hartley, K., Sinatra, G. M., Reynolds, R. E., & Bendixen, L. D. (2002, April). Enhancing the quality of on-line
          discussions. Paper presented at the Annual meeting of the American Educational Research Association, New Orleans,
          LA.
O'Donnell, A. M. (1999). Structuring dyadic interaction through scripted cooperation. In A. M. O'Donnell & A. King (Eds.),
          Cognitive perspectives on peer learning (pp. 179-196). Mahwah, NJ: Erlbaum.
Osborne, J., Erduran, S., & Simon, S. (2004). Enhancing the quality of argumentation in science classrooms. Journal of Research
          in Science Teaching, 41(10), 994-1020.
Pea, R.   D.  (1994). Seeing   what we    build   together: Distributed multimedia   learning environments    for transformative
          communications. Special Issue: Computer support for collaborative learning. Journal of the Learning Sciences, 3(3),
          285-299.
Perkins, D. N. (1989) Reasoning as it is and as it could be: An empirical perspective, in D. M. Topping, D. C. Crowell, & V.N.
          Kobayashi (Eds.), Thinking across Cultures: the third international conference on thinking (175-194). Hillsdale, NJ:
          Erlbaum.
Perkins, D.   N., &   Simmons,  P.  E.   (1988). Patterns  of misunderstanding:  An  interactive model   for science, math,  and
          programming. Review of Educational Research, 58, 303-326.
Reiser, B. J. (2002). Why scaffolding should sometimes make tasks more difficult for learners. Paper presented at
          the CSCL Conference, Boulder, CO.
Sandoval, W. A., & Millwood, K. A. (2005). The quality of student's use of evidence in written scientific explanations. Cognition
          and Instruction, 23(1), 23-55.
Schwarz, B. B., Neuman, Y., Gil, J., & Ilya, M. (2003). Construction of collective and individual knowledge in argumentative
          activity. The Journal of the Learning Sciences, 12(2), 219-256.
Shepperd, J. A. (1993). Productivity loss in performance groups: A motivation analysis. Psychological Bulletin, 113(1), 67-81.
Toulmin, S. (1958). The uses of argument. Cambridge: University Press.
Wampold, B.E. (1992). The intensive examination of social interaction. In T.R. Kratochwill & J.R. Levin (Eds.) Single-case
          research design and analysis: New directions for psychology and education (p.93-133). Hillsdale, NJ: Erlbaum.
Weinberger, A., & Fischer, F. (2006). A framework to analyze argumentative knowledge construction in computer-supported
          collaborative learning. Computers & Education, 46, 71-95.
Weinberger, A., Ertl, B., Fischer, F., & Mandl, H. (2005). Epistemic and social scripts in computer-supported collaborative
          learning. Instructional Science, 33(1), 1-30.
Zumbach, J., Hillers, A., & Reimann, P. (2004). Distributed problem-based learning: The use of feedback mechanisms in online
          learning. In T. S. Roberts (Ed.), Online collaborative learning: Theory and practice (pp. 86-102). Hershey, PA: Idea
          Group.

Acknowledgements
The projects were partly funded by the Netherlands Organization for Scientific Research as part of the CRoCiCL
project (nr. 411-02-121), the US National Science Foundation (NSF-CLT), and the Deutsche
Forschungsgemeinschaft (DFG; FI 792/2-2).

                                                               1100                                                   ICLS 2006
