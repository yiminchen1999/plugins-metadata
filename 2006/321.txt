           Using Students' Epistemologies of Science to Guide the
                                        Practice of Argumentation

  Lisa Kenyon, Wright State University, 3640 Colonel Glenn Hwy Dayton OH 45435, lisa.kenyon@wright.edu
          Leema Kuhn, Brian J. Reiser, Northwestern University, 2120 Campus Drive Evanston IL 60208
                              Emails: l-kuhn@northwestern.edu, reiser@northwestern.edu

          Abstract: Understanding students' epistemologies of science have become a primary focus for
          scientific literacy. We want students to be able to reason about evidence and evaluate knowledge
          claims. This requires an understanding about the epistemology of science and inquiry practices. In
          this paper, we propose a functional approach for using students' epistemologies to guide inquiry
          practices. In our design, students use a set of criteria that reflects epistemologies of science and
          guides  construction   and  evaluation  of explanations     in their    scientific investigations.  We   use
          argumentation   to  create a  need  for students  to use  these   criteria to  compare    and   evaluate one
          another's explanations.    This study   takes place  in a  7th grade     project-based    ecology  unit. Our
          analysis shows    that these  criteria guide  students  as  they  construct    and  evaluate  explanations.
          During   this process,  students enhance   their epistemologies      of  science   and the quality  of   their
          scientific work products.

          Understanding what students know about science has been a long-term goal for scientific literacy (AAAS,
1990;  NRC,    1996).   We   want students   to  understand  epistemology      of  science,  and  more    importantly,   how   the
scientific community engages in real life decision-making. Ultimately, we want students to be able to reason and
evaluate knowledge claims about scientific issues. This requires an understanding of both epistemology of science
and inquiry practices. Most empirical research has focused on epistemological understandings as an end in itself
relying on explicit instructional approaches and assessments to determine student understandings (Abd-El-Khalick
& Lederman, 2000; Bartholomew, Osborne, & Ratcliffe, 2004; Schwartz & Lederman, 2002). We see the value in
using  an explicit  approach,    but question   whether  students  will  see   relevancy     and use  these  understandings    in
authentic situations.

         Duschl (2000) suggests that nature of science is made explicit when students examine, discuss, and argue
about good evidence and decide between alternative explanations through their own investigations. Hogan (2000)
supports  this notion   that  epistemology   resides in  the  practice   of inquiry.    Recently,   Sandoval  (2005)     made  an
argument  for  further   study   of  student  practical epistemologies      in which    students    apply their  own   scientific
knowledge  building     through  inquiry  and school  science. He    makes     the distinction   between  practical and   formal
epistemologies, the latter referring to students' expressed beliefs about professional science, and trying to make the
bridge between    the   two  understandings.  Sandoval   suggests   a research     agenda  in  which  we   document    students'
epistemic decisions     while constructing   and  evaluating  scientific work      products.  It is common    to   see nature  of
science and epistemology of science used interchangeably, both expressing the theory of scientific knowledge. For
purposes  of this  paper  and  examining   students'  beliefs  about  scientific   knowledge     we  will use epistemology     of
science.

          In this study, we build on this idea of using epistemological understandings to influence the practice of
inquiry.  We   use  design   strategies  focused  on creating   opportunities      that convince    students  of   the utility of
epistemological understandings in their decision-making process. Our first design strategy was to use argumentation
(in small and whole class settings) to create a need for students to use epistemologies of science throughout their
interactions with one another - argumentation made the epistemologies of science necessary. In the second design
strategy, students develop a set of epistemological criteria that they use to help guide their arguments and decision-
making. Thus, the criteria support students' engaging in scientific argumentation by providing them with tools on
which to base their evaluations of one another's explanations. In this paper, we examine ways students learn to use
the criteria to construct and evaluate explanations, how the uses of the criteria affect the quality of the work, and
what epistemologies of science students learn through this process.

                                                             321                                                       ICLS 2006
Curriculum Context
         This study took place in the context of a 7th grade ecology unit that situates student learning in project-
based inquiry investigations (Bruozas, Finn, Tzou, Hug, Kuhn, & Reiser, 2004). The unit is designed for eight-
weeks and divided into two parts. The existing unit supported the practice of constructing explanation; we extended
the explanation  supports   to foster sophisticated epistemologies     of science, by  having   students argue   about their
explanations  thereby   motivating   the relevancy  of  these epistemological     understandings. The    design  team  used
Toulmin's argumentation model (1953) to design an instructional framework to support scientific explanations. This
framework consists of three components, claim, evidence, and reasoning (McNeill & Krajcik, in press). In order to
enable students  to    use epistemologies  to guide   their inquiry,   we took  this design   approach   a  step further  by
enhancing the instructional framework. In the first part of the unit, students are asked to develop a list of criteria
specific to claim, evidence and reasoning during a whole class discussion (see Table 1). This list of explicit criteria
was then refined and turned into a scoring rubric that students used to assess the quality of claim, evidence, and
reasoning during construction and evaluation of explanations.

Table 1. Students' criteria list of claim, evidence, and reasoning.
    Claim                                Evidence                                  Reasoning
    The claim answers the                The evidence is specific.                 The big ideas connect to
    question.                                                                      evidence.
    The claim is specific.               The evidence came from data not
                                         opinion.
    The claim is based on facts.         There is enough evidence.
                                         The evidence supports the claim.

         Although students participated in the entire eight-week unit, for this paper we present research findings
from the second part of the unit. In part two, students learn about an ecological crisis in the Galapagos Islands where
the majority of ground finches have suddenly died during the dry season of 1977. While investigating the mystery
about why most finches died but some survived, students use Galapagos Finches software and work with a dataset,
find mathematical patterns in species survival, and build a scientific explanation that accounts for the differential
survival (Reiser, Tabak, Sandoval, Smith, Steinmuller, & Leone, 2001). Over the course of this investigation we
designed activities to provide students with opportunities to use the epistemological criteria to guide their arguments
about their differing solutions to the finch mystery. This investigation provides an opportunity for students to use
criteria about claim, evidence and reasoning while arguing about which solutions to the finch mystery are most
convincing.

Method
         We collected data from a 7th grade science class in which the cooperating teacher recruited for the study
had pilot tested project-based curriculum for our research teams in prior years and had some familiarity with the
approach of project-based science. It is important to point out that these students had completed our chemistry unit
prior to the  enactment    of  this  biology unit. Students   were   therefore  introduced   to the  scientific  explanation
framework   used    in both  units.  However,  students did   not use   a set  of criteria to construct  or evaluate   their
explanations within an argumentation context. Our study focuses on this extension: in what ways did students use
the criteria to guide the practices.

         Participants included 64 students divided among three class periods from an urban Midwestern school. The
design   strategies were   developed   through  weekly   design   meetings    with  the  second   author   and   the teacher
participating in the   study.  Researchers   acted as participant  observers   in  the third  period class, observing     and
occasionally interacting with the teacher and students throughout the lessons. Eight students from this class were
randomly selected as a focus group to observe and follow during the enactment. We collected daily videotapes and
pre/post interviews    from the third  period and  written  artifacts, pre/post epistemological   questionnaires     from all
periods.

         We used Conley et al. (2004) epistemological questionnaire to examine students' epistemological beliefs
before and after the enactment of the unit. This questionnaire was based upon earlier work by Elder (2002) and
divided into four epistemological belief dimensions: knowledge form external authorities (source), science has one

                                                            322                                                    ICLS 2006
right answer (certainty), science as an evolving and changing discipline (development) and how individuals support
and justify knowledge (justification). The questionnaire was composed of 26-items and rated on a 5-point Likert
scale (1=strongly    disagree; 5=    strongly agree). We   also included   a  second written  part   to  the questionnaire  to
examine   how    the   epistemological  criteria  with   which  they had   practiced  throughout     the unit  affected their
evaluations of scientific explanations. In this second part, students were given a fictional scenario followed by four
scientific explanations. Students evaluated the claim, evidence, and reasoning for each explanation using a scoring
rubric on a 5-point Likert scale (1=poor, 3=average, 5=excellent). We conducted pre/post interviews with the focus
students in which they explained their evaluation of the explanations.

Analysis
        In   this study,  we   examined    how   using   epistemological  criteria about   claim,  evidence,  and   reasoning
influenced   the  construction   and    evaluation    of  student   explanations.  These    criteria  represented   students'
epistemologies of science, particularly the nature of evidence, and we wanted to see ways that students learned to
use these    criteria. We    analyzed  videotape   and    interview  data  to examine    how   students     were  using their
epistemologies    to construct and   evaluate  explanations.  We  examined    the  quality of scientific explanations   using
videotape  data   and  written artifacts. Lastly, we   looked  at pre/post epistemological    questionnaires   to  investigate
changes in students' epistemological beliefs.

Learning to Use the Criteria
        We looked at student discourse in the classroom to find out how they were using the criteria to construct
and evaluate explanations. Each student pair was given a packet to guide their investigations of the software. The
packet included a scoring rubric for pairs to evaluate one another in small and large group settings. We designed two
activities for students to use the criteria to evaluate one another's scientific explanations (Kuhn, Kenyon, & Reiser,
2006). One occurred during an argument jigsaw (and activity in which the student pairs combined to become a
group of four that was then asked to converge upon a single answer with which all students agreed) and the other
during a whole class debate setting. We noticed that when students constructed scientific explanations they did not
always  explicitly   talk about  the   criteria. However,   we    know   that they  looked    for evidence    with  particular
characteristics that may suggest they were using the criteria to guide their decision-making.

    For example, when trying to figure out why some finches died, we see Toby and Peter examining and making
sense of the available evidence: Toby, "Right, it has something to do with their weight, let's look at this last one.
Wow, yeah that was a trend okay." Peter replies, "They pretty much stopped dying." Toby responds, "No, that likes
90, that likes 85. Yeah, they are all dying at about 8 grams. So what kind of trend do we see?" Here, we see Toby
examining the data to find trends. His work therefore reflects a key aspect of the criteria: he was using evidence. In
another example, Alicia presents an early draft of her finch explanation to the whole class. Like Toby and Peter, she
does not explicitly discuss the criteria, but she presents a careful description of the evidence that is specific, one of
the criteria on  their list: "birds, name  GF10    and it said once  the  plant started to decrease,    her  weight started to
decrease and in time when the plant went to zero in the dry season." Thus, as with Toby's knowledge construction
process, Alicia's presentation reflects the epistemic criteria we were hoping to foster.

        Interestingly, when the pairs combined to form groups of four (Kuhn et al., 2006) to evaluate one another in
an argument jigsaw, some students explicitly pointed out criteria they used within their explanations. For example,
in the following quote, Janelle presents her explanation to the other student pair and includes her claim, evidence,
and reasoning. She points out that she does have evidence and that she has an appropriate quantity of evidence.

        Our claim is the rainfall because of an indirect effect because of a drought. Evidence? Okay, we
        have a lot of evidence. First part of our evidence is rainfall measurement because during the wet
        season the measurements decreased over time until 1977 and the same thing with the dry season. It
        went from 200 to 162 to 25...

At this point, Janelle is interrupted by one of the students and tells them that she is not finished giving all of her
explanation.  She    proceeds  with  giving   more data   and  reasoning  for her  explanation.    Like Alicia, Janelle has
presented evidence that is specific and includes numbers, thereby reflecting the criteria for good evidence.

                                                              323                                                   ICLS 2006
          We found that the scoring rubric was helpful in guiding students' evaluation of good evidence. Sometimes,
students would use the rubric to give a score without further elaboration about why they gave it a specific score.
Continuing from the earlier clip where Janelle presents her evidence for why the finches died, we show Toby's
evaluation. It is important to point out that Toby had misinterpreted the scoring rubric and he thought that 1 was
excellent and 5 was poor. In this example, Toby interrupts Janelle's presentation of her evidence to give her a score,
"you get a 1, 1, you get a 1." Janelle responds, "I'm not done." Toby replies, "Yeah, still get a 1. That is good
evidence." We see that Toby gives her a score without any explanation. However, we did notice that his evaluation
occurs directly after Janelle gives numbers for her evidence thereby implying that Toby may identify numbers with
the criterion that evidence is based on data not opinion and this may be the reason for his evaluative score.

          There were other instances during evaluation where students clearly questioned the validity of the evidence
based on specific criteria and pointed it out to the other students. During the argument jigsaw, Janelle questions
Toby's evidence, "our evidence is that we actually have measurements that says the rainfall decreased." Toby's
says, "Yeah." Janelle responds, "But do you actually have numbers that says the rainfall increased, because you
can't  say it increased without   numbers."  Janelle is explicit in pointing out  to Toby  that he does   not have  good
evidence because he is not using numerical data.

          The evaluation process was also prominent during whole class debate. For the design we used the idea of
audience roles to evaluate and defend explanations (Herrenkohl & Guerra, 1998). These roles included presenters,
questioners, and observers and facilitated student-to-student discussion. This evaluation process helped us observe
how students used their epistemological understandings to question one another in a whole class setting. Students
used the criteria as they questioned the quality of the components of the explanations. Some of the questions from
the questioners included, "ok, I believe your evidence because it is very specific, its persuasive, it also has numbers
to back up your claims", "do you think there are any holes in your claims at all", and "I don't have a question, but
ya'll need to have more evidence."

          The students' evaluation process was also monitored through pre/post interviews. In the pre/post written
component,    seven students evaluated   four explanations and   explained  in their interview  why  they gave    specific
rubric  scores for claim, evidence,  and  reasoning.  Some  of   the comments    included, Toby,  "I think  the   scientist
needed  to support  his  evidence  with  more evidence",   Janelle  says, "And  evidence   should be facts, not   opinion
because it says...and that's not really good evidence", and Vanessa comments, "and eats the same food, I mean
that's evidence, but it's not, like specific." Table 2 shows the total frequency of students' evaluative comments for
each specific criterion before and after their participation in the study. The most prominent evidence found in Table
2 was the students' emphasis on the volume of evidence and specificity of claim and evidence in both pre- and post-
tests.

Table 2. Frequency of Students' Evaluative Comments for Epistemological Criteria. N= 7 participants.
           Epistemological Criteria                                       Pre-Interview      Post-Interview
           The claim answers the question.                                     0                     3
           The claim is specific.                                              7                   10
           The claim is based on facts.                                        0                     2
           The evidence is specific.                                           7                   10
           The evidence came from data and is not opinion.                     4                     6
           There is enough evidence.                                           16                  16
           The evidence supports the claim.                                    3                     1
           The big ideas connect to the evidence.                              2                     5
           Total Score                                                         39                  53

Influencing the Quality of Scientific Explanations
          We examined whether students' used their epistemologies to guide the construction of their scientific work
products. We found examples where students used the criteria to guide their written work and other times when they
were unsuccessful in this process. Below we follow the learning progression of an early draft written explanation to
the final  draft after argument   jigsaw and  whole  class debate.   Here we   see Vanessa  and   Sarah's initial written
explanation for why some finches survived: "the owl population was going up and they were eating the birds. The
little ones have bigger wings so they could fly away faster so they survived." The next example is the presentation of

                                                           324                                                 ICLS 2006
their explanation as a group of four in the whole class debate. Jackie says, "the wing length because the food was
drying up, they have to fly farther for food and the finches with larger wings were better at flying farther for food."
At this point, they received questions about the quality of their data and evidence. Their final written explanation
shows the specificity of their evidence, data rather than inferences, and quantity of evidence.

        The trait that affected the finches' ability to survive was the wing length because the food was
        drying up, they had to fly farther to food. We know this information because in our evidence, it
        shows that during the years of 1976 and 1977, the portulaca seeds went from 450 to 130 to 20 and
        down to 0. The chamae seeds went from 57 to 21 to 5 and then down to 0. The cactus seeds went
        from 500 to 230 to 100 then down to 20. The tribulus seeds went from 663 to 500 to 240 then
        down to 80.

        One of the challenges for developing scientific explanations was the consistency between discourse and
work   products. In instances   of student  discourse it was   evident   that students    knew  specific criteria  for good
evidence, but when writing or presenting actual explanations this was not always the case. For example, Toby many
times referred to good evidence as having numbers and data, but when he presented his explanation he did not
always back up his claims with this type of evidence. Mostly, he made inferences to support his claims, Toby says,
"Our evidence is, usually when there are harsh rains it kinda pushes you down and you can't fly to get your food and
it kills you...and also sometimes it like floods the plants." Shortly after, Toby tells his group that they need to make
sure they include numerical evidence, "ok, we need to back this up with evidence, the graphs, the data tables and
charts." Again, when he presents his evidence in the whole class debate he gives inferential evidence, "well it wasn't
that heavy, but that it was killing the food that was killing the lighter finches because the heavier finches would eat
all the food before the lighter finches could get to it. " We see again that Toby's struggles with giving evidence that
represents the appropriate criteria.

Changes in Epistemological Beliefs
        We   used   an epistemological  questionnaire  (Conley   et al., 2004)  to   test for any student  epistemological
changes after participation in the study. In Table 3, we report results of four separate paired t-tests for each of the
four epistemological belief dimensions at Time 1 (pre unit) and Time 2 (post unit). We found that students had
relatively sophisticated epistemological views when they took the questionnaire before and after their participation
in the unit. There  were little changes  in epistemological    beliefs. There  is a  possibility  that the reason  for their
sophisticated views was because of their prior involvement with our chemistry unit. It was interesting to see that
after participation in the biology unit, we found that there was a significant change in epistemological beliefs about
science as an  evolving  and  changing  subject (see  Table  3). This   suggests  that our    extension to the explanation
framework ­ the use of argumentation to foster sophisticated epistemic understandings­ helped students develop a
more sophisticated understanding about how scientific understandings evolve.

Table 3: Changes in Epistemological Beliefs from Time 1 to Time 2. N=64 participants.

                  Category                  Time 1 M (SD)         Time 2 M (SD)             t-Valuea       Effectb
                    Source                    2.36    (0.77)            2.27  (0.79)        1.08            0.12
                    Certainty                 1.87 (0.61)               1.97  (0.81)        1.00            0.16
                    Development               4.33 (0.47)               4.46  (0.41)        3.09***         0.28
                    Justification             4.48 (0.35)               4.46  (0.44)        0.50            0.06

aTwo-tailed paired t-test, *** p <.01
bEffect Size: Calculated by dividing the difference between posttest and pretest mean scores by the pretest standard deviation.

        Students revised their explanations throughout both argument jigsaw and whole class settings. Moreover,
there were a couple of times during the investigation in which students learned that they had misinterpreted their
data and could no longer use their data as evidence to support their claim. For example, Janelle explains to the class
that their interpretation of the evidence was incorrect and that they will have to make a new claim, "first we looked
at graphs and believed that the lighter finches were dying, found out that finches reproduce in the wet season and
mature in the dry season, we have to go back and change." Toby supports Janelle's statement and says, "yeah, we
have to go back and change the trait that we believe in and that is probably going to change the whole idea about

                                                           325                                                    ICLS 2006
how the finches are dying and surviving." The experience of continual revision of scientific explanations may have
influenced this change in epistemological beliefs about development in science.

         There were also moments when students made explicit their epistemological understandings to make sense
of why everyone was looking at the same data but constructing different explanations. In the next example, Rhonda
is confused about why so many of her classmates have different explanations, asking: "some ideas say they might
have killed the finches, somebody said that it was small or that it was big does that mean that maybe one of us is
misinterpreting the graphs?" Another student, Michael responds, saying: "It could be another way to look at it." In
other words, Michael thinks that maybe they are interpreting the data in different ways.  The teacher answers her
question, verifying Rhonda and Michael's ideas to explain the different explanations, "It is possible that somebody
is misinterpreting the graphs, it is also possible that you can interpret the evidence in more than one way." Here we
see that students have noticed the role of subjectivity in the development of scientific knowledge; they are struggling
with the idea that scientists interpret their data in order to solve problems. This may have contributed to their beliefs
about science as an evolving subject.

Discussion
         As consumers of science, we want students' to be able to think and reason about scientific issues. In doing
so, they will need the epistemological knowledge and inquiry skills to guide these types of decisions. This study
supports  the need  to  further examine   using epistemological   criteria  and its influences on     explanation  and
argumentation practices. Talking about epistemologies of science is difficult for students. We know that students are
using the criteria to guide development of explanation, but we need to know more about why they make certain
decisions at particular points in the evaluative process and how these epistemologies influence their explanations. In
whole class debate many students did not take their questions to a higher level or elaborately defend their answers.
For instance, the questioners would comment that the presenting group needed more evidence, but failed to question
the group about  why   they chose their particular evidence  or why  they   did not have enough      evidence.  We see
opportunities to design scaffolds  that probe more  deeply   into students'  epistemic decisions     and support  more
thoughtful student questioning and evaluation that guide inquiry practices.

References
Abd-El-Khalick, F., & Lederman, N.G. (2000). Improving science teachers' conceptions of nature of
         science: A critical review of the literature. International Journal of Science Education, 22, 665-701.
American Association for the Advancement of Science. (1990). Science for all Americans. New York:
         Oxford University Press.
Bartholomew, H., Osborne, J., & Ratcliffe, M. (2004). Teaching students ideas about science: Five
         dimensions of effective practice. Science Education, 88, 655-682.
Bruozas, M., Finn, L.-E., Tzou, C., Hug, B., Kuhn, L., & Reiser, B. J. (2004). Struggle in natural
         environments: What will survive? In J. Krajcik & B. J. Reiser (Eds.), IQWST: Investigating and
         questioning our world through science and technology. Evanston, IL: Northwestern University.
Conley, A.M., Pintrich, P.R., Vekiri, I., & Harrison, D. (2004). Changes in epistemological beliefs in
         elementary science students. Contemporary Educational Psychology, 29, 186-204.
Duschl, R. A. (2000). Making the nature of science explicit. In R. Millar, J. Leach & J. Osborne (Eds.),
         Improving science education: The contribution of research (pp. 187-206). Buckingham, UK: Open
         University Press.
Elder, A.D. (2002). Characterizing fifth grade students' epistemological beliefs in science. In P.R.
         Pintrich (Ed.), Personal epistemology: The psychology of beliefs about knowledge and knowing (pp.
         347-364). Mahwah, NJ, USA: Lawrence Erlbaum Associates.
Herrenkohl, L. R., & Guerra, M. R. (1998). Participant structures, scientific discourse, and student
         engagement in fourth grade. Cognition and Instruction, 16(4), 431-473.
Hogan, K. (2000) Exploring a process view of students' knowledge about the nature of science. Science
         Education, 84(1), 51-70.
Kuhn, L., Kenyon, L., & Reiser, B. J. (2006). Fostering scientific argumentation by creating a need
         for students to attend to each other's claims and evidence. A paper submitted to the 7th International
         Conference for the Learning Sciences, Bloomington, IN.
McNeill, K. L., & Krajcik, J. (in press). Middle school students' use of appropriate and inappropriate
         evidence in writing scientific explanations. In M. C. Lovett & P. Shah (Eds.), Thinking with data: The

                                                         326                                                  ICLS 2006
       proceedings of the 33rd carnegie symposium on cognition. Mahwah, NJ: Erlbaum.
National Research Council. (1996). National science education standards. Washington, DC: National
       Research Council.
Reiser, B.J., Tabak, I., Sandoval, W.A., Smith, B.K., Steinmuller, F., and Leone, A. J. (2001). BGuILE:
       Strategic and conceptual scaffolds for scientific inquiry in biology classrooms. In S.M. Carver & D.
       Khlar (Eds.), Cognition and instruction: Twenty-five years of progress (pp. 263-305). Mahwah, NJ:
Sandoval, W.A. (2005). Understanding students' practical epistemologies and their influence on learning
       through inquiry. Science Education, 89(4), 345-372.
Schwartz, R.S. & Lederman, N.G. (2002). It's the nature of the beast: The influence of knowledge and
       intentions on learning and teaching nature of science. Journal of Research in Science Teaching, 39,
       205-236.
Toulmin, S. (1953). The philosophy of science: An introduction. London: Hutchinson & Co. Ltd.

Acknowledgments
We gratefully acknowledge the teacher and students for their contribution to this study and report.
The National Science Foundation through grants ESI-0101780, ESI-0439352, and ESI-0439493 to the Investigating
and Questioning Our World Through Science and Technology (IQWST) project and ESI-0227557 to the Center for
Curriculum Materials in Science supported this research. Opinions expressed are those of the authors and not
necessarily those of NSF.

                                                        327                                                 ICLS 2006
