   Effects of Part-task and Whole-task Instructional Approaches and
                                 Levels of Learner Expertise on
       Learner Acquisition and Transfer of a Complex Cognitive Skill

                                 Jung Lim, and Robert A. Reiser, Florida State University
                                      307 Stone Building, Tallahassee, Florida 32306
                                      Email: jjl0862@fsu.edu, rreiser@mailer.fsu.edu

         Abstract: In complex learning environments, providing instruction that facilitates transfer of learning
         is important. The study investigated the effects of two instructional approaches (whole-task vs. part-
         task) and levels of learner expertise (novice vs. advanced) on learner acquisition and transfer of a
         complex    cognitive  skill (e.g., preparing  a  grade  book    in   excel) in  an  introductory   educational
         technology course. The study also examined the effects of these variables on learners' cognitive load,
         instructional efficiency, time on task and their attitudes towards the instruction. The results indicated
         that there were statistically significant differences between the two treatment groups (whole-task >
         part-task) on (a) whole-task performance, (b) far-transfer performance, (c) instructional efficiency on
         the whole-task performance, and d) instructional efficiency on the far-transfer performance. However,
         no significant differences were found for (a) cognitive load, (b) time spent on the whole-task test, (c)
         time spent on the far-transfer test, and (d) attitudes toward instruction.

Introduction
         Recently, traditional instructional systems design methodologies have shown to be ineffective in reaching
transfer of learning, particularly in complex learning domains. Several authors (e.g., de Croock, Paas, Schlanbusch,
&  van Merriënboer,    2002)  argue  that this is the result of their  analytic   approach   where   the learning  domain  is
described in terms of distinct objectives in a process of instructional analysis, and then instructional methods are
selected for  reaching  each  of the  separate  objectives. This may     lead  to fragmented    instruction, the inability to
integrate what has been learned in new situations, and low transfer of learning.
         Recent instructional and learning theories tend to focus on authentic learning tasks that are based on real-
world problems as the driving force for transfer of learning (Merrill, 2002; van Merriënboer & Kirschner, 2001).
The main idea is that such tasks help learners to integrate the knowledge, skills, and attitudes necessary for effective
task performance; give them the opportunity to learn to coordinate constituent skills that make up complex task
performance;   and  eventually   enable them   to  transfer what   is learned  to  their  daily life or  work   settings (van
Merriënboer & de Croock, 2002).
         Developed by van Merriënboer (1997), the 4C/ID model (the Four Component Instructional Design model)
also stresses authentic, whole learning tasks for acquisition of complex skills. Several authors (e.g., Clark & Estes,
2001)  characterize   the  4C/ID-model  as  the  most comprehensive      instructional   design  methodology    for  complex
learning that  is yet available. The  4C/ID   model,  in  addition to  focusing   on  whole   task practice,  also takes into
account the qualitative differences in desired performance of constituent skills. These constituent skills are classified
as either non-recurrent or recurrent. For non-recurrent (novel, effortful) skills, the desired performance varies from
problem to problem situation, and is guided by cognitive schemata that steer problem-solving behavior and allow for
reasoning about the domain. For recurrent (routine) constituent skills, the desired performance is highly similar from
problem  situation  to problem   situation, and is driven   by rules  that  link  particular characteristics of  the problem
situation to particular actions (Van Merriënboer, Clark, & de Croock, 2002).
         In terms of learner characteristics, recent research on cognitive load has suggested that instruction should
be tailored to the  level  of expertise of  intended  learners (Kalyuga,    Ayres,   Chandler   &  Sweller,  2003).  Findings
indicate that many of the instructional prescriptions derived from research on cognitive load have a positive effect
on learning  only  among   those  students  with  limited or no  knowledge     or  skills in the  area  being taught  (called
"expertise reversal effect"). A number of studies have shown that worked examples were effective for novices, but
interfered with   learning by  more  advanced   learners  (Kalyuga,   et al., 2003).  Several   studies have  confirmed   this
effect (e.g., Yeung, Jin, & Sweller, 1997).

                                                            425                                                     ICLS 2006
         The purpose of this study was to investigate the effects of two instructional approaches (whole-task vs.
part-task) and levels of learner expertise (novice vs. advanced) on learner acquisition and transfer of a complex
cognitive skill--preparing a grade book using Microsoft Excel. The effects of these variables on learners' cognitive
load, instructional efficiency, time on task, and their attitudes toward the instruction were also examined.
         Two research questions were investigated: 1) What are the effects of two instructional approaches (whole-
task vs. part-task)  on  (a) performance   (whole-task  & part-task   achievement  tests; near &  far- transfer tests), (b)
cognitive load, (c) instructional efficiency, (d) time on task, and (e) attitudes toward instruction?; and 2) What are
the effects of the levels of learner expertise (novice vs. advanced) in each instructional approach on the measures,
(a) ­ (e)?
         The study is significant in that no study has investigated the effects of instructional programs based on the
4C/ID-model from a holistic perspective. Most studies have investigated particular aspects of the 4C/ID-model, such
as the timing of information presentation (Kester, Kirschner, van Merriënboer & Baumer, 2001), and the optimal
step sizes for learning tasks (Nadolski, Kirschner, van Merriënboer & Hummel, 2001). In a similar vein, this study is
important in that there has been no study that has examined the effects of learner level of expertise (i.e., novice vs.
advanced) on performance from the whole perspective of the 4C/ID-model.
METHOD
Participants
         A total of 51 undergraduate students enrolled in four sections of an Introduction to Educational Technology
course in a large southeastern university in the United States participated in the study (average age = 20.6 years;
82% female).

Task and Materials
         Students in this study were taught how to prepare a grade book using Microsoft Excel. An instructor-led
instruction was designed and developed based on the 4C/ID-Model (van Merrinboer, 1997). The total time spent on
instruction was 120 minutes (60 minutes for each lesson). The instruction took place in a computer lab.

Independent Variables
Instructional approach (part-task vs. whole-task)
         The first portion of each of the two lessons involved (a) introduction of learning goals, (b) explanations of
the concepts involved in each lesson, and (c) presentations of examples (e.g., Excel applications, grade books). The
second   portion  of the  lesson including  (a) demonstrations    and (b) practice activities, which varies between     the
conditions, then began.

         In the part-task approach, a complex skill (i.e., preparing a grade book) was decomposed into a series of
smaller tasks or skills, each of which was practiced separately. This part- task approach can be seen in a traditional
instructional setting in which learners have the opportunity to practice the whole constituent skills at the end of
instruction after practicing  part skills. In this condition,  the participants received  two  sets of part-task practice
activities involving  the performance  of   the skills related to preparing a simple  grade    book using Excel, each   of
which was given during each of the two lessons. During the second portion of the first lesson, the first set (20 items)
was given involving basic skills (e.g., entering data, labeling data) to prepare a grade book using Excel and the skills
to prepare descriptive statistics using the given grades (e.g., using a formula, deciding appropriate statistics to use).
During the second portion of the second lesson, the second set (9 items) focusing on skills to create charts based on
weighted grades was given. Each of the practice items required students to perform one of the skills (i.e., part skill)
they were taught. At the end of the second set of the practice activity, the participants were asked to prepare a grade
book as a whole.

         In the whole-task approach, the instruction was designed and developed based on the 4C/ID-Model (van
Merrienboer, 1997) in which a complex skill (e.g., preparing a grade book) was decomposed into constituent skills
and each of the skills was classified as non-recurrent or recurrent skill based on its qualitative difference described
above (see Introduction). Task classes were then sequenced from simple to complex, and an individual learning
problem or task was designed (e.g., modeling example, completion problem). During the second portion of the first
lesson, the participants received two whole task practice problems within the same task class (i.e., simple grade
book: preparing a grade book using descriptive statistics), with the second problem being of greater task difficulty

                                                            426                                                 ICLS 2006
than the first. During the second portion of the second lesson, the participants were given two other whole task
practice problems within a second task class (i.e., complex grade book: preparing a grade book based on weighted
grades using charts), with the second problem being of greater task difficulty than the first.      Within each of the two
task classes, the format of each problem was different, with decreasing learner support (e.g., providing a modeling
example for the first problem vs. presenting a conventional problem without an example for the second problem).

Level of learner expertise (novice vs. advanced)
       The     levels  of  learner expertise  were  determined    by using  the    data obtained from   a pretest  which  was
administered before conducting the study. The pretest measured whether or not a learner could already perform
certain skills (e.g., using a formula) that were the focus of the instruction. If a learner was able to perform more than
seven skills out of the total of 16 skills assessed, he or she was classified as an advanced learner; otherwise he or she
was classified as a novice. This was not just a median point cut off, but rather was based on a critical skill difference
among the group. In other words, if a learner was able to perform the skill necessary to create a grade book (i.e.,
domain specific skill), such as a formula or function (e.g., average, sum), he or she was defined as an advanced
learner. If a learner was only able to perform skills acquired from using other applications (i.e., domain general
skills), such as formatting fonts, he or she was defined as a novice.

Dependent Variables
      Performance            Learner   performance      was  measured    based  on   achievement    and   transfer tests. The
achievement test consisted of two parts: 1) part-task test: requiring students to perform each constituent skill they
have learned, and 2) whole-task test: a performance test requiring them to prepare a grade book. The transfer test
also consisted of two parts: 1) near-transfer: a performance test requiring students to draw a grade book on a sheet
of paper and 2) far-transfer: a performance test requiring students to prepare a budget report.

      Cognitive Load           Perceived cognitive load was measured by using a single item student self-rating scale
developed by Paas and van Merriënboer (1994). The item asked the participants to use a nine-point Likert-type scale
to identify the amount of mental effort they invested on the instruction they have received.

      Instructional        efficiency     Instructional Efficiency   (E) was   computed    using a  formula, E=    (P-M)/  2,
developed by Paas and Van Merriënboer (1993), on the basis of perceived cognitive load during instruction and
performance of the two parts of achievement test and the two parts of transfer test (P: Performance z-scores; M:
Cognitive load   z-scores).

      Time      on   Task   Time on task was measured by asking students to record their start and end time on (a) the
two parts of achievement test (whole-task test & part-task test), and (b) the two parts of transfer test (near-transfer &
far-transfer).

      Learner Attitudes            Student attitudes toward the instruction was measured by a questionnaire (33 items)
adapted from the Instructional Material Motivational Survey (Keller, 1993).

Procedures
       The study was conducted in a university computer lab. The four classes were randomly assigned to each
treatment condition (part task or whole task). Two days before conducting the study, a prior skill check test was
given to the participants to determine their skill levels (novice or advanced).
       On      the day  of experiment,    two  60-minute  instructor-led  lessons   were  delivered with   a 5-minute  break
separating the two lessons by the same instructor. During the two lessons, students learned about how to create a
grade book using Excel; the instructor first provided a general instruction (presenting goals, concepts, and examples)
then provided demonstrations and practice activities according to the instructional approaches described above. On
completion  of  each    practice activity, participants  in both  treatment    groups   were asked  to  rate their  perceived
cognitive load.    They were  then  asked   to   review model  answers   on    the course website   to check how    well  they
performed  on   their practice   activity (i.e., feedback). Two   days   after the  second  lesson, students  were  asked   to
complete the attitude survey measuring their attitudes toward the instruction and then the students were given the
two parts of achievement and transfer tests, separately.

                                                              427                                                   ICLS 2006
Results
Performance
Achievement Test (whole-task & part-task)
         ANOVA revealed that there was a statistically significant main effect for the instructional approach on the
whole-task test, F (1, 47) = 6.12, p> .05, 2 =.12, indicating that students in the whole-task instructional approach
performed significantly better on the whole-task test (M=32.2, SD=5) than students in the part-task instructional
approach (M=28.7, SD=5.72). There was no difference between the two groups on the part-task test.

Transfer Test (near-transfer & far-transfer)
         ANOVA     revealed  no  main  effect   for  instructional approach   on the near-transfer  test, indicating no
difference between the two groups on the near-transfer test. With regard to the far-transfer test, the results indicated
a statistically significant main effect for the instructional approach, F (1, 47) = 15.87, p= .000, 2 =.25, indicating
that students in the whole-task instructional approach performed significantly better on the far-transfer test (M=30.9,
SD=4.36) than students in the part-task instructional approach (M=24.6, SD=6.67). No difference was found on the
near-transfer test. With regard to the levels of learner expertise, there was a statistically significant main effect on
the far-transfer test, F (1, 47) = 6.57, p= .014, 2 =.12, indicating that advanced students performed better on the far-
transfer test (M=30,   SD=4.84)  than novice   students (M=25.9,    SD=7.04)   regardless of the instructional approach
employed.
Cognitive load
         The   results indicated no   statistically significant effect for  learner  perceived cognitive   load ratings,
indicating no significant difference between the treatment conditions. Descriptive statistics for cognitive load are
presented in Table 1.

Instructional Efficiency (IE)
IE on the Achievement Test (whole-task test & part-task test)
         ANOVA revealed that there was a statistically significant main effect for instructional approach on the
instructional efficiency on the whole-task test, F (1, 47) = 4.77, p= .034, 2 =.09, indicating that the whole-task
instructional approach was significantly more efficient (M=.56, SD=2.14) than the part-task instructional approach
(M= -.54, SD=1.84) in terms of the whole-task test. No difference was found on IE on the part-task test. ANOVA
revealed no interaction between the two instructional approaches and the levels of learner expertise. However, there
was a statistically significant main effect for the levels of learner expertise on the instructional efficiency on the
whole-task test, F (1, 47) = 4.95, p= .031, 2 =.1, indicating--regardless of the instructional approach employed--
that the advanced students (M= .69, SD=1.86) performed more efficiently than did the novice students (M= -.52,
SD=2.06) on the whole-task test.
IE on the Transfer Test (near-transfer & far-transfer)
         ANOVA     revealed  a   statistically significant main    effect for instructional  approach on   instructional
efficiency on the far-transfer test, F (1, 47) = 7.4, p= .009, 2 = .14, indicating that the whole-task instructional
approach was significantly more efficient (M= .82, SD= 1.97) than the part-task instructional approach (M= -.79,
SD= 2.25) in terms of the far-transfer test. No difference was found on IE on the near-transfer test. In addition, there
was a statistically significant main effect for the levels of learner expertise on instructional efficiency based on the
far-transfer test, F (1, 47) = 6.32, p= .015, 2 = .12, indicating the instruction was significantly more efficient for the
advanced learners in terms of far-transfer performance (M= .84, SD= 1.71) than was it for novice learners (M= -.64,
SD= 2.42).

Time on Task
         The results indicated no statistically significant main effect for instructional approaches on the two parts of
the achievement tests and the two parts of the transfer tests. However, there was a statistically significant main effect
for the levels of learner expertise on time on the part-task test, F (1, 47) = 6.97, p< .025, 2 = .13, indicating--
regardless of the instructional approach employed--that the advanced students spent significantly less time on the
part-task test (M= 10.5, SD= 3.33) than did the novice students (M=14.1, SD= 5.61).

Learner Attitudes

                                                           428                                                 ICLS 2006
          A more conservative alpha level (.025) was set for this analysis as Lavene's test for a confidence measure
indicated a violation of the assumption of homogeneity of variance. MANOVA revealed no significant overall effect
for instructional    approach  on the attitudes,  indicating  no   significant difference   between the  two   groups in their
attitude scores    in   terms of attention,  relevance,    confidence, and    satisfaction.  However,  MANOVA      yielded    a
significant overall effect for the levels of learner expertise on the attitudes, Wilks Lambda= .77, F (4, 44) = 3.38, p=
.017, 2  = .04.    A follow-up ANOVA, using a Bonferroni adjusted alpha level of .005, revealed a main effect for the
levels of learner    expertise on confidence,   F (1, 47)   = 13.46, p= .001,  2  = .22,    indicating that  advanced students
showed significantly more confidence toward the instruction (M=4.5, SD= .47) than novice students (M=3.8, SD=
.72).
          No interactions were found on any of the dependent measures above.

Table1. Means and standard deviations of dependent variables across groups

                                                                        Treatment
                                           Whole-task Approach                               Part-task Approach
Dependent Measures                Novice(n=14)    Advanced(n=11) Total (n=25)      Novice(n=15)   Advanced(n=11) Total (n=26)
                                  M (SD)          M (SD)           M (SD)          M (SD)          M (SD)          M (SD)

 Performance
    Whole-task test a            30.4 (5.24)     34.5 (3.74)       32.2 (5)       28.4 (5.53)     29.1 (6.22)     28.7 (5.72)
    Part-task test b             30.5 (3.59)     31.5 (2.53)     30.9 (3.14)      31.3 (2.31)     31.2 (1.42)     31.3 (1.95)
    Near-transfer test c          8.5 (1.32)      7.9 (1.48)      8.2 (1.35)      8.2 (1.32)       8.9 (.84)      8.5 (1.17)
    Far-transfer test d           30 (5.18)      32.1 (2.84)     30.9 (4.36)      22.2 (6.56)     27.8 (5.56)     24.6 (6.67)
 Cognitive Load e                3.75 (1.83)      2.91 (.54)      3.4 (1.45)      3.73 (1.41)     3.41 (1.28)     3.6 (1.34)
 Instructional Efficiency f
    Whole-task test              -.27 (2.39)     1.62 (1.15)      .56 (2.14)      -.76 (1.74)     -.24 (2.02)     -.54 (1.84)

    Part-task test               -.59 (2.37)      .79 (1.64)      .01 (2.16)      -.12 (1.58)      .13 (1.9)      -.01 (1.69)

    Near-transfer test           -.12 (2.29)      .06 (1.72)     -.04 (2.02)      -.44 (1.83)     .68 (1.64)      .04 (1.81)

    Far-transfer test             .24 (2.38)      1.56 (.92)      .82 (1.97)     -1.45 (2.24)     .11 (2.03)      -.79 (2.25)

 Time on Task (min)
    Whole-task test              22.7 (7.31)     26.2 (10.02)    24.2 (8.59)      20.5 (7.48)     20.4 (9.69)     20.4 (8.3)

    Part-task test               14.4 (6.51)     12.2 (3.82)      13.4 (5.5)      13.8 (4.83)      8.9 (1.7)      11.7 (4.5)

    Near-transfer test            8.4 (4.6)       8.7 (4.76)      8.6 (4.57)      7.7 (4.74)      8.7 (6.66)      8.2 (5.53)

    Far-transfer test            18.6 (6.02)     21.4 (6.92)     19.8 (6.44)       18 (6.9)       15.5 (6.39)     16.9 (6.68)
 Attitudes g
    Attention                     3.8 (.72)       3.8 (.65)        3.8 (.67)       3.5 (.61)       3.8 (.77)       3.6 (.68)

    Relevance                     3.8 (.67)       3.9 (.64)        3.8 (.64)       3.6 (.54)       4.0 (.67)       3.7 (.62)

    Confidence                    3.9 (.96)       4.6 (.27)        4.2 (.81)       3.8 (.42)       4.4 (.6)        3.8 (.72)

    Satisfaction                  3.6 (.88)       3.8 (1.06)       3.7 (.94)       3.5 (.89)       3.9 (.76)       3.6 (.85)
Note.
a Maximum possible score was 36.           b Maximum possible score was 34.
c Maximum possible score was 10.           d Maximum possible score was 35.5.

                                                               429                                                   ICLS 2006
e A nine-point scale ranged from 1 (very, very low mental effort) to 9 (very, very high mental effort).
f Instructional efficiency was calculated for each student using a formula:  E= (P-M)/      2
(P: a performance score transformed to a Z-score; M: a cognitive load rating transformed to a Z-score).
g A five-point scale ranged from 1 (not true) to 5 (very true).

Discussion
          The study compared the effects of 4C/ID-Model-based instructional approach (i.e., whole-task approach)
and traditional instructional approach (i.e., part-task approach) on learner performance, cognitive load, instructional
efficiency, time on task and attitudes towards the instruction. The effects of levels of learner expertise (novice vs.
advanced) in each instructional condition on these variables were also investigated.
          With regard to learner performance, learners in the whole-task instructional approach performed
significantly better on the whole-task (achievement) test and on the far-transfer test than those in the part-task
instructional approach. In terms of the whole-task performance, one likely reason for this finding is that students in
this condition had more exposure to whole-task practice activities and thus had more opportunities to integrate and
coordinate the constituent skills throughout the instruction than those in the part-task approach. It is also notable that
learners in the whole-task approach performed equally well (M=30.9, Max=34) on the part-task (achievement) test
as those in the part-task approach (M=31.3), suggesting that the whole-task group was also able to perform the part-
tasks--but not only in an isolated version (part-task test) but also in an integrated context (whole-task test). This
indicates that the whole-task instructional approach not only focuses on the integration and coordination of
constituent skills but also assures the acquisition of part-skills that enhance the performance of a whole complex
skill.
          With regard to far-transfer performance, there are likely several reasons why learners in the whole-task
instruction group were better able to apply the skills they learned to new situations, such as preparing a budget
report in Excel. Perhaps this was the case because the whole-task approach varied the contexts in which the various
tasks had to be performed (i.e. high contextual interference), one of the most critical tactics for enhancing transfer of
learning. Another  possible  explanation    for superior far-transfer performance     may     be because  the whole-task
instructional approach particularly put an emphasis on promoting learners' schema construction for `non-recurrent'
aspects of a complex skill, that is, those constituent skills that are performed differently from one problem situation
to another.
          Concerning the cognitive load ratings, there was no difference between the two groups. The result indicates
that learner performance in the whole-task approach was improved without having any effect on overall cognitive
load. A possible reason for this may be because of the careful management of cognitive load in the whole-task
approach including intrinsic, extraneous and germane cognitive loads (Sweller, van Merriënboer & Paas, 1998).
          With regard to the instructional efficiency, the whole-task instructional approach showed a higher level of
instructional efficiency on the whole-task test and on the far-transfer test than learners in the part-task instructional
approach.   These findings  suggest  that   the whole-task  instructional approach    was     not  only efficient for the
acquisition of a complex skill, but also efficient for the far-transfer of the complex skill.
          No interactions were found between the two instructional approaches and the levels of learner expertise on
any of the dependent measures described above. Thus, the expertise reversal effects were not found. A possible
reason for this is that the effect seems to occur only when dealing with the instruction at a micro level as found in
the previous studies (e.g., worked-problem vs. conventional problem; Kalyuga, et al., 2003). The present study, on
the other hand, examined the whole-task instructional approach from a holistic perspective, rather than focusing on
specific parts of the instruction (e.g., problem formats). Therefore, the effect seems to be lost.
          In sum, the findings from the study indicate that an instructional approach based on the 4C/ ID-model can
facilitate acquisition and transfer of a complex cognitive skill. Future studies that build upon the current one should
shed further light on this important issue.

References
Clark, R. E., & Estes, F. (2001). The development of authentic educational technologies. Educational Technology,
          39(2), 5-16.
De Croock,   M. B. M.,   Paas, F., Schlanbusch,   H., &  van    Merriënboer, J. J. G. (2002).    ADAPT   it: Instructional
          Design (ID) tools for training design and evaluation. Educational Technology, Research and Development,
          50(4), 47-58.

                                                           430                                                   ICLS 2006
Kalyuga, S., Ayres, P., Chandler, P., & Sweller, J. (2003). The expertise reversal effect. Educational Psychologist,
         38, 23-33.
Kester, L., Kirschner, P. A., van Merriënboer, J. J. G., Baumer, A. (2001). Just-in-time information presentation and
         the acquistion of complex cognitive skills. Computers in Human Behaviour,17, 373-391
Merrill, M. D. (2002). First principles of instruction. Educational Technology, Research and Development, 50(3),
         43-59.
Nadolski, R. J., Kirschner, P. A., van Merriënboer, J. J. G., & Hummel, H. G. K. (2001). A model for optimizing
         step size of learning tasks in competency-based multimedia practicals. Educational Technology Research
         and Development, 49(3), 87­103.
Paas, F., & Van Merriënboer, J. J. G. (1993). The efficiency of instructional conditions: An appoach to combine
         mental-effort and performance measures. Human Factors, 35, 737-743.
Paas, F. G. W. C., & van Merriënboer, J. J. G. (1994). Variability of worked examples and transfer of geometrical
         problem solving skills: A cognitive load approach. Journal of Educational Psychology, 86, 122­133.
Sweller, J., van Merriënboer,  J. J. G., &  Paas, F.      (1998). Cognitive architecture and instructional design.
     Educational Psychology Review, 10, 251-296.
Van Merriënboer, J. J. G. (1997). Training complex cognitive skills. Englewood Cliffs, NJ: Educational Technology
         Publications.
Van Merriënboer, J. J. G., Clark, R. E., & de Croock, M. B. M. (2002). Blueprints for complex learning: The 4C/ID-
         model. Educational Technology, Research and Development, 50(2), 39-64.
Van Merriënboer, J. J. G., & de Croock, M. B. M. (2002). Performance-based ISD: 10 steps to complex learning.
         Performance Improvement, 41(7), 33-38.
Van Merriënboer, J. J. G., & Kirschner, P. A. (2001). Three worlds of instructional design: State of the art and future
         directions. Instructional Science, 29, 429-441.
Van Merriënboer, J. J. G., Kirschner, P. A., & Kester, L. (2003). Taking the load of a learners' mind: Instructional
         design for complex learning. Educational Psychologist, 38, 5-13.
Yeung, A. S., Jin, P., & Sweller, J. (1997). Cognitive load and learner expertise: Split-attention and redundancy
         effects in reading with explanatory notes. Contemporary Educational Psychology, 23, 1-21.

                                                          431                                               ICLS 2006
