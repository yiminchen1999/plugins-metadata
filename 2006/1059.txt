          Analyzing collaborative learning: Multiple approaches to
                        understanding processes and outcomes

  Chair: Cindy E. Hmelo-Silver, Rutgers University, 10 Seminary Place, New Brunswick, NJ 08901-1183, USA,
                                                chmelo@rci.rutgers.edu

        Abstract: It is important to consider collaborative processes from multiple perspectives because
        collaborative   learning  environments    are  complex,   often  requiring  multiple   methodological
        approaches to understand their different aspects (Hmelo-Silver, 2003). Collaborative learning is
        the subject of study in a wide variety of disciplines such as developmental psychology (e.g., socio-
        cognitive conflict), social psychology (person perception, motivation, group processes), sociology
        (status, power and authority), cognitive psychology (how learning occurs, learning outcomes) and
        sociocultural  perspectives  (cultural  influence on   interaction, mediation  of  learning).   These
        different perspectives suggest that a variety of methodological tools are needed to understand
        collaborative interactions. Each of the papers in this symposium explores one or more methods for
        examining the quality of collaborative interactions. The discussion will focus on criteria for good
        analyses of collaborative work as well as strengths and limitations of various methods.

        Collaborative   learning  environments    are   complex   beasts,   often requiring  multiple  methodological
approaches to understanding interactions (Hmelo-Silver, 2003).     Like   Rummel & Spada, 2004, we argue that it is
important to consider collaborative processes from multiple perspectives. Collaborative learning is the subject of
study in a wide variety of disciplines such as developmental psychology (e.g., socio-cognitive conflict), social
psychology (person perception, motivation, group processes), sociology (status, power and authority), cognitive
psychology   (how   learning occurs,   learning  outcomes)  and   sociocultural   perspectives  (cultural influence   on
interaction, mediation of learning). These different perspectives suggest that a variety of methodological tools are
needed to  understand  collaborative  interactions.  We  consider  methodological   tools that examine    the quality of
processes and trajectories of interactions.

        Two commonly used approaches for analyzing data are to classify individual learners' statements and to
provide descriptive, qualitative analyses of transcripts. Researchers using the first approach have used a diverse
range of approaches to classifying individual students' statements, ranging from classifying cognitive strategies
(such as elaboration or explanation) used by individual students (Webb & Farivar, 2000) to classifying moves such
as giving or receiving help. This general approach provides information about individuals' performance within
groups but does not provide a picture of the overall structure or flow of the group discourse or how individuals
contribute to this overall structure or flow. Researchers using the second, more descriptive approach have provided
rich pictures of interactions, but this is not a method that is well suited for making systematic comparisons across
different groups or discussions.

        Each   of  the papers in  this symposium      explores one   or more  methods  for  examining     the quality of
collaborative interactions. Chinn discusses five different approaches to analyzing argumentative discourse, noting
the strengths and limitations of each approach for generating both qualitative and quantitative understandings of
discourse quality. O'Donnell examines how individual contributions during dialogue can be traced in terms of their
influence on   others. Hmelo-Silver,   Chernobilsky,    and  Mastov     discuss representations  that can     aid in  the
interpretation of complex  collaborative    learning environments.   Erkens   and Janssen  discuss  how   the coding  of
dialogue acts can be made more tractable through reliable and valid automated coding mechanisms.

        Brigid Barron will comment on the presentations. The discussions among panelists and the discussant will
include a focus on criteria for good analyses of collaborative work. Examining the range of methods that we have
collectively used  to examine  the   quality of group  interactions, we  will discuss criteria that should    be  met by
methodological tools that succeed at capturing the richness of group interaction and the limitations of the different
approaches.

                                                          1059                                                 ICLS 2006
Assessing the Quality of Collaborative Argumentation
Clark A. Chinn, Rutgers University, 10 Seminary Place, New Brunswick, NJ 08901-1183, USA,
cchinn@rci.rutgers.edu

Introduction
         One important type of collaborative discourse is argumentation. Many tasks designed to develop students'
inquiry  skills  have   engaged collaborative  groups  of students in argumentation   (see Duschl   &  Osborne,   2002).
Hence,   it is  important to  develop effective  methods  of  assessing the  quality of argumentation  in  collaborative
groups.

Criteria for developing measures of collaborative argumentation
         Measures of argumentation should provide insights into both the quality of the overall group argumentation
and the quality of individual contributions to the group. They should illuminate the structure of the discourse and the
content of the discourse. And they should ideally provide both qualitative and quantitative windows into discourse
quality.

Measuring features of argumentation
         I discuss five methods that have been used to analyze collaborative argumentation. I discuss these methods
in the context of a study with seventh graders who were discussing epidemiological studies they had read about.

         Coding speech acts is a very common way of measuring aspects of many forms of discourse, including
argumentative discourse (e.g., Resnick et al., 1993). When applied to argumentation, speech act analysis involves
classifying statements into functional categories such as claims, supporting reasons, qualifiers, counterarguments,
rebuttals, concessions, and so on. Speech act analysis of argumentation provides a one-dimensional picture of the
distribution of speech acts in a group and in individuals. It does not provide insights into the structure or the content
of discussions.

         More specific reasoning strategies can also be coded. For instance, in the seventh graders' discussions, we
code the    use of particular reasoning strategies  in the discussion   such as weighing   sample   size, evaluating the
adequacy of comparison groups, and examining whether measurements are biased. Unlike speech act analyses,
analyses    of specific  reasoning strategies can distinguish between   good  reasons  (e.g., arguing that a conclusion
should be rejected because the methodology of a study is flawed) and poor reasons (e.g., arguing that West Nile
disease is contagious on the basis of a single person's impressions).

         The two measures discussed so far do not capture the structure of discourse. In contrast, an adaptation of
Toulmin's (1958) well-known method of diagramming arguments allows researchers to represent argumentation as
argument networks (see Chinn & Anderson, 1998). The figures below shows the structural outlines of a simple (left)
and  complex     (right) argument   network.  Rectangles  represent claims   made.   Reasons   for claims  are in ovals
connected to claims by arrows. Reasons given to support or contradict other reasons create deeper layers within the
network. Chinn, O'Donnell, and Jinks (2000) showed that students in groups of fifth graders who participated in
scientific discussions learned more when argument networks were more complex than when argument networks
were simpler.

Figure 1. Prototypical simple argument network          Figure 2. Prototypical complex argument network

         Argument networks are like speech act analyses in that they show the presence of claims and supporting
reasons, but they go further in that they capture the structure of the discussion. Argument networks can be used to
generate quantitative measures of both the quality of the group discussion and the quality of each individual's
contribution (Chinn & Anderson, 1998). Argument networks do not, however, provide any information about the

                                                           1060                                                ICLS 2006
content of the discussion. The complex argument network above could equally represent argumentation with strong
reasons and evidence and argumentation marked by sophistry.

         Analysis of argument schemas is a fourth approach that can be used to evaluate the quality of reasoning in
argumentation. In this approach, learning to argue is viewed as learning a variety of argument schemas (Chinn,
2006). For example, reasoners who employ arguments about sample size can be viewed as having rich underlying
schemas that specify when the sample size argument can be applied, when it is inapplicable, why the sample size
argument is valid, how the needed sample size varies according to relevant variables such as the variability of the
population, and so on. Reasoning schema analyses can be used to chart the development of particular argument
forms used by individuals and groups. This method provides a rich understanding of students' understanding of the
content of reasoning.

         A fifth type of measure that could be applied to argumentation but has not yet been extensively applied is
an analysis of the overall argumentative stance taken in the argumentation. In some argumentation, the predominant
stance  is one of persuasion; participants  are  trying to persuade    each other   that their view   is correct. Other
argumentation seems to take a problem solving approach, where reasons are advanced not primarily to persuade
(though  persuasion may  occur) but to   solve a problem   jointly.  Other  possible  stances  exist, as well. It seems
reasonable that the stance taken may powerfully influence the cognitive and affective outcomes of argumentation.

Summary
         Although   none of these  measures    taken singly   provides   a full picture  of   the quality  of  students'
argumentation, careful choice of two or three measures together can provide a much more complete picture of
collaborative argumentation. Researchers could improve research on argumentation by employing a broader range
of measures.

Representations for Analyzing Tool-mediated Collaborative Learning
Cindy E. Hmelo-Silver, Ellina Chernobilsky, Olga Mastov, Rutgers University, 10 Seminary Place, New Brunswick,
NJ 08901-1183, USA, chmelo@rci.rutgers.edu, ellinac@eden.rutgers.edu, omastov@eden.rutgers.edu

Introduction
         Sociocultural theories 1) argue that learning is inherently social and situated and 2) emphasize the critical
role of tools in mediating learning (Cole, 1996). This suggests a view of learning that is quite complex,  There are a
variety of approaches to examining collaborative learning discourse.    Analyzing the complexity of such
collaborations is often done using intricate multilevel coding schemes (e.g, Chinn & Anderson, 1998; Engle &
Conant, 2002; Hmelo-Silver, 2003).  Other researchers have used more qualitative approaches to studying
collaboration, such as Roschelle's (1996) study of computer-mediated convergent collaborative conceptual change.
The latter provides a detailed look at portions of a collaborative process, focusing on social and linguistic processes.
Some of the former approaches blend reliable cognitive and social analyses over larger periods of time but lose the
chronological detail and often, the relation between different kinds of utterances. Because we are interested in how
the different aspects of discourse relate to each other, as well as to the tools being used in the collaborative learning
process, a better understanding of how collaborations unfold and how tools are used is crucial. This requires going
beyond the coding of individual speech acts. The use of Chronologically-ordered Representation for Tool-Related
Activity (CORDTRA) is one way of achieving this understanding. This technique is a generalization of the
CORDFU methodology developed by Luckin et al (2001). Luckin and colleagues used this approach to examine
how alternative ways of structuring hypermedia affected collaborative discourse, allowing them to explore relations
between the software's features and collaborative knowledge construction.

CORDTRA Diagrams
         CORDTRA diagrams contain parallel timelines that allow a researcher to juxtapose a variety of codes to
understand an activity system--for example, these might be discourse, gestural, or tool-related codes (see Figure 1
for an example from Hmelo-Silver et al., 2005). Initially, we used this technique to examine face-to-face
collaboration in a problem-based learning (PBL) tutorial to understand how constructing a drawing mediated
learning (Hmelo-Silver, 2003). The work was expanded to study online collaborative learning in the eSTEP system
(Hmelo-Silver & Chernobilsky, 2004; Hmelo-Silver et al., 2005).      eSTEP is an integrated online PBL environment

                                                         1061                                                  ICLS 2006
                  Codes
for preservice teachers (Derry, 2006), containing a learning sciences hypermedia, a library of videocases, and an
online activity structure that gives students access to a suite of individual and collaborative tools. We hypothesize
that student learning and transfer will be enhanced when they repetitively bring together the conceptual ideas of the
learning sciences with perceptual ideas from the classroom video.                                                                                                                            To explore this, we contrasted two groups who
had used eSTEP (Hmelo-Silver & Chernobilsky, 2004).                                                                                                        The CORDTRA analysis demonstrated that the more
effective group started with initial discussion and exploration of the hypermedia and looked at the video as needed
throughout their work--offering new ideas as they explored the video and deepening them during independent
research. The students collaboratively developed and refined their ideas using the                                                                                                                                         hypermedia and video in cycles.
The less effective group worked sequentially, using the video early in their process and the hypermedia later.                                                                                                                                                                                      They
engaged in a lot of tool-related discussion until late in the activity and spent little time on their final group product.
We have used this analysis to generate hypotheses about how these tools might effectively mediate collaborative
learning. We have also used CORDTRA diagrams to study the development of one group over time as they eSTEP
on three problems (Hmelo-Silver et al., 2005). The CORDTRA diagrams allowed us to see how the activity patterns
changed over time as students moved from parallel lurking to active participation.
                                                                                                                                                                                                                                                                           Facilitator
                                                                                                                                                                                                                                                                           CHS
                        40                                                                                                                                                                                                                                                 Michelle
                                                                                                                                                                                                                                                                           Heather
                                                                                                                                                                                                                                                                           Betty
                                                                                                                                                                                                                                                                           Jahnvi
                                                                                                                                                                                                                                                                           Mark
                        35
                                                                                                                                                                                                                                                                          Self-directed learning
                                                                                                                                                                                                                                                                           Group monitoring
                                                                                                                                                                                                                                                                           Individual monitoring
                                                                                                                                                                                                                                                                           Grounded beliefs
                        30                                                                                                                                                                                                                                                 Personal beliefs
                                                                                                                                                                                                                                                                           Elaborations
                                                                                                                                                                                                                                                                           Explanations
                                                                                                                                                                                                                                                                           Transforming
                        25                                                                                                                                                                                                                                                 Elaborated telling
                                                                                                                                                                                                                                                                           Telling
                                                                                                                                                                                                                                                                           Acknowledgement
                                                                                                                                                                                                                                                                           Summary
                                                                                                                                                                                                                                                                           Disagreement
                        20                                                                                                                                                                                                                                                 Agreement
                                                                                                                                                                                                                                                                            Modifications
                                                                                                                                                                                                                                                                           New ideas
                                                                                                                                                                                                                                                                           Metacogntive ?
                                                                                                                                                                                                                                                                           Explanation ?
                        15                                                                                                                                                                                                                                                 Information ?
                                                                                                                                                                                                                                                                           Personal talk
                                                                                                                                                                                                                                                                           Concept
                                                                                                                                                                                                                                                                           Tool
                                                                                                                                                                                                                                                                           Task
                        10
                                                                                                                                                                                                                                                                           Lesson plans
                                                                                                                                                                                                                                                                           Help
                                                                                                                                                                                                                                                                           Research library
                                                                                                                                                                                                                                                                           White board
                         5                                                                                                                                                                                                                                                 Discussion board
                                                                                                                                                                                                                                                                           Notebook
                                                                                                                                                                                                                                                                           KW
                                                                                                                                                                                                                                                                           Video
                                                                                                                                                                                                                                                                           PBL
                         0
                           0                            200                         400              600                         800                          1000              1200                               1400              1600                             1800
                                    Steps 1 and 2                        Step 3                            Step 4                                  Step 5                             Step 6                Step 7                                      Steps  8  and  9

                               Figure 1. Example CORDTRA diagram

Understanding Patterns of Collaboration
          We are expanding the use of CORDTRA as a means to examine patterns in many groups over time,
determining how the nature of online discourse affects tool use and how the tools in turn affect the online discourse.
CORDTRA analyses are an important addition to multilevel coding schemes, allowing researchers studying
collaborative learning to go beyond coding                                                                          and counting to seeing the larger patterns that emerge.                                                                                                         This presentation
will show examples of how CORDTRA diagrams can be used to illuminate tool-mediated collaborative learning.

A Perspective on Collaborative Learning informed by a Focus on Outcomes
Angela M. O'Donnell, Rutgers University, 10 Seminary Place, New Brunswick, NJ 08901-1183, USA,
angelao@rci.rutgers.edu

Introduction
          What               should                         we                  expect     peers                     to learn                             from      opportunities                                   to   collaborate                                     with          others?     Various
implementations and analyses of collaboration learning reflect significant differences in underlying theory, methods,
and outcomes. Depending on the group process that occurs within a collaborative group, the actual collaborative
process of              different                   groups                      engaging     in                    the  same          task                  may      be                      explained                  by appealing                                     to    differing         theoretical
perspectives. Analyses of groups from the perspectives of these varied theoretical perspectives may allow for the
identification of dimensions of interaction that are necessary to allow for explanations of effective groups.

          In the study described here, students in three-person groups were asked to read a case about the classroom
difficulties experienced by a new teacher. They were asked to identify her problems and to develop a plan to help

                                                                                                                                                           1062                                                                                                                                   ICLS 2006
her solve the problems. No strategy was imposed on student groups. They were to come to consensus on their plan.
All participants were provided with the actual case but groups of participants were provided with access to varied
ancillary information. The purpose of doing so was to increase the information sources available in the group.

Method
          Participants took part in two sessions, separated by a one-week interval. Students signed up in triads. The
first set of questions  (#  1-5) were  intended  to  have students  rehearse knowledge   of  the specifics of the   case.
Question 6 was the central question: "What should Maggie do about the class behavior? Develop a plan for what she
should do."    Participants were directed to come up with a joint plan. They could either make a single record of the
agreed-upon plan or they could record this agreed-upon plan separately. During the second session, which took
place a week later, participants were asked to recall the jointly constructed plan for what Maggie should do about the
classroom behavior. They were reminded that they were to recall the group's plan and not their own.        A total of 76
groups (n=228) participated.

Results
          Transcripts of the discussions that resulted in the initial plan allow for the identification of contributors to
decisions made that subsequently were recorded as part of the group plan.     The individual recall protocols from the
second    session allow for the  analysis  of whose  ideas were  recalled. These  data  allow an  examination    of how
influence is accomplished in a group. The plan created by each group was used as the basis for the analysis. Each
idea in the plan was listed. The transcript of the session related to the development of the plan was examined to
identify who had contributed ideas that were eventually included in the plan agreed upon by members of the group.
Each idea recorded on the plan was credited to the student who introduced the idea on the tape. In addition, if
another student picked up on this idea in the discussion (e.g., supported the idea, elaborated upon it), that student
was also credited. Each students' recall was rated for the number of ideas recalled, the number of ideas in the recall
that were not part of the group's plan, the number of ideas that the student recalled and had been contributed by that
student in the transcript, and the number of ideas that they recalled that were contributed by others. Analyses of
these data suggest that individuals tend to retrieve the ideas they personally contributed to a plan and are influenced
rather infrequently by others. This pattern of influence may be best described by information processing theory. Not
all group's interactions and influences can be described in this way, however. Further analyses of groups that did not
conform to this interpretation are currently being conducted.

Discussion
          The method used to look at "joint cognition" has promise. The recorded plan for groups represented what
the   group  members   believed  to be their  consensus about   how Maggie   (the first year  teacher) should proceed.
However, recall of the joint plan was often poor and a great many additions were often added. Group cohesion can
be detected in the shared recalls of group members.

          In many ways, the characterization of what constitutes "joint cognition" here is very mechanistic.   There is
little attention paid (thus far) to the quality of the plan. The purpose here is mainly descriptive and answers the
question: "Do people include other people's ideas in their recall?"    This work is beginning to address within this
limited context what is learned in groups.

Automatic coding of communication in collaboration protocols
Gijsbert Erkens & Jeroen Janssen, Research Centre Learning in Interaction, Utrecht University, The Netherlands,
G.Erkens@fss.uu.nl, J.J.H.M.Janssen@fss.uu.nl

Introduction
          Initially, analyses of computer-supported   collaboration  focused  on  surface level  characteristics of  the
communication, such as the number of messages sent (Strijbos, Martens, Prins, & Jochems, 2006). However, over
the last 15 years the analysis of communication protocols is being used more and more to study collaboration
processes (Rourke & Anderson, 2004). The development of a systematic and valid method that can be used to
analyze communication protocols can be difficult. Furthermore, the process of analyzing a great number of protocols
can   be  time consuming.   Therefore,  in order  to speed  up  the process  of coding  communication    protocols,  an

                                                           1063                                               ICLS 2006
automated coding system was developed. This paper aims to describe the automatic coding procedure. Furthermore,
it focuses on reliability, validity and limitations concerning the developed procedure.

Method and Results
        The    coding system  developed   identifies  `dialogue acts,'  that is,  the communicative    function  of each
utterance typed by students during online collaboration and communication. Five main communicative functions are
distinguished: argumentative  (indicating  a  line of argumentation    or reasoning),    responsive (e.g., confirmations,
denials, and answers), informative (transfer of information), elicitative (questions or proposals requiring a response),
and imperative (commands). A total of 29 different dialogue acts are specified. For instance, an imperative action
(ImpAct) indicates a commanding utterance with regard to a specific action to be taken.

        To  automatically   code a  protocol  and  identify which   dialogue   acts  are used  during  collaboration, the
Multiple Episode Protocol Analysis (MEPA) computer program is used (Erkens, 2003). This program can be used
for the analysis and coding of collaborative discussions. Additionally, the program offers facilities for automatic
coding. A production rule system was created that automatically categorizes utterances into dialogue acts. A set of
if-then rules uses pattern matching to look for typical words or phrases, in this case for discourse markers. Discourse
markers are  characteristic words   signaling the  communicative     function  of  a  phrase in conversation  in natural
language (Schiffrin, 1987). For example, why at the beginning of an utterance usually indicates an open question
(EliQstOpn).   The developed  production   rule system   consists   of a  rule system    for automatic  segmentation   of
utterances in single messages (300 rules) and a rule system for dialogue act coding (1250 rules). This way, MEPA is
able to code a protocol consisting of 1,000 utterances in less than a second.

        Although automatic coding can dramatically speed up the coding process, several methodological issues
concerning reliability and validity need to be addressed. One concern is the reliability of the automatic coding
procedure. A previous study showed that reliability of the automatic coding procedure was high: two independent
coders established that over 90% of the utterances were coded correctly (Erkens, Jaspers, Prangsma, & Kanselaar,
2005).

        Examinations of group differences can be used to establish validity of the automatic coding procedure
(Rourke & Anderson, 2004). Since previous research has shown that men and women behave differently during
collaboration (Leaper & Smith, 2004): women use more affiliative speech (e.g., praise and responsiveness), whereas
men use  more   assertive speech  (e.g., negative  speech   and directives),   it would  be  useful to examine   these if
differences are replicated using the automatic coding procedure. Indeed, in our sample female students used more
responsive dialogue acts, whereas male students used more imperative dialogue acts. This result is a first step in
validating the automatic coding procedure. Another way to establish validity of the automatic coding procedure may
be through experimental intervention (Rourke & Anderson, 2004). In order to stimulate student participation and
argumentative knowledge construction, a new tool was added to an existing CSCL-environment. Indeed, as expected
students with access to this tool used more argumentative dialogue acts, compared to students without access to this
tool. Thus, the results described above indicate that the automatic coding procedure does not only speed up the
coding process, but also seems to yield reliable and valid results.

Conclusion
Preliminary results indicate favorable results concerning the validity and reliability of the automatic coding
procedure. Additionally, the results of the automatic coding procedure will be compared to results obtained with a
manual coding procedure. This manual coding focused on the collaborative activities students perform during
collaboration in a CSCL-environment (Janssen, Erkens, Kanselaar, & Jaspers, in press). Results concerning this
comparison of `dialogue acts' and `collaboration acts' will also be presented. Although results of the automatic
coding procedure do not provide insight into the structure of online discussions (see also Chinn, this symposium),
the procedure can be a starting point for more complex, sequential analyses. These sequential analyses can
subsequently be used to capture the structure and quality of online discussion (e.g., Erkens, Janssen, Jaspers, &
Kanselaar, 2006). Taken together, such an approach may constitute a valuable tool for researchers interested in
analyzing collaborative discussions

                                                         1064                                                   ICLS 2006
References
Chinn, C. A. (2006). Learning to argue. In A. M. O'Donnell, C. Hmelo-Silver & G. Erkens (Eds.), Collaborative
       learning, reasoning, and technology (pp. 355-383). Mahwah, NJ: Erlbaum.
Chinn, C. A., & Anderson, R. C. (1998). The structure of discussions that promote reasoning. Teachers College
       Record, 100, 315-368.
Chinn, C. A., O'Donnell, A. M., & Jinks, T. S. (2000). The structure of discourse in collaborative learning. Journal
       of Experimental Education, 69, 77-97.
Cole, M. (1996). Cultural psychology: A once and future discipline. Cambridge MA: Harvard.
Derry, S. J. ( 2006). STEP as a case of theory-based web course design. In A. O'Donnell, C. E. Hmelo-Silver, & G.
       Erkens (Eds.), Collaboration, Reasoning and Technology (pp. 171-196). Mahwah, NJ: Erlbaum.
Duschl, R. A., & Osborne, J. (2002). Supporting and promoting argumentation discourse in science education.
   Studies in Science Education, 38, 39-72.
Engle, R., & Conant, F.. (2002). Guiding principles for fostering productive disciplinary engagement: Explaining an
       emergent argument in a community of learners classroom. Cognition and Instruction, 20, 399-484.
Erkens, G. (2003). Multiple Episode Protocol Analysis (MEPA). Version 4.9. Retrieved October 24, 2005, from
       http://edugate.fss.uu.nl/mepa/
Erkens, G., Janssen, J., Jaspers, J., & Kanselaar, G. (2006). Visualizing participation to facilitate argumentation.
       Paper to be presented during the symposium "Argumentative Knowledge Construction in CSCL" at the 7th
       International Conference of the Learning Sciences.
Erkens, G., Jaspers, J., Prangsma, M., & Kanselaar, G. (2005). Coordination processes in computer supported
       collaborative writing. Computers in Human Behavior, 21(3), 463-486.
Hmelo-Silver, C. E. (2003). Analyzing collaborative knowledge construction: Multiple methods for integrated
       understanding. Computers and Education, 41, 397-420.
Hmelo-Silver, C. E., & Chernobilsky, E. (2004). Understanding collaborative activity systems: The relation of tools
       and discourse in mediating learning. In Y. Kafai, W. Sandoval, N. Enyedy, A. Nixon & F. Herrera (Eds.),
       Proceedings of ICLS 2004 (pp. 254-261). Mahwah NJ: Erlbaum.
Hmelo-Silver, C. E., Chernobilsky, E., & Nagarajan, A. (2005). Two sides of the coin: Multiple perspectives on
       collaborative knowledge construction in online problem-based learning. Paper presented at the European
       Association for Research on Learning and Instruction, Nicosia, Cyprus.
Janssen, J., Erkens, G., Kanselaar, G., & Jaspers, J. (in press). Visualization of participation: Does it contribute to
       successful computer-supported collaborative learning? Computers & Education.
Leaper, C., & Smith, T. E. (2004). A meta-analytic review of gender variations in children's language use:
       Talkativeness, affiliative speech, and assertive speech. Developmental Psychology, 40(6), 993-
       1027.Luckin, R., Plowman, L., Laurillard, D., Stratfold, M., Taylor, J., & Corben, S. (2001). Narrative
       evolution: Learning from students' talk about species variation. International Journal of Artificial
       Intelligence in Education, 12, 100-123.
Luckin, R., Plowman, L., Laurillard, D., Stratfold, M., Taylor, J., & Corben, S. (2001). Narrative evolution:
       Learning from students' talk about species variation. International Journal of Artificial Intelligence in
       Education, 12, 100-123.
Resnick, L. B., Salmon, M., Zeitz, C. M., Wathen, S. H., & Holowchak, M. (1993). Reasoning in conversation.
       Cognition and Instruction, 11, 347-364.
Roschelle, J. (1996). Learning by collaborating: Convergent conceptual change. In T. D. Koschmann (Ed.), CSCL:
       Theory and practice of an emerging paradigm (pp. 209-248). Mahwah NJ: Erlbaum.
Rourke, L., & Anderson, T. (2004). Validity in quantitative content analysis. Educational Technology Research and
       Development, 52(1), 5-18.
Rummel, N. & Spada, H. (2004). Cracking the nut--but which nutcracker to use? Diversity in approaches to
       analyzing collaborative processes in technology-supported settings. In Y. B. Kafai, W. A. Sandoval, N.
       Enyedy, A. S. Nixon & F. Herrera (Eds.), Proceedings of the  Sixth International Conference of the
       Learning Sciences (pp. 23). Mahwah NJ: Erlbaum.
Schiffrin, D. (1987). Discourse markers. Cambridge, MA: Cambridge University Press.
Strijbos, J.-W., Martens, R. L., Prins, F. J., & Jochems, W. M. G. (in press). Content analysis: What are they talking
       about? Computers and Education.
Toulmin, S. E. (1958). The uses of argument. Cambridge, England: Cambridge University Press.
Webb, N. M., & Farivar, S. (1999). Developing productive group interaction in middle-school mathematics. In A.
       M. O'Donnell & A. King (Eds.), Cognitive perspectives on peer learning (pp. 117-150). Mahwah NJ:
       Erlbaum.

                                                        1065                                                ICLS 2006
